{
    "67ead201e1cb0e7dc019002d7a2e4be53184261d": [
        [
            "AMQ5266SingleDestTest::startBroker()",
            " 101  \n 102  \n 103  \n 104  \n 105 -\n 106 -\n 107 -\n 108 -\n 109 -\n 110 -\n 111 -\n 112 -\n 113 -\n 114 -\n 115 -\n 116 -\n 117 -\n 118 -\n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136 -\n 137  \n 138  \n 139  \n 140  \n 141  ",
            "    @Before\n    public void startBroker() throws Exception {\n        brokerService = new BrokerService();\n\n        dataSource = new EmbeddedDataSource();\n        dataSource.setDatabaseName(\"target/derbyDb\");\n        dataSource.setCreateDatabase(\"create\");\n\n        JDBCPersistenceAdapter jdbcPersistenceAdapter = new JDBCPersistenceAdapter();\n        jdbcPersistenceAdapter.setDataSource(dataSource);\n        jdbcPersistenceAdapter.setUseLock(false);\n\n        if (!useDefaultStore) {\n            brokerService.setPersistenceAdapter(jdbcPersistenceAdapter);\n        } else {\n            KahaDBPersistenceAdapter kahaDBPersistenceAdapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n            kahaDBPersistenceAdapter.setConcurrentStoreAndDispatchQueues(true);\n        }\n        brokerService.setDeleteAllMessagesOnStartup(true);\n        brokerService.setUseJmx(false);\n\n\n        PolicyMap policyMap = new PolicyMap();\n        PolicyEntry defaultEntry = new PolicyEntry();\n        defaultEntry.setUseConsumerPriority(false); // java.lang.IllegalArgumentException: Comparison method violates its general contract!\n        defaultEntry.setMaxProducersToAudit(publisherThreadCount);\n        defaultEntry.setEnableAudit(true);\n        defaultEntry.setUseCache(useCache);\n        defaultEntry.setMaxPageSize(1000);\n        defaultEntry.setOptimizedDispatch(optimizeDispatch);\n        defaultEntry.setMemoryLimit(destMemoryLimit);\n        defaultEntry.setExpireMessagesPeriod(0);\n        policyMap.setDefaultEntry(defaultEntry);\n        brokerService.setDestinationPolicy(policyMap);\n\n        brokerService.getSystemUsage().getMemoryUsage().setLimit(512 * 1024 * 1024);\n\n        TransportConnector transportConnector = brokerService.addConnector(\"tcp://0.0.0.0:0\");\n        brokerService.start();\n        activemqURL = transportConnector.getPublishableConnectString();\n    }",
            "  98  \n  99  \n 100  \n 101  \n 102 +\n 103  \n 104  \n 105 +\n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121 +\n 122  \n 123  \n 124  \n 125  \n 126 +\n 127  ",
            "    @Before\n    public void startBroker() throws Exception {\n        brokerService = new BrokerService();\n\n        TestSupport.setPersistenceAdapter(brokerService, persistenceAdapterChoice);\n        brokerService.setDeleteAllMessagesOnStartup(true);\n        brokerService.setUseJmx(false);\n        brokerService.setAdvisorySupport(false);\n\n\n        PolicyMap policyMap = new PolicyMap();\n        PolicyEntry defaultEntry = new PolicyEntry();\n        defaultEntry.setUseConsumerPriority(false); // java.lang.IllegalArgumentException: Comparison method violates its general contract!\n        defaultEntry.setMaxProducersToAudit(publisherThreadCount);\n        defaultEntry.setEnableAudit(true);\n        defaultEntry.setUseCache(useCache);\n        defaultEntry.setMaxPageSize(1000);\n        defaultEntry.setOptimizedDispatch(optimizeDispatch);\n        defaultEntry.setMemoryLimit(destMemoryLimit);\n        defaultEntry.setExpireMessagesPeriod(0);\n        policyMap.setDefaultEntry(defaultEntry);\n        brokerService.setDestinationPolicy(policyMap);\n\n        brokerService.getSystemUsage().getMemoryUsage().setLimit(64 * 1024 * 1024);\n\n        TransportConnector transportConnector = brokerService.addConnector(\"tcp://0.0.0.0:0\");\n        brokerService.start();\n        activemqURL = transportConnector.getPublishableConnectString();\n        activemqURL += \"?jms.watchTopicAdvisories=false\"; // ensure all messages are queue or dlq messages\n    }"
        ],
        [
            "AMQ5266SingleDestTest::test()",
            " 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205 -\n 206 -\n 207 -\n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220 -\n 221 -\n 222 -\n 223 -\n 224 -\n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  ",
            "    @Test\n    public void test() throws Exception {\n\n        String activemqQueues = \"activemq\";\n        for (int i=1;i<numDests;i++) {\n            activemqQueues +=\",activemq\"+i;\n        }\n\n        int consumerWaitForConsumption = 5 * 60 * 1000;\n\n        ExportQueuePublisher publisher = null;\n        ExportQueueConsumer consumer = null;\n\n        LOG.info(\"Publisher will publish \" + (publisherMessagesPerThread * publisherThreadCount) + \" messages to each queue specified.\");\n        LOG.info(\"\\nBuilding Publisher...\");\n\n        publisher = new ExportQueuePublisher(activemqURL, activemqQueues, publisherMessagesPerThread, publisherThreadCount);\n\n        LOG.info(\"Building Consumer...\");\n\n        consumer = new ExportQueueConsumer(activemqURL, activemqQueues, consumerThreadsPerQueue, consumerBatchSize, publisherMessagesPerThread * publisherThreadCount);\n\n        long totalStart = System.currentTimeMillis();\n\n        LOG.info(\"Starting Publisher...\");\n\n        publisher.start();\n\n        LOG.info(\"Starting Consumer...\");\n\n        consumer.start();\n\n        int distinctPublishedCount = 0;\n\n\n        LOG.info(\"Waiting For Publisher Completion...\");\n\n        publisher.waitForCompletion();\n\n        List publishedIds = publisher.getIDs();\n        distinctPublishedCount = new TreeSet(publishedIds).size();\n\n        LOG.info(\"Publisher Complete. Published: \" + publishedIds.size() + \", Distinct IDs Published: \" + distinctPublishedCount);\n        LOG.info(\"Publisher duration: {}\", TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - totalStart));\n\n\n        long endWait = System.currentTimeMillis() + consumerWaitForConsumption;\n        while (!consumer.completed() && System.currentTimeMillis() < endWait) {\n            try {\n                int secs = (int) (endWait - System.currentTimeMillis()) / 1000;\n                LOG.info(\"Waiting For Consumer Completion. Time left: \" + secs + \" secs\");\n                if (!useDefaultStore) {\n                    DefaultJDBCAdapter.dumpTables(dataSource.getConnection());\n                }\n                Thread.sleep(1000);\n            } catch (Exception e) {\n            }\n        }\n\n        LOG.info(\"\\nConsumer Complete: \" + consumer.completed() +\", Shutting Down.\");\n\n        LOG.info(\"Total duration: {}\", TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - totalStart));\n\n        consumer.shutdown();\n\n        TimeUnit.SECONDS.sleep(2);\n        LOG.info(\"DB Contents START\");\n        if (!useDefaultStore) {\n            DefaultJDBCAdapter.dumpTables(dataSource.getConnection());\n        }\n        LOG.info(\"DB Contents END\");\n\n        LOG.info(\"Consumer Stats:\");\n\n        for (Map.Entry<String, List<String>> entry : consumer.getIDs().entrySet()) {\n\n            List<String> idList = entry.getValue();\n\n            int distinctConsumed = new TreeSet<String>(idList).size();\n\n            StringBuilder sb = new StringBuilder();\n            sb.append(\"   Queue: \" + entry.getKey() +\n                    \" -> Total Messages Consumed: \" + idList.size() +\n                    \", Distinct IDs Consumed: \" + distinctConsumed);\n\n            int diff = distinctPublishedCount - distinctConsumed;\n            sb.append(\" ( \" + (diff > 0 ? diff : \"NO\") + \" STUCK MESSAGES \" + \" ) \");\n            LOG.info(sb.toString());\n\n            assertEquals(\"expect to get all messages!\", 0, diff);\n\n        }\n    }",
            " 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220 +\n 221 +\n 222 +\n 223  ",
            "    @Test\n    public void test() throws Exception {\n\n        String activemqQueues = \"activemq\";\n        for (int i=1;i<numDests;i++) {\n            activemqQueues +=\",activemq\"+i;\n        }\n\n        int consumerWaitForConsumption = 5 * 60 * 1000;\n\n        ExportQueuePublisher publisher = null;\n        ExportQueueConsumer consumer = null;\n\n        LOG.info(\"Publisher will publish \" + (publisherMessagesPerThread * publisherThreadCount) + \" messages to each queue specified.\");\n        LOG.info(\"\\nBuilding Publisher...\");\n\n        publisher = new ExportQueuePublisher(activemqURL, activemqQueues, publisherMessagesPerThread, publisherThreadCount);\n\n        LOG.info(\"Building Consumer...\");\n\n        consumer = new ExportQueueConsumer(activemqURL, activemqQueues, consumerThreadsPerQueue, consumerBatchSize, publisherMessagesPerThread * publisherThreadCount);\n\n        long totalStart = System.currentTimeMillis();\n\n        LOG.info(\"Starting Publisher...\");\n\n        publisher.start();\n\n        LOG.info(\"Starting Consumer...\");\n\n        consumer.start();\n\n        int distinctPublishedCount = 0;\n\n\n        LOG.info(\"Waiting For Publisher Completion...\");\n\n        publisher.waitForCompletion();\n\n        List publishedIds = publisher.getIDs();\n        distinctPublishedCount = new TreeSet(publishedIds).size();\n\n        LOG.info(\"Publisher Complete. Published: \" + publishedIds.size() + \", Distinct IDs Published: \" + distinctPublishedCount);\n        LOG.info(\"Publisher duration: {}\", TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - totalStart));\n\n\n        long endWait = System.currentTimeMillis() + consumerWaitForConsumption;\n        while (!consumer.completed() && System.currentTimeMillis() < endWait) {\n            try {\n                int secs = (int) (endWait - System.currentTimeMillis()) / 1000;\n                LOG.info(\"Waiting For Consumer Completion. Time left: \" + secs + \" secs\");\n                Thread.sleep(1000);\n            } catch (Exception e) {\n            }\n        }\n\n        LOG.info(\"\\nConsumer Complete: \" + consumer.completed() +\", Shutting Down.\");\n\n        LOG.info(\"Total duration: {}\", TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - totalStart));\n\n        consumer.shutdown();\n\n        TimeUnit.SECONDS.sleep(2);\n\n        LOG.info(\"Consumer Stats:\");\n\n        for (Map.Entry<String, List<String>> entry : consumer.getIDs().entrySet()) {\n\n            List<String> idList = entry.getValue();\n\n            int distinctConsumed = new TreeSet<String>(idList).size();\n\n            StringBuilder sb = new StringBuilder();\n            sb.append(\"   Queue: \" + entry.getKey() +\n                    \" -> Total Messages Consumed: \" + idList.size() +\n                    \", Distinct IDs Consumed: \" + distinctConsumed);\n\n            int diff = distinctPublishedCount - distinctConsumed;\n            sb.append(\" ( \" + (diff > 0 ? diff : \"NO\") + \" STUCK MESSAGES \" + \" ) \");\n            LOG.info(sb.toString());\n\n            assertEquals(\"expect to get all messages!\", 0, diff);\n\n        }\n\n        // verify empty dlq\n        assertEquals(\"No pending messages\", 0l, ((RegionBroker) brokerService.getRegionBroker()).getDestinationStatistics().getMessages().getCount());\n    }"
        ],
        [
            "AMQ5266SingleDestTest::parameters()",
            "  92  \n  93  \n  94  \n  95 -\n  96  \n  97  ",
            "    @Parameterized.Parameters(name=\"#{0},producerThreads:{1},consumerThreads:{2},mL:{3},useCache:{4},useDefaultStore:{5},optimizedDispatch:{6}\")\n    public static Iterable<Object[]> parameters() {\n        return Arrays.asList(new Object[][]{\n                {1000,  80,  80,   1024*1024*5,  true, true, false},\n        });\n    }",
            "  89  \n  90  \n  91  \n  92 +\n  93  \n  94  ",
            "    @Parameterized.Parameters(name=\"#{0},producerThreads:{1},consumerThreads:{2},mL:{3},useCache:{4},useDefaultStore:{5},optimizedDispatch:{6}\")\n    public static Iterable<Object[]> parameters() {\n        return Arrays.asList(new Object[][]{\n                {1000,  80,  80,   1024*1024*1,  true, TestSupport.PersistenceAdapterChoice.KahaDB, false},\n        });\n    }"
        ],
        [
            "Queue::getMessage(String)",
            "1192  \n1193  \n1194  \n1195  \n1196  \n1197  \n1198  \n1199  \n1200  \n1201  \n1202  \n1203 -\n1204  \n1205  \n1206  \n1207  \n1208  \n1209  \n1210  \n1211  \n1212  \n1213  \n1214  \n1215  \n1216  \n1217  \n1218  \n1219  \n1220 -\n1221  \n1222  \n1223  ",
            "    public QueueMessageReference getMessage(String id) {\n        MessageId msgId = new MessageId(id);\n        pagedInMessagesLock.readLock().lock();\n        try {\n            QueueMessageReference ref = (QueueMessageReference)this.pagedInMessages.get(msgId);\n            if (ref != null) {\n                return ref;\n            }\n        } finally {\n            pagedInMessagesLock.readLock().unlock();\n        }\n        messagesLock.readLock().lock();\n        try{\n            try {\n                messages.reset();\n                while (messages.hasNext()) {\n                    MessageReference mr = messages.next();\n                    QueueMessageReference qmr = createMessageReference(mr.getMessage());\n                    qmr.decrementReferenceCount();\n                    messages.rollback(qmr.getMessageId());\n                    if (msgId.equals(qmr.getMessageId())) {\n                        return qmr;\n                    }\n                }\n            } finally {\n                messages.release();\n            }\n        }finally {\n            messagesLock.readLock().unlock();\n        }\n        return null;\n    }",
            "1192  \n1193  \n1194  \n1195  \n1196  \n1197  \n1198  \n1199  \n1200  \n1201  \n1202  \n1203 +\n1204  \n1205  \n1206  \n1207  \n1208  \n1209  \n1210  \n1211  \n1212  \n1213  \n1214  \n1215  \n1216  \n1217  \n1218  \n1219  \n1220 +\n1221  \n1222  \n1223  ",
            "    public QueueMessageReference getMessage(String id) {\n        MessageId msgId = new MessageId(id);\n        pagedInMessagesLock.readLock().lock();\n        try {\n            QueueMessageReference ref = (QueueMessageReference)this.pagedInMessages.get(msgId);\n            if (ref != null) {\n                return ref;\n            }\n        } finally {\n            pagedInMessagesLock.readLock().unlock();\n        }\n        messagesLock.writeLock().lock();\n        try{\n            try {\n                messages.reset();\n                while (messages.hasNext()) {\n                    MessageReference mr = messages.next();\n                    QueueMessageReference qmr = createMessageReference(mr.getMessage());\n                    qmr.decrementReferenceCount();\n                    messages.rollback(qmr.getMessageId());\n                    if (msgId.equals(qmr.getMessageId())) {\n                        return qmr;\n                    }\n                }\n            } finally {\n                messages.release();\n            }\n        }finally {\n            messagesLock.writeLock().unlock();\n        }\n        return null;\n    }"
        ],
        [
            "MessageDatabase::MessageOrderIndex::setBatch(Transaction,Long)",
            "2889  \n2890  \n2891  \n2892  \n2893  \n2894  \n2895 -\n2896 -\n2897 -\n2898 -\n2899 -\n2900 -\n2901 -\n2902 -\n2903  \n2904 -\n2905  \n2906  \n2907  \n2908  \n2909  ",
            "        void setBatch(Transaction tx, Long sequence) throws IOException {\n            if (sequence != null) {\n                Long nextPosition = new Long(sequence.longValue() + 1);\n                if (defaultPriorityIndex.containsKey(tx, sequence)) {\n                    lastDefaultKey = sequence;\n                    cursor.defaultCursorPosition = nextPosition.longValue();\n                } else if (highPriorityIndex != null) {\n                    if (highPriorityIndex.containsKey(tx, sequence)) {\n                        lastHighKey = sequence;\n                        cursor.highPriorityCursorPosition = nextPosition.longValue();\n                    } else if (lowPriorityIndex.containsKey(tx, sequence)) {\n                        lastLowKey = sequence;\n                        cursor.lowPriorityCursorPosition = nextPosition.longValue();\n                    }\n                } else {\n                    LOG.warn(\"setBatch: sequence \" + sequence + \" not found in orderindex:\" + this);\n                    lastDefaultKey = sequence;\n                    cursor.defaultCursorPosition = nextPosition.longValue();\n                }\n            }\n        }",
            "2889  \n2890  \n2891  \n2892  \n2893  \n2894  \n2895 +\n2896 +\n2897 +\n2898 +\n2899 +\n2900 +\n2901  \n2902  \n2903  \n2904  \n2905  \n2906  ",
            "        void setBatch(Transaction tx, Long sequence) throws IOException {\n            if (sequence != null) {\n                Long nextPosition = new Long(sequence.longValue() + 1);\n                if (defaultPriorityIndex.containsKey(tx, sequence)) {\n                    lastDefaultKey = sequence;\n                    cursor.defaultCursorPosition = nextPosition.longValue();\n                } else if (highPriorityIndex != null && highPriorityIndex.containsKey(tx, sequence)) {\n                    lastHighKey = sequence;\n                    cursor.highPriorityCursorPosition = nextPosition.longValue();\n                } else if (lowPriorityIndex.containsKey(tx, sequence)) {\n                    lastLowKey = sequence;\n                    cursor.lowPriorityCursorPosition = nextPosition.longValue();\n                } else {\n                    lastDefaultKey = sequence;\n                    cursor.defaultCursorPosition = nextPosition.longValue();\n                }\n            }\n        }"
        ],
        [
            "TestSupport::setPersistenceAdapter(BrokerService,PersistenceAdapterChoice)",
            " 182 -\n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  ",
            "    public PersistenceAdapter setPersistenceAdapter(BrokerService broker, PersistenceAdapterChoice choice) throws IOException {\n        PersistenceAdapter adapter = null;\n        switch (choice) {\n        case JDBC:\n            adapter = new JDBCPersistenceAdapter();\n            break;\n        case KahaDB:\n            adapter = new KahaDBPersistenceAdapter();\n            break;\n        case LevelDB:\n            adapter = new LevelDBPersistenceAdapter();\n            break;\n        case MEM:\n            adapter = new MemoryPersistenceAdapter();\n            break;\n        }\n        broker.setPersistenceAdapter(adapter);\n        return adapter;\n    }",
            " 182 +\n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  ",
            "    public static PersistenceAdapter setPersistenceAdapter(BrokerService broker, PersistenceAdapterChoice choice) throws IOException {\n        PersistenceAdapter adapter = null;\n        switch (choice) {\n        case JDBC:\n            adapter = new JDBCPersistenceAdapter();\n            break;\n        case KahaDB:\n            adapter = new KahaDBPersistenceAdapter();\n            break;\n        case LevelDB:\n            adapter = new LevelDBPersistenceAdapter();\n            break;\n        case MEM:\n            adapter = new MemoryPersistenceAdapter();\n            break;\n        }\n        broker.setPersistenceAdapter(adapter);\n        return adapter;\n    }"
        ],
        [
            "AMQ5266SingleDestTest::stopBroker()",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148 -\n 149 -\n 150 -\n 151 -\n 152  ",
            "    @After\n    public void stopBroker() throws Exception {\n        if (brokerService != null) {\n            brokerService.stop();\n        }\n        try {\n            dataSource.setShutdownDatabase(\"shutdown\");\n            dataSource.getConnection();\n        } catch (Exception ignored) {}\n    }",
            " 129  \n 130  \n 131  \n 132  \n 133  \n 134  ",
            "    @After\n    public void stopBroker() throws Exception {\n        if (brokerService != null) {\n            brokerService.stop();\n        }\n    }"
        ]
    ],
    "65cef691306dbd8cee37aa05b2621ebce264a07c": [
        [
            "AMQ3120Test::configurePersistence(BrokerService,boolean)",
            "  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  ",
            "    protected void configurePersistence(BrokerService brokerService, boolean deleteAllOnStart) throws Exception {\n        KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n\n        // ensure there are a bunch of data files but multiple entries in each\n        adapter.setJournalMaxFileLength(1024 * 20);\n\n        // speed up the test case, checkpoint an cleanup early and often\n        adapter.setCheckpointInterval(500);\n        adapter.setCleanupInterval(500);\n\n        if (!deleteAllOnStart) {\n            adapter.setForceRecoverIndex(true);\n        }\n\n    }",
            "  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82 +\n  83  \n  84  \n  85  \n  86  \n  87  \n  88  ",
            "    protected void configurePersistence(BrokerService brokerService, boolean deleteAllOnStart) throws Exception {\n        KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n\n        // ensure there are a bunch of data files but multiple entries in each\n        adapter.setJournalMaxFileLength(1024 * 20);\n\n        // speed up the test case, checkpoint an cleanup early and often\n        adapter.setCheckpointInterval(500);\n        adapter.setCleanupInterval(500);\n        adapter.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL.name());\n\n        if (!deleteAllOnStart) {\n            adapter.setForceRecoverIndex(true);\n        }\n\n    }"
        ],
        [
            "AMQ2832Test::configurePersistence(BrokerService,boolean)",
            " 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  ",
            "    protected void configurePersistence(BrokerService brokerService, boolean recover) throws Exception {\n        KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n\n        // ensure there are a bunch of data files but multiple entries in each\n        adapter.setJournalMaxFileLength(1024 * 20);\n\n        // speed up the test case, checkpoint an cleanup early and often\n        adapter.setCheckpointInterval(5000);\n        adapter.setCleanupInterval(5000);\n\n        if (recover) {\n            adapter.setForceRecoverIndex(true);\n        }\n    }",
            " 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110 +\n 111  \n 112  \n 113  \n 114  \n 115  ",
            "    protected void configurePersistence(BrokerService brokerService, boolean recover) throws Exception {\n        KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n\n        // ensure there are a bunch of data files but multiple entries in each\n        adapter.setJournalMaxFileLength(1024 * 20);\n\n        // speed up the test case, checkpoint an cleanup early and often\n        adapter.setCheckpointInterval(5000);\n        adapter.setCleanupInterval(5000);\n        adapter.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL.name());\n\n        if (recover) {\n            adapter.setForceRecoverIndex(true);\n        }\n    }"
        ],
        [
            "AMQ3120Test::testCleanupOfFiles()",
            " 112  \n 113  \n 114  \n 115  \n 116  \n 117 -\n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  ",
            "    @Test\n    public void testCleanupOfFiles() throws Exception {\n        final int messageCount = 500;\n        startBroker(true);\n        int fileCount = getFileCount(kahaDbDir);\n        assertEquals(5, fileCount);\n\n        Connection connection = new ActiveMQConnectionFactory(\n                broker.getTransportConnectors().get(0).getConnectUri()).createConnection();\n        connection.start();\n        Session producerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n        Session consumerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n\n        ProducerThread producer = new ProducerThread(producerSess, destination) {\n            @Override\n            protected Message createMessage(int i) throws Exception {\n                return session.createTextMessage(payload + \"::\" + i);\n            }\n        };\n        producer.setSleep(650);\n        producer.setMessageCount(messageCount);\n        ConsumerThread consumer = new ConsumerThread(consumerSess, destination);\n        consumer.setBreakOnNull(false);\n        consumer.setMessageCount(messageCount);\n\n        producer.start();\n        consumer.start();\n\n        producer.join();\n        consumer.join();\n\n        assertEquals(\"consumer got all produced messages\", producer.getMessageCount(), consumer.getReceived());\n\n        broker.stop();\n        broker.waitUntilStopped();\n\n    }",
            " 114  \n 115  \n 116  \n 117  \n 118  \n 119 +\n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  ",
            "    @Test\n    public void testCleanupOfFiles() throws Exception {\n        final int messageCount = 500;\n        startBroker(true);\n        int fileCount = getFileCount(kahaDbDir);\n        assertEquals(4, fileCount);\n\n        Connection connection = new ActiveMQConnectionFactory(\n                broker.getTransportConnectors().get(0).getConnectUri()).createConnection();\n        connection.start();\n        Session producerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n        Session consumerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n\n        ProducerThread producer = new ProducerThread(producerSess, destination) {\n            @Override\n            protected Message createMessage(int i) throws Exception {\n                return session.createTextMessage(payload + \"::\" + i);\n            }\n        };\n        producer.setSleep(650);\n        producer.setMessageCount(messageCount);\n        ConsumerThread consumer = new ConsumerThread(consumerSess, destination);\n        consumer.setBreakOnNull(false);\n        consumer.setMessageCount(messageCount);\n\n        producer.start();\n        consumer.start();\n\n        producer.join();\n        consumer.join();\n\n        assertEquals(\"consumer got all produced messages\", producer.getMessageCount(), consumer.getReceived());\n\n        broker.stop();\n        broker.waitUntilStopped();\n\n    }"
        ],
        [
            "AMQ4323Test::configurePersistence(BrokerService,boolean)",
            "  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  ",
            "    protected void configurePersistence(BrokerService brokerService, boolean deleteAllOnStart) throws Exception {\n        KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n\n        // ensure there are a bunch of data files but multiple entries in each\n        adapter.setJournalMaxFileLength(1024 * 20);\n\n        // speed up the test case, checkpoint an cleanup early and often\n        adapter.setCheckpointInterval(500);\n        adapter.setCleanupInterval(500);\n\n        if (!deleteAllOnStart) {\n            adapter.setForceRecoverIndex(true);\n        }\n\n    }",
            "  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85 +\n  86  \n  87  \n  88  \n  89  \n  90  \n  91  ",
            "    protected void configurePersistence(BrokerService brokerService, boolean deleteAllOnStart) throws Exception {\n        KahaDBPersistenceAdapter adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();\n\n        // ensure there are a bunch of data files but multiple entries in each\n        adapter.setJournalMaxFileLength(1024 * 20);\n\n        // speed up the test case, checkpoint an cleanup early and often\n        adapter.setCheckpointInterval(500);\n        adapter.setCleanupInterval(500);\n        adapter.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL.name());\n\n        if (!deleteAllOnStart) {\n            adapter.setForceRecoverIndex(true);\n        }\n\n    }"
        ],
        [
            "KahaDBIndexLocationTest::createBroker()",
            "  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  ",
            "    private void createBroker() throws Exception {\n        broker = new BrokerService();\n\n        KahaDBPersistenceAdapter persistenceAdapter = new KahaDBPersistenceAdapter();\n        persistenceAdapter.setDirectory(kahaDataDir);\n        persistenceAdapter.setIndexDirectory(kahaIndexDir);\n\n        broker.setDataDirectoryFile(testDataDir);\n        broker.setUseJmx(false);\n        broker.setAdvisorySupport(false);\n        broker.setSchedulerSupport(false);\n        broker.setDeleteAllMessagesOnStartup(true);\n        broker.setPersistenceAdapter(persistenceAdapter);\n    }",
            "  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98 +\n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  ",
            "    private void createBroker() throws Exception {\n        broker = new BrokerService();\n\n        KahaDBPersistenceAdapter persistenceAdapter = new KahaDBPersistenceAdapter();\n        persistenceAdapter.setDirectory(kahaDataDir);\n        persistenceAdapter.setIndexDirectory(kahaIndexDir);\n        persistenceAdapter.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL.name());\n\n        broker.setDataDirectoryFile(testDataDir);\n        broker.setUseJmx(false);\n        broker.setAdvisorySupport(false);\n        broker.setSchedulerSupport(false);\n        broker.setDeleteAllMessagesOnStartup(true);\n        broker.setPersistenceAdapter(persistenceAdapter);\n    }"
        ],
        [
            "Journal::start()",
            " 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286 -\n 287 -\n 288 -\n 289 -\n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  ",
            "    public synchronized void start() throws IOException {\n        if (started) {\n            return;\n        }\n\n        long start = System.currentTimeMillis();\n        accessorPool = new DataFileAccessorPool(this);\n        started = true;\n\n        appender = callerBufferAppender ? new CallerBufferingDataFileAppender(this) : new DataFileAppender(this);\n\n        File[] files = directory.listFiles(new FilenameFilter() {\n            @Override\n            public boolean accept(File dir, String n) {\n                return dir.equals(directory) && n.startsWith(filePrefix) && n.endsWith(fileSuffix);\n            }\n        });\n\n        if (files != null) {\n            for (File file : files) {\n                try {\n                    String n = file.getName();\n                    String numStr = n.substring(filePrefix.length(), n.length()-fileSuffix.length());\n                    int num = Integer.parseInt(numStr);\n                    DataFile dataFile = new DataFile(file, num);\n                    fileMap.put(dataFile.getDataFileId(), dataFile);\n                    totalLength.addAndGet(dataFile.getLength());\n                } catch (NumberFormatException e) {\n                    // Ignore file that do not match the pattern.\n                }\n            }\n\n            // Sort the list so that we can link the DataFiles together in the\n            // right order.\n            LinkedList<DataFile> l = new LinkedList<>(fileMap.values());\n            Collections.sort(l);\n            for (DataFile df : l) {\n                if (df.getLength() == 0) {\n                    // possibly the result of a previous failed write\n                    LOG.info(\"ignoring zero length, partially initialised journal data file: \" + df);\n                    continue;\n                } else if (l.getLast().equals(df) && isUnusedPreallocated(df)) {\n                    continue;\n                }\n                dataFiles.addLast(df);\n                fileByFileMap.put(df.getFile(), df);\n\n                if( isCheckForCorruptionOnStartup() ) {\n                    lastAppendLocation.set(recoveryCheck(df));\n                }\n            }\n        }\n\n        if (preallocationScope != PreallocationScope.NONE && preallocationStrategy == PreallocationStrategy.OS_KERNEL_COPY) {\n            // create a template file that will be used to pre-allocate the journal files\n            if (osKernelCopyTemplateFile == null) {\n                osKernelCopyTemplateFile = createJournalTemplateFile();\n            }\n        }\n\n        scheduler = Executors.newScheduledThreadPool(1, new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                Thread schedulerThread = new Thread(r);\n                schedulerThread.setName(\"ActiveMQ Journal Scheduled executor\");\n                schedulerThread.setDaemon(true);\n                return schedulerThread;\n            }\n        });\n\n        // init current write file\n        if (dataFiles.isEmpty()) {\n            nextDataFileId = 1;\n            rotateWriteFile();\n        } else {\n            currentDataFile.set(dataFiles.getTail());\n            nextDataFileId = currentDataFile.get().dataFileId + 1;\n        }\n\n        if (preallocationStrategy != PreallocationStrategy.SPARSE_FILE && maxFileLength != DEFAULT_MAX_FILE_LENGTH) {\n            LOG.warn(\"You are using a preallocation strategy and journal maxFileLength which should be benchmarked accordingly to not introduce unexpected latencies.\");\n        }\n\n        if( lastAppendLocation.get()==null ) {\n            DataFile df = dataFiles.getTail();\n            lastAppendLocation.set(recoveryCheck(df));\n        }\n\n        // ensure we don't report unused space of last journal file in size metric\n        if (totalLength.get() > maxFileLength && lastAppendLocation.get().getOffset() > 0) {\n            totalLength.addAndGet(lastAppendLocation.get().getOffset() - maxFileLength);\n        }\n\n        cleanupTask = scheduler.scheduleAtFixedRate(new Runnable() {\n            @Override\n            public void run() {\n                cleanup();\n            }\n        }, DEFAULT_CLEANUP_INTERVAL, DEFAULT_CLEANUP_INTERVAL, TimeUnit.MILLISECONDS);\n\n        long end = System.currentTimeMillis();\n        LOG.trace(\"Startup took: \"+(end-start)+\" ms\");\n    }",
            " 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  ",
            "    public synchronized void start() throws IOException {\n        if (started) {\n            return;\n        }\n\n        long start = System.currentTimeMillis();\n        accessorPool = new DataFileAccessorPool(this);\n        started = true;\n\n        appender = callerBufferAppender ? new CallerBufferingDataFileAppender(this) : new DataFileAppender(this);\n\n        File[] files = directory.listFiles(new FilenameFilter() {\n            @Override\n            public boolean accept(File dir, String n) {\n                return dir.equals(directory) && n.startsWith(filePrefix) && n.endsWith(fileSuffix);\n            }\n        });\n\n        if (files != null) {\n            for (File file : files) {\n                try {\n                    String n = file.getName();\n                    String numStr = n.substring(filePrefix.length(), n.length()-fileSuffix.length());\n                    int num = Integer.parseInt(numStr);\n                    DataFile dataFile = new DataFile(file, num);\n                    fileMap.put(dataFile.getDataFileId(), dataFile);\n                    totalLength.addAndGet(dataFile.getLength());\n                } catch (NumberFormatException e) {\n                    // Ignore file that do not match the pattern.\n                }\n            }\n\n            // Sort the list so that we can link the DataFiles together in the\n            // right order.\n            LinkedList<DataFile> l = new LinkedList<>(fileMap.values());\n            Collections.sort(l);\n            for (DataFile df : l) {\n                if (df.getLength() == 0) {\n                    // possibly the result of a previous failed write\n                    LOG.info(\"ignoring zero length, partially initialised journal data file: \" + df);\n                    continue;\n                } else if (l.getLast().equals(df) && isUnusedPreallocated(df)) {\n                    continue;\n                }\n                dataFiles.addLast(df);\n                fileByFileMap.put(df.getFile(), df);\n\n                if( isCheckForCorruptionOnStartup() ) {\n                    lastAppendLocation.set(recoveryCheck(df));\n                }\n            }\n        }\n\n        if (preallocationScope != PreallocationScope.NONE && preallocationStrategy == PreallocationStrategy.OS_KERNEL_COPY) {\n            // create a template file that will be used to pre-allocate the journal files\n            if (osKernelCopyTemplateFile == null) {\n                osKernelCopyTemplateFile = createJournalTemplateFile();\n            }\n        }\n\n        scheduler = Executors.newScheduledThreadPool(1, new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                Thread schedulerThread = new Thread(r);\n                schedulerThread.setName(\"ActiveMQ Journal Scheduled executor\");\n                schedulerThread.setDaemon(true);\n                return schedulerThread;\n            }\n        });\n\n        // init current write file\n        if (dataFiles.isEmpty()) {\n            nextDataFileId = 1;\n            rotateWriteFile();\n        } else {\n            currentDataFile.set(dataFiles.getTail());\n            nextDataFileId = currentDataFile.get().dataFileId + 1;\n        }\n\n        if( lastAppendLocation.get()==null ) {\n            DataFile df = dataFiles.getTail();\n            lastAppendLocation.set(recoveryCheck(df));\n        }\n\n        // ensure we don't report unused space of last journal file in size metric\n        if (totalLength.get() > maxFileLength && lastAppendLocation.get().getOffset() > 0) {\n            totalLength.addAndGet(lastAppendLocation.get().getOffset() - maxFileLength);\n        }\n\n        cleanupTask = scheduler.scheduleAtFixedRate(new Runnable() {\n            @Override\n            public void run() {\n                cleanup();\n            }\n        }, DEFAULT_CLEANUP_INTERVAL, DEFAULT_CLEANUP_INTERVAL, TimeUnit.MILLISECONDS);\n\n        long end = System.currentTimeMillis();\n        LOG.trace(\"Startup took: \"+(end-start)+\" ms\");\n    }"
        ],
        [
            "SubscriptionRecoveryTest::createBroker(boolean,boolean)",
            "  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  ",
            "    public void createBroker(boolean deleteAllMessages, boolean recover) throws Exception {\n        service = new BrokerService();\n        service.setBrokerName(\"InactiveSubTest\");\n        service.setDeleteAllMessagesOnStartup(deleteAllMessages);\n        service.setPersistent(true);\n\n        KahaDBPersistenceAdapter pa=new KahaDBPersistenceAdapter();\n        File dataFile=new File(\"KahaDB\");\n        pa.setDirectory(dataFile);\n        pa.setJournalMaxFileLength(10*1024);\n        pa.setCheckpointInterval(TimeUnit.SECONDS.toMillis(5));\n        pa.setCleanupInterval(TimeUnit.SECONDS.toMillis(5));\n        //Delete the index files on recovery\n        if (recover) {\n            for (File index : FileUtils.listFiles(dataFile, new WildcardFileFilter(\"*.data\"), TrueFileFilter.INSTANCE)) {\n                LOG.info(\"deleting: \" + index);\n                FileUtils.deleteQuietly(index);\n            }\n        }\n\n        service.setPersistenceAdapter(pa);\n        service.start();\n        service.waitUntilStarted();\n\n        connectionUri = \"vm://InactiveSubTest?create=false\";\n        cf = new ActiveMQConnectionFactory(connectionUri);\n    }",
            "  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79 +\n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  ",
            "    public void createBroker(boolean deleteAllMessages, boolean recover) throws Exception {\n        service = new BrokerService();\n        service.setBrokerName(\"InactiveSubTest\");\n        service.setDeleteAllMessagesOnStartup(deleteAllMessages);\n        service.setPersistent(true);\n\n        KahaDBPersistenceAdapter pa=new KahaDBPersistenceAdapter();\n        File dataFile=new File(\"KahaDB\");\n        pa.setDirectory(dataFile);\n        pa.setJournalMaxFileLength(10*1024);\n        pa.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL.name());\n        pa.setCheckpointInterval(TimeUnit.SECONDS.toMillis(5));\n        pa.setCleanupInterval(TimeUnit.SECONDS.toMillis(5));\n        //Delete the index files on recovery\n        if (recover) {\n            for (File index : FileUtils.listFiles(dataFile, new WildcardFileFilter(\"*.data\"), TrueFileFilter.INSTANCE)) {\n                LOG.info(\"deleting: \" + index);\n                FileUtils.deleteQuietly(index);\n            }\n        }\n\n        service.setPersistenceAdapter(pa);\n        service.start();\n        service.waitUntilStarted();\n\n        connectionUri = \"vm://InactiveSubTest?create=false\";\n        cf = new ActiveMQConnectionFactory(connectionUri);\n    }"
        ],
        [
            "KahaDBIndexLocationTest::testIndexDirExists()",
            " 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138 -\n 139  ",
            "    @Test\n    public void testIndexDirExists() throws Exception {\n        LOG.info(\"Index dir is configured as: {}\", kahaIndexDir);\n        assertTrue(kahaDataDir.exists());\n        assertTrue(kahaIndexDir.exists());\n\n        String[] index = kahaIndexDir.list(new FilenameFilter() {\n\n            @Override\n            public boolean accept(File dir, String name) {\n                LOG.info(\"Testing filename: {}\", name);\n                return name.endsWith(\"data\") || name.endsWith(\"redo\");\n            }\n        });\n\n        String[] journal = kahaDataDir.list(new FilenameFilter() {\n\n            @Override\n            public boolean accept(File dir, String name) {\n                LOG.info(\"Testing filename: {}\", name);\n                return name.endsWith(\"log\") || name.equals(\"lock\");\n            }\n        });\n\n        produceMessages();\n\n        // Should be db.data and db.redo and nothing else.\n        assertNotNull(index);\n        assertEquals(2, index.length);\n\n        // Should contain the initial log for the journal and the lock.\n        assertNotNull(journal);\n        assertEquals(3, journal.length);\n    }",
            " 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140 +\n 141  ",
            "    @Test\n    public void testIndexDirExists() throws Exception {\n        LOG.info(\"Index dir is configured as: {}\", kahaIndexDir);\n        assertTrue(kahaDataDir.exists());\n        assertTrue(kahaIndexDir.exists());\n\n        String[] index = kahaIndexDir.list(new FilenameFilter() {\n\n            @Override\n            public boolean accept(File dir, String name) {\n                LOG.info(\"Testing filename: {}\", name);\n                return name.endsWith(\"data\") || name.endsWith(\"redo\");\n            }\n        });\n\n        String[] journal = kahaDataDir.list(new FilenameFilter() {\n\n            @Override\n            public boolean accept(File dir, String name) {\n                LOG.info(\"Testing filename: {}\", name);\n                return name.endsWith(\"log\") || name.equals(\"lock\");\n            }\n        });\n\n        produceMessages();\n\n        // Should be db.data and db.redo and nothing else.\n        assertNotNull(index);\n        assertEquals(2, index.length);\n\n        // Should contain the initial log for the journal and the lock.\n        assertNotNull(journal);\n        assertEquals(2, journal.length);\n    }"
        ],
        [
            "AMQ4323Test::testCleanupOfFiles()",
            " 114  \n 115  \n 116  \n 117  \n 118  \n 119 -\n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152 -\n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  ",
            "    @Test\n    public void testCleanupOfFiles() throws Exception {\n        final int messageCount = 500;\n        startBroker(true);\n        int fileCount = getFileCount(kahaDbDir);\n        assertEquals(5, fileCount);\n\n        Connection connection = new ActiveMQConnectionFactory(\n                broker.getTransportConnectors().get(0).getConnectUri()).createConnection();\n        connection.start();\n        Session producerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n        Session consumerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n\n        ProducerThread producer = new ProducerThread(producerSess, destination) {\n            @Override\n            protected Message createMessage(int i) throws Exception {\n                return session.createTextMessage(payload + \"::\" + i);\n            }\n        };\n        producer.setMessageCount(messageCount);\n        ConsumerThread consumer = new ConsumerThread(consumerSess, destination);\n        consumer.setBreakOnNull(false);\n        consumer.setMessageCount(messageCount);\n\n        producer.start();\n        producer.join();\n\n        consumer.start();\n        consumer.join();\n\n        assertEquals(\"consumer got all produced messages\", producer.getMessageCount(), consumer.getReceived());\n\n        // verify cleanup\n        assertTrue(\"gc worked\", Wait.waitFor(new Wait.Condition() {\n            @Override\n            public boolean isSatisified() throws Exception {\n                int fileCount = getFileCount(kahaDbDir);\n                LOG.info(\"current filecount:\" + fileCount);\n                return 5 == fileCount;\n            }\n        }));\n\n        broker.stop();\n        broker.waitUntilStopped();\n\n    }",
            " 116  \n 117  \n 118  \n 119  \n 120  \n 121 +\n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154 +\n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  ",
            "    @Test\n    public void testCleanupOfFiles() throws Exception {\n        final int messageCount = 500;\n        startBroker(true);\n        int fileCount = getFileCount(kahaDbDir);\n        assertEquals(4, fileCount);\n\n        Connection connection = new ActiveMQConnectionFactory(\n                broker.getTransportConnectors().get(0).getConnectUri()).createConnection();\n        connection.start();\n        Session producerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n        Session consumerSess = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\n\n        ProducerThread producer = new ProducerThread(producerSess, destination) {\n            @Override\n            protected Message createMessage(int i) throws Exception {\n                return session.createTextMessage(payload + \"::\" + i);\n            }\n        };\n        producer.setMessageCount(messageCount);\n        ConsumerThread consumer = new ConsumerThread(consumerSess, destination);\n        consumer.setBreakOnNull(false);\n        consumer.setMessageCount(messageCount);\n\n        producer.start();\n        producer.join();\n\n        consumer.start();\n        consumer.join();\n\n        assertEquals(\"consumer got all produced messages\", producer.getMessageCount(), consumer.getReceived());\n\n        // verify cleanup\n        assertTrue(\"gc worked\", Wait.waitFor(new Wait.Condition() {\n            @Override\n            public boolean isSatisified() throws Exception {\n                int fileCount = getFileCount(kahaDbDir);\n                LOG.info(\"current filecount:\" + fileCount);\n                return 4 == fileCount;\n            }\n        }));\n\n        broker.stop();\n        broker.waitUntilStopped();\n\n    }"
        ],
        [
            "AMQ2832Test::testAlternateLossScenario()",
            " 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291 -\n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  ",
            "    @Test\n    public void testAlternateLossScenario() throws Exception {\n\n        startBroker();\n        PersistenceAdapter pa  = broker.getPersistenceAdapter();\n        if (pa instanceof LevelDBStore) {\n            return;\n        }\n\n        ActiveMQQueue queue = new ActiveMQQueue(\"MyQueue\");\n        ActiveMQQueue disposable = new ActiveMQQueue(\"MyDisposableQueue\");\n        ActiveMQTopic topic = new ActiveMQTopic(\"MyDurableTopic\");\n\n        // This ensure that data file 1 never goes away.\n        createInactiveDurableSub(topic);\n        assertEquals(1, getNumberOfJournalFiles());\n\n        // One Queue Message that will be acked in another data file.\n        produceMessages(queue, 1);\n        assertEquals(1, getNumberOfJournalFiles());\n\n        // Add some messages to consume space\n        produceMessages(disposable, 50);\n\n        int dataFilesCount = getNumberOfJournalFiles();\n        assertTrue(dataFilesCount > 1);\n\n        // Create an ack for the single message on this queue\n        drainQueue(queue);\n\n        // Add some more messages to consume space beyond tha data file with the ack\n        produceMessages(disposable, 50);\n\n        assertTrue(dataFilesCount < getNumberOfJournalFiles());\n        dataFilesCount = getNumberOfJournalFiles();\n\n        restartBroker();\n\n        // Clear out all queue data\n        broker.getAdminView().removeQueue(disposable.getQueueName());\n\n        // Once this becomes true our ack could be lost.\n        assertTrue(\"Less than three journal file expected, was \" + getNumberOfJournalFiles(), Wait.waitFor(new Wait.Condition() {\n            @Override\n            public boolean isSatisified() throws Exception {\n                return getNumberOfJournalFiles() <= 4;\n            }\n        }, TimeUnit.MINUTES.toMillis(3)));\n\n        // Recover and the Message should not be replayed but if the old MessageAck is lost\n        // then it could be.\n        recoverBroker();\n\n        assertTrue(drainQueue(queue) == 0);\n    }",
            " 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292 +\n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  ",
            "    @Test\n    public void testAlternateLossScenario() throws Exception {\n\n        startBroker();\n        PersistenceAdapter pa  = broker.getPersistenceAdapter();\n        if (pa instanceof LevelDBStore) {\n            return;\n        }\n\n        ActiveMQQueue queue = new ActiveMQQueue(\"MyQueue\");\n        ActiveMQQueue disposable = new ActiveMQQueue(\"MyDisposableQueue\");\n        ActiveMQTopic topic = new ActiveMQTopic(\"MyDurableTopic\");\n\n        // This ensure that data file 1 never goes away.\n        createInactiveDurableSub(topic);\n        assertEquals(1, getNumberOfJournalFiles());\n\n        // One Queue Message that will be acked in another data file.\n        produceMessages(queue, 1);\n        assertEquals(1, getNumberOfJournalFiles());\n\n        // Add some messages to consume space\n        produceMessages(disposable, 50);\n\n        int dataFilesCount = getNumberOfJournalFiles();\n        assertTrue(dataFilesCount > 1);\n\n        // Create an ack for the single message on this queue\n        drainQueue(queue);\n\n        // Add some more messages to consume space beyond tha data file with the ack\n        produceMessages(disposable, 50);\n\n        assertTrue(dataFilesCount < getNumberOfJournalFiles());\n        dataFilesCount = getNumberOfJournalFiles();\n\n        restartBroker();\n\n        // Clear out all queue data\n        broker.getAdminView().removeQueue(disposable.getQueueName());\n\n        // Once this becomes true our ack could be lost.\n        assertTrue(\"Less than three journal file expected, was \" + getNumberOfJournalFiles(), Wait.waitFor(new Wait.Condition() {\n            @Override\n            public boolean isSatisified() throws Exception {\n                return getNumberOfJournalFiles() <= 3;\n            }\n        }, TimeUnit.MINUTES.toMillis(3)));\n\n        // Recover and the Message should not be replayed but if the old MessageAck is lost\n        // then it could be.\n        recoverBroker();\n\n        assertTrue(drainQueue(queue) == 0);\n    }"
        ]
    ]
}