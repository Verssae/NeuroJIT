{
    "22a8204138fdb73115d9501b34a8867a2c4608c6": [
        [
            "MetricRegistry::MetricRegistry(MetricRegistryConfiguration)",
            "  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  ",
            "\t/**\n\t * Creates a new MetricRegistry and starts the configured reporter.\n\t */\n\tpublic MetricRegistry(MetricRegistryConfiguration config) {\n\t\tthis.scopeFormats = config.getScopeFormats();\n\t\tthis.globalDelimiter = config.getDelimiter();\n\n\t\t// second, instantiate any custom configured reporters\n\t\tthis.reporters = new ArrayList<>();\n\n\t\tList<Tuple2<String, Configuration>> reporterConfigurations = config.getReporterConfigurations();\n\n\t\tthis.executor = Executors.newSingleThreadScheduledExecutor(new MetricRegistryThreadFactory());\n\n\t\tif (reporterConfigurations.isEmpty()) {\n\t\t\t// no reporters defined\n\t\t\t// by default, don't report anything\n\t\t\tLOG.info(\"No metrics reporter configured, no metrics will be exposed/reported.\");\n\t\t} else {\n\t\t\t// we have some reporters so\n\t\t\tfor (Tuple2<String, Configuration> reporterConfiguration: reporterConfigurations) {\n\t\t\t\tString namedReporter = reporterConfiguration.f0;\n\t\t\t\tConfiguration reporterConfig = reporterConfiguration.f1;\n\n\t\t\t\tfinal String className = reporterConfig.getString(ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, null);\n\t\t\t\tif (className == null) {\n\t\t\t\t\tLOG.error(\"No reporter class set for reporter \" + namedReporter + \". Metrics might not be exposed/reported.\");\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tString configuredPeriod = reporterConfig.getString(ConfigConstants.METRICS_REPORTER_INTERVAL_SUFFIX, null);\n\t\t\t\t\tTimeUnit timeunit = TimeUnit.SECONDS;\n\t\t\t\t\tlong period = 10;\n\n\t\t\t\t\tif (configuredPeriod != null) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tString[] interval = configuredPeriod.split(\" \");\n\t\t\t\t\t\t\tperiod = Long.parseLong(interval[0]);\n\t\t\t\t\t\t\ttimeunit = TimeUnit.valueOf(interval[1]);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\t\tLOG.error(\"Cannot parse report interval from config: \" + configuredPeriod +\n\t\t\t\t\t\t\t\t\t\" - please use values like '10 SECONDS' or '500 MILLISECONDS'. \" +\n\t\t\t\t\t\t\t\t\t\"Using default reporting interval.\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tClass<?> reporterClass = Class.forName(className);\n\t\t\t\t\tMetricReporter reporterInstance = (MetricReporter) reporterClass.newInstance();\n\n\t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n\t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n\t\t\t\t\treporterInstance.open(metricConfig);\n\n\t\t\t\t\tif (reporterInstance instanceof Scheduled) {\n\t\t\t\t\t\tLOG.info(\"Periodically reporting metrics in intervals of {} {} for reporter {} of type {}.\", period, timeunit.name(), namedReporter, className);\n\n\t\t\t\t\t\texecutor.scheduleWithFixedDelay(\n\t\t\t\t\t\t\t\tnew MetricRegistry.ReporterTask((Scheduled) reporterInstance), period, period, timeunit);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLOG.info(\"Reporting metrics for reporter {} of type {}.\", namedReporter, className);\n\t\t\t\t\t}\n\t\t\t\t\treporters.add(reporterInstance);\n\n\t\t\t\t\tString delimiterForReporter = reporterConfig.getString(ConfigConstants.METRICS_REPORTER_SCOPE_DELIMITER, String.valueOf(globalDelimiter));\n\t\t\t\t\tif (delimiterForReporter.length() != 1) {\n\t\t\t\t\t\tLOG.warn(\"Failed to parse delimiter '{}' for reporter '{}', using global delimiter '{}'.\", delimiterForReporter, namedReporter, globalDelimiter);\n\t\t\t\t\t\tdelimiterForReporter = String.valueOf(globalDelimiter);\n\t\t\t\t\t}\n\t\t\t\t\tthis.delimiters.add(delimiterForReporter.charAt(0));\n\t\t\t\t}\n\t\t\t\tcatch (Throwable t) {\n\t\t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", namedReporter, t);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
            "  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119 +\n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  ",
            "\t/**\n\t * Creates a new MetricRegistry and starts the configured reporter.\n\t */\n\tpublic MetricRegistry(MetricRegistryConfiguration config) {\n\t\tthis.scopeFormats = config.getScopeFormats();\n\t\tthis.globalDelimiter = config.getDelimiter();\n\n\t\t// second, instantiate any custom configured reporters\n\t\tthis.reporters = new ArrayList<>();\n\n\t\tList<Tuple2<String, Configuration>> reporterConfigurations = config.getReporterConfigurations();\n\n\t\tthis.executor = Executors.newSingleThreadScheduledExecutor(new MetricRegistryThreadFactory());\n\n\t\tif (reporterConfigurations.isEmpty()) {\n\t\t\t// no reporters defined\n\t\t\t// by default, don't report anything\n\t\t\tLOG.info(\"No metrics reporter configured, no metrics will be exposed/reported.\");\n\t\t} else {\n\t\t\t// we have some reporters so\n\t\t\tfor (Tuple2<String, Configuration> reporterConfiguration: reporterConfigurations) {\n\t\t\t\tString namedReporter = reporterConfiguration.f0;\n\t\t\t\tConfiguration reporterConfig = reporterConfiguration.f1;\n\n\t\t\t\tfinal String className = reporterConfig.getString(ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, null);\n\t\t\t\tif (className == null) {\n\t\t\t\t\tLOG.error(\"No reporter class set for reporter \" + namedReporter + \". Metrics might not be exposed/reported.\");\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tString configuredPeriod = reporterConfig.getString(ConfigConstants.METRICS_REPORTER_INTERVAL_SUFFIX, null);\n\t\t\t\t\tTimeUnit timeunit = TimeUnit.SECONDS;\n\t\t\t\t\tlong period = 10;\n\n\t\t\t\t\tif (configuredPeriod != null) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tString[] interval = configuredPeriod.split(\" \");\n\t\t\t\t\t\t\tperiod = Long.parseLong(interval[0]);\n\t\t\t\t\t\t\ttimeunit = TimeUnit.valueOf(interval[1]);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\t\tLOG.error(\"Cannot parse report interval from config: \" + configuredPeriod +\n\t\t\t\t\t\t\t\t\t\" - please use values like '10 SECONDS' or '500 MILLISECONDS'. \" +\n\t\t\t\t\t\t\t\t\t\"Using default reporting interval.\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tClass<?> reporterClass = Class.forName(className);\n\t\t\t\t\tMetricReporter reporterInstance = (MetricReporter) reporterClass.newInstance();\n\n\t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n\t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n\t\t\t\t\tLOG.info(\"Configuring {} with {}.\", reporterClass.getSimpleName(), metricConfig);\n\t\t\t\t\treporterInstance.open(metricConfig);\n\n\t\t\t\t\tif (reporterInstance instanceof Scheduled) {\n\t\t\t\t\t\tLOG.info(\"Periodically reporting metrics in intervals of {} {} for reporter {} of type {}.\", period, timeunit.name(), namedReporter, className);\n\n\t\t\t\t\t\texecutor.scheduleWithFixedDelay(\n\t\t\t\t\t\t\t\tnew MetricRegistry.ReporterTask((Scheduled) reporterInstance), period, period, timeunit);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tLOG.info(\"Reporting metrics for reporter {} of type {}.\", namedReporter, className);\n\t\t\t\t\t}\n\t\t\t\t\treporters.add(reporterInstance);\n\n\t\t\t\t\tString delimiterForReporter = reporterConfig.getString(ConfigConstants.METRICS_REPORTER_SCOPE_DELIMITER, String.valueOf(globalDelimiter));\n\t\t\t\t\tif (delimiterForReporter.length() != 1) {\n\t\t\t\t\t\tLOG.warn(\"Failed to parse delimiter '{}' for reporter '{}', using global delimiter '{}'.\", delimiterForReporter, namedReporter, globalDelimiter);\n\t\t\t\t\t\tdelimiterForReporter = String.valueOf(globalDelimiter);\n\t\t\t\t\t}\n\t\t\t\t\tthis.delimiters.add(delimiterForReporter.charAt(0));\n\t\t\t\t}\n\t\t\t\tcatch (Throwable t) {\n\t\t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", namedReporter, t);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "JMXReporter::open(MetricConfig)",
            " 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  ",
            "\t@Override\n\tpublic void open(MetricConfig config) {\n\t\tString portsConfig = config.getString(ARG_PORT, null);\n\n\t\tif (portsConfig != null) {\n\t\t\tIterator<Integer> ports = NetUtils.getPortRangeFromString(portsConfig);\n\n\t\t\tJMXServer server = new JMXServer();\n\t\t\twhile (ports.hasNext()) {\n\t\t\t\tint port = ports.next();\n\t\t\t\ttry {\n\t\t\t\t\tserver.start(port);\n\t\t\t\t\tLOG.info(\"Started JMX server on port \" + port + \".\");\n\t\t\t\t\t// only set our field if the server was actually started\n\t\t\t\t\tjmxServer = server;\n\t\t\t\t\tbreak;\n\t\t\t\t} catch (IOException ioe) { //assume port conflict\n\t\t\t\t\tLOG.debug(\"Could not start JMX server on port \" + port + \".\", ioe);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tserver.stop();\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tLOG.debug(\"Could not stop JMX server.\", e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (jmxServer == null) {\n\t\t\t\tthrow new RuntimeException(\"Could not start JMX server on any configured port. Ports: \" + portsConfig);\n\t\t\t}\n\t\t}\n\t}",
            " 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130 +\n 131  ",
            "\t@Override\n\tpublic void open(MetricConfig config) {\n\t\tString portsConfig = config.getString(ARG_PORT, null);\n\n\t\tif (portsConfig != null) {\n\t\t\tIterator<Integer> ports = NetUtils.getPortRangeFromString(portsConfig);\n\n\t\t\tJMXServer server = new JMXServer();\n\t\t\twhile (ports.hasNext()) {\n\t\t\t\tint port = ports.next();\n\t\t\t\ttry {\n\t\t\t\t\tserver.start(port);\n\t\t\t\t\tLOG.info(\"Started JMX server on port \" + port + \".\");\n\t\t\t\t\t// only set our field if the server was actually started\n\t\t\t\t\tjmxServer = server;\n\t\t\t\t\tbreak;\n\t\t\t\t} catch (IOException ioe) { //assume port conflict\n\t\t\t\t\tLOG.debug(\"Could not start JMX server on port \" + port + \".\", ioe);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tserver.stop();\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tLOG.debug(\"Could not stop JMX server.\", e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (jmxServer == null) {\n\t\t\t\tthrow new RuntimeException(\"Could not start JMX server on any configured port. Ports: \" + portsConfig);\n\t\t\t}\n\t\t}\n\t\tLOG.info(\"Configured JMXReporter with {port:{}}\", portsConfig);\n\t}"
        ],
        [
            "StatsDReporter::open(MetricConfig)",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75 -\n  76 -\n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  ",
            "\t@Override\n\tpublic void open(MetricConfig config) {\n\t\tString host = config.getString(ARG_HOST, null);\n\t\tint port = config.getInteger(ARG_PORT, -1);\n\n\t\tif (host == null || host.length() == 0 || port < 1) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid host/port configuration. Host: \" + host + \" Port: \" + port);\n\t\t}\n\n\t\tthis.address = new InetSocketAddress(host, port);\n\n\t\tLOG.info(\"Starting StatsDReporter to send metric reports to \" + address);\n\n//\t\tString conversionRate = config.getString(ARG_CONVERSION_RATE, \"SECONDS\");\n//\t\tString conversionDuration = config.getString(ARG_CONVERSION_DURATION, \"MILLISECONDS\");\n//\t\tthis.rateFactor = TimeUnit.valueOf(conversionRate).toSeconds(1);\n//\t\tthis.durationFactor = 1.0 / TimeUnit.valueOf(conversionDuration).toNanos(1);\n\n\t\ttry {\n\t\t\tthis.socket = new DatagramSocket(0);\n\t\t} catch (SocketException e) {\n\t\t\tthrow new RuntimeException(\"Could not create datagram socket. \", e);\n\t\t}\n\t}",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85 +\n  86  ",
            "\t@Override\n\tpublic void open(MetricConfig config) {\n\t\tString host = config.getString(ARG_HOST, null);\n\t\tint port = config.getInteger(ARG_PORT, -1);\n\n\t\tif (host == null || host.length() == 0 || port < 1) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid host/port configuration. Host: \" + host + \" Port: \" + port);\n\t\t}\n\n\t\tthis.address = new InetSocketAddress(host, port);\n\n//\t\tString conversionRate = config.getString(ARG_CONVERSION_RATE, \"SECONDS\");\n//\t\tString conversionDuration = config.getString(ARG_CONVERSION_DURATION, \"MILLISECONDS\");\n//\t\tthis.rateFactor = TimeUnit.valueOf(conversionRate).toSeconds(1);\n//\t\tthis.durationFactor = 1.0 / TimeUnit.valueOf(conversionDuration).toNanos(1);\n\n\t\ttry {\n\t\t\tthis.socket = new DatagramSocket(0);\n\t\t} catch (SocketException e) {\n\t\t\tthrow new RuntimeException(\"Could not create datagram socket. \", e);\n\t\t}\n\t\tlog.info(\"Configured StatsDReporter with {host:{}, port:{}}\", host, port);\n\t}"
        ],
        [
            "GraphiteReporter::getReporter(MetricConfig)",
            "  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  ",
            "\t@Override\n\tpublic ScheduledReporter getReporter(MetricConfig config) {\n\t\tString host = config.getString(ARG_HOST, null);\n\t\tint port = config.getInteger(ARG_PORT, -1);\n\n\t\tif (host == null || host.length() == 0 || port < 1) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid host/port configuration. Host: \" + host + \" Port: \" + port);\n\t\t}\n\n\t\tString prefix = config.getString(ARG_PREFIX, null);\n\t\tString conversionRate = config.getString(ARG_CONVERSION_RATE, null);\n\t\tString conversionDuration = config.getString(ARG_CONVERSION_DURATION, null);\n\t\tString protocol = config.getString(ARG_PROTOCOL, \"TCP\");\n\n\t\tcom.codahale.metrics.graphite.GraphiteReporter.Builder builder =\n\t\t\tcom.codahale.metrics.graphite.GraphiteReporter.forRegistry(registry);\n\n\t\tif (prefix != null) {\n\t\t\tbuilder.prefixedWith(prefix);\n\t\t}\n\n\t\tif (conversionRate != null) {\n\t\t\tbuilder.convertRatesTo(TimeUnit.valueOf(conversionRate));\n\t\t}\n\n\t\tif (conversionDuration != null) {\n\t\t\tbuilder.convertDurationsTo(TimeUnit.valueOf(conversionDuration));\n\t\t}\n\n\t\tProtocol prot;\n\t\ttry {\n\t\t\tprot = Protocol.valueOf(protocol);\n\t\t} catch (IllegalArgumentException iae) {\n\t\t\tlog.warn(\"Invalid protocol configuration: \" + protocol + \" Expected: TCP or UDP, defaulting to TCP.\");\n\t\t\tprot = Protocol.TCP;\n\t\t}\n\n\t\tswitch(prot) {\n\t\t\tcase UDP:\n\t\t\t\treturn builder.build(new GraphiteUDP(host, port));\t\t\t\t\n\t\t\tcase TCP:\n\t\t\tdefault:\n\t\t\t\treturn builder.build(new Graphite(host, port));\n\t\t}\n\t}",
            "  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78 +\n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  ",
            "\t@Override\n\tpublic ScheduledReporter getReporter(MetricConfig config) {\n\t\tString host = config.getString(ARG_HOST, null);\n\t\tint port = config.getInteger(ARG_PORT, -1);\n\n\t\tif (host == null || host.length() == 0 || port < 1) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid host/port configuration. Host: \" + host + \" Port: \" + port);\n\t\t}\n\n\t\tString prefix = config.getString(ARG_PREFIX, null);\n\t\tString conversionRate = config.getString(ARG_CONVERSION_RATE, null);\n\t\tString conversionDuration = config.getString(ARG_CONVERSION_DURATION, null);\n\t\tString protocol = config.getString(ARG_PROTOCOL, \"TCP\");\n\n\t\tcom.codahale.metrics.graphite.GraphiteReporter.Builder builder =\n\t\t\tcom.codahale.metrics.graphite.GraphiteReporter.forRegistry(registry);\n\n\t\tif (prefix != null) {\n\t\t\tbuilder.prefixedWith(prefix);\n\t\t}\n\n\t\tif (conversionRate != null) {\n\t\t\tbuilder.convertRatesTo(TimeUnit.valueOf(conversionRate));\n\t\t}\n\n\t\tif (conversionDuration != null) {\n\t\t\tbuilder.convertDurationsTo(TimeUnit.valueOf(conversionDuration));\n\t\t}\n\n\t\tProtocol prot;\n\t\ttry {\n\t\t\tprot = Protocol.valueOf(protocol);\n\t\t} catch (IllegalArgumentException iae) {\n\t\t\tlog.warn(\"Invalid protocol configuration: \" + protocol + \" Expected: TCP or UDP, defaulting to TCP.\");\n\t\t\tprot = Protocol.TCP;\n\t\t}\n\n\t\tlog.info(\"Configured GraphiteReporter with {host:{}, port:{}, protocol:{}}\", host, port, prot);\n\t\tswitch(prot) {\n\t\t\tcase UDP:\n\t\t\t\treturn builder.build(new GraphiteUDP(host, port));\t\t\t\t\n\t\t\tcase TCP:\n\t\t\tdefault:\n\t\t\t\treturn builder.build(new Graphite(host, port));\n\t\t}\n\t}"
        ],
        [
            "GangliaReporter::getReporter(MetricConfig)",
            "  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  ",
            "\t@Override\n\tpublic ScheduledReporter getReporter(MetricConfig config) {\n\n\t\ttry {\n\t\t\tString host = config.getString(ARG_HOST, null);\n\t\t\tint port = config.getInteger(ARG_PORT, -1);\n\t\t\tif (host == null || host.length() == 0 || port < 1) {\n\t\t\t\tthrow new IllegalArgumentException(\"Invalid host/port configuration. Host: \" + host + \" Port: \" + port);\n\t\t\t}\n\t\t\tString addressingMode = config.getString(ARG_MODE_ADDRESSING, \"MULTICAST\");\n\t\t\tint ttl = config.getInteger(ARG_TTL, 1);\n\t\t\tGMetric gMetric = new GMetric(host, port, GMetric.UDPAddressingMode.valueOf(addressingMode), ttl);\n\n\t\t\tString prefix = config.getString(ARG_PREFIX, null);\n\t\t\tString conversionRate = config.getString(ARG_CONVERSION_RATE, null);\n\t\t\tString conversionDuration = config.getString(ARG_CONVERSION_DURATION, null);\n\t\t\tint dMax = config.getInteger(ARG_DMAX, 0);\n\t\t\tint tMax = config.getInteger(ARG_TMAX, 60);\n\n\t\t\tcom.codahale.metrics.ganglia.GangliaReporter.Builder builder =\n\t\t\t\tcom.codahale.metrics.ganglia.GangliaReporter.forRegistry(registry);\n\n\t\t\tif (prefix != null) {\n\t\t\t\tbuilder.prefixedWith(prefix);\n\t\t\t}\n\t\t\tif (conversionRate != null) {\n\t\t\t\tbuilder.convertRatesTo(TimeUnit.valueOf(conversionRate));\n\t\t\t}\n\t\t\tif (conversionDuration != null) {\n\t\t\t\tbuilder.convertDurationsTo(TimeUnit.valueOf(conversionDuration));\n\t\t\t}\n\t\t\tbuilder.withDMax(dMax);\n\t\t\tbuilder.withTMax(tMax);\n\n\t\t\treturn builder.build(gMetric);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(\"Error while instantiating GangliaReporter.\", e);\n\t\t}\n\t}",
            "  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74 +\n  75 +\n  76  \n  77  \n  78  \n  79  \n  80  ",
            "\t@Override\n\tpublic ScheduledReporter getReporter(MetricConfig config) {\n\n\t\ttry {\n\t\t\tString host = config.getString(ARG_HOST, null);\n\t\t\tint port = config.getInteger(ARG_PORT, -1);\n\t\t\tif (host == null || host.length() == 0 || port < 1) {\n\t\t\t\tthrow new IllegalArgumentException(\"Invalid host/port configuration. Host: \" + host + \" Port: \" + port);\n\t\t\t}\n\t\t\tString addressingMode = config.getString(ARG_MODE_ADDRESSING, \"MULTICAST\");\n\t\t\tint ttl = config.getInteger(ARG_TTL, 1);\n\t\t\tGMetric gMetric = new GMetric(host, port, GMetric.UDPAddressingMode.valueOf(addressingMode), ttl);\n\n\t\t\tString prefix = config.getString(ARG_PREFIX, null);\n\t\t\tString conversionRate = config.getString(ARG_CONVERSION_RATE, null);\n\t\t\tString conversionDuration = config.getString(ARG_CONVERSION_DURATION, null);\n\t\t\tint dMax = config.getInteger(ARG_DMAX, 0);\n\t\t\tint tMax = config.getInteger(ARG_TMAX, 60);\n\n\t\t\tcom.codahale.metrics.ganglia.GangliaReporter.Builder builder =\n\t\t\t\tcom.codahale.metrics.ganglia.GangliaReporter.forRegistry(registry);\n\n\t\t\tif (prefix != null) {\n\t\t\t\tbuilder.prefixedWith(prefix);\n\t\t\t}\n\t\t\tif (conversionRate != null) {\n\t\t\t\tbuilder.convertRatesTo(TimeUnit.valueOf(conversionRate));\n\t\t\t}\n\t\t\tif (conversionDuration != null) {\n\t\t\t\tbuilder.convertDurationsTo(TimeUnit.valueOf(conversionDuration));\n\t\t\t}\n\t\t\tbuilder.withDMax(dMax);\n\t\t\tbuilder.withTMax(tMax);\n\n\t\t\tlog.info(\"Configured GangliaReporter with {host:{}, port:{}, dmax:{}, tmax:{}, ttl:{}, addressingMode:{}}\",\n\t\t\t\thost, port, dMax, tMax, ttl, addressingMode);\t\t\t\n\t\t\treturn builder.build(gMetric);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(\"Error while instantiating GangliaReporter.\", e);\n\t\t}\n\t}"
        ]
    ],
    "6a86e9d62045386b76026f4deead8baa559f008e": [
        [
            "OperatorStateBackendTest::createNewOperatorStateBackend()",
            "  48 -\n  49 -\n  50  \n  51  \n  52  ",
            "\tprivate OperatorStateBackend createNewOperatorStateBackend() throws Exception {\n\t\treturn abstractStateBackend.createOperatorStateBackend(\n\t\t\t\tcreateMockEnvironment(),\n\t\t\t\t\"test-operator\");\n\t}",
            "  48 +\n  49 +\n  50 +\n  51  \n  52  \n  53  ",
            "\tprivate DefaultOperatorStateBackend createNewOperatorStateBackend() throws Exception {\n\t\t//TODO this is temporarily casted to test already functionality that we do not yet expose through public API\n\t\treturn (DefaultOperatorStateBackend) abstractStateBackend.createOperatorStateBackend(\n\t\t\t\tcreateMockEnvironment(),\n\t\t\t\t\"test-operator\");\n\t}"
        ],
        [
            "OperatorStateBackendTest::testSnapshotRestore()",
            " 144  \n 145  \n 146 -\n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174 -\n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  ",
            "\t@Test\n\tpublic void testSnapshotRestore() throws Exception {\n\t\tOperatorStateBackend operatorStateBackend = createNewOperatorStateBackend();\n\t\tListStateDescriptor<Serializable> stateDescriptor1 = new ListStateDescriptor<>(\"test1\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor2 = new ListStateDescriptor<>(\"test2\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor3 = new ListStateDescriptor<>(\"test3\", new JavaSerializer<>());\n\t\tListState<Serializable> listState1 = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\tListState<Serializable> listState2 = operatorStateBackend.getOperatorState(stateDescriptor2);\n\t\tListState<Serializable> listState3 = operatorStateBackend.getBroadcastOperatorState(stateDescriptor3);\n\n\t\tlistState1.add(42);\n\t\tlistState1.add(4711);\n\n\t\tlistState2.add(7);\n\t\tlistState2.add(13);\n\t\tlistState2.add(23);\n\n\t\tlistState3.add(17);\n\t\tlistState3.add(18);\n\t\tlistState3.add(19);\n\t\tlistState3.add(20);\n\n\t\tCheckpointStreamFactory streamFactory = abstractStateBackend.createStreamFactory(new JobID(), \"testOperator\");\n\t\tOperatorStateHandle stateHandle = operatorStateBackend.snapshot(1, 1, streamFactory).get();\n\n\t\ttry {\n\n\t\t\toperatorStateBackend.close();\n\t\t\toperatorStateBackend.dispose();\n\n\t\t\toperatorStateBackend = abstractStateBackend.createOperatorStateBackend(\n\t\t\t\t\tcreateMockEnvironment(),\n\t\t\t\t\t\"testOperator\");\n\n\t\t\toperatorStateBackend.restore(Collections.singletonList(stateHandle));\n\n\t\t\tassertEquals(3, operatorStateBackend.getRegisteredStateNames().size());\n\n\t\t\tlistState1 = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\t\tlistState2 = operatorStateBackend.getOperatorState(stateDescriptor2);\n\t\t\tlistState3 = operatorStateBackend.getBroadcastOperatorState(stateDescriptor3);\n\n\t\t\tassertEquals(3, operatorStateBackend.getRegisteredStateNames().size());\n\n\t\t\tIterator<Serializable> it = listState1.get().iterator();\n\t\t\tassertEquals(42, it.next());\n\t\t\tassertEquals(4711, it.next());\n\t\t\tassertTrue(!it.hasNext());\n\n\t\t\tit = listState2.get().iterator();\n\t\t\tassertEquals(7, it.next());\n\t\t\tassertEquals(13, it.next());\n\t\t\tassertEquals(23, it.next());\n\t\t\tassertTrue(!it.hasNext());\n\n\t\t\tit = listState3.get().iterator();\n\t\t\tassertEquals(17, it.next());\n\t\t\tassertEquals(18, it.next());\n\t\t\tassertEquals(19, it.next());\n\t\t\tassertEquals(20, it.next());\n\t\t\tassertTrue(!it.hasNext());\n\n\t\t\toperatorStateBackend.close();\n\t\t\toperatorStateBackend.dispose();\n\t\t} finally {\n\t\t\tstateHandle.discardState();\n\t\t}\n\t}",
            " 145  \n 146  \n 147 +\n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175 +\n 176 +\n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  ",
            "\t@Test\n\tpublic void testSnapshotRestore() throws Exception {\n\t\tDefaultOperatorStateBackend operatorStateBackend = createNewOperatorStateBackend();\n\t\tListStateDescriptor<Serializable> stateDescriptor1 = new ListStateDescriptor<>(\"test1\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor2 = new ListStateDescriptor<>(\"test2\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor3 = new ListStateDescriptor<>(\"test3\", new JavaSerializer<>());\n\t\tListState<Serializable> listState1 = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\tListState<Serializable> listState2 = operatorStateBackend.getOperatorState(stateDescriptor2);\n\t\tListState<Serializable> listState3 = operatorStateBackend.getBroadcastOperatorState(stateDescriptor3);\n\n\t\tlistState1.add(42);\n\t\tlistState1.add(4711);\n\n\t\tlistState2.add(7);\n\t\tlistState2.add(13);\n\t\tlistState2.add(23);\n\n\t\tlistState3.add(17);\n\t\tlistState3.add(18);\n\t\tlistState3.add(19);\n\t\tlistState3.add(20);\n\n\t\tCheckpointStreamFactory streamFactory = abstractStateBackend.createStreamFactory(new JobID(), \"testOperator\");\n\t\tOperatorStateHandle stateHandle = operatorStateBackend.snapshot(1, 1, streamFactory).get();\n\n\t\ttry {\n\n\t\t\toperatorStateBackend.close();\n\t\t\toperatorStateBackend.dispose();\n\n\t\t\t//TODO this is temporarily casted to test already functionality that we do not yet expose through public API\n\t\t\toperatorStateBackend = (DefaultOperatorStateBackend) abstractStateBackend.createOperatorStateBackend(\n\t\t\t\t\tcreateMockEnvironment(),\n\t\t\t\t\t\"testOperator\");\n\n\t\t\toperatorStateBackend.restore(Collections.singletonList(stateHandle));\n\n\t\t\tassertEquals(3, operatorStateBackend.getRegisteredStateNames().size());\n\n\t\t\tlistState1 = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\t\tlistState2 = operatorStateBackend.getOperatorState(stateDescriptor2);\n\t\t\tlistState3 = operatorStateBackend.getBroadcastOperatorState(stateDescriptor3);\n\n\t\t\tassertEquals(3, operatorStateBackend.getRegisteredStateNames().size());\n\n\t\t\tIterator<Serializable> it = listState1.get().iterator();\n\t\t\tassertEquals(42, it.next());\n\t\t\tassertEquals(4711, it.next());\n\t\t\tassertTrue(!it.hasNext());\n\n\t\t\tit = listState2.get().iterator();\n\t\t\tassertEquals(7, it.next());\n\t\t\tassertEquals(13, it.next());\n\t\t\tassertEquals(23, it.next());\n\t\t\tassertTrue(!it.hasNext());\n\n\t\t\tit = listState3.get().iterator();\n\t\t\tassertEquals(17, it.next());\n\t\t\tassertEquals(18, it.next());\n\t\t\tassertEquals(19, it.next());\n\t\t\tassertEquals(20, it.next());\n\t\t\tassertTrue(!it.hasNext());\n\n\t\t\toperatorStateBackend.close();\n\t\t\toperatorStateBackend.dispose();\n\t\t} finally {\n\t\t\tstateHandle.discardState();\n\t\t}\n\t}"
        ],
        [
            "OperatorStateBackendTest::testRegisterStates()",
            "  61  \n  62  \n  63 -\n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  ",
            "\t@Test\n\tpublic void testRegisterStates() throws Exception {\n\t\tOperatorStateBackend operatorStateBackend = createNewOperatorStateBackend();\n\t\tListStateDescriptor<Serializable> stateDescriptor1 = new ListStateDescriptor<>(\"test1\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor2 = new ListStateDescriptor<>(\"test2\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor3 = new ListStateDescriptor<>(\"test3\", new JavaSerializer<>());\n\t\tListState<Serializable> listState1 = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\tassertNotNull(listState1);\n\t\tassertEquals(1, operatorStateBackend.getRegisteredStateNames().size());\n\t\tIterator<Serializable> it = listState1.get().iterator();\n\t\tassertTrue(!it.hasNext());\n\t\tlistState1.add(42);\n\t\tlistState1.add(4711);\n\n\t\tit = listState1.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tListState<Serializable> listState2 = operatorStateBackend.getOperatorState(stateDescriptor2);\n\t\tassertNotNull(listState2);\n\t\tassertEquals(2, operatorStateBackend.getRegisteredStateNames().size());\n\t\tassertTrue(!it.hasNext());\n\t\tlistState2.add(7);\n\t\tlistState2.add(13);\n\t\tlistState2.add(23);\n\n\t\tit = listState2.get().iterator();\n\t\tassertEquals(7, it.next());\n\t\tassertEquals(13, it.next());\n\t\tassertEquals(23, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tListState<Serializable> listState3 = operatorStateBackend.getBroadcastOperatorState(stateDescriptor3);\n\t\tassertNotNull(listState3);\n\t\tassertEquals(3, operatorStateBackend.getRegisteredStateNames().size());\n\t\tassertTrue(!it.hasNext());\n\t\tlistState3.add(17);\n\t\tlistState3.add(3);\n\t\tlistState3.add(123);\n\n\t\tit = listState3.get().iterator();\n\t\tassertEquals(17, it.next());\n\t\tassertEquals(3, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tListState<Serializable> listState1b = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\tassertNotNull(listState1b);\n\t\tlistState1b.add(123);\n\t\tit = listState1b.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tit = listState1.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tit = listState1b.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\ttry {\n\t\t\toperatorStateBackend.getBroadcastOperatorState(stateDescriptor2);\n\t\t\tfail(\"Did not detect changed mode\");\n\t\t} catch (IllegalStateException ignored) {\n\n\t\t}\n\n\t\ttry {\n\t\t\toperatorStateBackend.getOperatorState(stateDescriptor3);\n\t\t\tfail(\"Did not detect changed mode\");\n\t\t} catch (IllegalStateException ignored) {\n\n\t\t}\n\t}",
            "  62  \n  63  \n  64 +\n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  ",
            "\t@Test\n\tpublic void testRegisterStates() throws Exception {\n\t\tDefaultOperatorStateBackend operatorStateBackend = createNewOperatorStateBackend();\n\t\tListStateDescriptor<Serializable> stateDescriptor1 = new ListStateDescriptor<>(\"test1\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor2 = new ListStateDescriptor<>(\"test2\", new JavaSerializer<>());\n\t\tListStateDescriptor<Serializable> stateDescriptor3 = new ListStateDescriptor<>(\"test3\", new JavaSerializer<>());\n\t\tListState<Serializable> listState1 = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\tassertNotNull(listState1);\n\t\tassertEquals(1, operatorStateBackend.getRegisteredStateNames().size());\n\t\tIterator<Serializable> it = listState1.get().iterator();\n\t\tassertTrue(!it.hasNext());\n\t\tlistState1.add(42);\n\t\tlistState1.add(4711);\n\n\t\tit = listState1.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tListState<Serializable> listState2 = operatorStateBackend.getOperatorState(stateDescriptor2);\n\t\tassertNotNull(listState2);\n\t\tassertEquals(2, operatorStateBackend.getRegisteredStateNames().size());\n\t\tassertTrue(!it.hasNext());\n\t\tlistState2.add(7);\n\t\tlistState2.add(13);\n\t\tlistState2.add(23);\n\n\t\tit = listState2.get().iterator();\n\t\tassertEquals(7, it.next());\n\t\tassertEquals(13, it.next());\n\t\tassertEquals(23, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tListState<Serializable> listState3 = operatorStateBackend.getBroadcastOperatorState(stateDescriptor3);\n\t\tassertNotNull(listState3);\n\t\tassertEquals(3, operatorStateBackend.getRegisteredStateNames().size());\n\t\tassertTrue(!it.hasNext());\n\t\tlistState3.add(17);\n\t\tlistState3.add(3);\n\t\tlistState3.add(123);\n\n\t\tit = listState3.get().iterator();\n\t\tassertEquals(17, it.next());\n\t\tassertEquals(3, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tListState<Serializable> listState1b = operatorStateBackend.getOperatorState(stateDescriptor1);\n\t\tassertNotNull(listState1b);\n\t\tlistState1b.add(123);\n\t\tit = listState1b.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tit = listState1.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\tit = listState1b.get().iterator();\n\t\tassertEquals(42, it.next());\n\t\tassertEquals(4711, it.next());\n\t\tassertEquals(123, it.next());\n\t\tassertTrue(!it.hasNext());\n\n\t\ttry {\n\t\t\toperatorStateBackend.getBroadcastOperatorState(stateDescriptor2);\n\t\t\tfail(\"Did not detect changed mode\");\n\t\t} catch (IllegalStateException ignored) {\n\n\t\t}\n\n\t\ttry {\n\t\t\toperatorStateBackend.getOperatorState(stateDescriptor3);\n\t\t\tfail(\"Did not detect changed mode\");\n\t\t} catch (IllegalStateException ignored) {\n\n\t\t}\n\t}"
        ],
        [
            "RescalingITCase::PartitionedStateSource::initializeState(FunctionInitializationContext)",
            " 968  \n 969  \n 970  \n 971  \n 972  \n 973 -\n 974  \n 975  \n 976  \n 977  \n 978  \n 979  \n 980  \n 981  \n 982  \n 983  \n 984  \n 985  ",
            "\t\t@Override\n\t\tpublic void initializeState(FunctionInitializationContext context) throws Exception {\n\n\t\t\tif (broadcast) {\n\t\t\t\tthis.counterPartitions =\n\t\t\t\t\t\tcontext.getOperatorStateStore().getBroadcastSerializableListState(\"counter_partitions\");\n\t\t\t} else {\n\t\t\t\tthis.counterPartitions =\n\t\t\t\t\t\tcontext.getOperatorStateStore().getSerializableListState(\"counter_partitions\");\n\t\t\t}\n\n\t\t\tif (context.isRestored()) {\n\t\t\t\tfor (int v : counterPartitions.get()) {\n\t\t\t\t\tcounter += v;\n\t\t\t\t}\n\t\t\t\tCHECK_CORRECT_RESTORE[getRuntimeContext().getIndexOfThisSubtask()] = counter;\n\t\t\t}\n\t\t}",
            " 969  \n 970  \n 971  \n 972  \n 973 +\n 974 +\n 975  \n 976 +\n 977  \n 978  \n 979  \n 980  \n 981  \n 982  \n 983  \n 984  \n 985  \n 986  \n 987  \n 988  ",
            "\t\t@Override\n\t\tpublic void initializeState(FunctionInitializationContext context) throws Exception {\n\n\t\t\tif (broadcast) {\n\t\t\t\t//TODO this is temporarily casted to test already functionality that we do not yet expose through public API\n\t\t\t\tDefaultOperatorStateBackend operatorStateStore = (DefaultOperatorStateBackend) context.getOperatorStateStore();\n\t\t\t\tthis.counterPartitions =\n\t\t\t\t\t\toperatorStateStore.getBroadcastSerializableListState(\"counter_partitions\");\n\t\t\t} else {\n\t\t\t\tthis.counterPartitions =\n\t\t\t\t\t\tcontext.getOperatorStateStore().getSerializableListState(\"counter_partitions\");\n\t\t\t}\n\n\t\t\tif (context.isRestored()) {\n\t\t\t\tfor (int v : counterPartitions.get()) {\n\t\t\t\t\tcounter += v;\n\t\t\t\t}\n\t\t\t\tCHECK_CORRECT_RESTORE[getRuntimeContext().getIndexOfThisSubtask()] = counter;\n\t\t\t}\n\t\t}"
        ]
    ],
    "6b5e1f68a9b78901f0af57f446b465a7b03a88bd": [
        [
            "ClientConnectionTest::testFailureBehavior(InetSocketAddress)",
            "  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118 -\n 119 -\n 120  \n 121  \n 122  \n 123  \n 124 -\n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  ",
            "\tprivate void testFailureBehavior(final InetSocketAddress unreachableEndpoint) {\n\n\t\tfinal Configuration config = new Configuration();\n\t\tconfig.setString(ConfigConstants.AKKA_ASK_TIMEOUT, (ASK_STARTUP_TIMEOUT/1000) + \" s\");\n\t\tconfig.setString(ConfigConstants.AKKA_LOOKUP_TIMEOUT, (CONNECT_TIMEOUT/1000) + \" s\");\n\t\tconfig.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, unreachableEndpoint.getHostName());\n\t\tconfig.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, unreachableEndpoint.getPort());\n\n\n\t\ttry {\n\t\t\tJobVertex vertex = new JobVertex(\"Test Vertex\");\n\t\t\tvertex.setInvokableClass(TestInvokable.class);\n\n\t\t\tfinal AtomicReference<Throwable> error = new AtomicReference<Throwable>();\n\n\t\t\tThread invoker = new Thread(\"test invoker\") {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tnew StandaloneClusterClient(config);\n\t\t\t\t\t\tfail(\"This should fail with an exception since the JobManager is unreachable.\");\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Throwable t) {\n\t\t\t\t\t\tsynchronized (error) {\n\t\t\t\t\t\t\terror.set(t);\n\t\t\t\t\t\t\terror.notifyAll();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tinvoker.setDaemon(true);\n\t\t\tinvoker.start();\n\n\t\t\ttry {\n\t\t\t\t// wait until the caller is successful, for at most the given time\n\t\t\t\tlong now = System.currentTimeMillis();\n\t\t\t\tlong deadline = now + MAX_DELAY;\n\n\t\t\t\tsynchronized (error) {\n\t\t\t\t\twhile (invoker.isAlive() && error.get() == null && now < deadline) {\n\t\t\t\t\t\terror.wait(1000);\n\t\t\t\t\t\tnow = System.currentTimeMillis();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tThrowable t = error.get();\n\t\t\t\tif (t == null) {\n\t\t\t\t\tfail(\"Job invocation did not fail in expected time interval.\");\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tassertNotNull(t.getMessage());\n\t\t\t\t\tassertTrue(t.getMessage(), t.getMessage().contains(\"JobManager\"));\n\t\t\t\t}\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tif (invoker.isAlive()) {\n\t\t\t\t\tinvoker.interrupt();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\tfail(e.getMessage());\n\t\t}\n\t}",
            "  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118 +\n 119 +\n 120  \n 121  \n 122  \n 123  \n 124 +\n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  ",
            "\tprivate void testFailureBehavior(final InetSocketAddress unreachableEndpoint) {\n\n\t\tfinal Configuration config = new Configuration();\n\t\tconfig.setString(ConfigConstants.AKKA_ASK_TIMEOUT, (ASK_STARTUP_TIMEOUT/1000) + \" s\");\n\t\tconfig.setString(ConfigConstants.AKKA_LOOKUP_TIMEOUT, (CONNECT_TIMEOUT/1000) + \" s\");\n\t\tconfig.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, unreachableEndpoint.getHostName());\n\t\tconfig.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, unreachableEndpoint.getPort());\n\n\n\t\ttry {\n\t\t\tJobVertex vertex = new JobVertex(\"Test Vertex\");\n\t\t\tvertex.setInvokableClass(TestInvokable.class);\n\n\t\t\tfinal AtomicReference<Throwable> error = new AtomicReference<Throwable>();\n\n\t\t\tThread invoker = new Thread(\"test invoker\") {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tnew StandaloneClusterClient(config);\n\t\t\t\t\t\tfail(\"This should fail with an exception since the JobManager is unreachable.\");\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Throwable t) {\n\t\t\t\t\t\tsynchronized (error) {\n\t\t\t\t\t\t\terror.set(t);\n\t\t\t\t\t\t\terror.notifyAll();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tinvoker.setDaemon(true);\n\t\t\tinvoker.start();\n\n\t\t\ttry {\n\t\t\t\t// wait until the caller is successful, for at most the given time\n\t\t\t\tlong now = System.nanoTime();\n\t\t\t\tlong deadline = now + MAX_DELAY * 1_000_000;\n\n\t\t\t\tsynchronized (error) {\n\t\t\t\t\twhile (invoker.isAlive() && error.get() == null && now < deadline) {\n\t\t\t\t\t\terror.wait(1000);\n\t\t\t\t\t\tnow = System.nanoTime();\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tThrowable t = error.get();\n\t\t\t\tif (t == null) {\n\t\t\t\t\tfail(\"Job invocation did not fail in expected time interval.\");\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tassertNotNull(t.getMessage());\n\t\t\t\t\tassertTrue(t.getMessage(), t.getMessage().contains(\"JobManager\"));\n\t\t\t\t}\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tif (invoker.isAlive()) {\n\t\t\t\t\tinvoker.interrupt();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\tfail(e.getMessage());\n\t\t}\n\t}"
        ]
    ],
    "30bb958a73e74ced94548897962740a59677dc12": [
        [
            "PythonSender::open(String)",
            "  47  \n  48  \n  49  ",
            "\tpublic void open(String path) throws IOException {\n\t\tsetupMappedFile(path);\n\t}",
            "  49  \n  50 +\n  51 +\n  52  \n  53  ",
            "\tpublic void open(String path) throws IOException {\n\t\tsaved = new ByteBuffer[2];\n\t\tserializer = new Serializer[2];\n\t\tsetupMappedFile(path);\n\t}"
        ],
        [
            "PythonStreamer::destroyProcess()",
            " 197  \n 198  \n 199  \n 200 -\n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207 -\n 208  \n 209  \n 210  \n 211 -\n 212  \n 213  \n 214  \n 215  \n 216  \n 217  ",
            "\tprivate void destroyProcess() throws IOException {\n\t\ttry {\n\t\t\tprocess.exitValue();\n\t\t} catch (IllegalThreadStateException ise) { //process still active\n\t\t\tif (process.getClass().getName().equals(\"java.lang.UNIXProcess\")) {\n\t\t\t\tint pid;\n\t\t\t\ttry {\n\t\t\t\t\tField f = process.getClass().getDeclaredField(\"pid\");\n\t\t\t\t\tf.setAccessible(true);\n\t\t\t\t\tpid = f.getInt(process);\n\t\t\t\t} catch (Throwable e) {\n\t\t\t\t\tprocess.destroy();\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tString[] args = new String[]{\"kill\", \"-9\", \"\" + pid};\n\t\t\t\tRuntime.getRuntime().exec(args);\n\t\t\t} else {\n\t\t\t\tprocess.destroy();\n\t\t\t}\n\t\t}\n\t}",
            " 195  \n 196  \n 197  \n 198 +\n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205 +\n 206  \n 207  \n 208  \n 209 +\n 210  \n 211  \n 212  \n 213  \n 214  \n 215  ",
            "\tprivate void destroyProcess() throws IOException {\n\t\ttry {\n\t\t\tprocess.exitValue();\n\t\t} catch (IllegalThreadStateException ignored) { //process still active\n\t\t\tif (process.getClass().getName().equals(\"java.lang.UNIXProcess\")) {\n\t\t\t\tint pid;\n\t\t\t\ttry {\n\t\t\t\t\tField f = process.getClass().getDeclaredField(\"pid\");\n\t\t\t\t\tf.setAccessible(true);\n\t\t\t\t\tpid = f.getInt(process);\n\t\t\t\t} catch (Throwable ignore) {\n\t\t\t\t\tprocess.destroy();\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tString[] args = new String[]{\"kill\", \"-9\", String.valueOf(pid)};\n\t\t\t\tRuntime.getRuntime().exec(args);\n\t\t\t} else {\n\t\t\t\tprocess.destroy();\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "PythonReceiver::open(String)",
            "  48  \n  49  \n  50 -\n  51  ",
            "\tpublic void open(String path) throws IOException {\n\t\tsetupMappedFile(path);\n\t\tdeserializer = readAsByteArray ? new ByteArrayDeserializer() : new TupleDeserializer();\n\t}",
            "  47  \n  48  \n  49 +\n  50  ",
            "\tpublic void open(String path) throws IOException {\n\t\tsetupMappedFile(path);\n\t\tdeserializer = (Deserializer<OUT>) (readAsByteArray ? new ByteArrayDeserializer() : new TupleDeserializer());\n\t}"
        ],
        [
            "PythonReceiver::closeMappedFile()",
            "  75  \n  76  \n  77  \n  78  ",
            "\tprivate void closeMappedFile() throws IOException {\n\t\tinputChannel.close();\n\t\tinputRAF.close();\n\t}",
            "  74  \n  75  \n  76  \n  77 +\n  78  ",
            "\tprivate void closeMappedFile() throws IOException {\n\t\tinputChannel.close();\n\t\tinputRAF.close();\n\t\tinputFile.delete();\n\t}"
        ],
        [
            "PythonPlanStreamer::close()",
            "  93  \n  94  \n  95  \n  96 -\n  97 -\n  98  \n  99  \n 100  ",
            "\tpublic void close() {\n\t\ttry {\n\t\t\tprocess.exitValue();\n\t\t} catch (NullPointerException npe) { //exception occurred before process was started\n\t\t} catch (IllegalThreadStateException ise) { //process still active\n\t\t\tprocess.destroy();\n\t\t}\n\t}",
            "  97  \n  98  \n  99  \n 100 +\n 101 +\n 102  \n 103 +\n 104 +\n 105 +\n 106 +\n 107 +\n 108 +\n 109  \n 110  ",
            "\tpublic void close() {\n\t\ttry {\n\t\t\tprocess.exitValue();\n\t\t} catch (NullPointerException ignored) { //exception occurred before process was started\n\t\t} catch (IllegalThreadStateException ignored) { //process still active\n\t\t\tprocess.destroy();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tsocket.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tLOG.error(\"Failed to close socket.\", e);\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "PythonReceiver::collectBuffer(Collector,int)",
            "  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92 -\n  93  \n  94  \n  95  \n  96  \n  97  \n  98  ",
            "\t/**\n\t * Reads a buffer of the given size from the memory-mapped file, and collects all records contained. This method\n\t * assumes that all values in the buffer are of the same type. This method does NOT take care of synchronization.\n\t * The user must guarantee that the buffer was completely written before calling this method.\n\t *\n\t * @param c Collector to collect records\n\t * @param bufferSize size of the buffer\n\t * @throws IOException\n\t */\n\t@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n\tpublic void collectBuffer(Collector c, int bufferSize) throws IOException {\n\t\tfileBuffer.position(0);\n\n\t\twhile (fileBuffer.position() < bufferSize) {\n\t\t\tc.collect(deserializer.deserialize());\n\t\t}\n\t}",
            "  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92 +\n  93  \n  94  \n  95  \n  96  \n  97  \n  98  ",
            "\t/**\n\t * Reads a buffer of the given size from the memory-mapped file, and collects all records contained. This method\n\t * assumes that all values in the buffer are of the same type. This method does NOT take care of synchronization.\n\t * The user must guarantee that the buffer was completely written before calling this method.\n\t *\n\t * @param c Collector to collect records\n\t * @param bufferSize size of the buffer\n\t * @throws IOException\n\t */\n\t@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n\tpublic void collectBuffer(Collector<OUT> c, int bufferSize) throws IOException {\n\t\tfileBuffer.position(0);\n\n\t\twhile (fileBuffer.position() < bufferSize) {\n\t\t\tc.collect(deserializer.deserialize());\n\t\t}\n\t}"
        ],
        [
            "PythonReceiver::setupMappedFile(String)",
            "  53 -\n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  ",
            "\tprivate void setupMappedFile(String inputFilePath) throws FileNotFoundException, IOException {\n\t\tFile x = new File(FLINK_TMP_DATA_DIR);\n\t\tx.mkdirs();\n\n\t\tinputFile = new File(inputFilePath);\n\t\tif (inputFile.exists()) {\n\t\t\tinputFile.delete();\n\t\t}\n\t\tinputFile.createNewFile();\n\t\tinputRAF = new RandomAccessFile(inputFilePath, \"rw\");\n\t\tinputRAF.setLength(MAPPED_FILE_SIZE);\n\t\tinputRAF.seek(MAPPED_FILE_SIZE - 1);\n\t\tinputRAF.writeByte(0);\n\t\tinputRAF.seek(0);\n\t\tinputChannel = inputRAF.getChannel();\n\t\tfileBuffer = inputChannel.map(FileChannel.MapMode.READ_WRITE, 0, MAPPED_FILE_SIZE);\n\t}",
            "  52 +\n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  ",
            "\tprivate void setupMappedFile(String inputFilePath) throws IOException {\n\t\tFile x = new File(FLINK_TMP_DATA_DIR);\n\t\tx.mkdirs();\n\n\t\tinputFile = new File(inputFilePath);\n\t\tif (inputFile.exists()) {\n\t\t\tinputFile.delete();\n\t\t}\n\t\tinputFile.createNewFile();\n\t\tinputRAF = new RandomAccessFile(inputFilePath, \"rw\");\n\t\tinputRAF.setLength(MAPPED_FILE_SIZE);\n\t\tinputRAF.seek(MAPPED_FILE_SIZE - 1);\n\t\tinputRAF.writeByte(0);\n\t\tinputRAF.seek(0);\n\t\tinputChannel = inputRAF.getChannel();\n\t\tfileBuffer = inputChannel.map(FileChannel.MapMode.READ_WRITE, 0, MAPPED_FILE_SIZE);\n\t}"
        ],
        [
            "PythonSender::setupMappedFile(String)",
            "  51 -\n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "\tprivate void setupMappedFile(String outputFilePath) throws FileNotFoundException, IOException {\n\t\tFile x = new File(FLINK_TMP_DATA_DIR);\n\t\tx.mkdirs();\n\n\t\toutputFile = new File(outputFilePath);\n\t\tif (outputFile.exists()) {\n\t\t\toutputFile.delete();\n\t\t}\n\t\toutputFile.createNewFile();\n\t\toutputRAF = new RandomAccessFile(outputFilePath, \"rw\");\n\t\toutputRAF.setLength(MAPPED_FILE_SIZE);\n\t\toutputRAF.seek(MAPPED_FILE_SIZE - 1);\n\t\toutputRAF.writeByte(0);\n\t\toutputRAF.seek(0);\n\t\toutputChannel = outputRAF.getChannel();\n\t\tfileBuffer = outputChannel.map(FileChannel.MapMode.READ_WRITE, 0, MAPPED_FILE_SIZE);\n\t}",
            "  55 +\n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  ",
            "\tprivate void setupMappedFile(String outputFilePath) throws IOException {\n\t\tFile x = new File(FLINK_TMP_DATA_DIR);\n\t\tx.mkdirs();\n\n\t\toutputFile = new File(outputFilePath);\n\t\tif (outputFile.exists()) {\n\t\t\toutputFile.delete();\n\t\t}\n\t\toutputFile.createNewFile();\n\t\toutputRAF = new RandomAccessFile(outputFilePath, \"rw\");\n\t\toutputRAF.setLength(MAPPED_FILE_SIZE);\n\t\toutputRAF.seek(MAPPED_FILE_SIZE - 1);\n\t\toutputRAF.writeByte(0);\n\t\toutputRAF.seek(0);\n\t\toutputChannel = outputRAF.getChannel();\n\t\tfileBuffer = outputChannel.map(FileChannel.MapMode.READ_WRITE, 0, MAPPED_FILE_SIZE);\n\t}"
        ],
        [
            "PythonCoGroup::PythonCoGroup(int,TypeInformation)",
            "  34  \n  35  \n  36 -\n  37  ",
            "\tpublic PythonCoGroup(int id, TypeInformation<OUT> typeInformation) {\n\t\tthis.typeInformation = typeInformation;\n\t\tstreamer = new PythonStreamer(this, id, true);\n\t}",
            "  37  \n  38  \n  39 +\n  40  ",
            "\tpublic PythonCoGroup(int id, TypeInformation<OUT> typeInformation) {\n\t\tthis.typeInformation = typeInformation;\n\t\tstreamer = new PythonStreamer<>(this, id, true);\n\t}"
        ],
        [
            "PythonPlanStreamer::checkPythonProcessHealth()",
            " 102  \n 103  \n 104  \n 105  \n 106  \n 107 -\n 108 -\n 109  \n 110  \n 111 -\n 112  \n 113  ",
            "\tprivate void checkPythonProcessHealth() {\n\t\ttry {\n\t\t\tint value = process.exitValue();\n\t\t\tif (value != 0) {\n\t\t\t\tthrow new RuntimeException(\"Plan file caused an error. Check log-files for details.\");\n\t\t\t}\n\t\t\tif (value == 0) {\n\t\t\t\tthrow new RuntimeException(\"Plan file exited prematurely without an error.\");\n\t\t\t}\n\t\t} catch (IllegalThreadStateException ise) {//Process still running\n\t\t}\n\t}",
            " 112  \n 113  \n 114  \n 115  \n 116  \n 117 +\n 118  \n 119  \n 120 +\n 121  \n 122  ",
            "\tprivate void checkPythonProcessHealth() {\n\t\ttry {\n\t\t\tint value = process.exitValue();\n\t\t\tif (value != 0) {\n\t\t\t\tthrow new RuntimeException(\"Plan file caused an error. Check log-files for details.\");\n\t\t\t} else {\n\t\t\t\tthrow new RuntimeException(\"Plan file exited prematurely without an error.\");\n\t\t\t}\n\t\t} catch (IllegalThreadStateException ignored) {//Process still running\n\t\t}\n\t}"
        ],
        [
            "PythonStreamer::streamBufferWithGroups(Iterator,Iterator,Collector)",
            " 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316 -\n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340 -\n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351 -\n 352  \n 353  \n 354  ",
            "\t/**\n\t * Sends all values contained in both iterators to the external process and collects all results.\n\t *\n\t * @param i1 iterator\n\t * @param i2 iterator\n\t * @param c collector\n\t * @throws IOException\n\t */\n\tpublic final void streamBufferWithGroups(Iterator i1, Iterator i2, Collector c) throws IOException {\n\t\ttry {\n\t\t\tint size;\n\t\t\tif (i1.hasNext() || i2.hasNext()) {\n\t\t\t\twhile (true) {\n\t\t\t\t\tint sig = in.readInt();\n\t\t\t\t\tswitch (sig) {\n\t\t\t\t\t\tcase SIGNAL_BUFFER_REQUEST_G0:\n\t\t\t\t\t\t\tif (i1.hasNext() || sender.hasRemaining(0)) {\n\t\t\t\t\t\t\t\tsize = sender.sendBuffer(i1, 0);\n\t\t\t\t\t\t\t\tsendWriteNotification(size, sender.hasRemaining(0) || i1.hasNext());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase SIGNAL_BUFFER_REQUEST_G1:\n\t\t\t\t\t\t\tif (i2.hasNext() || sender.hasRemaining(1)) {\n\t\t\t\t\t\t\t\tsize = sender.sendBuffer(i2, 1);\n\t\t\t\t\t\t\t\tsendWriteNotification(size, sender.hasRemaining(1) || i2.hasNext());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase SIGNAL_FINISHED:\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\tcase SIGNAL_ERROR:\n\t\t\t\t\t\t\ttry { //wait before terminating to ensure that the complete error message is printed\n\t\t\t\t\t\t\t\tThread.sleep(2000);\n\t\t\t\t\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthrow new RuntimeException(\n\t\t\t\t\t\t\t\t\t\"External process for task \" + function.getRuntimeContext().getTaskName() + \" terminated prematurely due to an error.\" + msg);\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treceiver.collectBuffer(c, sig);\n\t\t\t\t\t\t\tsendReadConfirmation();\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (SocketTimeoutException ste) {\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" stopped responding.\" + msg);\n\t\t}\n\t}",
            " 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314 +\n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338 +\n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349 +\n 350  \n 351  \n 352  ",
            "\t/**\n\t * Sends all values contained in both iterators to the external process and collects all results.\n\t *\n\t * @param i1 iterator\n\t * @param i2 iterator\n\t * @param c collector\n\t * @throws IOException\n\t */\n\tpublic final void streamBufferWithGroups(Iterator<IN1> i1, Iterator<IN2> i2, Collector<OUT> c) throws IOException {\n\t\ttry {\n\t\t\tint size;\n\t\t\tif (i1.hasNext() || i2.hasNext()) {\n\t\t\t\twhile (true) {\n\t\t\t\t\tint sig = in.readInt();\n\t\t\t\t\tswitch (sig) {\n\t\t\t\t\t\tcase SIGNAL_BUFFER_REQUEST_G0:\n\t\t\t\t\t\t\tif (i1.hasNext() || sender.hasRemaining(0)) {\n\t\t\t\t\t\t\t\tsize = sender.sendBuffer(i1, 0);\n\t\t\t\t\t\t\t\tsendWriteNotification(size, sender.hasRemaining(0) || i1.hasNext());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase SIGNAL_BUFFER_REQUEST_G1:\n\t\t\t\t\t\t\tif (i2.hasNext() || sender.hasRemaining(1)) {\n\t\t\t\t\t\t\t\tsize = sender.sendBuffer(i2, 1);\n\t\t\t\t\t\t\t\tsendWriteNotification(size, sender.hasRemaining(1) || i2.hasNext());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase SIGNAL_FINISHED:\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\tcase SIGNAL_ERROR:\n\t\t\t\t\t\t\ttry { //wait before terminating to ensure that the complete error message is printed\n\t\t\t\t\t\t\t\tThread.sleep(2000);\n\t\t\t\t\t\t\t} catch (InterruptedException ignored) {\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthrow new RuntimeException(\n\t\t\t\t\t\t\t\t\t\"External process for task \" + function.getRuntimeContext().getTaskName() + \" terminated prematurely due to an error.\" + msg);\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treceiver.collectBuffer(c, sig);\n\t\t\t\t\t\t\tsendReadConfirmation();\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (SocketTimeoutException ignored) {\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" stopped responding.\" + msg);\n\t\t}\n\t}"
        ],
        [
            "PythonSender::closeMappedFile()",
            "  73  \n  74  \n  75  \n  76  ",
            "\tprivate void closeMappedFile() throws IOException {\n\t\toutputChannel.close();\n\t\toutputRAF.close();\n\t}",
            "  77  \n  78  \n  79  \n  80 +\n  81  ",
            "\tprivate void closeMappedFile() throws IOException {\n\t\toutputChannel.close();\n\t\toutputRAF.close();\n\t\toutputFile.delete();\n\t}"
        ],
        [
            "PythonSender::getSerializer(Object)",
            " 168 -\n 169  \n 170  \n 171  \n 172 -\n 173  \n 174  \n 175 -\n 176  \n 177  \n 178 -\n 179  ",
            "\tprivate Serializer getSerializer(Object value) {\n\t\tif (value instanceof byte[]) {\n\t\t\treturn new ArraySerializer();\n\t\t}\n\t\tif (((Tuple2) value).f0 instanceof byte[]) {\n\t\t\treturn new ValuePairSerializer();\n\t\t}\n\t\tif (((Tuple2) value).f0 instanceof Tuple) {\n\t\t\treturn new KeyValuePairSerializer();\n\t\t}\n\t\tthrow new IllegalArgumentException(\"This object can't be serialized: \" + value.toString());\n\t}",
            " 173 +\n 174  \n 175  \n 176  \n 177 +\n 178  \n 179  \n 180 +\n 181  \n 182  \n 183 +\n 184  ",
            "\tprivate Serializer<?> getSerializer(Object value) {\n\t\tif (value instanceof byte[]) {\n\t\t\treturn new ArraySerializer();\n\t\t}\n\t\tif (((Tuple2<?, ?>) value).f0 instanceof byte[]) {\n\t\t\treturn new ValuePairSerializer();\n\t\t}\n\t\tif (((Tuple2<?, ?>) value).f0 instanceof Tuple) {\n\t\t\treturn new KeyValuePairSerializer();\n\t\t}\n\t\tthrow new IllegalArgumentException(\"This object can't be serialized: \" + value);\n\t}"
        ],
        [
            "PythonPlanStreamer::startPython(String,String)",
            "  68  \n  69  \n  70  \n  71  \n  72  \n  73 -\n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83 -\n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  ",
            "\tprivate void startPython(String tmpPath, String args) throws IOException {\n\t\tString pythonBinaryPath = usePython3 ? FLINK_PYTHON3_BINARY_PATH : FLINK_PYTHON2_BINARY_PATH;\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().exec(pythonBinaryPath);\n\t\t} catch (IOException ex) {\n\t\t\tthrow new RuntimeException(pythonBinaryPath + \" does not point to a valid python binary.\");\n\t\t}\n\t\tprocess = Runtime.getRuntime().exec(pythonBinaryPath + \" -B \" + tmpPath + FLINK_PYTHON_PLAN_NAME + args);\n\n\t\tnew StreamPrinter(process.getInputStream()).start();\n\t\tnew StreamPrinter(process.getErrorStream()).start();\n\n\t\ttry {\n\t\t\tThread.sleep(2000);\n\t\t} catch (InterruptedException ex) {\n\t\t}\n\n\t\tcheckPythonProcessHealth();\n\n\t\tprocess.getOutputStream().write(\"plan\\n\".getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocess.getOutputStream().write((server.getLocalPort() + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocess.getOutputStream().flush();\n\t}",
            "  72  \n  73  \n  74  \n  75  \n  76  \n  77 +\n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87 +\n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  ",
            "\tprivate void startPython(String tmpPath, String args) throws IOException {\n\t\tString pythonBinaryPath = usePython3 ? FLINK_PYTHON3_BINARY_PATH : FLINK_PYTHON2_BINARY_PATH;\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().exec(pythonBinaryPath);\n\t\t} catch (IOException ignored) {\n\t\t\tthrow new RuntimeException(pythonBinaryPath + \" does not point to a valid python binary.\");\n\t\t}\n\t\tprocess = Runtime.getRuntime().exec(pythonBinaryPath + \" -B \" + tmpPath + FLINK_PYTHON_PLAN_NAME + args);\n\n\t\tnew StreamPrinter(process.getInputStream()).start();\n\t\tnew StreamPrinter(process.getErrorStream()).start();\n\n\t\ttry {\n\t\t\tThread.sleep(2000);\n\t\t} catch (InterruptedException ignored) {\n\t\t}\n\n\t\tcheckPythonProcessHealth();\n\n\t\tprocess.getOutputStream().write(\"plan\\n\".getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocess.getOutputStream().write((server.getLocalPort() + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocess.getOutputStream().flush();\n\t}"
        ],
        [
            "PythonSender::sendBuffer(Iterator,int)",
            " 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131 -\n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  ",
            "\t/**\n\t * Extracts records from an iterator and writes them to the memory-mapped file. This method assumes that all values\n\t * in the iterator are of the same type. This method does NOT take care of synchronization. The caller must\n\t * guarantee that the file may be written to before calling this method.\n\t *\n\t * @param i iterator containing records\n\t * @param group group to which the iterator belongs, most notably used by CoGroup-functions.\n\t * @return size of the written buffer\n\t * @throws IOException\n\t */\n\t@SuppressWarnings(\"unchecked\")\n\tpublic int sendBuffer(Iterator i, int group) throws IOException {\n\t\tfileBuffer.clear();\n\n\t\tObject value;\n\t\tByteBuffer bb;\n\t\tif (serializer[group] == null) {\n\t\t\tvalue = i.next();\n\t\t\tserializer[group] = getSerializer(value);\n\t\t\tbb = serializer[group].serialize(value);\n\t\t\tif (bb.remaining() > MAPPED_FILE_SIZE) {\n\t\t\t\tthrow new RuntimeException(\"Serialized object does not fit into a single buffer.\");\n\t\t\t}\n\t\t\tfileBuffer.put(bb);\n\n\t\t}\n\t\tif (saved[group] != null) {\n\t\t\tfileBuffer.put(saved[group]);\n\t\t\tsaved[group] = null;\n\t\t}\n\t\twhile (i.hasNext() && saved[group] == null) {\n\t\t\tvalue = i.next();\n\t\t\tbb = serializer[group].serialize(value);\n\t\t\tif (bb.remaining() > MAPPED_FILE_SIZE) {\n\t\t\t\tthrow new RuntimeException(\"Serialized object does not fit into a single buffer.\");\n\t\t\t}\n\t\t\tif (bb.remaining() <= fileBuffer.remaining()) {\n\t\t\t\tfileBuffer.put(bb);\n\t\t\t} else {\n\t\t\t\tsaved[group] = bb;\n\t\t\t}\n\t\t}\n\n\t\tint size = fileBuffer.position();\n\t\treturn size;\n\t}",
            " 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136 +\n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  ",
            "\t/**\n\t * Extracts records from an iterator and writes them to the memory-mapped file. This method assumes that all values\n\t * in the iterator are of the same type. This method does NOT take care of synchronization. The caller must\n\t * guarantee that the file may be written to before calling this method.\n\t *\n\t * @param i iterator containing records\n\t * @param group group to which the iterator belongs, most notably used by CoGroup-functions.\n\t * @return size of the written buffer\n\t * @throws IOException\n\t */\n\t@SuppressWarnings(\"unchecked\")\n\tpublic int sendBuffer(Iterator<?> i, int group) throws IOException {\n\t\tfileBuffer.clear();\n\n\t\tObject value;\n\t\tByteBuffer bb;\n\t\tif (serializer[group] == null) {\n\t\t\tvalue = i.next();\n\t\t\tserializer[group] = getSerializer(value);\n\t\t\tbb = serializer[group].serialize(value);\n\t\t\tif (bb.remaining() > MAPPED_FILE_SIZE) {\n\t\t\t\tthrow new RuntimeException(\"Serialized object does not fit into a single buffer.\");\n\t\t\t}\n\t\t\tfileBuffer.put(bb);\n\n\t\t}\n\t\tif (saved[group] != null) {\n\t\t\tfileBuffer.put(saved[group]);\n\t\t\tsaved[group] = null;\n\t\t}\n\t\twhile (i.hasNext() && saved[group] == null) {\n\t\t\tvalue = i.next();\n\t\t\tbb = serializer[group].serialize(value);\n\t\t\tif (bb.remaining() > MAPPED_FILE_SIZE) {\n\t\t\t\tthrow new RuntimeException(\"Serialized object does not fit into a single buffer.\");\n\t\t\t}\n\t\t\tif (bb.remaining() <= fileBuffer.remaining()) {\n\t\t\t\tfileBuffer.put(bb);\n\t\t\t} else {\n\t\t\t\tsaved[group] = bb;\n\t\t\t}\n\t\t}\n\n\t\tint size = fileBuffer.position();\n\t\treturn size;\n\t}"
        ],
        [
            "PythonStreamer::streamBufferWithoutGroups(Iterator,Collector)",
            " 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272 -\n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292 -\n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303 -\n 304  \n 305  \n 306  ",
            "\t/**\n\t * Sends all values contained in the iterator to the external process and collects all results.\n\t *\n\t * @param i iterator\n\t * @param c collector\n\t * @throws IOException\n\t */\n\tpublic final void streamBufferWithoutGroups(Iterator i, Collector c) throws IOException {\n\t\ttry {\n\t\t\tint size;\n\t\t\tif (i.hasNext()) {\n\t\t\t\twhile (true) {\n\t\t\t\t\tint sig = in.readInt();\n\t\t\t\t\tswitch (sig) {\n\t\t\t\t\t\tcase SIGNAL_BUFFER_REQUEST:\n\t\t\t\t\t\t\tif (i.hasNext() || sender.hasRemaining(0)) {\n\t\t\t\t\t\t\t\tsize = sender.sendBuffer(i, 0);\n\t\t\t\t\t\t\t\tsendWriteNotification(size, sender.hasRemaining(0) || i.hasNext());\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"External process requested data even though none is available.\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase SIGNAL_FINISHED:\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\tcase SIGNAL_ERROR:\n\t\t\t\t\t\t\ttry { //wait before terminating to ensure that the complete error message is printed\n\t\t\t\t\t\t\t\tThread.sleep(2000);\n\t\t\t\t\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthrow new RuntimeException(\n\t\t\t\t\t\t\t\t\t\"External process for task \" + function.getRuntimeContext().getTaskName() + \" terminated prematurely due to an error.\" + msg);\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treceiver.collectBuffer(c, sig);\n\t\t\t\t\t\t\tsendReadConfirmation();\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (SocketTimeoutException ste) {\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" stopped responding.\" + msg);\n\t\t}\n\t}",
            " 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270 +\n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290 +\n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301 +\n 302  \n 303  \n 304  ",
            "\t/**\n\t * Sends all values contained in the iterator to the external process and collects all results.\n\t *\n\t * @param i iterator\n\t * @param c collector\n\t * @throws IOException\n\t */\n\tpublic final void streamBufferWithoutGroups(Iterator<IN1> i, Collector<OUT> c) throws IOException {\n\t\ttry {\n\t\t\tint size;\n\t\t\tif (i.hasNext()) {\n\t\t\t\twhile (true) {\n\t\t\t\t\tint sig = in.readInt();\n\t\t\t\t\tswitch (sig) {\n\t\t\t\t\t\tcase SIGNAL_BUFFER_REQUEST:\n\t\t\t\t\t\t\tif (i.hasNext() || sender.hasRemaining(0)) {\n\t\t\t\t\t\t\t\tsize = sender.sendBuffer(i, 0);\n\t\t\t\t\t\t\t\tsendWriteNotification(size, sender.hasRemaining(0) || i.hasNext());\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tthrow new RuntimeException(\"External process requested data even though none is available.\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase SIGNAL_FINISHED:\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\tcase SIGNAL_ERROR:\n\t\t\t\t\t\t\ttry { //wait before terminating to ensure that the complete error message is printed\n\t\t\t\t\t\t\t\tThread.sleep(2000);\n\t\t\t\t\t\t\t} catch (InterruptedException ignored) {\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthrow new RuntimeException(\n\t\t\t\t\t\t\t\t\t\"External process for task \" + function.getRuntimeContext().getTaskName() + \" terminated prematurely due to an error.\" + msg);\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treceiver.collectBuffer(c, sig);\n\t\t\t\t\t\t\tsendReadConfirmation();\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (SocketTimeoutException ignored) {\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" stopped responding.\" + msg);\n\t\t}\n\t}"
        ],
        [
            "PythonStreamer::checkPythonProcessHealth()",
            " 165  \n 166  \n 167  \n 168  \n 169  \n 170 -\n 171 -\n 172  \n 173  \n 174 -\n 175  \n 176  ",
            "\tprivate void checkPythonProcessHealth() {\n\t\ttry {\n\t\t\tint value = process.exitValue();\n\t\t\tif (value != 0) {\n\t\t\t\tthrow new RuntimeException(\"Plan file caused an error. Check log-files for details.\");\n\t\t\t}\n\t\t\tif (value == 0) {\n\t\t\t\tthrow new RuntimeException(\"Plan file exited prematurely without an error.\");\n\t\t\t}\n\t\t} catch (IllegalThreadStateException ise) {//Process still running\n\t\t}\n\t}",
            " 164  \n 165  \n 166  \n 167  \n 168  \n 169 +\n 170  \n 171  \n 172 +\n 173  \n 174  ",
            "\tprivate void checkPythonProcessHealth() {\n\t\ttry {\n\t\t\tint value = process.exitValue();\n\t\t\tif (value != 0) {\n\t\t\t\tthrow new RuntimeException(\"Plan file caused an error. Check log-files for details.\");\n\t\t\t} else {\n\t\t\t\tthrow new RuntimeException(\"Plan file exited prematurely without an error.\");\n\t\t\t}\n\t\t} catch (IllegalThreadStateException ignored) {//Process still running\n\t\t}\n\t}"
        ],
        [
            "PythonStreamer::sendBroadCastVariables(Configuration)",
            " 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250 -\n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  ",
            "\t/**\n\t * Sends all broadcast-variables encoded in the configuration to the external process.\n\t *\n\t * @param config configuration object containing broadcast-variable count and names\n\t * @throws IOException\n\t */\n\tpublic final void sendBroadCastVariables(Configuration config) throws IOException {\n\t\ttry {\n\t\t\tint broadcastCount = config.getInteger(PLANBINDER_CONFIG_BCVAR_COUNT, 0);\n\n\t\t\tString[] names = new String[broadcastCount];\n\n\t\t\tfor (int x = 0; x < names.length; x++) {\n\t\t\t\tnames[x] = config.getString(PLANBINDER_CONFIG_BCVAR_NAME_PREFIX + x, null);\n\t\t\t}\n\n\t\t\tout.write(new IntSerializer().serializeWithoutTypeInfo(broadcastCount));\n\n\t\t\tStringSerializer stringSerializer = new StringSerializer();\n\t\t\tfor (String name : names) {\n\t\t\t\tIterator bcv = function.getRuntimeContext().getBroadcastVariable(name).iterator();\n\n\t\t\t\tout.write(stringSerializer.serializeWithoutTypeInfo(name));\n\n\t\t\t\twhile (bcv.hasNext()) {\n\t\t\t\t\tout.writeByte(1);\n\t\t\t\t\tout.write((byte[]) bcv.next());\n\t\t\t\t}\n\t\t\t\tout.writeByte(0);\n\t\t\t}\n\t\t} catch (SocketTimeoutException ste) {\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" stopped responding.\" + msg);\n\t\t}\n\t}",
            " 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248 +\n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  ",
            "\t/**\n\t * Sends all broadcast-variables encoded in the configuration to the external process.\n\t *\n\t * @param config configuration object containing broadcast-variable count and names\n\t * @throws IOException\n\t */\n\tpublic final void sendBroadCastVariables(Configuration config) throws IOException {\n\t\ttry {\n\t\t\tint broadcastCount = config.getInteger(PLANBINDER_CONFIG_BCVAR_COUNT, 0);\n\n\t\t\tString[] names = new String[broadcastCount];\n\n\t\t\tfor (int x = 0; x < names.length; x++) {\n\t\t\t\tnames[x] = config.getString(PLANBINDER_CONFIG_BCVAR_NAME_PREFIX + x, null);\n\t\t\t}\n\n\t\t\tout.write(new IntSerializer().serializeWithoutTypeInfo(broadcastCount));\n\n\t\t\tStringSerializer stringSerializer = new StringSerializer();\n\t\t\tfor (String name : names) {\n\t\t\t\tIterator<?> bcv = function.getRuntimeContext().getBroadcastVariable(name).iterator();\n\n\t\t\t\tout.write(stringSerializer.serializeWithoutTypeInfo(name));\n\n\t\t\t\twhile (bcv.hasNext()) {\n\t\t\t\t\tout.writeByte(1);\n\t\t\t\t\tout.write((byte[]) bcv.next());\n\t\t\t\t}\n\t\t\t\tout.writeByte(0);\n\t\t\t}\n\t\t} catch (SocketTimeoutException ste) {\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" stopped responding.\" + msg);\n\t\t}\n\t}"
        ],
        [
            "PythonPlanReceiver::getDeserializer()",
            "  52  \n  53 -\n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  ",
            "\tprivate Deserializer getDeserializer() throws IOException {\n\t\tbyte type = (byte) input.readByte();\n\t\tif (type >= 0 && type < 26) {\n\t\t\t\tDeserializer[] d = new Deserializer[type];\n\t\t\t\tfor (int x = 0; x < d.length; x++) {\n\t\t\t\t\td[x] = getDeserializer();\n\t\t\t\t}\n\t\t\t\treturn new TupleDeserializer(d);\n\t\t}\n\t\tswitch (type) {\n\t\t\tcase TYPE_BOOLEAN:\n\t\t\t\treturn new BooleanDeserializer();\n\t\t\tcase TYPE_BYTE:\n\t\t\t\treturn new ByteDeserializer();\n\t\t\tcase TYPE_INTEGER:\n\t\t\t\treturn new IntDeserializer();\n\t\t\tcase TYPE_LONG:\n\t\t\t\treturn new LongDeserializer();\n\t\t\tcase TYPE_FLOAT:\n\t\t\t\treturn new FloatDeserializer();\n\t\t\tcase TYPE_DOUBLE:\n\t\t\t\treturn new DoubleDeserializer();\n\t\t\tcase TYPE_STRING:\n\t\t\t\treturn new StringDeserializer();\n\t\t\tcase TYPE_BYTES:\n\t\t\t\treturn new BytesDeserializer();\n\t\t\tcase TYPE_NULL:\n\t\t\t\treturn new NullDeserializer();\n\t\t\tdefault:\n\t\t\t\treturn new CustomTypeDeserializer(type);\n\t\t}\n\t}",
            "  51  \n  52 +\n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  ",
            "\tprivate Deserializer getDeserializer() throws IOException {\n\t\tbyte type = input.readByte();\n\t\tif (type >= 0 && type < 26) {\n\t\t\t\tDeserializer[] d = new Deserializer[type];\n\t\t\t\tfor (int x = 0; x < d.length; x++) {\n\t\t\t\t\td[x] = getDeserializer();\n\t\t\t\t}\n\t\t\t\treturn new TupleDeserializer(d);\n\t\t}\n\t\tswitch (type) {\n\t\t\tcase TYPE_BOOLEAN:\n\t\t\t\treturn new BooleanDeserializer();\n\t\t\tcase TYPE_BYTE:\n\t\t\t\treturn new ByteDeserializer();\n\t\t\tcase TYPE_INTEGER:\n\t\t\t\treturn new IntDeserializer();\n\t\t\tcase TYPE_LONG:\n\t\t\t\treturn new LongDeserializer();\n\t\t\tcase TYPE_FLOAT:\n\t\t\t\treturn new FloatDeserializer();\n\t\t\tcase TYPE_DOUBLE:\n\t\t\t\treturn new DoubleDeserializer();\n\t\t\tcase TYPE_STRING:\n\t\t\t\treturn new StringDeserializer();\n\t\t\tcase TYPE_BYTES:\n\t\t\t\treturn new BytesDeserializer();\n\t\t\tcase TYPE_NULL:\n\t\t\t\treturn new NullDeserializer();\n\t\t\tdefault:\n\t\t\t\treturn new CustomTypeDeserializer(type);\n\t\t}\n\t}"
        ],
        [
            "PythonStreamer::startPython()",
            "  99  \n 100 -\n 101 -\n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113 -\n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126 -\n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145 -\n 146  \n 147  \n 148  \n 149  \n 150 -\n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  ",
            "\tprivate void startPython() throws IOException {\n\t\tthis.outputFilePath = FLINK_TMP_DATA_DIR + \"/\" + id + this.function.getRuntimeContext().getIndexOfThisSubtask() + \"output\";\n\t\tthis.inputFilePath = FLINK_TMP_DATA_DIR + \"/\" + id + this.function.getRuntimeContext().getIndexOfThisSubtask() + \"input\";\n\n\t\tsender.open(inputFilePath);\n\t\treceiver.open(outputFilePath);\n\n\t\tString path = function.getRuntimeContext().getDistributedCache().getFile(FLINK_PYTHON_DC_ID).getAbsolutePath();\n\t\tString planPath = path + FLINK_PYTHON_PLAN_NAME;\n\n\t\tString pythonBinaryPath = usePython3 ? FLINK_PYTHON3_BINARY_PATH : FLINK_PYTHON2_BINARY_PATH;\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().exec(pythonBinaryPath);\n\t\t} catch (IOException ex) {\n\t\t\tthrow new RuntimeException(pythonBinaryPath + \" does not point to a valid python binary.\");\n\t\t}\n\n\t\tprocess = Runtime.getRuntime().exec(pythonBinaryPath + \" -O -B \" + planPath + planArguments);\n\t\tnew StreamPrinter(process.getInputStream()).start();\n\t\tnew StreamPrinter(process.getErrorStream(), true, msg).start();\n\n\t\tshutdownThread = new Thread() {\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\ttry {\n\t\t\t\t\tdestroyProcess();\n\t\t\t\t} catch (IOException ex) {\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tRuntime.getRuntime().addShutdownHook(shutdownThread);\n\n\t\tOutputStream processOutput = process.getOutputStream();\n\t\tprocessOutput.write(\"operator\\n\".getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((\"\" + server.getLocalPort() + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((id + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((this.function.getRuntimeContext().getIndexOfThisSubtask() + \"\\n\")\n\t\t\t.getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((inputFilePath + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((outputFilePath + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.flush();\n\n\t\ttry { // wait a bit to catch syntax errors\n\t\t\tThread.sleep(2000);\n\t\t} catch (InterruptedException ex) {\n\t\t}\n\t\ttry {\n\t\t\tprocess.exitValue();\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" terminated prematurely.\" + msg);\n\t\t} catch (IllegalThreadStateException ise) { //process still active -> start receiving data\n\t\t}\n\n\t\twhile (true) {\n\t\t\ttry {\n\t\t\t\tsocket = server.accept();\n\t\t\t\tbreak;\n\t\t\t} catch (SocketTimeoutException ignored) {\n\t\t\t\tcheckPythonProcessHealth();\n\t\t\t}\n\t\t}\n\t\tin = new DataInputStream(socket.getInputStream());\n\t\tout = new DataOutputStream(socket.getOutputStream());\n\t}",
            "  98  \n  99 +\n 100 +\n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112 +\n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125 +\n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144 +\n 145  \n 146  \n 147  \n 148  \n 149 +\n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  ",
            "\tprivate void startPython() throws IOException {\n\t\tString outputFilePath = FLINK_TMP_DATA_DIR + \"/\" + id + this.function.getRuntimeContext().getIndexOfThisSubtask() + \"output\";\n\t\tString inputFilePath = FLINK_TMP_DATA_DIR + \"/\" + id + this.function.getRuntimeContext().getIndexOfThisSubtask() + \"input\";\n\n\t\tsender.open(inputFilePath);\n\t\treceiver.open(outputFilePath);\n\n\t\tString path = function.getRuntimeContext().getDistributedCache().getFile(FLINK_PYTHON_DC_ID).getAbsolutePath();\n\t\tString planPath = path + FLINK_PYTHON_PLAN_NAME;\n\n\t\tString pythonBinaryPath = usePython3 ? FLINK_PYTHON3_BINARY_PATH : FLINK_PYTHON2_BINARY_PATH;\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().exec(pythonBinaryPath);\n\t\t} catch (IOException ignored) {\n\t\t\tthrow new RuntimeException(pythonBinaryPath + \" does not point to a valid python binary.\");\n\t\t}\n\n\t\tprocess = Runtime.getRuntime().exec(pythonBinaryPath + \" -O -B \" + planPath + planArguments);\n\t\tnew StreamPrinter(process.getInputStream()).start();\n\t\tnew StreamPrinter(process.getErrorStream(), true, msg).start();\n\n\t\tshutdownThread = new Thread() {\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\ttry {\n\t\t\t\t\tdestroyProcess();\n\t\t\t\t} catch (IOException ignored) {\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tRuntime.getRuntime().addShutdownHook(shutdownThread);\n\n\t\tOutputStream processOutput = process.getOutputStream();\n\t\tprocessOutput.write(\"operator\\n\".getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((\"\" + server.getLocalPort() + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((id + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((this.function.getRuntimeContext().getIndexOfThisSubtask() + \"\\n\")\n\t\t\t.getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((inputFilePath + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.write((outputFilePath + \"\\n\").getBytes(ConfigConstants.DEFAULT_CHARSET));\n\t\tprocessOutput.flush();\n\n\t\ttry { // wait a bit to catch syntax errors\n\t\t\tThread.sleep(2000);\n\t\t} catch (InterruptedException ignored) {\n\t\t}\n\t\ttry {\n\t\t\tprocess.exitValue();\n\t\t\tthrow new RuntimeException(\"External process for task \" + function.getRuntimeContext().getTaskName() + \" terminated prematurely.\" + msg);\n\t\t} catch (IllegalThreadStateException ignored) { //process still active -> start receiving data\n\t\t}\n\n\t\twhile (true) {\n\t\t\ttry {\n\t\t\t\tsocket = server.accept();\n\t\t\t\tbreak;\n\t\t\t} catch (SocketTimeoutException ignored) {\n\t\t\t\tcheckPythonProcessHealth();\n\t\t\t}\n\t\t}\n\t\tin = new DataInputStream(socket.getInputStream());\n\t\tout = new DataOutputStream(socket.getOutputStream());\n\t}"
        ],
        [
            "PythonMapPartition::PythonMapPartition(int,TypeInformation)",
            "  35  \n  36  \n  37 -\n  38  ",
            "\tpublic PythonMapPartition(int id, TypeInformation<OUT> typeInformation) {\n\t\tthis.typeInformation = typeInformation;\n\t\tstreamer = new PythonStreamer(this, id, typeInformation instanceof PrimitiveArrayTypeInfo);\n\t}",
            "  38  \n  39  \n  40 +\n  41  ",
            "\tpublic PythonMapPartition(int id, TypeInformation<OUT> typeInformation) {\n\t\tthis.typeInformation = typeInformation;\n\t\tstreamer = new PythonStreamer<>(this, id, typeInformation instanceof PrimitiveArrayTypeInfo);\n\t}"
        ],
        [
            "PythonStreamer::close()",
            " 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189 -\n 190  \n 191  \n 192  \n 193  \n 194  \n 195  ",
            "\t/**\n\t * Closes this streamer.\n\t *\n\t * @throws IOException\n\t */\n\tpublic void close() throws IOException {\n\t\ttry {\n\t\t\tsocket.close();\n\t\t\tsender.close();\n\t\t\treceiver.close();\n\t\t} catch (Exception e) {\n\t\t\tLOG.error(\"Exception occurred while closing Streamer. :\" + e.getMessage());\n\t\t}\n\t\tdestroyProcess();\n\t\tif (shutdownThread != null) {\n\t\t\tRuntime.getRuntime().removeShutdownHook(shutdownThread);\n\t\t}\n\t}",
            " 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187 +\n 188  \n 189  \n 190  \n 191  \n 192  \n 193  ",
            "\t/**\n\t * Closes this streamer.\n\t *\n\t * @throws IOException\n\t */\n\tpublic void close() throws IOException {\n\t\ttry {\n\t\t\tsocket.close();\n\t\t\tsender.close();\n\t\t\treceiver.close();\n\t\t} catch (Exception e) {\n\t\t\tLOG.error(\"Exception occurred while closing Streamer. :{}\", e.getMessage());\n\t\t}\n\t\tdestroyProcess();\n\t\tif (shutdownThread != null) {\n\t\t\tRuntime.getRuntime().removeShutdownHook(shutdownThread);\n\t\t}\n\t}"
        ]
    ],
    "283f5efd50bdb3e94cc947d1edab6fc0c8cbc77e": [
        [
            "LocalExecutor::endSession(JobID)",
            " 219  \n 220  \n 221 -\n 222 -\n 223 -\n 224 -\n 225  \n 226  ",
            "\t@Override\n\tpublic void endSession(JobID jobID) throws Exception {\n\t\tLocalFlinkMiniCluster flink = this.flink;\n\t\tif (flink != null) {\n\t\t\tActorGateway leaderGateway = flink.getLeaderGateway(AkkaUtils.getDefaultTimeoutAsFiniteDuration());\n\t\t\tleaderGateway.tell(new JobManagerMessages.RemoveCachedJob(jobID));\n\t\t}\n\t}",
            " 221  \n 222  \n 223 +\n 224 +\n 225 +\n 226 +\n 227 +\n 228 +\n 229  \n 230  ",
            "\t@Override\n\tpublic void endSession(JobID jobID) throws Exception {\n\t\tsynchronized (LocalExecutor.class) {\n\t\t\tLocalFlinkMiniCluster flink = this.flink;\n\t\t\tif (flink != null) {\n\t\t\t\tActorGateway leaderGateway = flink.getLeaderGateway(AkkaUtils.getDefaultTimeoutAsFiniteDuration());\n\t\t\t\tleaderGateway.tell(new JobManagerMessages.RemoveCachedJob(jobID));\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "LocalExecutor::isRunning()",
            " 133  \n 134  \n 135 -\n 136  ",
            "\t@Override\n\tpublic boolean isRunning() {\n\t\treturn flink != null;\n\t}",
            " 133  \n 134  \n 135 +\n 136 +\n 137 +\n 138  ",
            "\t@Override\n\tpublic boolean isRunning() {\n\t\tsynchronized (lock) {\n\t\t\treturn flink != null;\n\t\t}\n\t}"
        ]
    ],
    "f2af1a9f916bd9b941a48a1da577d19fc07badde": [
        [
            "RocksDBKeyedStateBackend::RocksDBFullRestoreOperation::RocksDBFullRestoreOperation(RocksDBKeyedStateBackend)",
            "1053  \n1054  \n1055  \n1056  \n1057  \n1058 -\n1059  \n1060  ",
            "\t\t/**\n\t\t * Creates a restore operation object for the given state backend instance.\n\t\t *\n\t\t * @param rocksDBKeyedStateBackend the state backend into which we restore\n\t\t */\n\t\tpublic RocksDBFullRestoreOperation(RocksDBKeyedStateBackend<?> rocksDBKeyedStateBackend) {\n\t\t\tthis.rocksDBKeyedStateBackend = Preconditions.checkNotNull(rocksDBKeyedStateBackend);\n\t\t}",
            "1050  \n1051  \n1052  \n1053  \n1054  \n1055 +\n1056  \n1057  ",
            "\t\t/**\n\t\t * Creates a restore operation object for the given state backend instance.\n\t\t *\n\t\t * @param rocksDBKeyedStateBackend the state backend into which we restore\n\t\t */\n\t\tpublic RocksDBFullRestoreOperation(RocksDBKeyedStateBackend<K> rocksDBKeyedStateBackend) {\n\t\t\tthis.rocksDBKeyedStateBackend = Preconditions.checkNotNull(rocksDBKeyedStateBackend);\n\t\t}"
        ],
        [
            "KeyedBackendSerializationProxy::KeyedBackendSerializationProxy(TypeSerializer,List)",
            "  57  \n  58 -\n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "\tpublic KeyedBackendSerializationProxy(\n\t\t\tTypeSerializer<?> keySerializer,\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> stateMetaInfoSnapshots) {\n\n\t\tthis.keySerializer = Preconditions.checkNotNull(keySerializer);\n\t\tthis.keySerializerConfigSnapshot = Preconditions.checkNotNull(keySerializer.snapshotConfiguration());\n\n\t\tPreconditions.checkNotNull(stateMetaInfoSnapshots);\n\t\tPreconditions.checkArgument(stateMetaInfoSnapshots.size() <= Short.MAX_VALUE);\n\t\tthis.stateMetaInfoSnapshots = stateMetaInfoSnapshots;\n\t}",
            "  57  \n  58 +\n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "\tpublic KeyedBackendSerializationProxy(\n\t\t\tTypeSerializer<K> keySerializer,\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> stateMetaInfoSnapshots) {\n\n\t\tthis.keySerializer = Preconditions.checkNotNull(keySerializer);\n\t\tthis.keySerializerConfigSnapshot = Preconditions.checkNotNull(keySerializer.snapshotConfiguration());\n\n\t\tPreconditions.checkNotNull(stateMetaInfoSnapshots);\n\t\tPreconditions.checkArgument(stateMetaInfoSnapshots.size() <= Short.MAX_VALUE);\n\t\tthis.stateMetaInfoSnapshots = stateMetaInfoSnapshots;\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::snapshotIncrementally(long,long,CheckpointStreamFactory)",
            " 312  \n 313  \n 314  \n 315  \n 316  \n 317 -\n 318 -\n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  ",
            "\tprivate RunnableFuture<KeyedStateHandle> snapshotIncrementally(\n\t\t\tfinal long checkpointId,\n\t\t\tfinal long checkpointTimestamp,\n\t\t\tfinal CheckpointStreamFactory checkpointStreamFactory) throws Exception {\n\n\t\tfinal RocksDBIncrementalSnapshotOperation snapshotOperation =\n\t\t\tnew RocksDBIncrementalSnapshotOperation(\n\t\t\t\tthis,\n\t\t\t\tcheckpointStreamFactory,\n\t\t\t\tcheckpointId,\n\t\t\t\tcheckpointTimestamp);\n\n\t\tsynchronized (asyncSnapshotLock) {\n\t\t\tif (db == null) {\n\t\t\t\tthrow new IOException(\"RocksDB closed.\");\n\t\t\t}\n\n\t\t\tif (!hasRegisteredState()) {\n\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\tLOG.debug(\"Asynchronous RocksDB snapshot performed on empty keyed state at \" +\n\t\t\t\t\t\t\tcheckpointTimestamp + \" . Returning null.\");\n\t\t\t\t}\n\t\t\t\treturn DoneFuture.nullValue();\n\t\t\t}\n\n\t\t\tsnapshotOperation.takeSnapshot();\n\t\t}\n\n\t\treturn new FutureTask<KeyedStateHandle>(\n\t\t\tnew Callable<KeyedStateHandle>() {\n\t\t\t\t@Override\n\t\t\t\tpublic KeyedStateHandle call() throws Exception {\n\t\t\t\t\treturn snapshotOperation.materializeSnapshot();\n\t\t\t\t}\n\t\t\t}\n\t\t) {\n\t\t\t@Override\n\t\t\tpublic boolean cancel(boolean mayInterruptIfRunning) {\n\t\t\t\tsnapshotOperation.stop();\n\t\t\t\treturn super.cancel(mayInterruptIfRunning);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tprotected void done() {\n\t\t\t\tsnapshotOperation.releaseResources(isCancelled());\n\t\t\t}\n\t\t};\n\t}",
            " 309  \n 310  \n 311  \n 312  \n 313  \n 314 +\n 315 +\n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  ",
            "\tprivate RunnableFuture<KeyedStateHandle> snapshotIncrementally(\n\t\t\tfinal long checkpointId,\n\t\t\tfinal long checkpointTimestamp,\n\t\t\tfinal CheckpointStreamFactory checkpointStreamFactory) throws Exception {\n\n\t\tfinal RocksDBIncrementalSnapshotOperation<K> snapshotOperation =\n\t\t\tnew RocksDBIncrementalSnapshotOperation<>(\n\t\t\t\tthis,\n\t\t\t\tcheckpointStreamFactory,\n\t\t\t\tcheckpointId,\n\t\t\t\tcheckpointTimestamp);\n\n\t\tsynchronized (asyncSnapshotLock) {\n\t\t\tif (db == null) {\n\t\t\t\tthrow new IOException(\"RocksDB closed.\");\n\t\t\t}\n\n\t\t\tif (!hasRegisteredState()) {\n\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\tLOG.debug(\"Asynchronous RocksDB snapshot performed on empty keyed state at \" +\n\t\t\t\t\t\t\tcheckpointTimestamp + \" . Returning null.\");\n\t\t\t\t}\n\t\t\t\treturn DoneFuture.nullValue();\n\t\t\t}\n\n\t\t\tsnapshotOperation.takeSnapshot();\n\t\t}\n\n\t\treturn new FutureTask<KeyedStateHandle>(\n\t\t\tnew Callable<KeyedStateHandle>() {\n\t\t\t\t@Override\n\t\t\t\tpublic KeyedStateHandle call() throws Exception {\n\t\t\t\t\treturn snapshotOperation.materializeSnapshot();\n\t\t\t\t}\n\t\t\t}\n\t\t) {\n\t\t\t@Override\n\t\t\tpublic boolean cancel(boolean mayInterruptIfRunning) {\n\t\t\t\tsnapshotOperation.stop();\n\t\t\t\treturn super.cancel(mayInterruptIfRunning);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tprotected void done() {\n\t\t\t\tsnapshotOperation.releaseResources(isCancelled());\n\t\t\t}\n\t\t};\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBFullSnapshotOperation::RocksDBFullSnapshotOperation(RocksDBKeyedStateBackend,CheckpointStreamFactory)",
            " 463  \n 464 -\n 465  \n 466  \n 467  \n 468  \n 469  \n 470  ",
            "\t\tRocksDBFullSnapshotOperation(\n\t\t\t\tRocksDBKeyedStateBackend<?> stateBackend,\n\t\t\t\tCheckpointStreamFactory checkpointStreamFactory) {\n\n\t\t\tthis.stateBackend = stateBackend;\n\t\t\tthis.checkpointStreamFactory = checkpointStreamFactory;\n\t\t\tthis.keyGroupRangeOffsets = new KeyGroupRangeOffsets(stateBackend.keyGroupRange);\n\t\t}",
            " 460  \n 461 +\n 462  \n 463  \n 464  \n 465  \n 466  \n 467  ",
            "\t\tRocksDBFullSnapshotOperation(\n\t\t\t\tRocksDBKeyedStateBackend<K> stateBackend,\n\t\t\t\tCheckpointStreamFactory checkpointStreamFactory) {\n\n\t\t\tthis.stateBackend = stateBackend;\n\t\t\tthis.checkpointStreamFactory = checkpointStreamFactory;\n\t\t\tthis.keyGroupRangeOffsets = new KeyGroupRangeOffsets(stateBackend.keyGroupRange);\n\t\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBIncrementalSnapshotOperation::materializeMetaData()",
            " 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813 -\n 814 -\n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  ",
            "\t\tprivate StreamStateHandle materializeMetaData() throws Exception {\n\t\t\tCheckpointStreamFactory.CheckpointStateOutputStream outputStream = null;\n\n\t\t\ttry {\n\t\t\t\toutputStream = checkpointStreamFactory\n\t\t\t\t\t.createCheckpointStateOutputStream(checkpointId, checkpointTimestamp);\n\t\t\t\tcloseableRegistry.registerClosable(outputStream);\n\n\t\t\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy(stateBackend.keySerializer, stateMetaInfoSnapshots);\n\t\t\t\tDataOutputView out = new DataOutputViewStreamWrapper(outputStream);\n\n\t\t\t\tserializationProxy.write(out);\n\n\t\t\t\tcloseableRegistry.unregisterClosable(outputStream);\n\t\t\t\tStreamStateHandle result = outputStream.closeAndGetHandle();\n\t\t\t\toutputStream = null;\n\n\t\t\t\treturn result;\n\t\t\t} finally {\n\t\t\t\tif (outputStream != null) {\n\t\t\t\t\tcloseableRegistry.unregisterClosable(outputStream);\n\t\t\t\t\toutputStream.close();\n\t\t\t\t}\n\t\t\t}\n\t\t}",
            " 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810 +\n 811 +\n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  ",
            "\t\tprivate StreamStateHandle materializeMetaData() throws Exception {\n\t\t\tCheckpointStreamFactory.CheckpointStateOutputStream outputStream = null;\n\n\t\t\ttry {\n\t\t\t\toutputStream = checkpointStreamFactory\n\t\t\t\t\t.createCheckpointStateOutputStream(checkpointId, checkpointTimestamp);\n\t\t\t\tcloseableRegistry.registerClosable(outputStream);\n\n\t\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy<>(stateBackend.keySerializer, stateMetaInfoSnapshots);\n\t\t\t\tDataOutputView out = new DataOutputViewStreamWrapper(outputStream);\n\n\t\t\t\tserializationProxy.write(out);\n\n\t\t\t\tcloseableRegistry.unregisterClosable(outputStream);\n\t\t\t\tStreamStateHandle result = outputStream.closeAndGetHandle();\n\t\t\t\toutputStream = null;\n\n\t\t\t\treturn result;\n\t\t\t} finally {\n\t\t\t\tif (outputStream != null) {\n\t\t\t\t\tcloseableRegistry.unregisterClosable(outputStream);\n\t\t\t\t\toutputStream.close();\n\t\t\t\t}\n\t\t\t}\n\t\t}"
        ],
        [
            "RocksDBKeyedStateBackend::restoreOldSavepointKeyedState(Collection)",
            "1889  \n1890  \n1891  \n1892  \n1893  \n1894  \n1895  \n1896  \n1897  \n1898  \n1899  \n1900  \n1901  \n1902  \n1903  \n1904  \n1905  \n1906  \n1907  \n1908  \n1909  \n1910  \n1911  \n1912  \n1913  \n1914  \n1915  \n1916  \n1917  \n1918  \n1919  \n1920  \n1921  \n1922  \n1923  \n1924  \n1925  \n1926  \n1927  \n1928  \n1929  \n1930  \n1931  \n1932 -\n1933  \n1934  \n1935  \n1936  \n1937  \n1938  \n1939  \n1940  \n1941  \n1942  \n1943  \n1944  \n1945  \n1946  \n1947  \n1948  \n1949  \n1950  \n1951  \n1952  \n1953  \n1954  \n1955  \n1956  \n1957  \n1958  \n1959  \n1960  \n1961  \n1962  \n1963  \n1964  \n1965  \n1966  \n1967  \n1968  \n1969  \n1970  \n1971  \n1972  \n1973  \n1974  \n1975  \n1976  \n1977  \n1978  \n1979  \n1980  \n1981  \n1982  \n1983  \n1984  \n1985  \n1986  \n1987  \n1988  \n1989  \n1990  \n1991  ",
            "\t/**\n\t * For backwards compatibility, remove again later!\n\t *\n\t * @deprecated Internal method used for backwards compatibility.\n\t */\n\t@Deprecated\n\tprivate void restoreOldSavepointKeyedState(Collection<KeyedStateHandle> restoreState) throws Exception {\n\t\tcreateDB();\n\n\t\tPreconditions.checkState(1 == restoreState.size(), \"Only one element expected here.\");\n\n\t\tKeyedStateHandle keyedStateHandle = restoreState.iterator().next();\n\t\tif (!(keyedStateHandle instanceof MigrationKeyGroupStateHandle)) {\n\t\t\tthrow new IllegalStateException(\"Unexpected state handle type, \" +\n\t\t\t\t\t\"expected: \" + MigrationKeyGroupStateHandle.class +\n\t\t\t\t\t\", but found: \" + keyedStateHandle.getClass());\n\t\t}\n\n\t\tMigrationKeyGroupStateHandle keyGroupStateHandle = (MigrationKeyGroupStateHandle) keyedStateHandle;\n\n\t\tHashMap<String, RocksDBStateBackend.FinalFullyAsyncSnapshot> namedStates;\n\t\ttry (FSDataInputStream inputStream = keyGroupStateHandle.openInputStream()) {\n\t\t\tnamedStates = InstantiationUtil.deserializeObject(inputStream, userCodeClassLoader);\n\t\t}\n\n\t\tPreconditions.checkState(1 == namedStates.size(), \"Only one element expected here.\");\n\t\tDataInputView inputView = namedStates.values().iterator().next().stateHandle.getState(userCodeClassLoader);\n\n\t\t// clear k/v state information before filling it\n\t\tkvStateInformation.clear();\n\n\t\trestoredKvStateMetaInfos = new HashMap<>(namedStates.size());\n\n\t\t// first get the column family mapping\n\t\tint numColumns = inputView.readInt();\n\t\tMap<Byte, StateDescriptor<?, ?>> columnFamilyMapping = new HashMap<>(numColumns);\n\t\tfor (int i = 0; i < numColumns; i++) {\n\t\t\tbyte mappingByte = inputView.readByte();\n\n\t\t\tObjectInputStream ooIn =\n\t\t\t\t\tnew InstantiationUtil.ClassLoaderObjectInputStream(\n\t\t\t\t\t\t\tnew DataInputViewStream(inputView), userCodeClassLoader);\n\n\t\t\tStateDescriptor stateDescriptor = (StateDescriptor) ooIn.readObject();\n\n\t\t\tcolumnFamilyMapping.put(mappingByte, stateDescriptor);\n\n\t\t\t// mimic a restored kv state meta info\n\t\t\trestoredKvStateMetaInfos.put(\n\t\t\t\tstateDescriptor.getName(),\n\t\t\t\tnew RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\t\t\tstateDescriptor.getType(),\n\t\t\t\t\tstateDescriptor.getName(),\n\t\t\t\t\tMigrationNamespaceSerializerProxy.INSTANCE,\n\t\t\t\t\tstateDescriptor.getSerializer()).snapshot());\n\n\t\t\t// this will fill in the k/v state information\n\t\t\tgetColumnFamily(stateDescriptor, MigrationNamespaceSerializerProxy.INSTANCE);\n\t\t}\n\n\t\t// try and read until EOF\n\t\ttry {\n\t\t\t// the EOFException will get us out of this...\n\t\t\twhile (true) {\n\t\t\t\tbyte mappingByte = inputView.readByte();\n\t\t\t\tColumnFamilyHandle handle = getColumnFamily(\n\t\t\t\t\t\tcolumnFamilyMapping.get(mappingByte), MigrationNamespaceSerializerProxy.INSTANCE);\n\n\t\t\t\tbyte[] keyAndNamespace = BytePrimitiveArraySerializer.INSTANCE.deserialize(inputView);\n\n\t\t\t\tByteArrayInputStreamWithPos bis = new ByteArrayInputStreamWithPos(keyAndNamespace);\n\n\t\t\t\tK reconstructedKey = keySerializer.deserialize(new DataInputViewStreamWrapper(bis));\n\t\t\t\tint len = bis.getPosition();\n\n\t\t\t\tint keyGroup = (byte) KeyGroupRangeAssignment.assignToKeyGroup(reconstructedKey, numberOfKeyGroups);\n\n\t\t\t\tif (keyGroupPrefixBytes == 1) {\n\t\t\t\t\t// copy and override one byte (42) between key and namespace\n\t\t\t\t\tSystem.arraycopy(keyAndNamespace, 0, keyAndNamespace, 1, len);\n\t\t\t\t\tkeyAndNamespace[0] = (byte) keyGroup;\n\t\t\t\t} else {\n\t\t\t\t\tbyte[] largerKey = new byte[1 + keyAndNamespace.length];\n\n\t\t\t\t\t// write key-group\n\t\t\t\t\tlargerKey[0] = (byte) ((keyGroup >> 8) & 0xFF);\n\t\t\t\t\tlargerKey[1] = (byte) (keyGroup & 0xFF);\n\n\t\t\t\t\t// write key\n\t\t\t\t\tSystem.arraycopy(keyAndNamespace, 0, largerKey, 2, len);\n\n\t\t\t\t\t//skip one byte (42), write namespace\n\t\t\t\t\tSystem.arraycopy(keyAndNamespace, 1 + len, largerKey, 2 + len, keyAndNamespace.length - len - 1);\n\t\t\t\t\tkeyAndNamespace = largerKey;\n\t\t\t\t}\n\n\t\t\t\tbyte[] value = BytePrimitiveArraySerializer.INSTANCE.deserialize(inputView);\n\t\t\t\tdb.put(handle, keyAndNamespace, value);\n\t\t\t}\n\t\t} catch (EOFException e) {\n\t\t\t// expected\n\t\t}\n\t}",
            "1884  \n1885  \n1886  \n1887  \n1888  \n1889  \n1890  \n1891  \n1892  \n1893  \n1894  \n1895  \n1896  \n1897  \n1898  \n1899  \n1900  \n1901  \n1902  \n1903  \n1904  \n1905  \n1906  \n1907  \n1908  \n1909  \n1910  \n1911  \n1912  \n1913  \n1914  \n1915  \n1916  \n1917  \n1918  \n1919  \n1920  \n1921  \n1922  \n1923  \n1924  \n1925  \n1926  \n1927 +\n1928  \n1929  \n1930  \n1931  \n1932  \n1933  \n1934  \n1935  \n1936  \n1937  \n1938  \n1939  \n1940  \n1941  \n1942  \n1943  \n1944  \n1945  \n1946  \n1947  \n1948  \n1949  \n1950  \n1951  \n1952  \n1953  \n1954  \n1955  \n1956  \n1957  \n1958  \n1959  \n1960  \n1961  \n1962  \n1963  \n1964  \n1965  \n1966  \n1967  \n1968  \n1969  \n1970  \n1971  \n1972  \n1973  \n1974  \n1975  \n1976  \n1977  \n1978  \n1979  \n1980  \n1981  \n1982  \n1983  \n1984  \n1985  \n1986  ",
            "\t/**\n\t * For backwards compatibility, remove again later!\n\t *\n\t * @deprecated Internal method used for backwards compatibility.\n\t */\n\t@Deprecated\n\tprivate void restoreOldSavepointKeyedState(Collection<KeyedStateHandle> restoreState) throws Exception {\n\t\tcreateDB();\n\n\t\tPreconditions.checkState(1 == restoreState.size(), \"Only one element expected here.\");\n\n\t\tKeyedStateHandle keyedStateHandle = restoreState.iterator().next();\n\t\tif (!(keyedStateHandle instanceof MigrationKeyGroupStateHandle)) {\n\t\t\tthrow new IllegalStateException(\"Unexpected state handle type, \" +\n\t\t\t\t\t\"expected: \" + MigrationKeyGroupStateHandle.class +\n\t\t\t\t\t\", but found: \" + keyedStateHandle.getClass());\n\t\t}\n\n\t\tMigrationKeyGroupStateHandle keyGroupStateHandle = (MigrationKeyGroupStateHandle) keyedStateHandle;\n\n\t\tHashMap<String, RocksDBStateBackend.FinalFullyAsyncSnapshot> namedStates;\n\t\ttry (FSDataInputStream inputStream = keyGroupStateHandle.openInputStream()) {\n\t\t\tnamedStates = InstantiationUtil.deserializeObject(inputStream, userCodeClassLoader);\n\t\t}\n\n\t\tPreconditions.checkState(1 == namedStates.size(), \"Only one element expected here.\");\n\t\tDataInputView inputView = namedStates.values().iterator().next().stateHandle.getState(userCodeClassLoader);\n\n\t\t// clear k/v state information before filling it\n\t\tkvStateInformation.clear();\n\n\t\trestoredKvStateMetaInfos = new HashMap<>(namedStates.size());\n\n\t\t// first get the column family mapping\n\t\tint numColumns = inputView.readInt();\n\t\tMap<Byte, StateDescriptor<?, ?>> columnFamilyMapping = new HashMap<>(numColumns);\n\t\tfor (int i = 0; i < numColumns; i++) {\n\t\t\tbyte mappingByte = inputView.readByte();\n\n\t\t\tObjectInputStream ooIn =\n\t\t\t\t\tnew InstantiationUtil.ClassLoaderObjectInputStream(\n\t\t\t\t\t\t\tnew DataInputViewStream(inputView), userCodeClassLoader);\n\n\t\t\tStateDescriptor<?, ?> stateDescriptor = (StateDescriptor<?, ?>) ooIn.readObject();\n\n\t\t\tcolumnFamilyMapping.put(mappingByte, stateDescriptor);\n\n\t\t\t// mimic a restored kv state meta info\n\t\t\trestoredKvStateMetaInfos.put(\n\t\t\t\tstateDescriptor.getName(),\n\t\t\t\tnew RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\t\t\tstateDescriptor.getType(),\n\t\t\t\t\tstateDescriptor.getName(),\n\t\t\t\t\tMigrationNamespaceSerializerProxy.INSTANCE,\n\t\t\t\t\tstateDescriptor.getSerializer()).snapshot());\n\n\t\t\t// this will fill in the k/v state information\n\t\t\tgetColumnFamily(stateDescriptor, MigrationNamespaceSerializerProxy.INSTANCE);\n\t\t}\n\n\t\t// try and read until EOF\n\t\ttry {\n\t\t\t// the EOFException will get us out of this...\n\t\t\twhile (true) {\n\t\t\t\tbyte mappingByte = inputView.readByte();\n\t\t\t\tColumnFamilyHandle handle = getColumnFamily(\n\t\t\t\t\t\tcolumnFamilyMapping.get(mappingByte), MigrationNamespaceSerializerProxy.INSTANCE);\n\n\t\t\t\tbyte[] keyAndNamespace = BytePrimitiveArraySerializer.INSTANCE.deserialize(inputView);\n\n\t\t\t\tByteArrayInputStreamWithPos bis = new ByteArrayInputStreamWithPos(keyAndNamespace);\n\n\t\t\t\tK reconstructedKey = keySerializer.deserialize(new DataInputViewStreamWrapper(bis));\n\t\t\t\tint len = bis.getPosition();\n\n\t\t\t\tint keyGroup = (byte) KeyGroupRangeAssignment.assignToKeyGroup(reconstructedKey, numberOfKeyGroups);\n\n\t\t\t\tif (keyGroupPrefixBytes == 1) {\n\t\t\t\t\t// copy and override one byte (42) between key and namespace\n\t\t\t\t\tSystem.arraycopy(keyAndNamespace, 0, keyAndNamespace, 1, len);\n\t\t\t\t\tkeyAndNamespace[0] = (byte) keyGroup;\n\t\t\t\t} else {\n\t\t\t\t\tbyte[] largerKey = new byte[1 + keyAndNamespace.length];\n\n\t\t\t\t\t// write key-group\n\t\t\t\t\tlargerKey[0] = (byte) ((keyGroup >> 8) & 0xFF);\n\t\t\t\t\tlargerKey[1] = (byte) (keyGroup & 0xFF);\n\n\t\t\t\t\t// write key\n\t\t\t\t\tSystem.arraycopy(keyAndNamespace, 0, largerKey, 2, len);\n\n\t\t\t\t\t//skip one byte (42), write namespace\n\t\t\t\t\tSystem.arraycopy(keyAndNamespace, 1 + len, largerKey, 2 + len, keyAndNamespace.length - len - 1);\n\t\t\t\t\tkeyAndNamespace = largerKey;\n\t\t\t\t}\n\n\t\t\t\tbyte[] value = BytePrimitiveArraySerializer.INSTANCE.deserialize(inputView);\n\t\t\t\tdb.put(handle, keyAndNamespace, value);\n\t\t\t}\n\t\t} catch (EOFException e) {\n\t\t\t// expected\n\t\t}\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBFullSnapshotOperation::writeKVStateMetaData()",
            " 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604 -\n 605 -\n 606  \n 607  \n 608  ",
            "\t\tprivate void writeKVStateMetaData() throws IOException {\n\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> metaInfoSnapshots =\n\t\t\t\t\tnew ArrayList<>(stateBackend.kvStateInformation.size());\n\n\t\t\tint kvStateId = 0;\n\t\t\tfor (Map.Entry<String, Tuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>>> column :\n\t\t\t\t\tstateBackend.kvStateInformation.entrySet()) {\n\n\t\t\t\tmetaInfoSnapshots.add(column.getValue().f1.snapshot());\n\n\t\t\t\t//retrieve iterator for this k/v states\n\t\t\t\treadOptions = new ReadOptions();\n\t\t\t\treadOptions.setSnapshot(snapshot);\n\n\t\t\t\tkvStateIterators.add(\n\t\t\t\t\t\tnew Tuple2<>(stateBackend.db.newIterator(column.getValue().f0, readOptions), kvStateId));\n\n\t\t\t\t++kvStateId;\n\t\t\t}\n\n\t\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy(stateBackend.getKeySerializer(), metaInfoSnapshots);\n\n\t\t\tserializationProxy.write(outputView);\n\t\t}",
            " 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601 +\n 602 +\n 603  \n 604  \n 605  ",
            "\t\tprivate void writeKVStateMetaData() throws IOException {\n\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> metaInfoSnapshots =\n\t\t\t\t\tnew ArrayList<>(stateBackend.kvStateInformation.size());\n\n\t\t\tint kvStateId = 0;\n\t\t\tfor (Map.Entry<String, Tuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>>> column :\n\t\t\t\t\tstateBackend.kvStateInformation.entrySet()) {\n\n\t\t\t\tmetaInfoSnapshots.add(column.getValue().f1.snapshot());\n\n\t\t\t\t//retrieve iterator for this k/v states\n\t\t\t\treadOptions = new ReadOptions();\n\t\t\t\treadOptions.setSnapshot(snapshot);\n\n\t\t\t\tkvStateIterators.add(\n\t\t\t\t\t\tnew Tuple2<>(stateBackend.db.newIterator(column.getValue().f0, readOptions), kvStateId));\n\n\t\t\t\t++kvStateId;\n\t\t\t}\n\n\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy<>(stateBackend.getKeySerializer(), metaInfoSnapshots);\n\n\t\t\tserializationProxy.write(outputView);\n\t\t}"
        ],
        [
            "SerializationProxiesTest::testKeyedBackendSerializationProxyRoundtripWithSerializerSerializationFailures()",
            "  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106 -\n 107 -\n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116 -\n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  ",
            "\t@Test\n\tpublic void testKeyedBackendSerializationProxyRoundtripWithSerializerSerializationFailures() throws Exception {\n\n\t\tTypeSerializer<?> keySerializer = IntSerializer.INSTANCE;\n\t\tTypeSerializer<?> namespaceSerializer = LongSerializer.INSTANCE;\n\t\tTypeSerializer<?> stateSerializer = DoubleSerializer.INSTANCE;\n\n\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> stateMetaInfoList = new ArrayList<>();\n\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"a\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"b\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"c\", namespaceSerializer, stateSerializer).snapshot());\n\n\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\tnew KeyedBackendSerializationProxy(keySerializer, stateMetaInfoList);\n\n\t\tbyte[] serialized;\n\t\ttry (ByteArrayOutputStreamWithPos out = new ByteArrayOutputStreamWithPos()) {\n\t\t\tserializationProxy.write(new DataOutputViewStreamWrapper(out));\n\t\t\tserialized = out.toByteArray();\n\t\t}\n\n\t\tserializationProxy =\n\t\t\tnew KeyedBackendSerializationProxy(Thread.currentThread().getContextClassLoader());\n\n\t\t// mock failure when deserializing serializers\n\t\tTypeSerializerSerializationProxy<?> mockProxy = mock(TypeSerializerSerializationProxy.class);\n\t\tdoThrow(new IOException()).when(mockProxy).read(any(DataInputViewStreamWrapper.class));\n\t\tPowerMockito.whenNew(TypeSerializerSerializationProxy.class).withAnyArguments().thenReturn(mockProxy);\n\n\t\ttry (ByteArrayInputStreamWithPos in = new ByteArrayInputStreamWithPos(serialized)) {\n\t\t\tserializationProxy.read(new DataInputViewStreamWrapper(in));\n\t\t}\n\n\t\tAssert.assertEquals(null, serializationProxy.getKeySerializer());\n\t\tAssert.assertEquals(keySerializer.snapshotConfiguration(), serializationProxy.getKeySerializerConfigSnapshot());\n\n\t\tfor (RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?> meta : serializationProxy.getStateMetaInfoSnapshots()) {\n\t\t\tAssert.assertEquals(null, meta.getNamespaceSerializer());\n\t\t\tAssert.assertEquals(null, meta.getStateSerializer());\n\t\t\tAssert.assertEquals(namespaceSerializer.snapshotConfiguration(), meta.getNamespaceSerializerConfigSnapshot());\n\t\t\tAssert.assertEquals(stateSerializer.snapshotConfiguration(), meta.getStateSerializerConfigSnapshot());\n\t\t}\n\t}",
            "  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106 +\n 107 +\n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116 +\n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  ",
            "\t@Test\n\tpublic void testKeyedBackendSerializationProxyRoundtripWithSerializerSerializationFailures() throws Exception {\n\n\t\tTypeSerializer<?> keySerializer = IntSerializer.INSTANCE;\n\t\tTypeSerializer<?> namespaceSerializer = LongSerializer.INSTANCE;\n\t\tTypeSerializer<?> stateSerializer = DoubleSerializer.INSTANCE;\n\n\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> stateMetaInfoList = new ArrayList<>();\n\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"a\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"b\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"c\", namespaceSerializer, stateSerializer).snapshot());\n\n\t\tKeyedBackendSerializationProxy<?> serializationProxy =\n\t\t\tnew KeyedBackendSerializationProxy<>(keySerializer, stateMetaInfoList);\n\n\t\tbyte[] serialized;\n\t\ttry (ByteArrayOutputStreamWithPos out = new ByteArrayOutputStreamWithPos()) {\n\t\t\tserializationProxy.write(new DataOutputViewStreamWrapper(out));\n\t\t\tserialized = out.toByteArray();\n\t\t}\n\n\t\tserializationProxy =\n\t\t\tnew KeyedBackendSerializationProxy<>(Thread.currentThread().getContextClassLoader());\n\n\t\t// mock failure when deserializing serializers\n\t\tTypeSerializerSerializationProxy<?> mockProxy = mock(TypeSerializerSerializationProxy.class);\n\t\tdoThrow(new IOException()).when(mockProxy).read(any(DataInputViewStreamWrapper.class));\n\t\tPowerMockito.whenNew(TypeSerializerSerializationProxy.class).withAnyArguments().thenReturn(mockProxy);\n\n\t\ttry (ByteArrayInputStreamWithPos in = new ByteArrayInputStreamWithPos(serialized)) {\n\t\t\tserializationProxy.read(new DataInputViewStreamWrapper(in));\n\t\t}\n\n\t\tAssert.assertEquals(null, serializationProxy.getKeySerializer());\n\t\tAssert.assertEquals(keySerializer.snapshotConfiguration(), serializationProxy.getKeySerializerConfigSnapshot());\n\n\t\tfor (RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?> meta : serializationProxy.getStateMetaInfoSnapshots()) {\n\t\t\tAssert.assertEquals(null, meta.getNamespaceSerializer());\n\t\t\tAssert.assertEquals(null, meta.getStateSerializer());\n\t\t\tAssert.assertEquals(namespaceSerializer.snapshotConfiguration(), meta.getNamespaceSerializerConfigSnapshot());\n\t\t\tAssert.assertEquals(stateSerializer.snapshotConfiguration(), meta.getStateSerializerConfigSnapshot());\n\t\t}\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::snapshotFully(long,long,CheckpointStreamFactory)",
            " 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368 -\n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  ",
            "\tprivate RunnableFuture<KeyedStateHandle> snapshotFully(\n\t\t\tfinal long checkpointId,\n\t\t\tfinal long timestamp,\n\t\t\tfinal CheckpointStreamFactory streamFactory) throws Exception {\n\n\t\tlong startTime = System.currentTimeMillis();\n\n\t\tfinal RocksDBFullSnapshotOperation snapshotOperation = new RocksDBFullSnapshotOperation(this, streamFactory);\n\t\t// hold the db lock while operation on the db to guard us against async db disposal\n\t\tsynchronized (asyncSnapshotLock) {\n\n\t\t\tif (db != null) {\n\n\t\t\t\tif (!hasRegisteredState()) {\n\t\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\t\tLOG.debug(\"Asynchronous RocksDB snapshot performed on empty keyed state at \" + timestamp +\n\t\t\t\t\t\t\t\t\" . Returning null.\");\n\t\t\t\t\t}\n\t\t\t\t\treturn DoneFuture.nullValue();\n\t\t\t\t}\n\n\t\t\t\tsnapshotOperation.takeDBSnapShot(checkpointId, timestamp);\n\t\t\t} else {\n\t\t\t\tthrow new IOException(\"RocksDB closed.\");\n\t\t\t}\n\t\t}\n\n\t\t// implementation of the async IO operation, based on FutureTask\n\t\tAbstractAsyncIOCallable<KeyedStateHandle, CheckpointStreamFactory.CheckpointStateOutputStream> ioCallable =\n\t\t\t\tnew AbstractAsyncIOCallable<KeyedStateHandle, CheckpointStreamFactory.CheckpointStateOutputStream>() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream openIOHandle() throws Exception {\n\t\t\t\t\t\tsnapshotOperation.openCheckpointStream();\n\t\t\t\t\t\treturn snapshotOperation.getOutStream();\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic KeyGroupsStateHandle performOperation() throws Exception {\n\t\t\t\t\t\tlong startTime = System.currentTimeMillis();\n\t\t\t\t\t\tsynchronized (asyncSnapshotLock) {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t// hold the db lock while operation on the db to guard us against async db disposal\n\t\t\t\t\t\t\t\tif (db == null) {\n\t\t\t\t\t\t\t\t\tthrow new IOException(\"RocksDB closed.\");\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tsnapshotOperation.writeDBSnapshot();\n\n\t\t\t\t\t\t\t} finally {\n\t\t\t\t\t\t\t\tsnapshotOperation.closeCheckpointStream();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tLOG.info(\"Asynchronous RocksDB snapshot ({}, asynchronous part) in thread {} took {} ms.\",\n\t\t\t\t\t\t\tstreamFactory, Thread.currentThread(), (System.currentTimeMillis() - startTime));\n\n\t\t\t\t\t\treturn snapshotOperation.getSnapshotResultStateHandle();\n\t\t\t\t\t}\n\n\t\t\t\t\tprivate void releaseSnapshotOperationResources(boolean canceled) {\n\t\t\t\t\t\t// hold the db lock while operation on the db to guard us against async db disposal\n\t\t\t\t\t\tsynchronized (asyncSnapshotLock) {\n\t\t\t\t\t\t\tsnapshotOperation.releaseSnapshotResources(canceled);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void done(boolean canceled) {\n\t\t\t\t\t\treleaseSnapshotOperationResources(canceled);\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\tLOG.info(\"Asynchronous RocksDB snapshot (\" + streamFactory + \", synchronous part) in thread \" +\n\t\t\t\tThread.currentThread() + \" took \" + (System.currentTimeMillis() - startTime) + \" ms.\");\n\n\t\treturn AsyncStoppableTaskWithCallback.from(ioCallable);\n\t}",
            " 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365 +\n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  ",
            "\tprivate RunnableFuture<KeyedStateHandle> snapshotFully(\n\t\t\tfinal long checkpointId,\n\t\t\tfinal long timestamp,\n\t\t\tfinal CheckpointStreamFactory streamFactory) throws Exception {\n\n\t\tlong startTime = System.currentTimeMillis();\n\n\t\tfinal RocksDBFullSnapshotOperation<K> snapshotOperation = new RocksDBFullSnapshotOperation<>(this, streamFactory);\n\t\t// hold the db lock while operation on the db to guard us against async db disposal\n\t\tsynchronized (asyncSnapshotLock) {\n\n\t\t\tif (db != null) {\n\n\t\t\t\tif (!hasRegisteredState()) {\n\t\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\t\tLOG.debug(\"Asynchronous RocksDB snapshot performed on empty keyed state at \" + timestamp +\n\t\t\t\t\t\t\t\t\" . Returning null.\");\n\t\t\t\t\t}\n\t\t\t\t\treturn DoneFuture.nullValue();\n\t\t\t\t}\n\n\t\t\t\tsnapshotOperation.takeDBSnapShot(checkpointId, timestamp);\n\t\t\t} else {\n\t\t\t\tthrow new IOException(\"RocksDB closed.\");\n\t\t\t}\n\t\t}\n\n\t\t// implementation of the async IO operation, based on FutureTask\n\t\tAbstractAsyncIOCallable<KeyedStateHandle, CheckpointStreamFactory.CheckpointStateOutputStream> ioCallable =\n\t\t\t\tnew AbstractAsyncIOCallable<KeyedStateHandle, CheckpointStreamFactory.CheckpointStateOutputStream>() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic CheckpointStreamFactory.CheckpointStateOutputStream openIOHandle() throws Exception {\n\t\t\t\t\t\tsnapshotOperation.openCheckpointStream();\n\t\t\t\t\t\treturn snapshotOperation.getOutStream();\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic KeyGroupsStateHandle performOperation() throws Exception {\n\t\t\t\t\t\tlong startTime = System.currentTimeMillis();\n\t\t\t\t\t\tsynchronized (asyncSnapshotLock) {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t// hold the db lock while operation on the db to guard us against async db disposal\n\t\t\t\t\t\t\t\tif (db == null) {\n\t\t\t\t\t\t\t\t\tthrow new IOException(\"RocksDB closed.\");\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tsnapshotOperation.writeDBSnapshot();\n\n\t\t\t\t\t\t\t} finally {\n\t\t\t\t\t\t\t\tsnapshotOperation.closeCheckpointStream();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tLOG.info(\"Asynchronous RocksDB snapshot ({}, asynchronous part) in thread {} took {} ms.\",\n\t\t\t\t\t\t\tstreamFactory, Thread.currentThread(), (System.currentTimeMillis() - startTime));\n\n\t\t\t\t\t\treturn snapshotOperation.getSnapshotResultStateHandle();\n\t\t\t\t\t}\n\n\t\t\t\t\tprivate void releaseSnapshotOperationResources(boolean canceled) {\n\t\t\t\t\t\t// hold the db lock while operation on the db to guard us against async db disposal\n\t\t\t\t\t\tsynchronized (asyncSnapshotLock) {\n\t\t\t\t\t\t\tsnapshotOperation.releaseSnapshotResources(canceled);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void done(boolean canceled) {\n\t\t\t\t\t\treleaseSnapshotOperationResources(canceled);\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\tLOG.info(\"Asynchronous RocksDB snapshot (\" + streamFactory + \", synchronous part) in thread \" +\n\t\t\t\tThread.currentThread() + \" took \" + (System.currentTimeMillis() - startTime) + \" ms.\");\n\n\t\treturn AsyncStoppableTaskWithCallback.from(ioCallable);\n\t}"
        ],
        [
            "KeyedBackendSerializationProxy::read(DataInputView)",
            " 121  \n 122  \n 123  \n 124  \n 125 -\n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  ",
            "\t@Override\n\tpublic void read(DataInputView in) throws IOException {\n\t\tsuper.read(in);\n\n\t\tfinal TypeSerializerSerializationProxy<?> keySerializerProxy =\n\t\t\tnew TypeSerializerSerializationProxy<>(userCodeClassLoader);\n\n\t\t// only starting from version 3, we have the key serializer and its config snapshot written\n\t\tif (getReadVersion() >= 3) {\n\t\t\tint keySerializerConfigSnapshotOffset = in.readInt();\n\t\t\tint numBufferedBytes = in.readInt();\n\t\t\tbyte[] keySerializerAndConfigBytes = new byte[numBufferedBytes];\n\t\t\tin.readFully(keySerializerAndConfigBytes);\n\n\t\t\ttry (\n\t\t\t\tByteArrayInputStreamWithPos buffer = new ByteArrayInputStreamWithPos(keySerializerAndConfigBytes);\n\t\t\t\tDataInputViewStreamWrapper bufferWrapper = new DataInputViewStreamWrapper(buffer)) {\n\n\t\t\t\ttry {\n\t\t\t\t\tkeySerializerProxy.read(bufferWrapper);\n\t\t\t\t\tthis.keySerializer = keySerializerProxy.getTypeSerializer();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tthis.keySerializer = null;\n\t\t\t\t}\n\n\t\t\t\tbuffer.setPosition(keySerializerConfigSnapshotOffset);\n\t\t\t\tthis.keySerializerConfigSnapshot =\n\t\t\t\t\tTypeSerializerUtil.readSerializerConfigSnapshot(bufferWrapper, userCodeClassLoader);\n\t\t\t}\n\t\t} else {\n\t\t\tkeySerializerProxy.read(in);\n\t\t\tthis.keySerializer = keySerializerProxy.getTypeSerializer();\n\t\t\tthis.keySerializerConfigSnapshot = null;\n\t\t}\n\n\t\tint numKvStates = in.readShort();\n\t\tstateMetaInfoSnapshots = new ArrayList<>(numKvStates);\n\t\tfor (int i = 0; i < numKvStates; i++) {\n\t\t\tstateMetaInfoSnapshots.add(\n\t\t\t\tKeyedBackendStateMetaInfoSnapshotReaderWriters\n\t\t\t\t\t.getReaderForVersion(getReadVersion(), userCodeClassLoader)\n\t\t\t\t\t.readStateMetaInfo(in));\n\t\t}\n\t}",
            " 121  \n 122  \n 123  \n 124  \n 125 +\n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  ",
            "\t@Override\n\tpublic void read(DataInputView in) throws IOException {\n\t\tsuper.read(in);\n\n\t\tfinal TypeSerializerSerializationProxy<K> keySerializerProxy =\n\t\t\tnew TypeSerializerSerializationProxy<>(userCodeClassLoader);\n\n\t\t// only starting from version 3, we have the key serializer and its config snapshot written\n\t\tif (getReadVersion() >= 3) {\n\t\t\tint keySerializerConfigSnapshotOffset = in.readInt();\n\t\t\tint numBufferedBytes = in.readInt();\n\t\t\tbyte[] keySerializerAndConfigBytes = new byte[numBufferedBytes];\n\t\t\tin.readFully(keySerializerAndConfigBytes);\n\n\t\t\ttry (\n\t\t\t\tByteArrayInputStreamWithPos buffer = new ByteArrayInputStreamWithPos(keySerializerAndConfigBytes);\n\t\t\t\tDataInputViewStreamWrapper bufferWrapper = new DataInputViewStreamWrapper(buffer)) {\n\n\t\t\t\ttry {\n\t\t\t\t\tkeySerializerProxy.read(bufferWrapper);\n\t\t\t\t\tthis.keySerializer = keySerializerProxy.getTypeSerializer();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tthis.keySerializer = null;\n\t\t\t\t}\n\n\t\t\t\tbuffer.setPosition(keySerializerConfigSnapshotOffset);\n\t\t\t\tthis.keySerializerConfigSnapshot =\n\t\t\t\t\tTypeSerializerUtil.readSerializerConfigSnapshot(bufferWrapper, userCodeClassLoader);\n\t\t\t}\n\t\t} else {\n\t\t\tkeySerializerProxy.read(in);\n\t\t\tthis.keySerializer = keySerializerProxy.getTypeSerializer();\n\t\t\tthis.keySerializerConfigSnapshot = null;\n\t\t}\n\n\t\tint numKvStates = in.readShort();\n\t\tstateMetaInfoSnapshots = new ArrayList<>(numKvStates);\n\t\tfor (int i = 0; i < numKvStates; i++) {\n\t\t\tstateMetaInfoSnapshots.add(\n\t\t\t\tKeyedBackendStateMetaInfoSnapshotReaderWriters\n\t\t\t\t\t.getReaderForVersion(getReadVersion(), userCodeClassLoader)\n\t\t\t\t\t.readStateMetaInfo(in));\n\t\t}\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBKeyedStateBackend(JobID,String,ClassLoader,File,DBOptions,ColumnFamilyOptions,TaskKvStateRegistry,TypeSerializer,int,KeyGroupRange,ExecutionConfig,boolean)",
            " 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201 -\n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  ",
            "\tpublic RocksDBKeyedStateBackend(\n\t\t\tJobID jobId,\n\t\t\tString operatorIdentifier,\n\t\t\tClassLoader userCodeClassLoader,\n\t\t\tFile instanceBasePath,\n\t\t\tDBOptions dbOptions,\n\t\t\tColumnFamilyOptions columnFamilyOptions,\n\t\t\tTaskKvStateRegistry kvStateRegistry,\n\t\t\tTypeSerializer<K> keySerializer,\n\t\t\tint numberOfKeyGroups,\n\t\t\tKeyGroupRange keyGroupRange,\n\t\t\tExecutionConfig executionConfig,\n\t\t\tboolean enableIncrementalCheckpointing\n\t) throws IOException {\n\n\t\tsuper(kvStateRegistry, keySerializer, userCodeClassLoader, numberOfKeyGroups, keyGroupRange, executionConfig);\n\n\t\tthis.jobId = Preconditions.checkNotNull(jobId);\n\t\tthis.operatorIdentifier = Preconditions.checkNotNull(operatorIdentifier);\n\n\t\tthis.enableIncrementalCheckpointing = enableIncrementalCheckpointing;\n\n\t\tthis.columnOptions = Preconditions.checkNotNull(columnFamilyOptions);\n\t\tthis.dbOptions = Preconditions.checkNotNull(dbOptions);\n\n\t\tthis.instanceBasePath = Preconditions.checkNotNull(instanceBasePath);\n\t\tthis.instanceRocksDBPath = new File(instanceBasePath, \"db\");\n\n\t\tif (!instanceBasePath.exists()) {\n\t\t\tif (!instanceBasePath.mkdirs()) {\n\t\t\t\tthrow new IOException(\"Could not create RocksDB data directory.\");\n\t\t\t}\n\t\t}\n\n\t\t// clean it, this will remove the last part of the path but RocksDB will recreate it\n\t\ttry {\n\t\t\tif (instanceRocksDBPath.exists()) {\n\t\t\t\tLOG.warn(\"Deleting already existing db directory {}.\", instanceRocksDBPath);\n\t\t\t\tFileUtils.deleteDirectory(instanceRocksDBPath);\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new IOException(\"Error cleaning RocksDB data directory.\", e);\n\t\t}\n\n\t\tkeyGroupPrefixBytes = getNumberOfKeyGroups() > (Byte.MAX_VALUE + 1) ? 2 : 1;\n\t\tkvStateInformation = new HashMap<>();\n\t}",
            " 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  ",
            "\tpublic RocksDBKeyedStateBackend(\n\t\t\tJobID jobId,\n\t\t\tString operatorIdentifier,\n\t\t\tClassLoader userCodeClassLoader,\n\t\t\tFile instanceBasePath,\n\t\t\tDBOptions dbOptions,\n\t\t\tColumnFamilyOptions columnFamilyOptions,\n\t\t\tTaskKvStateRegistry kvStateRegistry,\n\t\t\tTypeSerializer<K> keySerializer,\n\t\t\tint numberOfKeyGroups,\n\t\t\tKeyGroupRange keyGroupRange,\n\t\t\tExecutionConfig executionConfig,\n\t\t\tboolean enableIncrementalCheckpointing\n\t) throws IOException {\n\n\t\tsuper(kvStateRegistry, keySerializer, userCodeClassLoader, numberOfKeyGroups, keyGroupRange, executionConfig);\n\n\t\tthis.operatorIdentifier = Preconditions.checkNotNull(operatorIdentifier);\n\n\t\tthis.enableIncrementalCheckpointing = enableIncrementalCheckpointing;\n\n\t\tthis.columnOptions = Preconditions.checkNotNull(columnFamilyOptions);\n\t\tthis.dbOptions = Preconditions.checkNotNull(dbOptions);\n\n\t\tthis.instanceBasePath = Preconditions.checkNotNull(instanceBasePath);\n\t\tthis.instanceRocksDBPath = new File(instanceBasePath, \"db\");\n\n\t\tif (!instanceBasePath.exists()) {\n\t\t\tif (!instanceBasePath.mkdirs()) {\n\t\t\t\tthrow new IOException(\"Could not create RocksDB data directory.\");\n\t\t\t}\n\t\t}\n\n\t\t// clean it, this will remove the last part of the path but RocksDB will recreate it\n\t\ttry {\n\t\t\tif (instanceRocksDBPath.exists()) {\n\t\t\t\tLOG.warn(\"Deleting already existing db directory {}.\", instanceRocksDBPath);\n\t\t\t\tFileUtils.deleteDirectory(instanceRocksDBPath);\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new IOException(\"Error cleaning RocksDB data directory.\", e);\n\t\t}\n\n\t\tkeyGroupPrefixBytes = getNumberOfKeyGroups() > (Byte.MAX_VALUE + 1) ? 2 : 1;\n\t\tkvStateInformation = new HashMap<>();\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBIncrementalSnapshotOperation::RocksDBIncrementalSnapshotOperation(RocksDBKeyedStateBackend,CheckpointStreamFactory,long,long)",
            " 750  \n 751 -\n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760  ",
            "\t\tprivate RocksDBIncrementalSnapshotOperation(\n\t\t\t\tRocksDBKeyedStateBackend<?> stateBackend,\n\t\t\t\tCheckpointStreamFactory checkpointStreamFactory,\n\t\t\t\tlong checkpointId,\n\t\t\t\tlong checkpointTimestamp) {\n\n\t\t\tthis.stateBackend = stateBackend;\n\t\t\tthis.checkpointStreamFactory = checkpointStreamFactory;\n\t\t\tthis.checkpointId = checkpointId;\n\t\t\tthis.checkpointTimestamp = checkpointTimestamp;\n\t\t}",
            " 747  \n 748 +\n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  ",
            "\t\tprivate RocksDBIncrementalSnapshotOperation(\n\t\t\t\tRocksDBKeyedStateBackend<K> stateBackend,\n\t\t\t\tCheckpointStreamFactory checkpointStreamFactory,\n\t\t\t\tlong checkpointId,\n\t\t\t\tlong checkpointTimestamp) {\n\n\t\t\tthis.stateBackend = stateBackend;\n\t\t\tthis.checkpointStreamFactory = checkpointStreamFactory;\n\t\t\tthis.checkpointId = checkpointId;\n\t\t\tthis.checkpointTimestamp = checkpointTimestamp;\n\t\t}"
        ],
        [
            "HeapKeyedStateBackend::restorePartitionedState(Collection)",
            " 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386 -\n 387 -\n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398 -\n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408 -\n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  ",
            "\t@SuppressWarnings({\"unchecked\"})\n\tprivate void restorePartitionedState(Collection<KeyedStateHandle> state) throws Exception {\n\n\t\tfinal Map<Integer, String> kvStatesById = new HashMap<>();\n\t\tint numRegisteredKvStates = 0;\n\t\tstateTables.clear();\n\n\t\tboolean keySerializerRestored = false;\n\n\t\tfor (KeyedStateHandle keyedStateHandle : state) {\n\n\t\t\tif (keyedStateHandle == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(keyedStateHandle instanceof KeyGroupsStateHandle)) {\n\t\t\t\tthrow new IllegalStateException(\"Unexpected state handle type, \" +\n\t\t\t\t\t\t\"expected: \" + KeyGroupsStateHandle.class +\n\t\t\t\t\t\t\", but found: \" + keyedStateHandle.getClass());\n\t\t\t}\n\n\t\t\tKeyGroupsStateHandle keyGroupsStateHandle = (KeyGroupsStateHandle) keyedStateHandle;\n\t\t\tFSDataInputStream fsDataInputStream = keyGroupsStateHandle.openInputStream();\n\t\t\tcancelStreamRegistry.registerClosable(fsDataInputStream);\n\n\t\t\ttry {\n\t\t\t\tDataInputViewStreamWrapper inView = new DataInputViewStreamWrapper(fsDataInputStream);\n\n\t\t\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\t\t\t\tnew KeyedBackendSerializationProxy(userCodeClassLoader);\n\n\t\t\t\tserializationProxy.read(inView);\n\n\t\t\t\tif (!keySerializerRestored) {\n\t\t\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\t\t\tif (StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\t\tserializationProxy.getKeySerializer(),\n\t\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\t\tserializationProxy.getKeySerializerConfigSnapshot(),\n\t\t\t\t\t\t(TypeSerializer) keySerializer)\n\t\t\t\t\t\t.isRequiresMigration()) {\n\n\t\t\t\t\t\t// TODO replace with state migration; note that key hash codes need to remain the same after migration\n\t\t\t\t\t\tthrow new RuntimeException(\"The new key serializer is not compatible to read previous keys. \" +\n\t\t\t\t\t\t\t\"Aborting now since state migration is currently not available\");\n\t\t\t\t\t}\n\n\t\t\t\t\tkeySerializerRestored = true;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> restoredMetaInfos =\n\t\t\t\t\t\tserializationProxy.getStateMetaInfoSnapshots();\n\n\t\t\t\tfor (RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?> restoredMetaInfo : restoredMetaInfos) {\n\n\t\t\t\t\tif (restoredMetaInfo.getStateSerializer() == null ||\n\t\t\t\t\t\t\trestoredMetaInfo.getStateSerializer()\n\t\t\t\t\t\t\t\tinstanceof TypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer) {\n\n\t\t\t\t\t\t// must fail now if the previous serializer cannot be restored because there is no serializer\n\t\t\t\t\t\t// capable of reading previous state\n\t\t\t\t\t\t// TODO when eager state registration is in place, we can try to get a convert deserializer\n\t\t\t\t\t\t// TODO from the newly registered serializer instead of simply failing here\n\n\t\t\t\t\t\tthrow new IOException(\"Unable to restore keyed state [\" + restoredMetaInfo.getName() + \"].\" +\n\t\t\t\t\t\t\t\" For memory-backed keyed state, the previous serializer of the keyed state must be\" +\n\t\t\t\t\t\t\t\" present; the serializer could have been removed from the classpath, or its implementation\" +\n\t\t\t\t\t\t\t\" have changed and could not be loaded. This is a temporary restriction that will be fixed\" +\n\t\t\t\t\t\t\t\" in future versions.\");\n\t\t\t\t\t}\n\n\t\t\t\t\tStateTable<K, ?, ?> stateTable = stateTables.get(restoredMetaInfo.getName());\n\n\t\t\t\t\t//important: only create a new table we did not already create it previously\n\t\t\t\t\tif (null == stateTable) {\n\n\t\t\t\t\t\tRegisteredKeyedBackendStateMetaInfo<?, ?> registeredKeyedBackendStateMetaInfo =\n\t\t\t\t\t\t\t\tnew RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getStateType(),\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getName(),\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getNamespaceSerializer(),\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getStateSerializer());\n\n\t\t\t\t\t\tstateTable = newStateTable(registeredKeyedBackendStateMetaInfo);\n\t\t\t\t\t\tstateTables.put(restoredMetaInfo.getName(), stateTable);\n\t\t\t\t\t\tkvStatesById.put(numRegisteredKvStates, restoredMetaInfo.getName());\n\t\t\t\t\t\t++numRegisteredKvStates;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfor (Tuple2<Integer, Long> groupOffset : keyGroupsStateHandle.getGroupRangeOffsets()) {\n\t\t\t\t\tint keyGroupIndex = groupOffset.f0;\n\t\t\t\t\tlong offset = groupOffset.f1;\n\n\t\t\t\t\t// Check that restored key groups all belong to the backend.\n\t\t\t\t\tPreconditions.checkState(keyGroupRange.contains(keyGroupIndex), \"The key group must belong to the backend.\");\n\n\t\t\t\t\tfsDataInputStream.seek(offset);\n\n\t\t\t\t\tint writtenKeyGroupIndex = inView.readInt();\n\n\t\t\t\t\tPreconditions.checkState(writtenKeyGroupIndex == keyGroupIndex,\n\t\t\t\t\t\t\t\"Unexpected key-group in restore.\");\n\n\t\t\t\t\tfor (int i = 0; i < restoredMetaInfos.size(); i++) {\n\t\t\t\t\t\tint kvStateId = inView.readShort();\n\t\t\t\t\t\tStateTable<K, ?, ?> stateTable = stateTables.get(kvStatesById.get(kvStateId));\n\n\t\t\t\t\t\tStateTableByKeyGroupReader keyGroupReader =\n\t\t\t\t\t\t\t\tStateTableByKeyGroupReaders.readerForVersion(\n\t\t\t\t\t\t\t\t\t\tstateTable,\n\t\t\t\t\t\t\t\t\t\tserializationProxy.getReadVersion());\n\n\t\t\t\t\t\tkeyGroupReader.readMappingsInKeyGroup(inView, keyGroupIndex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} finally {\n\t\t\t\tcancelStreamRegistry.unregisterClosable(fsDataInputStream);\n\t\t\t\tIOUtils.closeQuietly(fsDataInputStream);\n\t\t\t}\n\t\t}\n\t}",
            " 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386 +\n 387 +\n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398 +\n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408 +\n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  ",
            "\t@SuppressWarnings({\"unchecked\"})\n\tprivate void restorePartitionedState(Collection<KeyedStateHandle> state) throws Exception {\n\n\t\tfinal Map<Integer, String> kvStatesById = new HashMap<>();\n\t\tint numRegisteredKvStates = 0;\n\t\tstateTables.clear();\n\n\t\tboolean keySerializerRestored = false;\n\n\t\tfor (KeyedStateHandle keyedStateHandle : state) {\n\n\t\t\tif (keyedStateHandle == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(keyedStateHandle instanceof KeyGroupsStateHandle)) {\n\t\t\t\tthrow new IllegalStateException(\"Unexpected state handle type, \" +\n\t\t\t\t\t\t\"expected: \" + KeyGroupsStateHandle.class +\n\t\t\t\t\t\t\", but found: \" + keyedStateHandle.getClass());\n\t\t\t}\n\n\t\t\tKeyGroupsStateHandle keyGroupsStateHandle = (KeyGroupsStateHandle) keyedStateHandle;\n\t\t\tFSDataInputStream fsDataInputStream = keyGroupsStateHandle.openInputStream();\n\t\t\tcancelStreamRegistry.registerClosable(fsDataInputStream);\n\n\t\t\ttry {\n\t\t\t\tDataInputViewStreamWrapper inView = new DataInputViewStreamWrapper(fsDataInputStream);\n\n\t\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\t\t\tnew KeyedBackendSerializationProxy<>(userCodeClassLoader);\n\n\t\t\t\tserializationProxy.read(inView);\n\n\t\t\t\tif (!keySerializerRestored) {\n\t\t\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\t\t\tif (StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\t\tserializationProxy.getKeySerializer(),\n\t\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\t\tserializationProxy.getKeySerializerConfigSnapshot(),\n\t\t\t\t\t\tkeySerializer)\n\t\t\t\t\t\t.isRequiresMigration()) {\n\n\t\t\t\t\t\t// TODO replace with state migration; note that key hash codes need to remain the same after migration\n\t\t\t\t\t\tthrow new RuntimeException(\"The new key serializer is not compatible to read previous keys. \" +\n\t\t\t\t\t\t\t\"Aborting now since state migration is currently not available\");\n\t\t\t\t\t}\n\n\t\t\t\t\tkeySerializerRestored = true;\n\t\t\t\t}\n\n\t\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> restoredMetaInfos =\n\t\t\t\t\t\tserializationProxy.getStateMetaInfoSnapshots();\n\n\t\t\t\tfor (RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?> restoredMetaInfo : restoredMetaInfos) {\n\n\t\t\t\t\tif (restoredMetaInfo.getStateSerializer() == null ||\n\t\t\t\t\t\t\trestoredMetaInfo.getStateSerializer()\n\t\t\t\t\t\t\t\tinstanceof TypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer) {\n\n\t\t\t\t\t\t// must fail now if the previous serializer cannot be restored because there is no serializer\n\t\t\t\t\t\t// capable of reading previous state\n\t\t\t\t\t\t// TODO when eager state registration is in place, we can try to get a convert deserializer\n\t\t\t\t\t\t// TODO from the newly registered serializer instead of simply failing here\n\n\t\t\t\t\t\tthrow new IOException(\"Unable to restore keyed state [\" + restoredMetaInfo.getName() + \"].\" +\n\t\t\t\t\t\t\t\" For memory-backed keyed state, the previous serializer of the keyed state must be\" +\n\t\t\t\t\t\t\t\" present; the serializer could have been removed from the classpath, or its implementation\" +\n\t\t\t\t\t\t\t\" have changed and could not be loaded. This is a temporary restriction that will be fixed\" +\n\t\t\t\t\t\t\t\" in future versions.\");\n\t\t\t\t\t}\n\n\t\t\t\t\tStateTable<K, ?, ?> stateTable = stateTables.get(restoredMetaInfo.getName());\n\n\t\t\t\t\t//important: only create a new table we did not already create it previously\n\t\t\t\t\tif (null == stateTable) {\n\n\t\t\t\t\t\tRegisteredKeyedBackendStateMetaInfo<?, ?> registeredKeyedBackendStateMetaInfo =\n\t\t\t\t\t\t\t\tnew RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getStateType(),\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getName(),\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getNamespaceSerializer(),\n\t\t\t\t\t\t\t\t\trestoredMetaInfo.getStateSerializer());\n\n\t\t\t\t\t\tstateTable = newStateTable(registeredKeyedBackendStateMetaInfo);\n\t\t\t\t\t\tstateTables.put(restoredMetaInfo.getName(), stateTable);\n\t\t\t\t\t\tkvStatesById.put(numRegisteredKvStates, restoredMetaInfo.getName());\n\t\t\t\t\t\t++numRegisteredKvStates;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfor (Tuple2<Integer, Long> groupOffset : keyGroupsStateHandle.getGroupRangeOffsets()) {\n\t\t\t\t\tint keyGroupIndex = groupOffset.f0;\n\t\t\t\t\tlong offset = groupOffset.f1;\n\n\t\t\t\t\t// Check that restored key groups all belong to the backend.\n\t\t\t\t\tPreconditions.checkState(keyGroupRange.contains(keyGroupIndex), \"The key group must belong to the backend.\");\n\n\t\t\t\t\tfsDataInputStream.seek(offset);\n\n\t\t\t\t\tint writtenKeyGroupIndex = inView.readInt();\n\n\t\t\t\t\tPreconditions.checkState(writtenKeyGroupIndex == keyGroupIndex,\n\t\t\t\t\t\t\t\"Unexpected key-group in restore.\");\n\n\t\t\t\t\tfor (int i = 0; i < restoredMetaInfos.size(); i++) {\n\t\t\t\t\t\tint kvStateId = inView.readShort();\n\t\t\t\t\t\tStateTable<K, ?, ?> stateTable = stateTables.get(kvStatesById.get(kvStateId));\n\n\t\t\t\t\t\tStateTableByKeyGroupReader keyGroupReader =\n\t\t\t\t\t\t\t\tStateTableByKeyGroupReaders.readerForVersion(\n\t\t\t\t\t\t\t\t\t\tstateTable,\n\t\t\t\t\t\t\t\t\t\tserializationProxy.getReadVersion());\n\n\t\t\t\t\t\tkeyGroupReader.readMappingsInKeyGroup(inView, keyGroupIndex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} finally {\n\t\t\t\tcancelStreamRegistry.unregisterClosable(fsDataInputStream);\n\t\t\t\tIOUtils.closeQuietly(fsDataInputStream);\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBIncrementalRestoreOperation::RocksDBIncrementalRestoreOperation(RocksDBKeyedStateBackend)",
            "1228 -\n1229  \n1230  ",
            "\t\tprivate RocksDBIncrementalRestoreOperation(RocksDBKeyedStateBackend<?> stateBackend) {\n\t\t\tthis.stateBackend = stateBackend;\n\t\t}",
            "1224 +\n1225  \n1226  ",
            "\t\tprivate RocksDBIncrementalRestoreOperation(RocksDBKeyedStateBackend<T> stateBackend) {\n\t\t\tthis.stateBackend = stateBackend;\n\t\t}"
        ],
        [
            "RocksDBKeyedStateBackend::getColumnFamily(StateDescriptor,TypeSerializer)",
            "1513  \n1514  \n1515  \n1516  \n1517  \n1518  \n1519  \n1520  \n1521  \n1522  \n1523  \n1524  \n1525  \n1526  \n1527  \n1528  \n1529  \n1530  \n1531  \n1532  \n1533  \n1534  \n1535  \n1536  \n1537  \n1538  \n1539 -\n1540  \n1541  \n1542  \n1543  \n1544  \n1545  \n1546  \n1547  \n1548  \n1549  \n1550  \n1551  \n1552  \n1553  \n1554  \n1555  \n1556  \n1557  \n1558  \n1559 -\n1560  \n1561  \n1562  \n1563  \n1564  \n1565  \n1566  \n1567  \n1568  \n1569  \n1570  \n1571  \n1572  \n1573  \n1574  \n1575  \n1576  \n1577  \n1578  \n1579  \n1580  \n1581  \n1582  \n1583  \n1584  \n1585  \n1586  \n1587  \n1588  \n1589  \n1590  \n1591  \n1592  \n1593  ",
            "\t/**\n\t * Creates a column family handle for use with a k/v state. When restoring from a snapshot\n\t * we don't restore the individual k/v states, just the global RocksDB data base and the\n\t * list of column families. When a k/v state is first requested we check here whether we\n\t * already have a column family for that and return it or create a new one if it doesn't exist.\n\t *\n\t * <p>This also checks whether the {@link StateDescriptor} for a state matches the one\n\t * that we checkpointed, i.e. is already in the map of column families.\n\t */\n\t@SuppressWarnings(\"rawtypes, unchecked\")\n\tprotected <N, S> ColumnFamilyHandle getColumnFamily(\n\t\t\tStateDescriptor<?, S> descriptor, TypeSerializer<N> namespaceSerializer) throws IOException {\n\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>> stateInfo =\n\t\t\t\tkvStateInformation.get(descriptor.getName());\n\n\t\tRegisteredKeyedBackendStateMetaInfo<N, S> newMetaInfo = new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tdescriptor.getType(),\n\t\t\tdescriptor.getName(),\n\t\t\tnamespaceSerializer,\n\t\t\tdescriptor.getSerializer());\n\n\t\tif (stateInfo != null) {\n\t\t\t// TODO with eager registration in place, these checks should be moved to restore()\n\n\t\t\tRegisteredKeyedBackendStateMetaInfo.Snapshot<N, S> restoredMetaInfo =\n\t\t\t\trestoredKvStateMetaInfos.get(descriptor.getName());\n\n\t\t\tPreconditions.checkState(\n\t\t\t\tnewMetaInfo.getName().equals(restoredMetaInfo.getName()),\n\t\t\t\t\"Incompatible state names. \" +\n\t\t\t\t\t\"Was [\" + restoredMetaInfo.getName() + \"], \" +\n\t\t\t\t\t\"registered with [\" + newMetaInfo.getName() + \"].\");\n\n\t\t\tif (!newMetaInfo.getStateType().equals(StateDescriptor.Type.UNKNOWN)\n\t\t\t\t&& !restoredMetaInfo.getStateType().equals(StateDescriptor.Type.UNKNOWN)) {\n\n\t\t\t\tPreconditions.checkState(\n\t\t\t\t\tnewMetaInfo.getStateType().equals(restoredMetaInfo.getStateType()),\n\t\t\t\t\t\"Incompatible state types. \" +\n\t\t\t\t\t\t\"Was [\" + restoredMetaInfo.getStateType() + \"], \" +\n\t\t\t\t\t\t\"registered with [\" + newMetaInfo.getStateType() + \"].\");\n\t\t\t}\n\n\t\t\t// check compatibility results to determine if state migration is required\n\n\t\t\tCompatibilityResult<N> namespaceCompatibility = StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\trestoredMetaInfo.getNamespaceSerializer(),\n\t\t\t\t\tMigrationNamespaceSerializerProxy.class,\n\t\t\t\t\trestoredMetaInfo.getNamespaceSerializerConfigSnapshot(),\n\t\t\t\t\tnewMetaInfo.getNamespaceSerializer());\n\n\t\t\tCompatibilityResult<S> stateCompatibility = StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\trestoredMetaInfo.getStateSerializer(),\n\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\trestoredMetaInfo.getStateSerializerConfigSnapshot(),\n\t\t\t\t\tnewMetaInfo.getStateSerializer());\n\n\t\t\tif (!namespaceCompatibility.isRequiresMigration() && !stateCompatibility.isRequiresMigration()) {\n\t\t\t\tstateInfo.f1 = newMetaInfo;\n\t\t\t\treturn stateInfo.f0;\n\t\t\t} else {\n\t\t\t\t// TODO state migration currently isn't possible.\n\t\t\t\tthrow new RuntimeException(\"State migration currently isn't supported.\");\n\t\t\t}\n\t\t}\n\n\t\tColumnFamilyDescriptor columnDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\tdescriptor.getName().getBytes(ConfigConstants.DEFAULT_CHARSET), columnOptions);\n\n\t\ttry {\n\t\t\tColumnFamilyHandle columnFamily = db.createColumnFamily(columnDescriptor);\n\t\t\tTuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<N, S>> tuple =\n\t\t\t\t\tnew Tuple2<>(columnFamily, newMetaInfo);\n\t\t\tMap rawAccess = kvStateInformation;\n\t\t\trawAccess.put(descriptor.getName(), tuple);\n\t\t\treturn columnFamily;\n\t\t} catch (RocksDBException e) {\n\t\t\tthrow new IOException(\"Error creating ColumnFamilyHandle.\", e);\n\t\t}\n\t}",
            "1508  \n1509  \n1510  \n1511  \n1512  \n1513  \n1514  \n1515  \n1516  \n1517  \n1518  \n1519  \n1520  \n1521  \n1522  \n1523  \n1524  \n1525  \n1526  \n1527  \n1528  \n1529  \n1530  \n1531  \n1532  \n1533  \n1534 +\n1535  \n1536  \n1537  \n1538  \n1539  \n1540  \n1541  \n1542  \n1543  \n1544  \n1545  \n1546  \n1547  \n1548  \n1549  \n1550  \n1551  \n1552  \n1553  \n1554 +\n1555  \n1556  \n1557  \n1558  \n1559  \n1560  \n1561  \n1562  \n1563  \n1564  \n1565  \n1566  \n1567  \n1568  \n1569  \n1570  \n1571  \n1572  \n1573  \n1574  \n1575  \n1576  \n1577  \n1578  \n1579  \n1580  \n1581  \n1582  \n1583  \n1584  \n1585  \n1586  \n1587  \n1588  ",
            "\t/**\n\t * Creates a column family handle for use with a k/v state. When restoring from a snapshot\n\t * we don't restore the individual k/v states, just the global RocksDB data base and the\n\t * list of column families. When a k/v state is first requested we check here whether we\n\t * already have a column family for that and return it or create a new one if it doesn't exist.\n\t *\n\t * <p>This also checks whether the {@link StateDescriptor} for a state matches the one\n\t * that we checkpointed, i.e. is already in the map of column families.\n\t */\n\t@SuppressWarnings(\"rawtypes, unchecked\")\n\tprotected <N, S> ColumnFamilyHandle getColumnFamily(\n\t\t\tStateDescriptor<?, S> descriptor, TypeSerializer<N> namespaceSerializer) throws IOException {\n\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>> stateInfo =\n\t\t\t\tkvStateInformation.get(descriptor.getName());\n\n\t\tRegisteredKeyedBackendStateMetaInfo<N, S> newMetaInfo = new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tdescriptor.getType(),\n\t\t\tdescriptor.getName(),\n\t\t\tnamespaceSerializer,\n\t\t\tdescriptor.getSerializer());\n\n\t\tif (stateInfo != null) {\n\t\t\t// TODO with eager registration in place, these checks should be moved to restore()\n\n\t\t\tRegisteredKeyedBackendStateMetaInfo.Snapshot<N, S> restoredMetaInfo =\n\t\t\t\t(RegisteredKeyedBackendStateMetaInfo.Snapshot<N, S>) restoredKvStateMetaInfos.get(descriptor.getName());\n\n\t\t\tPreconditions.checkState(\n\t\t\t\tnewMetaInfo.getName().equals(restoredMetaInfo.getName()),\n\t\t\t\t\"Incompatible state names. \" +\n\t\t\t\t\t\"Was [\" + restoredMetaInfo.getName() + \"], \" +\n\t\t\t\t\t\"registered with [\" + newMetaInfo.getName() + \"].\");\n\n\t\t\tif (!newMetaInfo.getStateType().equals(StateDescriptor.Type.UNKNOWN)\n\t\t\t\t&& !restoredMetaInfo.getStateType().equals(StateDescriptor.Type.UNKNOWN)) {\n\n\t\t\t\tPreconditions.checkState(\n\t\t\t\t\tnewMetaInfo.getStateType().equals(restoredMetaInfo.getStateType()),\n\t\t\t\t\t\"Incompatible state types. \" +\n\t\t\t\t\t\t\"Was [\" + restoredMetaInfo.getStateType() + \"], \" +\n\t\t\t\t\t\t\"registered with [\" + newMetaInfo.getStateType() + \"].\");\n\t\t\t}\n\n\t\t\t// check compatibility results to determine if state migration is required\n\n\t\t\tCompatibilityResult<?> namespaceCompatibility = StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\trestoredMetaInfo.getNamespaceSerializer(),\n\t\t\t\t\tMigrationNamespaceSerializerProxy.class,\n\t\t\t\t\trestoredMetaInfo.getNamespaceSerializerConfigSnapshot(),\n\t\t\t\t\tnewMetaInfo.getNamespaceSerializer());\n\n\t\t\tCompatibilityResult<S> stateCompatibility = StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\trestoredMetaInfo.getStateSerializer(),\n\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\trestoredMetaInfo.getStateSerializerConfigSnapshot(),\n\t\t\t\t\tnewMetaInfo.getStateSerializer());\n\n\t\t\tif (!namespaceCompatibility.isRequiresMigration() && !stateCompatibility.isRequiresMigration()) {\n\t\t\t\tstateInfo.f1 = newMetaInfo;\n\t\t\t\treturn stateInfo.f0;\n\t\t\t} else {\n\t\t\t\t// TODO state migration currently isn't possible.\n\t\t\t\tthrow new RuntimeException(\"State migration currently isn't supported.\");\n\t\t\t}\n\t\t}\n\n\t\tColumnFamilyDescriptor columnDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\tdescriptor.getName().getBytes(ConfigConstants.DEFAULT_CHARSET), columnOptions);\n\n\t\ttry {\n\t\t\tColumnFamilyHandle columnFamily = db.createColumnFamily(columnDescriptor);\n\t\t\tTuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<N, S>> tuple =\n\t\t\t\t\tnew Tuple2<>(columnFamily, newMetaInfo);\n\t\t\tMap rawAccess = kvStateInformation;\n\t\t\trawAccess.put(descriptor.getName(), tuple);\n\t\t\treturn columnFamily;\n\t\t} catch (RocksDBException e) {\n\t\t\tthrow new IOException(\"Error creating ColumnFamilyHandle.\", e);\n\t\t}\n\t}"
        ],
        [
            "HeapKeyedStateBackend::snapshot(long,long,CheckpointStreamFactory,CheckpointOptions)",
            " 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275 -\n 276 -\n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  ",
            "\t@Override\n\t@SuppressWarnings(\"unchecked\")\n\tpublic  RunnableFuture<KeyedStateHandle> snapshot(\n\t\t\tfinal long checkpointId,\n\t\t\tfinal long timestamp,\n\t\t\tfinal CheckpointStreamFactory streamFactory,\n\t\t\tCheckpointOptions checkpointOptions) throws Exception {\n\n\t\tif (!hasRegisteredState()) {\n\t\t\treturn DoneFuture.nullValue();\n\t\t}\n\n\t\tlong syncStartTime = System.currentTimeMillis();\n\n\t\tPreconditions.checkState(stateTables.size() <= Short.MAX_VALUE,\n\t\t\t\t\"Too many KV-States: \" + stateTables.size() +\n\t\t\t\t\t\t\". Currently at most \" + Short.MAX_VALUE + \" states are supported\");\n\n\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> metaInfoSnapshots = new ArrayList<>(stateTables.size());\n\n\t\tfinal Map<String, Integer> kVStateToId = new HashMap<>(stateTables.size());\n\n\t\tfinal Map<StateTable<K, ?, ?>, StateTableSnapshot> cowStateStableSnapshots = new HashedMap(stateTables.size());\n\n\t\tfor (Map.Entry<String, StateTable<K, ?, ?>> kvState : stateTables.entrySet()) {\n\t\t\tmetaInfoSnapshots.add(kvState.getValue().getMetaInfo().snapshot());\n\t\t\tkVStateToId.put(kvState.getKey(), kVStateToId.size());\n\t\t\tStateTable<K, ?, ?> stateTable = kvState.getValue();\n\t\t\tif (null != stateTable) {\n\t\t\t\tcowStateStableSnapshots.put(stateTable, stateTable.createSnapshot());\n\t\t\t}\n\t\t}\n\n\t\tfinal KeyedBackendSerializationProxy serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy(keySerializer, metaInfoSnapshots);\n\n\t\t//--------------------------------------------------- this becomes the end of sync part\n\n\t\t// implementation of the async IO operation, based on FutureTask\n\t\tfinal AbstractAsyncSnapshotIOCallable<KeyedStateHandle> ioCallable =\n\t\t\tnew AbstractAsyncSnapshotIOCallable<KeyedStateHandle>(\n\t\t\t\tcheckpointId,\n\t\t\t\ttimestamp,\n\t\t\t\tstreamFactory,\n\t\t\t\tcancelStreamRegistry) {\n\n\t\t\t\t@Override\n\t\t\t\tpublic KeyGroupsStateHandle performOperation() throws Exception {\n\t\t\t\t\tlong asyncStartTime = System.currentTimeMillis();\n\t\t\t\t\tCheckpointStreamFactory.CheckpointStateOutputStream stream = getIoHandle();\n\t\t\t\t\tDataOutputViewStreamWrapper outView = new DataOutputViewStreamWrapper(stream);\n\t\t\t\t\tserializationProxy.write(outView);\n\n\t\t\t\t\tlong[] keyGroupRangeOffsets = new long[keyGroupRange.getNumberOfKeyGroups()];\n\n\t\t\t\t\tfor (int keyGroupPos = 0; keyGroupPos < keyGroupRange.getNumberOfKeyGroups(); ++keyGroupPos) {\n\t\t\t\t\t\tint keyGroupId = keyGroupRange.getKeyGroupId(keyGroupPos);\n\t\t\t\t\t\tkeyGroupRangeOffsets[keyGroupPos] = stream.getPos();\n\t\t\t\t\t\toutView.writeInt(keyGroupId);\n\n\t\t\t\t\t\tfor (Map.Entry<String, StateTable<K, ?, ?>> kvState : stateTables.entrySet()) {\n\t\t\t\t\t\t\toutView.writeShort(kVStateToId.get(kvState.getKey()));\n\t\t\t\t\t\t\tcowStateStableSnapshots.get(kvState.getValue()).writeMappingsInKeyGroup(outView, keyGroupId);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tfinal StreamStateHandle streamStateHandle = closeStreamAndGetStateHandle();\n\n\t\t\t\t\tif (asynchronousSnapshots) {\n\t\t\t\t\t\tLOG.info(\"Heap backend snapshot ({}, asynchronous part) in thread {} took {} ms.\",\n\t\t\t\t\t\t\tstreamFactory, Thread.currentThread(), (System.currentTimeMillis() - asyncStartTime));\n\t\t\t\t\t}\n\n\t\t\t\t\tif (streamStateHandle == null) {\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\n\t\t\t\t\tKeyGroupRangeOffsets offsets = new KeyGroupRangeOffsets(keyGroupRange, keyGroupRangeOffsets);\n\t\t\t\t\tfinal KeyGroupsStateHandle keyGroupsStateHandle = new KeyGroupsStateHandle(offsets, streamStateHandle);\n\n\t\t\t\t\treturn keyGroupsStateHandle;\n\t\t\t\t}\n\t\t\t};\n\n\t\tAsyncStoppableTaskWithCallback<KeyedStateHandle> task = AsyncStoppableTaskWithCallback.from(ioCallable);\n\n\t\tif (!asynchronousSnapshots) {\n\t\t\ttask.run();\n\t\t}\n\n\t\tLOG.info(\"Heap backend snapshot (\" + streamFactory + \", synchronous part) in thread \" +\n\t\t\t\tThread.currentThread() + \" took \" + (System.currentTimeMillis() - syncStartTime) + \" ms.\");\n\n\t\treturn task;\n\t}",
            " 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275 +\n 276 +\n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  ",
            "\t@Override\n\t@SuppressWarnings(\"unchecked\")\n\tpublic  RunnableFuture<KeyedStateHandle> snapshot(\n\t\t\tfinal long checkpointId,\n\t\t\tfinal long timestamp,\n\t\t\tfinal CheckpointStreamFactory streamFactory,\n\t\t\tCheckpointOptions checkpointOptions) throws Exception {\n\n\t\tif (!hasRegisteredState()) {\n\t\t\treturn DoneFuture.nullValue();\n\t\t}\n\n\t\tlong syncStartTime = System.currentTimeMillis();\n\n\t\tPreconditions.checkState(stateTables.size() <= Short.MAX_VALUE,\n\t\t\t\t\"Too many KV-States: \" + stateTables.size() +\n\t\t\t\t\t\t\". Currently at most \" + Short.MAX_VALUE + \" states are supported\");\n\n\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> metaInfoSnapshots = new ArrayList<>(stateTables.size());\n\n\t\tfinal Map<String, Integer> kVStateToId = new HashMap<>(stateTables.size());\n\n\t\tfinal Map<StateTable<K, ?, ?>, StateTableSnapshot> cowStateStableSnapshots = new HashedMap(stateTables.size());\n\n\t\tfor (Map.Entry<String, StateTable<K, ?, ?>> kvState : stateTables.entrySet()) {\n\t\t\tmetaInfoSnapshots.add(kvState.getValue().getMetaInfo().snapshot());\n\t\t\tkVStateToId.put(kvState.getKey(), kVStateToId.size());\n\t\t\tStateTable<K, ?, ?> stateTable = kvState.getValue();\n\t\t\tif (null != stateTable) {\n\t\t\t\tcowStateStableSnapshots.put(stateTable, stateTable.createSnapshot());\n\t\t\t}\n\t\t}\n\n\t\tfinal KeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(keySerializer, metaInfoSnapshots);\n\n\t\t//--------------------------------------------------- this becomes the end of sync part\n\n\t\t// implementation of the async IO operation, based on FutureTask\n\t\tfinal AbstractAsyncSnapshotIOCallable<KeyedStateHandle> ioCallable =\n\t\t\tnew AbstractAsyncSnapshotIOCallable<KeyedStateHandle>(\n\t\t\t\tcheckpointId,\n\t\t\t\ttimestamp,\n\t\t\t\tstreamFactory,\n\t\t\t\tcancelStreamRegistry) {\n\n\t\t\t\t@Override\n\t\t\t\tpublic KeyGroupsStateHandle performOperation() throws Exception {\n\t\t\t\t\tlong asyncStartTime = System.currentTimeMillis();\n\t\t\t\t\tCheckpointStreamFactory.CheckpointStateOutputStream stream = getIoHandle();\n\t\t\t\t\tDataOutputViewStreamWrapper outView = new DataOutputViewStreamWrapper(stream);\n\t\t\t\t\tserializationProxy.write(outView);\n\n\t\t\t\t\tlong[] keyGroupRangeOffsets = new long[keyGroupRange.getNumberOfKeyGroups()];\n\n\t\t\t\t\tfor (int keyGroupPos = 0; keyGroupPos < keyGroupRange.getNumberOfKeyGroups(); ++keyGroupPos) {\n\t\t\t\t\t\tint keyGroupId = keyGroupRange.getKeyGroupId(keyGroupPos);\n\t\t\t\t\t\tkeyGroupRangeOffsets[keyGroupPos] = stream.getPos();\n\t\t\t\t\t\toutView.writeInt(keyGroupId);\n\n\t\t\t\t\t\tfor (Map.Entry<String, StateTable<K, ?, ?>> kvState : stateTables.entrySet()) {\n\t\t\t\t\t\t\toutView.writeShort(kVStateToId.get(kvState.getKey()));\n\t\t\t\t\t\t\tcowStateStableSnapshots.get(kvState.getValue()).writeMappingsInKeyGroup(outView, keyGroupId);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tfinal StreamStateHandle streamStateHandle = closeStreamAndGetStateHandle();\n\n\t\t\t\t\tif (asynchronousSnapshots) {\n\t\t\t\t\t\tLOG.info(\"Heap backend snapshot ({}, asynchronous part) in thread {} took {} ms.\",\n\t\t\t\t\t\t\tstreamFactory, Thread.currentThread(), (System.currentTimeMillis() - asyncStartTime));\n\t\t\t\t\t}\n\n\t\t\t\t\tif (streamStateHandle == null) {\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\n\t\t\t\t\tKeyGroupRangeOffsets offsets = new KeyGroupRangeOffsets(keyGroupRange, keyGroupRangeOffsets);\n\t\t\t\t\tfinal KeyGroupsStateHandle keyGroupsStateHandle = new KeyGroupsStateHandle(offsets, streamStateHandle);\n\n\t\t\t\t\treturn keyGroupsStateHandle;\n\t\t\t\t}\n\t\t\t};\n\n\t\tAsyncStoppableTaskWithCallback<KeyedStateHandle> task = AsyncStoppableTaskWithCallback.from(ioCallable);\n\n\t\tif (!asynchronousSnapshots) {\n\t\t\ttask.run();\n\t\t}\n\n\t\tLOG.info(\"Heap backend snapshot (\" + streamFactory + \", synchronous part) in thread \" +\n\t\t\t\tThread.currentThread() + \" took \" + (System.currentTimeMillis() - syncStartTime) + \" ms.\");\n\n\t\treturn task;\n\t}"
        ],
        [
            "SerializationProxiesTest::testKeyedBackendSerializationProxyRoundtrip()",
            "  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69 -\n  70 -\n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79 -\n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  ",
            "\t@Test\n\tpublic void testKeyedBackendSerializationProxyRoundtrip() throws Exception {\n\n\t\tTypeSerializer<?> keySerializer = IntSerializer.INSTANCE;\n\t\tTypeSerializer<?> namespaceSerializer = LongSerializer.INSTANCE;\n\t\tTypeSerializer<?> stateSerializer = DoubleSerializer.INSTANCE;\n\n\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> stateMetaInfoList = new ArrayList<>();\n\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"a\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"b\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"c\", namespaceSerializer, stateSerializer).snapshot());\n\n\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy(keySerializer, stateMetaInfoList);\n\n\t\tbyte[] serialized;\n\t\ttry (ByteArrayOutputStreamWithPos out = new ByteArrayOutputStreamWithPos()) {\n\t\t\tserializationProxy.write(new DataOutputViewStreamWrapper(out));\n\t\t\tserialized = out.toByteArray();\n\t\t}\n\n\t\tserializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy(Thread.currentThread().getContextClassLoader());\n\n\t\ttry (ByteArrayInputStreamWithPos in = new ByteArrayInputStreamWithPos(serialized)) {\n\t\t\tserializationProxy.read(new DataInputViewStreamWrapper(in));\n\t\t}\n\n\t\tAssert.assertEquals(keySerializer, serializationProxy.getKeySerializer());\n\t\tAssert.assertEquals(keySerializer.snapshotConfiguration(), serializationProxy.getKeySerializerConfigSnapshot());\n\t\tAssert.assertEquals(stateMetaInfoList, serializationProxy.getStateMetaInfoSnapshots());\n\t}",
            "  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69 +\n  70 +\n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79 +\n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  ",
            "\t@Test\n\tpublic void testKeyedBackendSerializationProxyRoundtrip() throws Exception {\n\n\t\tTypeSerializer<?> keySerializer = IntSerializer.INSTANCE;\n\t\tTypeSerializer<?> namespaceSerializer = LongSerializer.INSTANCE;\n\t\tTypeSerializer<?> stateSerializer = DoubleSerializer.INSTANCE;\n\n\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> stateMetaInfoList = new ArrayList<>();\n\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"a\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"b\", namespaceSerializer, stateSerializer).snapshot());\n\t\tstateMetaInfoList.add(new RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\tStateDescriptor.Type.VALUE, \"c\", namespaceSerializer, stateSerializer).snapshot());\n\n\t\tKeyedBackendSerializationProxy<?> serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(keySerializer, stateMetaInfoList);\n\n\t\tbyte[] serialized;\n\t\ttry (ByteArrayOutputStreamWithPos out = new ByteArrayOutputStreamWithPos()) {\n\t\t\tserializationProxy.write(new DataOutputViewStreamWrapper(out));\n\t\t\tserialized = out.toByteArray();\n\t\t}\n\n\t\tserializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(Thread.currentThread().getContextClassLoader());\n\n\t\ttry (ByteArrayInputStreamWithPos in = new ByteArrayInputStreamWithPos(serialized)) {\n\t\t\tserializationProxy.read(new DataInputViewStreamWrapper(in));\n\t\t}\n\n\t\tAssert.assertEquals(keySerializer, serializationProxy.getKeySerializer());\n\t\tAssert.assertEquals(keySerializer.snapshotConfiguration(), serializationProxy.getKeySerializerConfigSnapshot());\n\t\tAssert.assertEquals(stateMetaInfoList, serializationProxy.getStateMetaInfoSnapshots());\n\t}"
        ],
        [
            "KeyedBackendSerializationProxy::getKeySerializer()",
            "  73 -\n  74  \n  75  ",
            "\tpublic TypeSerializer<?> getKeySerializer() {\n\t\treturn keySerializer;\n\t}",
            "  73 +\n  74  \n  75  ",
            "\tpublic TypeSerializer<K> getKeySerializer() {\n\t\treturn keySerializer;\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::restore(Collection)",
            " 952  \n 953  \n 954  \n 955  \n 956  \n 957  \n 958  \n 959  \n 960  \n 961  \n 962  \n 963  \n 964  \n 965  \n 966  \n 967 -\n 968  \n 969  \n 970 -\n 971  \n 972  \n 973  \n 974  \n 975  \n 976  \n 977  ",
            "\t@Override\n\tpublic void restore(Collection<KeyedStateHandle> restoreState) throws Exception {\n\t\tLOG.info(\"Initializing RocksDB keyed state backend from snapshot.\");\n\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tLOG.debug(\"Restoring snapshot from state handles: {}.\", restoreState);\n\t\t}\n\n\t\ttry {\n\t\t\tif (restoreState == null || restoreState.isEmpty()) {\n\t\t\t\tcreateDB();\n\t\t\t} else if (MigrationUtil.isOldSavepointKeyedState(restoreState)) {\n\t\t\t\tLOG.info(\"Converting RocksDB state from old savepoint.\");\n\t\t\t\trestoreOldSavepointKeyedState(restoreState);\n\t\t\t} else if (restoreState.iterator().next() instanceof IncrementalKeyedStateHandle) {\n\t\t\t\tRocksDBIncrementalRestoreOperation restoreOperation = new RocksDBIncrementalRestoreOperation(this);\n\t\t\t\trestoreOperation.restore(restoreState);\n\t\t\t} else {\n\t\t\t\tRocksDBFullRestoreOperation restoreOperation = new RocksDBFullRestoreOperation(this);\n\t\t\t\trestoreOperation.doRestore(restoreState);\n\t\t\t}\n\t\t} catch (Exception ex) {\n\t\t\tdispose();\n\t\t\tthrow ex;\n\t\t}\n\t}",
            " 949  \n 950  \n 951  \n 952  \n 953  \n 954  \n 955  \n 956  \n 957  \n 958  \n 959  \n 960  \n 961  \n 962  \n 963  \n 964 +\n 965  \n 966  \n 967 +\n 968  \n 969  \n 970  \n 971  \n 972  \n 973  \n 974  ",
            "\t@Override\n\tpublic void restore(Collection<KeyedStateHandle> restoreState) throws Exception {\n\t\tLOG.info(\"Initializing RocksDB keyed state backend from snapshot.\");\n\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tLOG.debug(\"Restoring snapshot from state handles: {}.\", restoreState);\n\t\t}\n\n\t\ttry {\n\t\t\tif (restoreState == null || restoreState.isEmpty()) {\n\t\t\t\tcreateDB();\n\t\t\t} else if (MigrationUtil.isOldSavepointKeyedState(restoreState)) {\n\t\t\t\tLOG.info(\"Converting RocksDB state from old savepoint.\");\n\t\t\t\trestoreOldSavepointKeyedState(restoreState);\n\t\t\t} else if (restoreState.iterator().next() instanceof IncrementalKeyedStateHandle) {\n\t\t\t\tRocksDBIncrementalRestoreOperation<K> restoreOperation = new RocksDBIncrementalRestoreOperation<>(this);\n\t\t\t\trestoreOperation.restore(restoreState);\n\t\t\t} else {\n\t\t\t\tRocksDBFullRestoreOperation<K> restoreOperation = new RocksDBFullRestoreOperation<>(this);\n\t\t\t\trestoreOperation.doRestore(restoreState);\n\t\t\t}\n\t\t} catch (Exception ex) {\n\t\t\tdispose();\n\t\t\tthrow ex;\n\t\t}\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBFullRestoreOperation::restoreKVStateMetaData()",
            "1112  \n1113  \n1114  \n1115  \n1116  \n1117  \n1118  \n1119  \n1120 -\n1121  \n1122 -\n1123 -\n1124  \n1125  \n1126  \n1127  \n1128  \n1129  \n1130  \n1131  \n1132  \n1133 -\n1134  \n1135  \n1136  \n1137  \n1138  \n1139  \n1140  \n1141  \n1142  \n1143  \n1144  \n1145  \n1146  \n1147  \n1148  \n1149  \n1150  \n1151  \n1152  \n1153  \n1154  \n1155  \n1156  \n1157  \n1158  \n1159  \n1160  \n1161  \n1162  \n1163  \n1164  \n1165  \n1166  \n1167  \n1168  \n1169  \n1170  \n1171  \n1172  \n1173  \n1174  ",
            "\t\t/**\n\t\t * Restore the KV-state / ColumnFamily meta data for all key-groups referenced by the current state handle\n\t\t *\n\t\t * @throws IOException\n\t\t * @throws ClassNotFoundException\n\t\t * @throws RocksDBException\n\t\t */\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tprivate void restoreKVStateMetaData() throws IOException, ClassNotFoundException, RocksDBException {\n\n\t\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy(rocksDBKeyedStateBackend.userCodeClassLoader);\n\n\t\t\tserializationProxy.read(currentStateHandleInView);\n\n\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\tif (StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\tserializationProxy.getKeySerializer(),\n\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\tserializationProxy.getKeySerializerConfigSnapshot(),\n\t\t\t\t\t(TypeSerializer) rocksDBKeyedStateBackend.keySerializer)\n\t\t\t\t.isRequiresMigration()) {\n\n\t\t\t\t// TODO replace with state migration; note that key hash codes need to remain the same after migration\n\t\t\t\tthrow new RuntimeException(\"The new key serializer is not compatible to read previous keys. \" +\n\t\t\t\t\t\"Aborting now since state migration is currently not available\");\n\t\t\t}\n\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> restoredMetaInfos =\n\t\t\t\t\tserializationProxy.getStateMetaInfoSnapshots();\n\n\t\t\tcurrentStateHandleKVStateColumnFamilies = new ArrayList<>(restoredMetaInfos.size());\n\t\t\trocksDBKeyedStateBackend.restoredKvStateMetaInfos = new HashMap<>(restoredMetaInfos.size());\n\n\t\t\tfor (RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?> restoredMetaInfo : restoredMetaInfos) {\n\n\t\t\t\tif (!rocksDBKeyedStateBackend.kvStateInformation.containsKey(restoredMetaInfo.getName())) {\n\t\t\t\t\tColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\t\t\trestoredMetaInfo.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),\n\t\t\t\t\t\trocksDBKeyedStateBackend.columnOptions);\n\n\t\t\t\t\tRegisteredKeyedBackendStateMetaInfo<?, ?> stateMetaInfo =\n\t\t\t\t\t\t\tnew RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\t\t\t\t\t\trestoredMetaInfo.getStateType(),\n\t\t\t\t\t\t\t\trestoredMetaInfo.getName(),\n\t\t\t\t\t\t\t\trestoredMetaInfo.getNamespaceSerializer(),\n\t\t\t\t\t\t\t\trestoredMetaInfo.getStateSerializer());\n\n\t\t\t\t\trocksDBKeyedStateBackend.restoredKvStateMetaInfos.put(restoredMetaInfo.getName(), restoredMetaInfo);\n\n\t\t\t\t\tColumnFamilyHandle columnFamily = rocksDBKeyedStateBackend.db.createColumnFamily(columnFamilyDescriptor);\n\n\t\t\t\t\trocksDBKeyedStateBackend.kvStateInformation.put(\n\t\t\t\t\t\tstateMetaInfo.getName(),\n\t\t\t\t\t\tnew Tuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>>(columnFamily, stateMetaInfo));\n\n\t\t\t\t\tcurrentStateHandleKVStateColumnFamilies.add(columnFamily);\n\t\t\t\t} else {\n\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t}\n\t\t\t}\n\t\t}",
            "1109  \n1110  \n1111  \n1112  \n1113  \n1114  \n1115  \n1116 +\n1117  \n1118 +\n1119 +\n1120  \n1121  \n1122  \n1123  \n1124  \n1125  \n1126  \n1127  \n1128  \n1129 +\n1130  \n1131  \n1132  \n1133  \n1134  \n1135  \n1136  \n1137  \n1138  \n1139  \n1140  \n1141  \n1142  \n1143  \n1144  \n1145  \n1146  \n1147  \n1148  \n1149  \n1150  \n1151  \n1152  \n1153  \n1154  \n1155  \n1156  \n1157  \n1158  \n1159  \n1160  \n1161  \n1162  \n1163  \n1164  \n1165  \n1166  \n1167  \n1168  \n1169  \n1170  ",
            "\t\t/**\n\t\t * Restore the KV-state / ColumnFamily meta data for all key-groups referenced by the current state handle\n\t\t *\n\t\t * @throws IOException\n\t\t * @throws ClassNotFoundException\n\t\t * @throws RocksDBException\n\t\t */\n\t\tprivate void restoreKVStateMetaData() throws IOException, RocksDBException {\n\n\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy<>(rocksDBKeyedStateBackend.userCodeClassLoader);\n\n\t\t\tserializationProxy.read(currentStateHandleInView);\n\n\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\tif (StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\tserializationProxy.getKeySerializer(),\n\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\tserializationProxy.getKeySerializerConfigSnapshot(),\n\t\t\t\t\trocksDBKeyedStateBackend.keySerializer)\n\t\t\t\t.isRequiresMigration()) {\n\n\t\t\t\t// TODO replace with state migration; note that key hash codes need to remain the same after migration\n\t\t\t\tthrow new RuntimeException(\"The new key serializer is not compatible to read previous keys. \" +\n\t\t\t\t\t\"Aborting now since state migration is currently not available\");\n\t\t\t}\n\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> restoredMetaInfos =\n\t\t\t\t\tserializationProxy.getStateMetaInfoSnapshots();\n\n\t\t\tcurrentStateHandleKVStateColumnFamilies = new ArrayList<>(restoredMetaInfos.size());\n\t\t\trocksDBKeyedStateBackend.restoredKvStateMetaInfos = new HashMap<>(restoredMetaInfos.size());\n\n\t\t\tfor (RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?> restoredMetaInfo : restoredMetaInfos) {\n\n\t\t\t\tif (!rocksDBKeyedStateBackend.kvStateInformation.containsKey(restoredMetaInfo.getName())) {\n\t\t\t\t\tColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\t\t\trestoredMetaInfo.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),\n\t\t\t\t\t\trocksDBKeyedStateBackend.columnOptions);\n\n\t\t\t\t\tRegisteredKeyedBackendStateMetaInfo<?, ?> stateMetaInfo =\n\t\t\t\t\t\t\tnew RegisteredKeyedBackendStateMetaInfo<>(\n\t\t\t\t\t\t\t\trestoredMetaInfo.getStateType(),\n\t\t\t\t\t\t\t\trestoredMetaInfo.getName(),\n\t\t\t\t\t\t\t\trestoredMetaInfo.getNamespaceSerializer(),\n\t\t\t\t\t\t\t\trestoredMetaInfo.getStateSerializer());\n\n\t\t\t\t\trocksDBKeyedStateBackend.restoredKvStateMetaInfos.put(restoredMetaInfo.getName(), restoredMetaInfo);\n\n\t\t\t\t\tColumnFamilyHandle columnFamily = rocksDBKeyedStateBackend.db.createColumnFamily(columnFamilyDescriptor);\n\n\t\t\t\t\trocksDBKeyedStateBackend.kvStateInformation.put(\n\t\t\t\t\t\tstateMetaInfo.getName(),\n\t\t\t\t\t\tnew Tuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>>(columnFamily, stateMetaInfo));\n\n\t\t\t\t\tcurrentStateHandleKVStateColumnFamilies.add(columnFamily);\n\t\t\t\t} else {\n\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t}\n\t\t\t}\n\t\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBIncrementalRestoreOperation::readMetaData(StreamStateHandle)",
            "1232  \n1233  \n1234  \n1235  \n1236  \n1237  \n1238  \n1239  \n1240  \n1241  \n1242 -\n1243 -\n1244  \n1245  \n1246  \n1247  \n1248  \n1249  \n1250  \n1251  \n1252  \n1253 -\n1254  \n1255  \n1256  \n1257  \n1258  \n1259  \n1260  \n1261  \n1262  \n1263  \n1264  \n1265  \n1266  \n1267  \n1268  ",
            "\t\t@SuppressWarnings(\"unchecked\")\n\t\tprivate List<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> readMetaData(\n\t\t\t\tStreamStateHandle metaStateHandle) throws Exception {\n\n\t\t\tFSDataInputStream inputStream = null;\n\n\t\t\ttry {\n\t\t\t\tinputStream = metaStateHandle.openInputStream();\n\t\t\t\tstateBackend.cancelStreamRegistry.registerClosable(inputStream);\n\n\t\t\t\tKeyedBackendSerializationProxy serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy(stateBackend.userCodeClassLoader);\n\t\t\t\tDataInputView in = new DataInputViewStreamWrapper(inputStream);\n\t\t\t\tserializationProxy.read(in);\n\n\t\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\t\tif (StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\t\tserializationProxy.getKeySerializer(),\n\t\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\t\tserializationProxy.getKeySerializerConfigSnapshot(),\n\t\t\t\t\t\t(TypeSerializer) stateBackend.keySerializer)\n\t\t\t\t\t.isRequiresMigration()) {\n\n\t\t\t\t\t// TODO replace with state migration; note that key hash codes need to remain the same after migration\n\t\t\t\t\tthrow new RuntimeException(\"The new key serializer is not compatible to read previous keys. \" +\n\t\t\t\t\t\t\"Aborting now since state migration is currently not available\");\n\t\t\t\t}\n\n\t\t\t\treturn serializationProxy.getStateMetaInfoSnapshots();\n\t\t\t} finally {\n\t\t\t\tif (inputStream != null) {\n\t\t\t\t\tstateBackend.cancelStreamRegistry.unregisterClosable(inputStream);\n\t\t\t\t\tinputStream.close();\n\t\t\t\t}\n\t\t\t}\n\t\t}",
            "1228  \n1229  \n1230  \n1231  \n1232  \n1233  \n1234  \n1235  \n1236  \n1237 +\n1238 +\n1239  \n1240  \n1241  \n1242  \n1243  \n1244  \n1245  \n1246  \n1247  \n1248 +\n1249  \n1250  \n1251  \n1252  \n1253  \n1254  \n1255  \n1256  \n1257  \n1258  \n1259  \n1260  \n1261  \n1262  \n1263  ",
            "\t\tprivate List<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> readMetaData(\n\t\t\t\tStreamStateHandle metaStateHandle) throws Exception {\n\n\t\t\tFSDataInputStream inputStream = null;\n\n\t\t\ttry {\n\t\t\t\tinputStream = metaStateHandle.openInputStream();\n\t\t\t\tstateBackend.cancelStreamRegistry.registerClosable(inputStream);\n\n\t\t\t\tKeyedBackendSerializationProxy<T> serializationProxy =\n\t\t\t\t\tnew KeyedBackendSerializationProxy<>(stateBackend.userCodeClassLoader);\n\t\t\t\tDataInputView in = new DataInputViewStreamWrapper(inputStream);\n\t\t\t\tserializationProxy.read(in);\n\n\t\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\t\tif (StateMigrationUtil.resolveCompatibilityResult(\n\t\t\t\t\t\tserializationProxy.getKeySerializer(),\n\t\t\t\t\t\tTypeSerializerSerializationProxy.ClassNotFoundDummyTypeSerializer.class,\n\t\t\t\t\t\tserializationProxy.getKeySerializerConfigSnapshot(),\n\t\t\t\t\t\tstateBackend.keySerializer)\n\t\t\t\t\t.isRequiresMigration()) {\n\n\t\t\t\t\t// TODO replace with state migration; note that key hash codes need to remain the same after migration\n\t\t\t\t\tthrow new RuntimeException(\"The new key serializer is not compatible to read previous keys. \" +\n\t\t\t\t\t\t\"Aborting now since state migration is currently not available\");\n\t\t\t\t}\n\n\t\t\t\treturn serializationProxy.getStateMetaInfoSnapshots();\n\t\t\t} finally {\n\t\t\t\tif (inputStream != null) {\n\t\t\t\t\tstateBackend.cancelStreamRegistry.unregisterClosable(inputStream);\n\t\t\t\t\tinputStream.close();\n\t\t\t\t}\n\t\t\t}\n\t\t}"
        ]
    ],
    "77b0fb9fe3656a5ae7e2ca3bbce28cfa5a0e247e": [
        [
            "YarnIntraNonHaMasterServicesTest::createHDFS()",
            "  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83 -\n  84 -\n  85  ",
            "\t@BeforeClass\n\tpublic static void createHDFS() throws Exception {\n\t\tAssume.assumeTrue(!OperatingSystem.isWindows());\n\n\t\tfinal File tempDir = TEMP_DIR.newFolder();\n\n\t\torg.apache.hadoop.conf.Configuration hdConf = new org.apache.hadoop.conf.Configuration();\n\t\thdConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, tempDir.getAbsolutePath());\n\n\t\tMiniDFSCluster.Builder builder = new MiniDFSCluster.Builder(hdConf);\n\t\tHDFS_CLUSTER = builder.build();\n\t\tHDFS_ROOT_PATH = new Path(HDFS_CLUSTER.getURI());\n\t}",
            "  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84 +\n  85 +\n  86  ",
            "\t@BeforeClass\n\tpublic static void createHDFS() throws Exception {\n\t\tAssume.assumeTrue(!OperatingSystem.isWindows());\n\n\t\tfinal File tempDir = TEMP_DIR.newFolder();\n\n\t\torg.apache.hadoop.conf.Configuration hdConf = new org.apache.hadoop.conf.Configuration();\n\t\thdConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, tempDir.getAbsolutePath());\n\n\t\tMiniDFSCluster.Builder builder = new MiniDFSCluster.Builder(hdConf);\n\t\thdfsCluster = builder.build();\n\t\thdfsRootPath = new Path(hdfsCluster.getURI());\n\t}"
        ],
        [
            "FlinkYarnSessionCli::addGeneralOptions(Options)",
            " 512  \n 513  \n 514 -\n 515  ",
            "\t@Override\n\tpublic void addGeneralOptions(Options baseOptions) {\n\t\tbaseOptions.addOption(APPLICATION_ID);\n\t}",
            " 512  \n 513  \n 514 +\n 515  ",
            "\t@Override\n\tpublic void addGeneralOptions(Options baseOptions) {\n\t\tbaseOptions.addOption(applicationId);\n\t}"
        ],
        [
            "FlinkYarnSessionCli::isActive(CommandLine,Configuration)",
            " 492  \n 493  \n 494  \n 495  \n 496 -\n 497  \n 498  ",
            "\t@Override\n\tpublic boolean isActive(CommandLine commandLine, Configuration configuration) {\n\t\tString jobManagerOption = commandLine.getOptionValue(ADDRESS_OPTION.getOpt(), null);\n\t\tboolean yarnJobManager = ID.equals(jobManagerOption);\n\t\tboolean yarnAppId = commandLine.hasOption(APPLICATION_ID.getOpt());\n\t\treturn yarnJobManager || yarnAppId || loadYarnPropertiesFile(commandLine, configuration) != null;\n\t}",
            " 492  \n 493  \n 494  \n 495  \n 496 +\n 497  \n 498  ",
            "\t@Override\n\tpublic boolean isActive(CommandLine commandLine, Configuration configuration) {\n\t\tString jobManagerOption = commandLine.getOptionValue(ADDRESS_OPTION.getOpt(), null);\n\t\tboolean yarnJobManager = ID.equals(jobManagerOption);\n\t\tboolean yarnAppId = commandLine.hasOption(applicationId.getOpt());\n\t\treturn yarnJobManager || yarnAppId || loadYarnPropertiesFile(commandLine, configuration) != null;\n\t}"
        ],
        [
            "FlinkYarnCLI::addRunOptions(Options)",
            " 202  \n 203  \n 204 -\n 205  \n 206  \n 207  ",
            "\t@Override\n\tpublic void addRunOptions(Options baseOptions) {\n\t\tfor (Object option : ALL_OPTIONS.getOptions()) {\n\t\t\tbaseOptions.addOption((Option) option);\n\t\t}\n\t}",
            " 204  \n 205  \n 206 +\n 207  \n 208  \n 209  ",
            "\t@Override\n\tpublic void addRunOptions(Options baseOptions) {\n\t\tfor (Object option : allOptions.getOptions()) {\n\t\t\tbaseOptions.addOption((Option) option);\n\t\t}\n\t}"
        ],
        [
            "FlinkYarnSessionCli::retrieveCluster(CommandLine,Configuration)",
            " 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523 -\n 524 -\n 525  \n 526  \n 527 -\n 528 -\n 529 -\n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  ",
            "\t@Override\n\tpublic YarnClusterClient retrieveCluster(\n\t\t\tCommandLine cmdLine,\n\t\t\tConfiguration config) throws UnsupportedOperationException {\n\n\t\t// first check for an application id, then try to load from yarn properties\n\t\tString applicationID = cmdLine.hasOption(APPLICATION_ID.getOpt()) ?\n\t\t\t\tcmdLine.getOptionValue(APPLICATION_ID.getOpt())\n\t\t\t\t: loadYarnPropertiesFile(cmdLine, config);\n\n\t\tif(null != applicationID) {\n\t\t\tString zkNamespace = cmdLine.hasOption(ZOOKEEPER_NAMESPACE.getOpt()) ?\n\t\t\t\t\tcmdLine.getOptionValue(ZOOKEEPER_NAMESPACE.getOpt())\n\t\t\t\t\t: config.getString(HighAvailabilityOptions.HA_CLUSTER_ID, applicationID);\n\t\t\tconfig.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace);\n\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor = getClusterDescriptor();\n\t\t\tyarnDescriptor.setFlinkConfiguration(config);\n\t\t\treturn yarnDescriptor.retrieve(applicationID);\n\t\t} else {\n\t\t\tthrow new UnsupportedOperationException(\"Could not resume a Yarn cluster.\");\n\t\t}\n\t}",
            " 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523 +\n 524 +\n 525  \n 526  \n 527 +\n 528 +\n 529 +\n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  ",
            "\t@Override\n\tpublic YarnClusterClient retrieveCluster(\n\t\t\tCommandLine cmdLine,\n\t\t\tConfiguration config) throws UnsupportedOperationException {\n\n\t\t// first check for an application id, then try to load from yarn properties\n\t\tString applicationID = cmdLine.hasOption(applicationId.getOpt()) ?\n\t\t\t\tcmdLine.getOptionValue(applicationId.getOpt())\n\t\t\t\t: loadYarnPropertiesFile(cmdLine, config);\n\n\t\tif (null != applicationID) {\n\t\t\tString zkNamespace = cmdLine.hasOption(zookeeperNamespace.getOpt()) ?\n\t\t\t\t\tcmdLine.getOptionValue(zookeeperNamespace.getOpt())\n\t\t\t\t\t: config.getString(HighAvailabilityOptions.HA_CLUSTER_ID, applicationID);\n\t\t\tconfig.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace);\n\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor = getClusterDescriptor();\n\t\t\tyarnDescriptor.setFlinkConfiguration(config);\n\t\t\treturn yarnDescriptor.retrieve(applicationID);\n\t\t} else {\n\t\t\tthrow new UnsupportedOperationException(\"Could not resume a Yarn cluster.\");\n\t\t}\n\t}"
        ],
        [
            "YarnFlinkResourceManager::RegisterApplicationMasterResponseReflector::RegisterApplicationMasterResponseReflector(Logger)",
            " 627 -\n 628 -\n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  ",
            "\t\tpublic RegisterApplicationMasterResponseReflector(Logger LOG) {\n\t\t\tthis.logger = LOG;\n\n\t\t\ttry {\n\t\t\t\tmethod = RegisterApplicationMasterResponse.class\n\t\t\t\t\t.getMethod(\"getContainersFromPreviousAttempts\");\n\n\t\t\t} catch (NoSuchMethodException e) {\n\t\t\t\t// that happens in earlier Hadoop versions\n\t\t\t\tlogger.info(\"Cannot reconnect to previously allocated containers. \" +\n\t\t\t\t\t\"This YARN version does not support 'getContainersFromPreviousAttempts()'\");\n\t\t\t}\n\t\t}",
            " 625 +\n 626 +\n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  ",
            "\t\tpublic RegisterApplicationMasterResponseReflector(Logger log) {\n\t\t\tthis.logger = log;\n\n\t\t\ttry {\n\t\t\t\tmethod = RegisterApplicationMasterResponse.class\n\t\t\t\t\t.getMethod(\"getContainersFromPreviousAttempts\");\n\n\t\t\t} catch (NoSuchMethodException e) {\n\t\t\t\t// that happens in earlier Hadoop versions\n\t\t\t\tlogger.info(\"Cannot reconnect to previously allocated containers. \" +\n\t\t\t\t\t\"This YARN version does not support 'getContainersFromPreviousAttempts()'\");\n\t\t\t}\n\t\t}"
        ],
        [
            "AbstractYarnClusterDescriptor::deployInternal()",
            " 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456 -\n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480 -\n 481  \n 482 -\n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498 -\n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506 -\n 507  \n 508  \n 509 -\n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518 -\n 519 -\n 520  \n 521  \n 522 -\n 523  \n 524  \n 525 -\n 526  \n 527  \n 528 -\n 529  \n 530  \n 531 -\n 532  \n 533  \n 534  \n 535  \n 536  \n 537 -\n 538  \n 539 -\n 540  \n 541  \n 542 -\n 543  \n 544 -\n 545  \n 546 -\n 547  \n 548 -\n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555 -\n 556  \n 557  \n 558 -\n 559  \n 560  \n 561 -\n 562 -\n 563  \n 564  \n 565  \n 566  \n 567 -\n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  ",
            "\t/**\n\t * This method will block until the ApplicationMaster/JobManager have been\n\t * deployed on YARN.\n\t */\n\tprotected YarnClusterClient deployInternal() throws Exception {\n\t\tisReadyForDeployment();\n\t\tLOG.info(\"Using values:\");\n\t\tLOG.info(\"\\tTaskManager count = {}\", taskManagerCount);\n\t\tLOG.info(\"\\tJobManager memory = {}\", jobManagerMemoryMb);\n\t\tLOG.info(\"\\tTaskManager memory = {}\", taskManagerMemoryMb);\n\n\t\tfinal YarnClient yarnClient = getYarnClient();\n\n\n\t\t// ------------------ Check if the specified queue exists --------------------\n\n\t\ttry {\n\t\t\tList<QueueInfo> queues = yarnClient.getAllQueues();\n\t\t\tif (queues.size() > 0 && this.yarnQueue != null) { // check only if there are queues configured in yarn and for this session.\n\t\t\t\tboolean queueFound = false;\n\t\t\t\tfor (QueueInfo queue : queues) {\n\t\t\t\t\tif (queue.getQueueName().equals(this.yarnQueue)) {\n\t\t\t\t\t\tqueueFound = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!queueFound) {\n\t\t\t\t\tString queueNames = \"\";\n\t\t\t\t\tfor (QueueInfo queue : queues) {\n\t\t\t\t\t\tqueueNames += queue.getQueueName() + \", \";\n\t\t\t\t\t}\n\t\t\t\t\tLOG.warn(\"The specified queue '\" + this.yarnQueue + \"' does not exist. \" +\n\t\t\t\t\t\t\"Available queues: \" + queueNames);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tLOG.debug(\"The YARN cluster does not have any queues configured\");\n\t\t\t}\n\t\t} catch(Throwable e) {\n\t\t\tLOG.warn(\"Error while getting queue information from YARN: \" + e.getMessage());\n\t\t\tif(LOG.isDebugEnabled()) {\n\t\t\t\tLOG.debug(\"Error details\", e);\n\t\t\t}\n\t\t}\n\n\t\t// ------------------ Add dynamic properties to local flinkConfiguraton ------\n\t\tMap<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded);\n\t\tfor (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {\n\t\t\tflinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue());\n\t\t}\n\n\t\t// ------------------ Check if the YARN ClusterClient has the requested resources --------------\n\n\t\t// the yarnMinAllocationMB specifies the smallest possible container allocation size.\n\t\t// all allocations below this value are automatically set to this value.\n\t\tfinal int yarnMinAllocationMB = conf.getInt(\"yarn.scheduler.minimum-allocation-mb\", 0);\n\t\tif(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {\n\t\t\tLOG.warn(\"The JobManager or TaskManager memory is below the smallest possible YARN Container size. \"\n\t\t\t\t+ \"The value of 'yarn.scheduler.minimum-allocation-mb' is '\" + yarnMinAllocationMB + \"'. Please increase the memory size.\" +\n\t\t\t\t\"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances \" +\n\t\t\t\t\"you requested will start.\");\n\t\t}\n\n\t\t// set the memory to minAllocationMB to do the next checks correctly\n\t\tif(jobManagerMemoryMb < yarnMinAllocationMB) {\n\t\t\tjobManagerMemoryMb =  yarnMinAllocationMB;\n\t\t}\n\t\tif(taskManagerMemoryMb < yarnMinAllocationMB) {\n\t\t\ttaskManagerMemoryMb =  yarnMinAllocationMB;\n\t\t}\n\n\t\t// Create application via yarnClient\n\t\tfinal YarnClientApplication yarnApplication = yarnClient.createApplication();\n\t\tGetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse();\n\n\t\tResource maxRes = appResponse.getMaximumResourceCapability();\n\t\tfinal String NOTE = \"Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\\n\";\n\t\tif(jobManagerMemoryMb > maxRes.getMemory() ) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow new YarnDeploymentException(\"The cluster does not have the requested resources for the JobManager available!\\n\"\n\t\t\t\t+ \"Maximum Memory: \" + maxRes.getMemory() + \"MB Requested: \" + jobManagerMemoryMb + \"MB. \" + NOTE);\n\t\t}\n\n\t\tif(taskManagerMemoryMb > maxRes.getMemory() ) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow new YarnDeploymentException(\"The cluster does not have the requested resources for the TaskManagers available!\\n\"\n\t\t\t\t+ \"Maximum Memory: \" + maxRes.getMemory() + \" Requested: \" + taskManagerMemoryMb + \"MB. \" + NOTE);\n\t\t}\n\n\t\tfinal String NOTE_RSC = \"\\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are \" +\n\t\t\t\"connecting from the beginning because the resources are currently not available in the cluster. \" +\n\t\t\t\"The allocation might take more time than usual because the Flink YARN client needs to wait until \" +\n\t\t\t\"the resources become available.\";\n\t\tint totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount;\n\t\tClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient);\n\t\tif(freeClusterMem.totalFreeMemory < totalMemoryRequired) {\n\t\t\tLOG.warn(\"This YARN session requires \" + totalMemoryRequired + \"MB of memory in the cluster. \"\n\t\t\t\t+ \"There are currently only \" + freeClusterMem.totalFreeMemory + \"MB available.\" + NOTE_RSC);\n\n\t\t}\n\t\tif(taskManagerMemoryMb > freeClusterMem.containerLimit) {\n\t\t\tLOG.warn(\"The requested amount of memory for the TaskManagers (\" + taskManagerMemoryMb + \"MB) is more than \"\n\t\t\t\t+ \"the largest possible YARN container: \" + freeClusterMem.containerLimit + NOTE_RSC);\n\t\t}\n\t\tif(jobManagerMemoryMb > freeClusterMem.containerLimit) {\n\t\t\tLOG.warn(\"The requested amount of memory for the JobManager (\" + jobManagerMemoryMb + \"MB) is more than \"\n\t\t\t\t+ \"the largest possible YARN container: \" + freeClusterMem.containerLimit + NOTE_RSC);\n\t\t}\n\n\t\t// ----------------- check if the requested containers fit into the cluster.\n\n\t\tint[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length);\n\t\t// first, allocate the jobManager somewhere.\n\t\tif(!allocateResource(nmFree, jobManagerMemoryMb)) {\n\t\t\tLOG.warn(\"Unable to find a NodeManager that can fit the JobManager/Application master. \" +\n\t\t\t\t\"The JobManager requires \" + jobManagerMemoryMb + \"MB. NodeManagers available: \" +\n\t\t\t\tArrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC);\n\t\t}\n\t\t// allocate TaskManagers\n\t\tfor(int i = 0; i < taskManagerCount; i++) {\n\t\t\tif(!allocateResource(nmFree, taskManagerMemoryMb)) {\n\t\t\t\tLOG.warn(\"There is not enough memory available in the YARN cluster. \" +\n\t\t\t\t\t\"The TaskManager(s) require \" + taskManagerMemoryMb + \"MB each. \" +\n\t\t\t\t\t\"NodeManagers available: \" + Arrays.toString(freeClusterMem.nodeManagersFree) + \"\\n\" +\n\t\t\t\t\t\"After allocating the JobManager (\" + jobManagerMemoryMb + \"MB) and (\" + i + \"/\" + taskManagerCount + \") TaskManagers, \" +\n\t\t\t\t\t\"the following NodeManagers are available: \" + Arrays.toString(nmFree)  + NOTE_RSC );\n\t\t\t}\n\t\t}\n\n\t\tApplicationReport report = startAppMaster(null, yarnClient, yarnApplication);\n\n\t\tString host = report.getHost();\n\t\tint port = report.getRpcPort();\n\n\t\t// Correctly initialize the Flink config\n\t\tflinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host);\n\t\tflinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port);\n\n\t\t// the Flink cluster is deployed in YARN. Represent cluster\n\t\treturn createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true);\n\t}",
            " 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486 +\n 487  \n 488 +\n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504 +\n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512 +\n 513  \n 514  \n 515 +\n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524 +\n 525 +\n 526  \n 527  \n 528 +\n 529  \n 530  \n 531 +\n 532  \n 533  \n 534 +\n 535  \n 536  \n 537 +\n 538  \n 539  \n 540  \n 541  \n 542  \n 543 +\n 544  \n 545 +\n 546  \n 547  \n 548 +\n 549  \n 550 +\n 551  \n 552 +\n 553  \n 554 +\n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561 +\n 562  \n 563  \n 564 +\n 565  \n 566  \n 567 +\n 568 +\n 569  \n 570  \n 571  \n 572  \n 573 +\n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  ",
            "\t/**\n\t * This method will block until the ApplicationMaster/JobManager have been\n\t * deployed on YARN.\n\t */\n\tprotected YarnClusterClient deployInternal() throws Exception {\n\t\tisReadyForDeployment();\n\t\tLOG.info(\"Using values:\");\n\t\tLOG.info(\"\\tTaskManager count = {}\", taskManagerCount);\n\t\tLOG.info(\"\\tJobManager memory = {}\", jobManagerMemoryMb);\n\t\tLOG.info(\"\\tTaskManager memory = {}\", taskManagerMemoryMb);\n\n\t\tfinal YarnClient yarnClient = getYarnClient();\n\n\t\t// ------------------ Check if the specified queue exists --------------------\n\n\t\ttry {\n\t\t\tList<QueueInfo> queues = yarnClient.getAllQueues();\n\t\t\tif (queues.size() > 0 && this.yarnQueue != null) { // check only if there are queues configured in yarn and for this session.\n\t\t\t\tboolean queueFound = false;\n\t\t\t\tfor (QueueInfo queue : queues) {\n\t\t\t\t\tif (queue.getQueueName().equals(this.yarnQueue)) {\n\t\t\t\t\t\tqueueFound = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!queueFound) {\n\t\t\t\t\tString queueNames = \"\";\n\t\t\t\t\tfor (QueueInfo queue : queues) {\n\t\t\t\t\t\tqueueNames += queue.getQueueName() + \", \";\n\t\t\t\t\t}\n\t\t\t\t\tLOG.warn(\"The specified queue '\" + this.yarnQueue + \"' does not exist. \" +\n\t\t\t\t\t\t\"Available queues: \" + queueNames);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tLOG.debug(\"The YARN cluster does not have any queues configured\");\n\t\t\t}\n\t\t} catch (Throwable e) {\n\t\t\tLOG.warn(\"Error while getting queue information from YARN: \" + e.getMessage());\n\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\tLOG.debug(\"Error details\", e);\n\t\t\t}\n\t\t}\n\n\t\t// ------------------ Add dynamic properties to local flinkConfiguraton ------\n\t\tMap<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded);\n\t\tfor (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {\n\t\t\tflinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue());\n\t\t}\n\n\t\t// ------------------ Check if the YARN ClusterClient has the requested resources --------------\n\n\t\t// the yarnMinAllocationMB specifies the smallest possible container allocation size.\n\t\t// all allocations below this value are automatically set to this value.\n\t\tfinal int yarnMinAllocationMB = conf.getInt(\"yarn.scheduler.minimum-allocation-mb\", 0);\n\t\tif (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {\n\t\t\tLOG.warn(\"The JobManager or TaskManager memory is below the smallest possible YARN Container size. \"\n\t\t\t\t+ \"The value of 'yarn.scheduler.minimum-allocation-mb' is '\" + yarnMinAllocationMB + \"'. Please increase the memory size.\" +\n\t\t\t\t\"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances \" +\n\t\t\t\t\"you requested will start.\");\n\t\t}\n\n\t\t// set the memory to minAllocationMB to do the next checks correctly\n\t\tif (jobManagerMemoryMb < yarnMinAllocationMB) {\n\t\t\tjobManagerMemoryMb =  yarnMinAllocationMB;\n\t\t}\n\t\tif (taskManagerMemoryMb < yarnMinAllocationMB) {\n\t\t\ttaskManagerMemoryMb =  yarnMinAllocationMB;\n\t\t}\n\n\t\t// Create application via yarnClient\n\t\tfinal YarnClientApplication yarnApplication = yarnClient.createApplication();\n\t\tGetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse();\n\n\t\tResource maxRes = appResponse.getMaximumResourceCapability();\n\t\tfinal String note = \"Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\\n\";\n\t\tif (jobManagerMemoryMb > maxRes.getMemory()) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow new YarnDeploymentException(\"The cluster does not have the requested resources for the JobManager available!\\n\"\n\t\t\t\t+ \"Maximum Memory: \" + maxRes.getMemory() + \"MB Requested: \" + jobManagerMemoryMb + \"MB. \" + note);\n\t\t}\n\n\t\tif (taskManagerMemoryMb > maxRes.getMemory()) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow new YarnDeploymentException(\"The cluster does not have the requested resources for the TaskManagers available!\\n\"\n\t\t\t\t+ \"Maximum Memory: \" + maxRes.getMemory() + \" Requested: \" + taskManagerMemoryMb + \"MB. \" + note);\n\t\t}\n\n\t\tfinal String noteRsc = \"\\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are \" +\n\t\t\t\"connecting from the beginning because the resources are currently not available in the cluster. \" +\n\t\t\t\"The allocation might take more time than usual because the Flink YARN client needs to wait until \" +\n\t\t\t\"the resources become available.\";\n\t\tint totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount;\n\t\tClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient);\n\t\tif (freeClusterMem.totalFreeMemory < totalMemoryRequired) {\n\t\t\tLOG.warn(\"This YARN session requires \" + totalMemoryRequired + \"MB of memory in the cluster. \"\n\t\t\t\t+ \"There are currently only \" + freeClusterMem.totalFreeMemory + \"MB available.\" + noteRsc);\n\n\t\t}\n\t\tif (taskManagerMemoryMb > freeClusterMem.containerLimit) {\n\t\t\tLOG.warn(\"The requested amount of memory for the TaskManagers (\" + taskManagerMemoryMb + \"MB) is more than \"\n\t\t\t\t+ \"the largest possible YARN container: \" + freeClusterMem.containerLimit + noteRsc);\n\t\t}\n\t\tif (jobManagerMemoryMb > freeClusterMem.containerLimit) {\n\t\t\tLOG.warn(\"The requested amount of memory for the JobManager (\" + jobManagerMemoryMb + \"MB) is more than \"\n\t\t\t\t+ \"the largest possible YARN container: \" + freeClusterMem.containerLimit + noteRsc);\n\t\t}\n\n\t\t// ----------------- check if the requested containers fit into the cluster.\n\n\t\tint[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length);\n\t\t// first, allocate the jobManager somewhere.\n\t\tif (!allocateResource(nmFree, jobManagerMemoryMb)) {\n\t\t\tLOG.warn(\"Unable to find a NodeManager that can fit the JobManager/Application master. \" +\n\t\t\t\t\"The JobManager requires \" + jobManagerMemoryMb + \"MB. NodeManagers available: \" +\n\t\t\t\tArrays.toString(freeClusterMem.nodeManagersFree) + noteRsc);\n\t\t}\n\t\t// allocate TaskManagers\n\t\tfor (int i = 0; i < taskManagerCount; i++) {\n\t\t\tif (!allocateResource(nmFree, taskManagerMemoryMb)) {\n\t\t\t\tLOG.warn(\"There is not enough memory available in the YARN cluster. \" +\n\t\t\t\t\t\"The TaskManager(s) require \" + taskManagerMemoryMb + \"MB each. \" +\n\t\t\t\t\t\"NodeManagers available: \" + Arrays.toString(freeClusterMem.nodeManagersFree) + \"\\n\" +\n\t\t\t\t\t\"After allocating the JobManager (\" + jobManagerMemoryMb + \"MB) and (\" + i + \"/\" + taskManagerCount + \") TaskManagers, \" +\n\t\t\t\t\t\"the following NodeManagers are available: \" + Arrays.toString(nmFree)  + noteRsc);\n\t\t\t}\n\t\t}\n\n\t\tApplicationReport report = startAppMaster(null, yarnClient, yarnApplication);\n\n\t\tString host = report.getHost();\n\t\tint port = report.getRpcPort();\n\n\t\t// Correctly initialize the Flink config\n\t\tflinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host);\n\t\tflinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port);\n\n\t\t// the Flink cluster is deployed in YARN. Represent cluster\n\t\treturn createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true);\n\t}"
        ],
        [
            "FlinkYarnSessionCli::runInteractiveCli(YarnClusterClient,boolean)",
            " 405  \n 406 -\n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446 -\n 447 -\n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461 -\n 462  \n 463  \n 464 -\n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474 -\n 475  \n 476  \n 477  ",
            "\tpublic static void runInteractiveCli(YarnClusterClient yarnCluster, boolean readConsoleInput) {\n\t\tfinal String HELP = \"Available commands:\\n\" +\n\t\t\t\t\"help - show these commands\\n\" +\n\t\t\t\t\"stop - stop the YARN session\";\n\t\tint numTaskmanagers = 0;\n\t\ttry {\n\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(System.in));\n\t\t\tlabel:\n\t\t\twhile (true) {\n\t\t\t\t// ------------------ check if there are updates by the cluster -----------\n\n\t\t\t\ttry {\n\t\t\t\t\tGetClusterStatusResponse status = yarnCluster.getClusterStatus();\n\t\t\t\t\tLOG.debug(\"Received status message: {}\", status);\n\n\t\t\t\t\tif (status != null && numTaskmanagers != status.numRegisteredTaskManagers()) {\n\t\t\t\t\t\tSystem.err.println(\"Number of connected TaskManagers changed to \" +\n\t\t\t\t\t\t\tstatus.numRegisteredTaskManagers() + \". \" +\n\t\t\t\t\t\t\t\"Slots available: \" + status.totalNumberOfSlots());\n\t\t\t\t\t\tnumTaskmanagers = status.numRegisteredTaskManagers();\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tLOG.warn(\"Could not retrieve the current cluster status. Skipping current retrieval attempt ...\", e);\n\t\t\t\t}\n\n\t\t\t\tList<String> messages = yarnCluster.getNewMessages();\n\t\t\t\tif (messages != null && messages.size() > 0) {\n\t\t\t\t\tSystem.err.println(\"New messages from the YARN cluster: \");\n\t\t\t\t\tfor (String msg : messages) {\n\t\t\t\t\t\tSystem.err.println(msg);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (yarnCluster.getApplicationStatus() != ApplicationStatus.SUCCEEDED) {\n\t\t\t\t\tSystem.err.println(\"The YARN cluster has failed\");\n\t\t\t\t\tyarnCluster.shutdown();\n\t\t\t\t}\n\n\t\t\t\t// wait until CLIENT_POLLING_INTERVAL is over or the user entered something.\n\t\t\t\tlong startTime = System.currentTimeMillis();\n\t\t\t\twhile ((System.currentTimeMillis() - startTime) < CLIENT_POLLING_INTERVALL * 1000\n\t\t\t\t\t\t&& (!readConsoleInput || !in.ready()))\n\t\t\t\t{\n\t\t\t\t\tThread.sleep(200);\n\t\t\t\t}\n\t\t\t\t//------------- handle interactive command by user. ----------------------\n\n\t\t\t\tif (readConsoleInput && in.ready()) {\n\t\t\t\t\tString command = in.readLine();\n\t\t\t\t\tswitch (command) {\n\t\t\t\t\t\tcase \"quit\":\n\t\t\t\t\t\tcase \"stop\":\n\t\t\t\t\t\t\tyarnCluster.shutdownCluster();\n\t\t\t\t\t\t\tbreak label;\n\n\t\t\t\t\t\tcase \"help\":\n\t\t\t\t\t\t\tSystem.err.println(HELP);\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tSystem.err.println(\"Unknown command '\" + command + \"'. Showing help: \\n\" + HELP);\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (yarnCluster.hasBeenShutdown()) {\n\t\t\t\t\tLOG.info(\"Stopping interactive command line interface, YARN cluster has been stopped.\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch(Exception e) {\n\t\t\tLOG.warn(\"Exception while running the interactive command line interface\", e);\n\t\t}\n\t}",
            " 406  \n 407 +\n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447 +\n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461 +\n 462  \n 463  \n 464 +\n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474 +\n 475  \n 476  \n 477  ",
            "\tpublic static void runInteractiveCli(YarnClusterClient yarnCluster, boolean readConsoleInput) {\n\t\tfinal String help = \"Available commands:\\n\" +\n\t\t\t\t\"help - show these commands\\n\" +\n\t\t\t\t\"stop - stop the YARN session\";\n\t\tint numTaskmanagers = 0;\n\t\ttry {\n\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(System.in));\n\t\t\tlabel:\n\t\t\twhile (true) {\n\t\t\t\t// ------------------ check if there are updates by the cluster -----------\n\n\t\t\t\ttry {\n\t\t\t\t\tGetClusterStatusResponse status = yarnCluster.getClusterStatus();\n\t\t\t\t\tLOG.debug(\"Received status message: {}\", status);\n\n\t\t\t\t\tif (status != null && numTaskmanagers != status.numRegisteredTaskManagers()) {\n\t\t\t\t\t\tSystem.err.println(\"Number of connected TaskManagers changed to \" +\n\t\t\t\t\t\t\tstatus.numRegisteredTaskManagers() + \". \" +\n\t\t\t\t\t\t\t\"Slots available: \" + status.totalNumberOfSlots());\n\t\t\t\t\t\tnumTaskmanagers = status.numRegisteredTaskManagers();\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tLOG.warn(\"Could not retrieve the current cluster status. Skipping current retrieval attempt ...\", e);\n\t\t\t\t}\n\n\t\t\t\tList<String> messages = yarnCluster.getNewMessages();\n\t\t\t\tif (messages != null && messages.size() > 0) {\n\t\t\t\t\tSystem.err.println(\"New messages from the YARN cluster: \");\n\t\t\t\t\tfor (String msg : messages) {\n\t\t\t\t\t\tSystem.err.println(msg);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (yarnCluster.getApplicationStatus() != ApplicationStatus.SUCCEEDED) {\n\t\t\t\t\tSystem.err.println(\"The YARN cluster has failed\");\n\t\t\t\t\tyarnCluster.shutdown();\n\t\t\t\t}\n\n\t\t\t\t// wait until CLIENT_POLLING_INTERVAL is over or the user entered something.\n\t\t\t\tlong startTime = System.currentTimeMillis();\n\t\t\t\twhile ((System.currentTimeMillis() - startTime) < CLIENT_POLLING_INTERVALL * 1000\n\t\t\t\t\t\t&& (!readConsoleInput || !in.ready())) {\n\t\t\t\t\tThread.sleep(200);\n\t\t\t\t}\n\t\t\t\t//------------- handle interactive command by user. ----------------------\n\n\t\t\t\tif (readConsoleInput && in.ready()) {\n\t\t\t\t\tString command = in.readLine();\n\t\t\t\t\tswitch (command) {\n\t\t\t\t\t\tcase \"quit\":\n\t\t\t\t\t\tcase \"stop\":\n\t\t\t\t\t\t\tyarnCluster.shutdownCluster();\n\t\t\t\t\t\t\tbreak label;\n\n\t\t\t\t\t\tcase \"help\":\n\t\t\t\t\t\t\tSystem.err.println(help);\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tSystem.err.println(\"Unknown command '\" + command + \"'. Showing help: \\n\" + help);\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (yarnCluster.hasBeenShutdown()) {\n\t\t\t\t\tLOG.info(\"Stopping interactive command line interface, YARN cluster has been stopped.\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Exception while running the interactive command line interface\", e);\n\t\t}\n\t}"
        ],
        [
            "YarnResourceManager::onShutdownRequest()",
            " 277  \n 278  \n 279  \n 280  \n 281  \n 282 -\n 283  \n 284  ",
            "\t@Override\n\tpublic void onShutdownRequest() {\n\t\ttry {\n\t\t\tshutDown();\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Fail to shutdown the YARN resource manager.\", e);\n\t\t}\n\t}",
            " 276  \n 277  \n 278  \n 279  \n 280  \n 281 +\n 282  \n 283  ",
            "\t@Override\n\tpublic void onShutdownRequest() {\n\t\ttry {\n\t\t\tshutDown();\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Fail to shutdown the YARN resource manager.\", e);\n\t\t}\n\t}"
        ],
        [
            "YarnClusterClient::shutdownCluster()",
            " 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368 -\n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388 -\n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  ",
            "\t/**\n\t * Shuts down the Yarn application\n\t */\n\tpublic void shutdownCluster() {\n\n\t\tif (hasBeenShutDown.getAndSet(true)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (!isConnected) {\n\t\t\tthrow new IllegalStateException(\"The cluster has been not been connected to the ApplicationMaster.\");\n\t\t}\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().removeShutdownHook(clientShutdownHook);\n\t\t} catch (IllegalStateException e) {\n\t\t\t// we are already in the shutdown hook\n\t\t}\n\n\t\tLOG.info(\"Sending shutdown request to the Application Master\");\n\t\ttry {\n\t\t\tFuture<Object> response =\n\t\t\t\tPatterns.ask(applicationClient.get(),\n\t\t\t\t\tnew YarnMessages.LocalStopYarnSession(getApplicationStatus(),\n\t\t\t\t\t\t\t\"Flink YARN Client requested shutdown\"),\n\t\t\t\t\tnew Timeout(akkaDuration));\n\t\t\tAwait.ready(response, akkaDuration);\n\t\t} catch(Exception e) {\n\t\t\tLOG.warn(\"Error while stopping YARN cluster.\", e);\n\t\t}\n\n\t\ttry {\n\t\t\tFile propertiesFile = FlinkYarnSessionCli.getYarnPropertiesLocation(flinkConfig);\n\t\t\tif (propertiesFile.isFile()) {\n\t\t\t\tif (propertiesFile.delete()) {\n\t\t\t\t\tLOG.info(\"Deleted Yarn properties file at {}\", propertiesFile.getAbsoluteFile().toString());\n\t\t\t\t} else {\n\t\t\t\t\tLOG.warn(\"Couldn't delete Yarn properties file at {}\", propertiesFile.getAbsoluteFile().toString());\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Exception while deleting the JobManager address file\", e);\n\t\t}\n\n\t\ttry {\n\t\t\tpollingRunner.stopRunner();\n\t\t\tpollingRunner.join(1000);\n\t\t} catch(InterruptedException e) {\n\t\t\tLOG.warn(\"Shutdown of the polling runner was interrupted\", e);\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\n\t\ttry {\n\t\t\tApplicationReport appReport = yarnClient.getApplicationReport(appId);\n\n\t\t\tLOG.info(\"Application \" + appId + \" finished with state \" + appReport\n\t\t\t\t.getYarnApplicationState() + \" and final state \" + appReport\n\t\t\t\t.getFinalApplicationStatus() + \" at \" + appReport.getFinishTime());\n\n\t\t\tif (appReport.getYarnApplicationState() == YarnApplicationState.FAILED || appReport.getYarnApplicationState()\n\t\t\t\t== YarnApplicationState.KILLED) {\n\t\t\t\tLOG.warn(\"Application failed. Diagnostics \" + appReport.getDiagnostics());\n\t\t\t\tLOG.warn(\"If log aggregation is activated in the Hadoop cluster, we recommend to retrieve \"\n\t\t\t\t\t+ \"the full application log using this command:\"\n\t\t\t\t\t+ System.lineSeparator()\n\t\t\t\t\t+ \"\\tyarn logs -applicationId \" + appReport.getApplicationId()\n\t\t\t\t\t+ System.lineSeparator()\n\t\t\t\t\t+ \"(It sometimes takes a few seconds until the logs are aggregated)\");\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Couldn't get final report\", e);\n\t\t}\n\n\t\tLOG.info(\"YARN Client is shutting down\");\n\t\tyarnClient.stop(); // actorRunner is using the yarnClient.\n\t\tyarnClient = null; // set null to clearly see if somebody wants to access it afterwards.\n\t}",
            " 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369 +\n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389 +\n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  ",
            "\t/**\n\t * Shuts down the Yarn application.\n\t */\n\tpublic void shutdownCluster() {\n\n\t\tif (hasBeenShutDown.getAndSet(true)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (!isConnected) {\n\t\t\tthrow new IllegalStateException(\"The cluster has been not been connected to the ApplicationMaster.\");\n\t\t}\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().removeShutdownHook(clientShutdownHook);\n\t\t} catch (IllegalStateException e) {\n\t\t\t// we are already in the shutdown hook\n\t\t}\n\n\t\tLOG.info(\"Sending shutdown request to the Application Master\");\n\t\ttry {\n\t\t\tFuture<Object> response =\n\t\t\t\tPatterns.ask(applicationClient.get(),\n\t\t\t\t\tnew YarnMessages.LocalStopYarnSession(getApplicationStatus(),\n\t\t\t\t\t\t\t\"Flink YARN Client requested shutdown\"),\n\t\t\t\t\tnew Timeout(akkaDuration));\n\t\t\tAwait.ready(response, akkaDuration);\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Error while stopping YARN cluster.\", e);\n\t\t}\n\n\t\ttry {\n\t\t\tFile propertiesFile = FlinkYarnSessionCli.getYarnPropertiesLocation(flinkConfig);\n\t\t\tif (propertiesFile.isFile()) {\n\t\t\t\tif (propertiesFile.delete()) {\n\t\t\t\t\tLOG.info(\"Deleted Yarn properties file at {}\", propertiesFile.getAbsoluteFile().toString());\n\t\t\t\t} else {\n\t\t\t\t\tLOG.warn(\"Couldn't delete Yarn properties file at {}\", propertiesFile.getAbsoluteFile().toString());\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Exception while deleting the JobManager address file\", e);\n\t\t}\n\n\t\ttry {\n\t\t\tpollingRunner.stopRunner();\n\t\t\tpollingRunner.join(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tLOG.warn(\"Shutdown of the polling runner was interrupted\", e);\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\n\t\ttry {\n\t\t\tApplicationReport appReport = yarnClient.getApplicationReport(appId);\n\n\t\t\tLOG.info(\"Application \" + appId + \" finished with state \" + appReport\n\t\t\t\t.getYarnApplicationState() + \" and final state \" + appReport\n\t\t\t\t.getFinalApplicationStatus() + \" at \" + appReport.getFinishTime());\n\n\t\t\tif (appReport.getYarnApplicationState() == YarnApplicationState.FAILED || appReport.getYarnApplicationState()\n\t\t\t\t== YarnApplicationState.KILLED) {\n\t\t\t\tLOG.warn(\"Application failed. Diagnostics \" + appReport.getDiagnostics());\n\t\t\t\tLOG.warn(\"If log aggregation is activated in the Hadoop cluster, we recommend to retrieve \"\n\t\t\t\t\t+ \"the full application log using this command:\"\n\t\t\t\t\t+ System.lineSeparator()\n\t\t\t\t\t+ \"\\tyarn logs -applicationId \" + appReport.getApplicationId()\n\t\t\t\t\t+ System.lineSeparator()\n\t\t\t\t\t+ \"(It sometimes takes a few seconds until the logs are aggregated)\");\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Couldn't get final report\", e);\n\t\t}\n\n\t\tLOG.info(\"YARN Client is shutting down\");\n\t\tyarnClient.stop(); // actorRunner is using the yarnClient.\n\t\tyarnClient = null; // set null to clearly see if somebody wants to access it afterwards.\n\t}"
        ],
        [
            "Utils::calculateHeapSize(int,org)",
            "  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105 -\n 106  \n 107  \n 108  \n 109  \n 110  ",
            "\t/**\n\t * See documentation\n\t */\n\tpublic static int calculateHeapSize(int memory, org.apache.flink.configuration.Configuration conf) {\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(conf,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_RATIO, ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO);\n\t\tBootstrapTools.substituteDeprecatedConfigKey(conf,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_MIN, ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN);\n\n\t\tfloat memoryCutoffRatio = conf.getFloat(ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO,\n\t\t\tConfigConstants.DEFAULT_YARN_HEAP_CUTOFF_RATIO);\n\t\tint minCutoff = conf.getInteger(ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN,\n\t\t\tConfigConstants.DEFAULT_YARN_HEAP_CUTOFF);\n\n\t\tif (memoryCutoffRatio > 1 || memoryCutoffRatio < 0) {\n\t\t\tthrow new IllegalArgumentException(\"The configuration value '\"\n\t\t\t\t+ ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO\n\t\t\t\t+ \"' must be between 0 and 1. Value given=\" + memoryCutoffRatio);\n\t\t}\n\t\tif (minCutoff > memory) {\n\t\t\tthrow new IllegalArgumentException(\"The configuration value '\"\n\t\t\t\t+ ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN\n\t\t\t\t+ \"' is higher (\" + minCutoff + \") than the requested amount of memory \" + memory);\n\t\t}\n\n\t\tint heapLimit = (int)((float)memory * memoryCutoffRatio);\n\t\tif (heapLimit < minCutoff) {\n\t\t\theapLimit = minCutoff;\n\t\t}\n\t\treturn memory - heapLimit;\n\t}",
            "  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104 +\n 105  \n 106  \n 107  \n 108  \n 109  ",
            "\t/**\n\t * See documentation.\n\t */\n\tpublic static int calculateHeapSize(int memory, org.apache.flink.configuration.Configuration conf) {\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(conf,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_RATIO, ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO);\n\t\tBootstrapTools.substituteDeprecatedConfigKey(conf,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_MIN, ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN);\n\n\t\tfloat memoryCutoffRatio = conf.getFloat(ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO,\n\t\t\tConfigConstants.DEFAULT_YARN_HEAP_CUTOFF_RATIO);\n\t\tint minCutoff = conf.getInteger(ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN,\n\t\t\tConfigConstants.DEFAULT_YARN_HEAP_CUTOFF);\n\n\t\tif (memoryCutoffRatio > 1 || memoryCutoffRatio < 0) {\n\t\t\tthrow new IllegalArgumentException(\"The configuration value '\"\n\t\t\t\t+ ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO\n\t\t\t\t+ \"' must be between 0 and 1. Value given=\" + memoryCutoffRatio);\n\t\t}\n\t\tif (minCutoff > memory) {\n\t\t\tthrow new IllegalArgumentException(\"The configuration value '\"\n\t\t\t\t+ ConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN\n\t\t\t\t+ \"' is higher (\" + minCutoff + \") than the requested amount of memory \" + memory);\n\t\t}\n\n\t\tint heapLimit = (int) ((float) memory * memoryCutoffRatio);\n\t\tif (heapLimit < minCutoff) {\n\t\t\theapLimit = minCutoff;\n\t\t}\n\t\treturn memory - heapLimit;\n\t}"
        ],
        [
            "FlinkYarnSessionCli::addRunOptions(Options)",
            " 505  \n 506  \n 507 -\n 508  \n 509  \n 510  ",
            "\t@Override\n\tpublic void addRunOptions(Options baseOptions) {\n\t\tfor (Object option : ALL_OPTIONS.getOptions()) {\n\t\t\tbaseOptions.addOption((Option) option);\n\t\t}\n\t}",
            " 505  \n 506  \n 507 +\n 508  \n 509  \n 510  ",
            "\t@Override\n\tpublic void addRunOptions(Options baseOptions) {\n\t\tfor (Object option : allOptions.getOptions()) {\n\t\t\tbaseOptions.addOption((Option) option);\n\t\t}\n\t}"
        ],
        [
            "YarnResourceManager::requestYarnContainer(Resource,Priority)",
            " 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336 -\n 337  \n 338  ",
            "\tprivate void requestYarnContainer(Resource resource, Priority priority) {\n\t\tresourceManagerClient.addContainerRequest(\n\t\t\t\tnew AMRMClient.ContainerRequest(resource, null, null, priority));\n\t\t// make sure we transmit the request fast and receive fast news of granted allocations\n\t\tresourceManagerClient.setHeartbeatInterval(FAST_YARN_HEARTBEAT_INTERVAL_MS);\n\n\t\tnumPendingContainerRequests++;\n\t\tLOG.info(\"Requesting new TaskManager container pending requests: {}\",\n\t\t\t\tnumPendingContainerRequests);\n\t}",
            " 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335 +\n 336  \n 337  ",
            "\tprivate void requestYarnContainer(Resource resource, Priority priority) {\n\t\tresourceManagerClient.addContainerRequest(\n\t\t\t\tnew AMRMClient.ContainerRequest(resource, null, null, priority));\n\t\t// make sure we transmit the request fast and receive fast news of granted allocations\n\t\tresourceManagerClient.setHeartbeatInterval(FAST_YARN_HEARTBEAT_INTERVAL_MS);\n\n\t\tnumPendingContainerRequests++;\n\t\tlog.info(\"Requesting new TaskManager container pending requests: {}\",\n\t\t\t\tnumPendingContainerRequests);\n\t}"
        ],
        [
            "YarnIntraNonHaMasterServicesTest::initConfig()",
            "  96  \n  97  \n  98  \n  99 -\n 100  ",
            "\t@Before\n\tpublic void initConfig() {\n\t\thadoopConfig = new org.apache.hadoop.conf.Configuration();\n\t\thadoopConfig.set(org.apache.hadoop.fs.FileSystem.FS_DEFAULT_NAME_KEY, HDFS_ROOT_PATH.toString());\n\t}",
            "  97  \n  98  \n  99  \n 100 +\n 101  ",
            "\t@Before\n\tpublic void initConfig() {\n\t\thadoopConfig = new org.apache.hadoop.conf.Configuration();\n\t\thadoopConfig.set(org.apache.hadoop.fs.FileSystem.FS_DEFAULT_NAME_KEY, hdfsRootPath.toString());\n\t}"
        ],
        [
            "YarnFlinkResourceManager::createActorProps(Class,Configuration,YarnConfiguration,LeaderRetrievalService,String,String,ContaineredTaskManagerParameters,ContainerLaunchContext,int,Logger)",
            " 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709 -\n 710 -\n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  ",
            "\t/**\n\t * Creates the props needed to instantiate this actor.\n\t * \n\t * Rather than extracting and validating parameters in the constructor, this factory method takes\n\t * care of that. That way, errors occur synchronously, and are not swallowed simply in a\n\t * failed asynchronous attempt to start the actor.\n\t \n\t * @param actorClass \n\t *             The actor class, to allow overriding this actor with subclasses for testing.\n\t * @param flinkConfig\n\t *             The Flink configuration object.\n\t * @param yarnConfig\n\t *             The YARN configuration object.\n\t * @param applicationMasterHostName\n\t *             The hostname where this application master actor runs.\n\t * @param webFrontendURL\n\t *             The URL of the tracking web frontend.\n\t * @param taskManagerParameters\n\t *             The parameters for launching TaskManager containers.\n\t * @param taskManagerLaunchContext\n\t *             The parameters for launching the TaskManager processes in the TaskManager containers.\n\t * @param numInitialTaskManagers\n\t *             The initial number of TaskManagers to allocate.\n\t * @param log\n\t *             The logger to log to.\n\t * \n\t * @return The Props object to instantiate the YarnFlinkResourceManager actor.\n\t */\n\tpublic static Props createActorProps(Class<? extends YarnFlinkResourceManager> actorClass,\n\t\t\tConfiguration flinkConfig,\n\t\t\tYarnConfiguration yarnConfig,\n\t\t\tLeaderRetrievalService leaderRetrievalService,\n\t\t\tString applicationMasterHostName,\n\t\t\tString webFrontendURL,\n\t\t\tContaineredTaskManagerParameters taskManagerParameters,\n\t\t\tContainerLaunchContext taskManagerLaunchContext,\n\t\t\tint numInitialTaskManagers,\n\t\t\tLogger log)\n\t{\n\t\tfinal int yarnHeartbeatIntervalMS = flinkConfig.getInteger(\n\t\t\tConfigConstants.YARN_HEARTBEAT_DELAY_SECONDS, DEFAULT_YARN_HEARTBEAT_INTERVAL_MS / 1000) * 1000;\n\n\t\tfinal long yarnExpiryIntervalMS = yarnConfig.getLong(\n\t\t\tYarnConfiguration.RM_AM_EXPIRY_INTERVAL_MS,\n\t\t\tYarnConfiguration.DEFAULT_RM_AM_EXPIRY_INTERVAL_MS);\n\n\t\tif (yarnHeartbeatIntervalMS >= yarnExpiryIntervalMS) {\n\t\t\tlog.warn(\"The heartbeat interval of the Flink Application master ({}) is greater \" +\n\t\t\t\t\t\"than YARN's expiry interval ({}). The application is likely to be killed by YARN.\",\n\t\t\t\tyarnHeartbeatIntervalMS, yarnExpiryIntervalMS);\n\t\t}\n\n\t\tfinal int maxFailedContainers = flinkConfig.getInteger(\n\t\t\tConfigConstants.YARN_MAX_FAILED_CONTAINERS, numInitialTaskManagers);\n\t\tif (maxFailedContainers >= 0) {\n\t\t\tlog.info(\"YARN application tolerates {} failed TaskManager containers before giving up\",\n\t\t\t\tmaxFailedContainers);\n\t\t}\n\n\t\treturn Props.create(actorClass,\n\t\t\tflinkConfig,\n\t\t\tyarnConfig,\n\t\t\tleaderRetrievalService,\n\t\t\tapplicationMasterHostName,\n\t\t\twebFrontendURL,\n\t\t\ttaskManagerParameters,\n\t\t\ttaskManagerLaunchContext,\n\t\t\tyarnHeartbeatIntervalMS,\n\t\t\tmaxFailedContainers,\n\t\t\tnumInitialTaskManagers);\n\t}",
            " 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707 +\n 708 +\n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  ",
            "\t/**\n\t * Creates the props needed to instantiate this actor.\n\t *\n\t * <p>Rather than extracting and validating parameters in the constructor, this factory method takes\n\t * care of that. That way, errors occur synchronously, and are not swallowed simply in a\n\t * failed asynchronous attempt to start the actor.\n\t *\n\t * @param actorClass\n\t *             The actor class, to allow overriding this actor with subclasses for testing.\n\t * @param flinkConfig\n\t *             The Flink configuration object.\n\t * @param yarnConfig\n\t *             The YARN configuration object.\n\t * @param applicationMasterHostName\n\t *             The hostname where this application master actor runs.\n\t * @param webFrontendURL\n\t *             The URL of the tracking web frontend.\n\t * @param taskManagerParameters\n\t *             The parameters for launching TaskManager containers.\n\t * @param taskManagerLaunchContext\n\t *             The parameters for launching the TaskManager processes in the TaskManager containers.\n\t * @param numInitialTaskManagers\n\t *             The initial number of TaskManagers to allocate.\n\t * @param log\n\t *             The logger to log to.\n\t *\n\t * @return The Props object to instantiate the YarnFlinkResourceManager actor.\n\t */\n\tpublic static Props createActorProps(Class<? extends YarnFlinkResourceManager> actorClass,\n\t\t\tConfiguration flinkConfig,\n\t\t\tYarnConfiguration yarnConfig,\n\t\t\tLeaderRetrievalService leaderRetrievalService,\n\t\t\tString applicationMasterHostName,\n\t\t\tString webFrontendURL,\n\t\t\tContaineredTaskManagerParameters taskManagerParameters,\n\t\t\tContainerLaunchContext taskManagerLaunchContext,\n\t\t\tint numInitialTaskManagers,\n\t\t\tLogger log) {\n\n\t\tfinal int yarnHeartbeatIntervalMS = flinkConfig.getInteger(\n\t\t\tConfigConstants.YARN_HEARTBEAT_DELAY_SECONDS, DEFAULT_YARN_HEARTBEAT_INTERVAL_MS / 1000) * 1000;\n\n\t\tfinal long yarnExpiryIntervalMS = yarnConfig.getLong(\n\t\t\tYarnConfiguration.RM_AM_EXPIRY_INTERVAL_MS,\n\t\t\tYarnConfiguration.DEFAULT_RM_AM_EXPIRY_INTERVAL_MS);\n\n\t\tif (yarnHeartbeatIntervalMS >= yarnExpiryIntervalMS) {\n\t\t\tlog.warn(\"The heartbeat interval of the Flink Application master ({}) is greater \" +\n\t\t\t\t\t\"than YARN's expiry interval ({}). The application is likely to be killed by YARN.\",\n\t\t\t\tyarnHeartbeatIntervalMS, yarnExpiryIntervalMS);\n\t\t}\n\n\t\tfinal int maxFailedContainers = flinkConfig.getInteger(\n\t\t\tConfigConstants.YARN_MAX_FAILED_CONTAINERS, numInitialTaskManagers);\n\t\tif (maxFailedContainers >= 0) {\n\t\t\tlog.info(\"YARN application tolerates {} failed TaskManager containers before giving up\",\n\t\t\t\tmaxFailedContainers);\n\t\t}\n\n\t\treturn Props.create(actorClass,\n\t\t\tflinkConfig,\n\t\t\tyarnConfig,\n\t\t\tleaderRetrievalService,\n\t\t\tapplicationMasterHostName,\n\t\t\twebFrontendURL,\n\t\t\ttaskManagerParameters,\n\t\t\ttaskManagerLaunchContext,\n\t\t\tyarnHeartbeatIntervalMS,\n\t\t\tmaxFailedContainers,\n\t\t\tnumInitialTaskManagers);\n\t}"
        ],
        [
            "FlinkYarnCLI::createDescriptor(String,CommandLine)",
            "  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103 -\n 104 -\n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120 -\n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128 -\n 129 -\n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141 -\n 142 -\n 143  \n 144  \n 145  \n 146 -\n 147 -\n 148  \n 149  \n 150  \n 151  \n 152 -\n 153 -\n 154  \n 155  \n 156  \n 157  \n 158  \n 159 -\n 160  \n 161  \n 162  \n 163  \n 164  \n 165 -\n 166  \n 167  \n 168  \n 169 -\n 170 -\n 171  \n 172  \n 173  \n 174  \n 175  ",
            "\tpublic YarnClusterDescriptorV2 createDescriptor(String defaultApplicationName, CommandLine cmd) {\n\n\t\tYarnClusterDescriptorV2 yarnClusterDescriptor = new YarnClusterDescriptorV2();\n\n\t\t// Jar Path\n\t\tPath localJarPath;\n\t\tif (cmd.hasOption(FLINK_JAR.getOpt())) {\n\t\t\tString userPath = cmd.getOptionValue(FLINK_JAR.getOpt());\n\t\t\tif (!userPath.startsWith(\"file://\")) {\n\t\t\t\tuserPath = \"file://\" + userPath;\n\t\t\t}\n\t\t\tlocalJarPath = new Path(userPath);\n\t\t} else {\n\t\t\tLOG.info(\"No path for the flink jar passed. Using the location of \"\n\t\t\t\t+ yarnClusterDescriptor.getClass() + \" to locate the jar\");\n\t\t\tString encodedJarPath =\n\t\t\t\tyarnClusterDescriptor.getClass().getProtectionDomain().getCodeSource().getLocation().getPath();\n\t\t\ttry {\n\t\t\t\t// we have to decode the url encoded parts of the path\n\t\t\t\tString decodedPath = URLDecoder.decode(encodedJarPath, Charset.defaultCharset().name());\n\t\t\t\tlocalJarPath = new Path(new File(decodedPath).toURI());\n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\tthrow new RuntimeException(\"Couldn't decode the encoded Flink dist jar path: \" + encodedJarPath +\n\t\t\t\t\t\" Please supply a path manually via the -\" + FLINK_JAR.getOpt() + \" option.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.setLocalJarPath(localJarPath);\n\n\t\tList<File> shipFiles = new ArrayList<>();\n\t\t// path to directory to ship\n\t\tif (cmd.hasOption(SHIP_PATH.getOpt())) {\n\t\t\tString shipPath = cmd.getOptionValue(SHIP_PATH.getOpt());\n\t\t\tFile shipDir = new File(shipPath);\n\t\t\tif (shipDir.isDirectory()) {\n\t\t\t\tshipFiles.add(shipDir);\n\t\t\t} else {\n\t\t\t\tLOG.warn(\"Ship directory is not a directory. Ignoring it.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.addShipFiles(shipFiles);\n\n\t\t// queue\n\t\tif (cmd.hasOption(QUEUE.getOpt())) {\n\t\t\tyarnClusterDescriptor.setQueue(cmd.getOptionValue(QUEUE.getOpt()));\n\t\t}\n\n\t\t// JobManager Memory\n\t\tif (cmd.hasOption(JM_MEMORY.getOpt())) {\n\t\t\tint jmMemory = Integer.valueOf(cmd.getOptionValue(JM_MEMORY.getOpt()));\n\t\t\tyarnClusterDescriptor.setJobManagerMemory(jmMemory);\n\t\t}\n\n\t\tString[] dynamicProperties = null;\n\t\tif (cmd.hasOption(DYNAMIC_PROPERTIES.getOpt())) {\n\t\t\tdynamicProperties = cmd.getOptionValues(DYNAMIC_PROPERTIES.getOpt());\n\t\t}\n\t\tString dynamicPropertiesEncoded = StringUtils.join(dynamicProperties, YARN_DYNAMIC_PROPERTIES_SEPARATOR);\n\n\t\tyarnClusterDescriptor.setDynamicPropertiesEncoded(dynamicPropertiesEncoded);\n\n\t\tif (cmd.hasOption(DETACHED.getOpt()) || cmd.hasOption(CliFrontendParser.DETACHED_OPTION.getOpt())) {\n\t\t\t// TODO: not support non detach mode now.\n\t\t\t//this.detachedMode = false;\n\t\t}\n\t\tyarnClusterDescriptor.setDetachedMode(this.detachedMode);\n\n\t\tif(defaultApplicationName != null) {\n\t\t\tyarnClusterDescriptor.setName(defaultApplicationName);\n\t\t}\n\n\t\tif (cmd.hasOption(ZOOKEEPER_NAMESPACE.getOpt())) {\n\t\t\tString zookeeperNamespace = cmd.getOptionValue(ZOOKEEPER_NAMESPACE.getOpt());\n\t\t\tyarnClusterDescriptor.setZookeeperNamespace(zookeeperNamespace);\n\t\t}\n\n\t\treturn yarnClusterDescriptor;\n\t}",
            "  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105 +\n 106 +\n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122 +\n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130 +\n 131 +\n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143 +\n 144 +\n 145  \n 146  \n 147  \n 148 +\n 149 +\n 150  \n 151  \n 152  \n 153  \n 154 +\n 155 +\n 156  \n 157  \n 158  \n 159  \n 160  \n 161 +\n 162  \n 163  \n 164  \n 165  \n 166  \n 167 +\n 168  \n 169  \n 170  \n 171 +\n 172 +\n 173  \n 174  \n 175  \n 176  \n 177  ",
            "\tpublic YarnClusterDescriptorV2 createDescriptor(String defaultApplicationName, CommandLine cmd) {\n\n\t\tYarnClusterDescriptorV2 yarnClusterDescriptor = new YarnClusterDescriptorV2();\n\n\t\t// Jar Path\n\t\tPath localJarPath;\n\t\tif (cmd.hasOption(flinkJar.getOpt())) {\n\t\t\tString userPath = cmd.getOptionValue(flinkJar.getOpt());\n\t\t\tif (!userPath.startsWith(\"file://\")) {\n\t\t\t\tuserPath = \"file://\" + userPath;\n\t\t\t}\n\t\t\tlocalJarPath = new Path(userPath);\n\t\t} else {\n\t\t\tLOG.info(\"No path for the flink jar passed. Using the location of \"\n\t\t\t\t+ yarnClusterDescriptor.getClass() + \" to locate the jar\");\n\t\t\tString encodedJarPath =\n\t\t\t\tyarnClusterDescriptor.getClass().getProtectionDomain().getCodeSource().getLocation().getPath();\n\t\t\ttry {\n\t\t\t\t// we have to decode the url encoded parts of the path\n\t\t\t\tString decodedPath = URLDecoder.decode(encodedJarPath, Charset.defaultCharset().name());\n\t\t\t\tlocalJarPath = new Path(new File(decodedPath).toURI());\n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\tthrow new RuntimeException(\"Couldn't decode the encoded Flink dist jar path: \" + encodedJarPath +\n\t\t\t\t\t\" Please supply a path manually via the -\" + flinkJar.getOpt() + \" option.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.setLocalJarPath(localJarPath);\n\n\t\tList<File> shipFiles = new ArrayList<>();\n\t\t// path to directory to ship\n\t\tif (cmd.hasOption(shipPath.getOpt())) {\n\t\t\tString shipPath = cmd.getOptionValue(this.shipPath.getOpt());\n\t\t\tFile shipDir = new File(shipPath);\n\t\t\tif (shipDir.isDirectory()) {\n\t\t\t\tshipFiles.add(shipDir);\n\t\t\t} else {\n\t\t\t\tLOG.warn(\"Ship directory is not a directory. Ignoring it.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.addShipFiles(shipFiles);\n\n\t\t// queue\n\t\tif (cmd.hasOption(queue.getOpt())) {\n\t\t\tyarnClusterDescriptor.setQueue(cmd.getOptionValue(queue.getOpt()));\n\t\t}\n\n\t\t// JobManager Memory\n\t\tif (cmd.hasOption(jmMemory.getOpt())) {\n\t\t\tint jmMemory = Integer.valueOf(cmd.getOptionValue(this.jmMemory.getOpt()));\n\t\t\tyarnClusterDescriptor.setJobManagerMemory(jmMemory);\n\t\t}\n\n\t\tString[] dynamicProperties = null;\n\t\tif (cmd.hasOption(this.dynamicProperties.getOpt())) {\n\t\t\tdynamicProperties = cmd.getOptionValues(this.dynamicProperties.getOpt());\n\t\t}\n\t\tString dynamicPropertiesEncoded = StringUtils.join(dynamicProperties, YARN_DYNAMIC_PROPERTIES_SEPARATOR);\n\n\t\tyarnClusterDescriptor.setDynamicPropertiesEncoded(dynamicPropertiesEncoded);\n\n\t\tif (cmd.hasOption(detached.getOpt()) || cmd.hasOption(CliFrontendParser.DETACHED_OPTION.getOpt())) {\n\t\t\t// TODO: not support non detach mode now.\n\t\t\t//this.detachedMode = false;\n\t\t}\n\t\tyarnClusterDescriptor.setDetachedMode(this.detachedMode);\n\n\t\tif (defaultApplicationName != null) {\n\t\t\tyarnClusterDescriptor.setName(defaultApplicationName);\n\t\t}\n\n\t\tif (cmd.hasOption(zookeeperNamespace.getOpt())) {\n\t\t\tString zookeeperNamespace = cmd.getOptionValue(this.zookeeperNamespace.getOpt());\n\t\t\tyarnClusterDescriptor.setZookeeperNamespace(zookeeperNamespace);\n\t\t}\n\n\t\treturn yarnClusterDescriptor;\n\t}"
        ],
        [
            "FlinkYarnSessionCli::run(String)",
            " 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573 -\n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580 -\n 581  \n 582  \n 583  \n 584  \n 585  \n 586 -\n 587  \n 588  \n 589  \n 590  \n 591  \n 592 -\n 593  \n 594  \n 595  \n 596  \n 597 -\n 598 -\n 599 -\n 600 -\n 601  \n 602  \n 603  \n 604  \n 605 -\n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613 -\n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632 -\n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  ",
            "\tpublic int run(String[] args) {\n\t\t//\n\t\t//\tCommand Line Options\n\t\t//\n\t\tOptions options = new Options();\n\t\taddGeneralOptions(options);\n\t\taddRunOptions(options);\n\n\t\tCommandLineParser parser = new PosixParser();\n\t\tCommandLine cmd;\n\t\ttry {\n\t\t\tcmd = parser.parse(options, args);\n\t\t} catch(Exception e) {\n\t\t\tSystem.out.println(e.getMessage());\n\t\t\tprintUsage();\n\t\t\treturn 1;\n\t\t}\n\n\t\t// Query cluster for metrics\n\t\tif (cmd.hasOption(QUERY.getOpt())) {\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor = getClusterDescriptor();\n\t\t\tString description;\n\t\t\ttry {\n\t\t\t\tdescription = yarnDescriptor.getClusterDescription();\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.err.println(\"Error while querying the YARN cluster for available resources: \"+e.getMessage());\n\t\t\t\te.printStackTrace(System.err);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tSystem.out.println(description);\n\t\t\treturn 0;\n\t\t} else if (cmd.hasOption(APPLICATION_ID.getOpt())) {\n\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor = getClusterDescriptor();\n\n\t\t\t//configure ZK namespace depending on the value passed\n\t\t\tString zkNamespace = cmd.hasOption(ZOOKEEPER_NAMESPACE.getOpt()) ?\n\t\t\t\t\t\t\t\t\tcmd.getOptionValue(ZOOKEEPER_NAMESPACE.getOpt())\n\t\t\t\t\t\t\t\t\t:yarnDescriptor.getFlinkConfiguration()\n\t\t\t\t\t\t\t\t\t.getString(HA_ZOOKEEPER_NAMESPACE_KEY, cmd.getOptionValue(APPLICATION_ID.getOpt()));\n\t\t\tLOG.info(\"Going to use the ZK namespace: {}\", zkNamespace);\n\t\t\tyarnDescriptor.getFlinkConfiguration().setString(HA_ZOOKEEPER_NAMESPACE_KEY, zkNamespace);\n\n\t\t\ttry {\n\t\t\t\tyarnCluster = yarnDescriptor.retrieve(cmd.getOptionValue(APPLICATION_ID.getOpt()));\n\t\t\t} catch (Exception e) {\n\t\t\t\tthrow new RuntimeException(\"Could not retrieve existing Yarn application\", e);\n\t\t\t}\n\n\t\t\tif (detachedMode) {\n\t\t\t\tLOG.info(\"The Flink YARN client has been started in detached mode. In order to stop \" +\n\t\t\t\t\t\"Flink on YARN, use the following command or a YARN web interface to stop it:\\n\" +\n\t\t\t\t\t\"yarn application -kill \" + APPLICATION_ID.getOpt());\n\t\t\t\tyarnCluster.disconnect();\n\t\t\t} else {\n\t\t\t\trunInteractiveCli(yarnCluster, true);\n\t\t\t}\n\t\t} else {\n\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor;\n\t\t\ttry {\n\t\t\t\tyarnDescriptor = createDescriptor(null, cmd);\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.err.println(\"Error while starting the YARN Client: \" + e.getMessage());\n\t\t\t\te.printStackTrace(System.err);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tyarnCluster = yarnDescriptor.deploy();\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.err.println(\"Error while deploying YARN cluster: \"+e.getMessage());\n\t\t\t\te.printStackTrace(System.err);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\t//------------------ ClusterClient deployed, handle connection details\n\t\t\tString jobManagerAddress =\n\t\t\t\tyarnCluster.getJobManagerAddress().getAddress().getHostName() +\n\t\t\t\t\t\":\" + yarnCluster.getJobManagerAddress().getPort();\n\n\t\t\tSystem.out.println(\"Flink JobManager is now running on \" + jobManagerAddress);\n\t\t\tSystem.out.println(\"JobManager Web Interface: \" + yarnCluster.getWebInterfaceURL());\n\n\t\t\t// file that we write into the conf/ dir containing the jobManager address and the dop.\n\t\t\tFile yarnPropertiesFile = getYarnPropertiesLocation(yarnCluster.getFlinkConfiguration());\n\n\t\t\tProperties yarnProps = new Properties();\n\t\t\tyarnProps.setProperty(YARN_APPLICATION_ID_KEY, yarnCluster.getApplicationId().toString());\n\t\t\tif (yarnDescriptor.getTaskManagerSlots() != -1) {\n\t\t\t\tString parallelism =\n\t\t\t\t\t\tInteger.toString(yarnDescriptor.getTaskManagerSlots() * yarnDescriptor.getTaskManagerCount());\n\t\t\t\tyarnProps.setProperty(YARN_PROPERTIES_PARALLELISM, parallelism);\n\t\t\t}\n\t\t\t// add dynamic properties\n\t\t\tif (yarnDescriptor.getDynamicPropertiesEncoded() != null) {\n\t\t\t\tyarnProps.setProperty(YARN_PROPERTIES_DYNAMIC_PROPERTIES_STRING,\n\t\t\t\t\t\tyarnDescriptor.getDynamicPropertiesEncoded());\n\t\t\t}\n\t\t\twriteYarnProperties(yarnProps, yarnPropertiesFile);\n\n\t\t\t//------------------ ClusterClient running, let user control it ------------\n\n\t\t\tif (detachedMode) {\n\t\t\t\t// print info and quit:\n\t\t\t\tLOG.info(\"The Flink YARN client has been started in detached mode. In order to stop \" +\n\t\t\t\t\t\t\"Flink on YARN, use the following command or a YARN web interface to stop it:\\n\" +\n\t\t\t\t\t\t\"yarn application -kill \" + yarnCluster.getApplicationId());\n\t\t\t\tyarnCluster.waitForClusterToBeReady();\n\t\t\t\tyarnCluster.disconnect();\n\t\t\t} else {\n\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\t}",
            " 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573 +\n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580 +\n 581  \n 582  \n 583  \n 584  \n 585  \n 586 +\n 587  \n 588  \n 589  \n 590  \n 591  \n 592 +\n 593  \n 594  \n 595  \n 596  \n 597 +\n 598 +\n 599 +\n 600 +\n 601  \n 602  \n 603  \n 604  \n 605 +\n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613 +\n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632 +\n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  ",
            "\tpublic int run(String[] args) {\n\t\t//\n\t\t//\tCommand Line Options\n\t\t//\n\t\tOptions options = new Options();\n\t\taddGeneralOptions(options);\n\t\taddRunOptions(options);\n\n\t\tCommandLineParser parser = new PosixParser();\n\t\tCommandLine cmd;\n\t\ttry {\n\t\t\tcmd = parser.parse(options, args);\n\t\t} catch (Exception e) {\n\t\t\tSystem.out.println(e.getMessage());\n\t\t\tprintUsage();\n\t\t\treturn 1;\n\t\t}\n\n\t\t// Query cluster for metrics\n\t\tif (cmd.hasOption(query.getOpt())) {\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor = getClusterDescriptor();\n\t\t\tString description;\n\t\t\ttry {\n\t\t\t\tdescription = yarnDescriptor.getClusterDescription();\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.err.println(\"Error while querying the YARN cluster for available resources: \" + e.getMessage());\n\t\t\t\te.printStackTrace(System.err);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tSystem.out.println(description);\n\t\t\treturn 0;\n\t\t} else if (cmd.hasOption(applicationId.getOpt())) {\n\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor = getClusterDescriptor();\n\n\t\t\t//configure ZK namespace depending on the value passed\n\t\t\tString zkNamespace = cmd.hasOption(zookeeperNamespace.getOpt()) ?\n\t\t\t\t\t\t\t\t\tcmd.getOptionValue(zookeeperNamespace.getOpt())\n\t\t\t\t\t\t\t\t\t: yarnDescriptor.getFlinkConfiguration()\n\t\t\t\t\t\t\t\t\t.getString(HA_ZOOKEEPER_NAMESPACE_KEY, cmd.getOptionValue(applicationId.getOpt()));\n\t\t\tLOG.info(\"Going to use the ZK namespace: {}\", zkNamespace);\n\t\t\tyarnDescriptor.getFlinkConfiguration().setString(HA_ZOOKEEPER_NAMESPACE_KEY, zkNamespace);\n\n\t\t\ttry {\n\t\t\t\tyarnCluster = yarnDescriptor.retrieve(cmd.getOptionValue(applicationId.getOpt()));\n\t\t\t} catch (Exception e) {\n\t\t\t\tthrow new RuntimeException(\"Could not retrieve existing Yarn application\", e);\n\t\t\t}\n\n\t\t\tif (detachedMode) {\n\t\t\t\tLOG.info(\"The Flink YARN client has been started in detached mode. In order to stop \" +\n\t\t\t\t\t\"Flink on YARN, use the following command or a YARN web interface to stop it:\\n\" +\n\t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n\t\t\t\tyarnCluster.disconnect();\n\t\t\t} else {\n\t\t\t\trunInteractiveCli(yarnCluster, true);\n\t\t\t}\n\t\t} else {\n\n\t\t\tAbstractYarnClusterDescriptor yarnDescriptor;\n\t\t\ttry {\n\t\t\t\tyarnDescriptor = createDescriptor(null, cmd);\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.err.println(\"Error while starting the YARN Client: \" + e.getMessage());\n\t\t\t\te.printStackTrace(System.err);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tyarnCluster = yarnDescriptor.deploy();\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.err.println(\"Error while deploying YARN cluster: \" + e.getMessage());\n\t\t\t\te.printStackTrace(System.err);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\t//------------------ ClusterClient deployed, handle connection details\n\t\t\tString jobManagerAddress =\n\t\t\t\tyarnCluster.getJobManagerAddress().getAddress().getHostName() +\n\t\t\t\t\t\":\" + yarnCluster.getJobManagerAddress().getPort();\n\n\t\t\tSystem.out.println(\"Flink JobManager is now running on \" + jobManagerAddress);\n\t\t\tSystem.out.println(\"JobManager Web Interface: \" + yarnCluster.getWebInterfaceURL());\n\n\t\t\t// file that we write into the conf/ dir containing the jobManager address and the dop.\n\t\t\tFile yarnPropertiesFile = getYarnPropertiesLocation(yarnCluster.getFlinkConfiguration());\n\n\t\t\tProperties yarnProps = new Properties();\n\t\t\tyarnProps.setProperty(YARN_APPLICATION_ID_KEY, yarnCluster.getApplicationId().toString());\n\t\t\tif (yarnDescriptor.getTaskManagerSlots() != -1) {\n\t\t\t\tString parallelism =\n\t\t\t\t\t\tInteger.toString(yarnDescriptor.getTaskManagerSlots() * yarnDescriptor.getTaskManagerCount());\n\t\t\t\tyarnProps.setProperty(YARN_PROPERTIES_PARALLELISM, parallelism);\n\t\t\t}\n\t\t\t// add dynamic properties\n\t\t\tif (yarnDescriptor.getDynamicPropertiesEncoded() != null) {\n\t\t\t\tyarnProps.setProperty(YARN_PROPERTIES_DYNAMIC_PROPERTIES_STRING,\n\t\t\t\t\t\tyarnDescriptor.getDynamicPropertiesEncoded());\n\t\t\t}\n\t\t\twriteYarnProperties(yarnProps, yarnPropertiesFile);\n\n\t\t\t//------------------ ClusterClient running, let user control it ------------\n\n\t\t\tif (detachedMode) {\n\t\t\t\t// print info and quit:\n\t\t\t\tLOG.info(\"The Flink YARN client has been started in detached mode. In order to stop \" +\n\t\t\t\t\t\t\"Flink on YARN, use the following command or a YARN web interface to stop it:\\n\" +\n\t\t\t\t\t\t\"yarn application -kill \" + yarnCluster.getApplicationId());\n\t\t\t\tyarnCluster.waitForClusterToBeReady();\n\t\t\t\tyarnCluster.disconnect();\n\t\t\t} else {\n\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\t}"
        ],
        [
            "YarnPreConfiguredMasterHaServicesTest::createHDFS()",
            "  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72 -\n  73 -\n  74  ",
            "\t@BeforeClass\n\tpublic static void createHDFS() throws Exception {\n\t\tAssume.assumeTrue(!OperatingSystem.isWindows());\n\n\t\tfinal File tempDir = TEMP_DIR.newFolder();\n\n\t\torg.apache.hadoop.conf.Configuration hdConf = new org.apache.hadoop.conf.Configuration();\n\t\thdConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, tempDir.getAbsolutePath());\n\n\t\tMiniDFSCluster.Builder builder = new MiniDFSCluster.Builder(hdConf);\n\t\tHDFS_CLUSTER = builder.build();\n\t\tHDFS_ROOT_PATH = new Path(HDFS_CLUSTER.getURI());\n\t}",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74 +\n  75 +\n  76  ",
            "\t@BeforeClass\n\tpublic static void createHDFS() throws Exception {\n\t\tAssume.assumeTrue(!OperatingSystem.isWindows());\n\n\t\tfinal File tempDir = TEMP_DIR.newFolder();\n\n\t\torg.apache.hadoop.conf.Configuration hdConf = new org.apache.hadoop.conf.Configuration();\n\t\thdConf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, tempDir.getAbsolutePath());\n\n\t\tMiniDFSCluster.Builder builder = new MiniDFSCluster.Builder(hdConf);\n\t\thdfsCluster = builder.build();\n\t\thdfsRootPath = new Path(hdfsCluster.getURI());\n\t}"
        ],
        [
            "YarnPreConfiguredMasterHaServicesTest::testCloseAndCleanup()",
            " 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145 -\n 146 -\n 147 -\n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  ",
            "\t@Test\n\tpublic void testCloseAndCleanup() throws Exception {\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(YarnConfigOptions.APP_MASTER_RPC_ADDRESS, \"localhost\");\n\t\tflinkConfig.setInteger(YarnConfigOptions.APP_MASTER_RPC_PORT, 1427);\n\n\t\t// create the services\n\t\tYarnHighAvailabilityServices services = new YarnPreConfiguredMasterNonHaServices(\n\t\t\tflinkConfig,\n\t\t\thadoopConfig,\n\t\t\tHighAvailabilityServicesUtils.AddressResolution.NO_ADDRESS_RESOLUTION);\n\t\tservices.closeAndCleanupAllData();\n\n\t\tfinal FileSystem fileSystem = HDFS_ROOT_PATH.getFileSystem();\n\t\tfinal Path workDir = new Path(HDFS_CLUSTER.getFileSystem().getWorkingDirectory().toString());\n\t\t\n\t\ttry {\n\t\t\tfileSystem.getFileStatus(new Path(workDir, YarnHighAvailabilityServices.FLINK_RECOVERY_DATA_DIR));\n\t\t\tfail(\"Flink recovery data directory still exists\");\n\t\t}\n\t\tcatch (FileNotFoundException e) {\n\t\t\t// expected, because the directory should have been cleaned up\n\t\t}\n\n\t\tassertTrue(services.isClosed());\n\n\t\t// doing another cleanup when the services are closed should fail\n\t\ttry {\n\t\t\tservices.closeAndCleanupAllData();\n\t\t\tfail(\"should fail with an IllegalStateException\");\n\t\t} catch (IllegalStateException e) {\n\t\t\t// expected\n\t\t}\n\t}",
            " 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147 +\n 148 +\n 149 +\n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  ",
            "\t@Test\n\tpublic void testCloseAndCleanup() throws Exception {\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(YarnConfigOptions.APP_MASTER_RPC_ADDRESS, \"localhost\");\n\t\tflinkConfig.setInteger(YarnConfigOptions.APP_MASTER_RPC_PORT, 1427);\n\n\t\t// create the services\n\t\tYarnHighAvailabilityServices services = new YarnPreConfiguredMasterNonHaServices(\n\t\t\tflinkConfig,\n\t\t\thadoopConfig,\n\t\t\tHighAvailabilityServicesUtils.AddressResolution.NO_ADDRESS_RESOLUTION);\n\t\tservices.closeAndCleanupAllData();\n\n\t\tfinal FileSystem fileSystem = hdfsRootPath.getFileSystem();\n\t\tfinal Path workDir = new Path(hdfsCluster.getFileSystem().getWorkingDirectory().toString());\n\n\t\ttry {\n\t\t\tfileSystem.getFileStatus(new Path(workDir, YarnHighAvailabilityServices.FLINK_RECOVERY_DATA_DIR));\n\t\t\tfail(\"Flink recovery data directory still exists\");\n\t\t}\n\t\tcatch (FileNotFoundException e) {\n\t\t\t// expected, because the directory should have been cleaned up\n\t\t}\n\n\t\tassertTrue(services.isClosed());\n\n\t\t// doing another cleanup when the services are closed should fail\n\t\ttry {\n\t\t\tservices.closeAndCleanupAllData();\n\t\t\tfail(\"should fail with an IllegalStateException\");\n\t\t} catch (IllegalStateException e) {\n\t\t\t// expected\n\t\t}\n\t}"
        ],
        [
            "YarnResourceManager::createTaskExecutorLaunchContext(Resource,String,String)",
            " 340  \n 341  \n 342  \n 343 -\n 344  \n 345  \n 346  \n 347  \n 348 -\n 349  \n 350  \n 351  \n 352  \n 353  \n 354 -\n 355  \n 356  \n 357  \n 358  \n 359 -\n 360  \n 361  \n 362 -\n 363  \n 364 -\n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  ",
            "\tprivate ContainerLaunchContext createTaskExecutorLaunchContext(Resource resource, String containerId, String host)\n\t\t\tthrows Exception {\n\t\t// init the ContainerLaunchContext\n\t\tfinal String currDir = ENV.get(ApplicationConstants.Environment.PWD.key());\n\n\t\tfinal ContaineredTaskManagerParameters taskManagerParameters =\n\t\t\t\tContaineredTaskManagerParameters.create(flinkConfig, resource.getMemory(), 1);\n\n\t\tLOG.info(\"TaskExecutor{} will be started with container size {} MB, JVM heap size {} MB, \" +\n\t\t\t\t\"JVM direct memory limit {} MB\",\n\t\t\t\tcontainerId,\n\t\t\t\ttaskManagerParameters.taskManagerTotalMemoryMB(),\n\t\t\t\ttaskManagerParameters.taskManagerHeapSizeMB(),\n\t\t\t\ttaskManagerParameters.taskManagerDirectMemoryLimitMB());\n\t\tint timeout = flinkConfig.getInteger(ConfigConstants.TASK_MANAGER_MAX_REGISTRATION_DURATION, \n\t\t\t\tDEFAULT_TASK_MANAGER_REGISTRATION_DURATION);\n\t\tFiniteDuration teRegistrationTimeout = new FiniteDuration(timeout, TimeUnit.SECONDS);\n\t\tfinal Configuration taskManagerConfig = BootstrapTools.generateTaskManagerConfiguration(\n\t\t\t\tflinkConfig, \"\", 0, 1, teRegistrationTimeout);\n\t\tLOG.debug(\"TaskManager configuration: {}\", taskManagerConfig);\n\n\t\tContainerLaunchContext taskExecutorLaunchContext = Utils.createTaskExecutorContext(\n\t\t\t\tflinkConfig, yarnConfig, ENV,\n\t\t\t\ttaskManagerParameters, taskManagerConfig,\n\t\t\t\tcurrDir, YarnTaskExecutorRunner.class, LOG);\n\n\t\t// set a special environment variable to uniquely identify this container\n\t\ttaskExecutorLaunchContext.getEnvironment()\n\t\t\t\t.put(ENV_FLINK_CONTAINER_ID, containerId);\n\t\ttaskExecutorLaunchContext.getEnvironment()\n\t\t\t\t.put(ENV_FLINK_NODE_ID, host);\n\t\treturn taskExecutorLaunchContext;\n\t}",
            " 339  \n 340  \n 341  \n 342 +\n 343  \n 344  \n 345  \n 346  \n 347 +\n 348  \n 349  \n 350  \n 351  \n 352  \n 353 +\n 354  \n 355  \n 356  \n 357  \n 358 +\n 359  \n 360  \n 361 +\n 362  \n 363 +\n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  ",
            "\tprivate ContainerLaunchContext createTaskExecutorLaunchContext(Resource resource, String containerId, String host)\n\t\t\tthrows Exception {\n\t\t// init the ContainerLaunchContext\n\t\tfinal String currDir = env.get(ApplicationConstants.Environment.PWD.key());\n\n\t\tfinal ContaineredTaskManagerParameters taskManagerParameters =\n\t\t\t\tContaineredTaskManagerParameters.create(flinkConfig, resource.getMemory(), 1);\n\n\t\tlog.info(\"TaskExecutor{} will be started with container size {} MB, JVM heap size {} MB, \" +\n\t\t\t\t\"JVM direct memory limit {} MB\",\n\t\t\t\tcontainerId,\n\t\t\t\ttaskManagerParameters.taskManagerTotalMemoryMB(),\n\t\t\t\ttaskManagerParameters.taskManagerHeapSizeMB(),\n\t\t\t\ttaskManagerParameters.taskManagerDirectMemoryLimitMB());\n\t\tint timeout = flinkConfig.getInteger(ConfigConstants.TASK_MANAGER_MAX_REGISTRATION_DURATION,\n\t\t\t\tDEFAULT_TASK_MANAGER_REGISTRATION_DURATION);\n\t\tFiniteDuration teRegistrationTimeout = new FiniteDuration(timeout, TimeUnit.SECONDS);\n\t\tfinal Configuration taskManagerConfig = BootstrapTools.generateTaskManagerConfiguration(\n\t\t\t\tflinkConfig, \"\", 0, 1, teRegistrationTimeout);\n\t\tlog.debug(\"TaskManager configuration: {}\", taskManagerConfig);\n\n\t\tContainerLaunchContext taskExecutorLaunchContext = Utils.createTaskExecutorContext(\n\t\t\t\tflinkConfig, yarnConfig, env,\n\t\t\t\ttaskManagerParameters, taskManagerConfig,\n\t\t\t\tcurrDir, YarnTaskExecutorRunner.class, log);\n\n\t\t// set a special environment variable to uniquely identify this container\n\t\ttaskExecutorLaunchContext.getEnvironment()\n\t\t\t\t.put(ENV_FLINK_CONTAINER_ID, containerId);\n\t\ttaskExecutorLaunchContext.getEnvironment()\n\t\t\t\t.put(ENV_FLINK_NODE_ID, host);\n\t\treturn taskExecutorLaunchContext;\n\t}"
        ],
        [
            "YarnPreConfiguredMasterHaServicesTest::destroyHDFS()",
            "  76  \n  77  \n  78 -\n  79 -\n  80  \n  81 -\n  82 -\n  83  ",
            "\t@AfterClass\n\tpublic static void destroyHDFS() {\n\t\tif (HDFS_CLUSTER != null) {\n\t\t\tHDFS_CLUSTER.shutdown();\n\t\t}\n\t\tHDFS_CLUSTER = null;\n\t\tHDFS_ROOT_PATH = null;\n\t}",
            "  78  \n  79  \n  80 +\n  81 +\n  82  \n  83 +\n  84 +\n  85  ",
            "\t@AfterClass\n\tpublic static void destroyHDFS() {\n\t\tif (hdfsCluster != null) {\n\t\t\thdfsCluster.shutdown();\n\t\t}\n\t\thdfsCluster = null;\n\t\thdfsRootPath = null;\n\t}"
        ],
        [
            "FlinkYarnSessionCli::createDescriptor(String,CommandLine)",
            " 256  \n 257  \n 258  \n 259  \n 260 -\n 261 -\n 262  \n 263 -\n 264  \n 265 -\n 266  \n 267  \n 268  \n 269 -\n 270 -\n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286 -\n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294 -\n 295 -\n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307 -\n 308 -\n 309  \n 310  \n 311  \n 312 -\n 313 -\n 314  \n 315  \n 316  \n 317  \n 318 -\n 319 -\n 320  \n 321  \n 322  \n 323 -\n 324 -\n 325  \n 326  \n 327  \n 328  \n 329 -\n 330 -\n 331  \n 332  \n 333  \n 334  \n 335  \n 336 -\n 337  \n 338  \n 339  \n 340  \n 341 -\n 342 -\n 343  \n 344  \n 345 -\n 346  \n 347  \n 348  \n 349  \n 350 -\n 351 -\n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371 -\n 372  \n 373  \n 374  \n 375  \n 376  \n 377  ",
            "\tpublic AbstractYarnClusterDescriptor createDescriptor(String defaultApplicationName, CommandLine cmd) {\n\n\t\tAbstractYarnClusterDescriptor yarnClusterDescriptor = getClusterDescriptor();\n\n\t\tif (!cmd.hasOption(CONTAINER.getOpt())) { // number of containers is required option!\n\t\t\tLOG.error(\"Missing required argument {}\", CONTAINER.getOpt());\n\t\t\tprintUsage();\n\t\t\tthrow new IllegalArgumentException(\"Missing required argument \" + CONTAINER.getOpt());\n\t\t}\n\t\tyarnClusterDescriptor.setTaskManagerCount(Integer.valueOf(cmd.getOptionValue(CONTAINER.getOpt())));\n\n\t\t// Jar Path\n\t\tPath localJarPath;\n\t\tif (cmd.hasOption(FLINK_JAR.getOpt())) {\n\t\t\tString userPath = cmd.getOptionValue(FLINK_JAR.getOpt());\n\t\t\tif (!userPath.startsWith(\"file://\")) {\n\t\t\t\tuserPath = \"file://\" + userPath;\n\t\t\t}\n\t\t\tlocalJarPath = new Path(userPath);\n\t\t} else {\n\t\t\tLOG.info(\"No path for the flink jar passed. Using the location of \"\n\t\t\t\t+ yarnClusterDescriptor.getClass() + \" to locate the jar\");\n\t\t\tString encodedJarPath =\n\t\t\t\tyarnClusterDescriptor.getClass().getProtectionDomain().getCodeSource().getLocation().getPath();\n\t\t\ttry {\n\t\t\t\t// we have to decode the url encoded parts of the path\n\t\t\t\tString decodedPath = URLDecoder.decode(encodedJarPath, Charset.defaultCharset().name());\n\t\t\t\tlocalJarPath = new Path(new File(decodedPath).toURI());\n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\tthrow new RuntimeException(\"Couldn't decode the encoded Flink dist jar path: \" + encodedJarPath +\n\t\t\t\t\t\" Please supply a path manually via the -\" + FLINK_JAR.getOpt() + \" option.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.setLocalJarPath(localJarPath);\n\n\t\tList<File> shipFiles = new ArrayList<>();\n\t\t// path to directory to ship\n\t\tif (cmd.hasOption(SHIP_PATH.getOpt())) {\n\t\t\tString shipPath = cmd.getOptionValue(SHIP_PATH.getOpt());\n\t\t\tFile shipDir = new File(shipPath);\n\t\t\tif (shipDir.isDirectory()) {\n\t\t\t\tshipFiles.add(shipDir);\n\t\t\t} else {\n\t\t\t\tLOG.warn(\"Ship directory is not a directory. Ignoring it.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.addShipFiles(shipFiles);\n\n\t\t// queue\n\t\tif (cmd.hasOption(QUEUE.getOpt())) {\n\t\t\tyarnClusterDescriptor.setQueue(cmd.getOptionValue(QUEUE.getOpt()));\n\t\t}\n\n\t\t// JobManager Memory\n\t\tif (cmd.hasOption(JM_MEMORY.getOpt())) {\n\t\t\tint jmMemory = Integer.valueOf(cmd.getOptionValue(JM_MEMORY.getOpt()));\n\t\t\tyarnClusterDescriptor.setJobManagerMemory(jmMemory);\n\t\t}\n\n\t\t// Task Managers memory\n\t\tif (cmd.hasOption(TM_MEMORY.getOpt())) {\n\t\t\tint tmMemory = Integer.valueOf(cmd.getOptionValue(TM_MEMORY.getOpt()));\n\t\t\tyarnClusterDescriptor.setTaskManagerMemory(tmMemory);\n\t\t}\n\n\t\tif (cmd.hasOption(SLOTS.getOpt())) {\n\t\t\tint slots = Integer.valueOf(cmd.getOptionValue(SLOTS.getOpt()));\n\t\t\tyarnClusterDescriptor.setTaskManagerSlots(slots);\n\t\t}\n\n\t\tString[] dynamicProperties = null;\n\t\tif (cmd.hasOption(DYNAMIC_PROPERTIES.getOpt())) {\n\t\t\tdynamicProperties = cmd.getOptionValues(DYNAMIC_PROPERTIES.getOpt());\n\t\t}\n\t\tString dynamicPropertiesEncoded = StringUtils.join(dynamicProperties, YARN_DYNAMIC_PROPERTIES_SEPARATOR);\n\n\t\tyarnClusterDescriptor.setDynamicPropertiesEncoded(dynamicPropertiesEncoded);\n\n\t\tif (cmd.hasOption(DETACHED.getOpt()) || cmd.hasOption(CliFrontendParser.DETACHED_OPTION.getOpt())) {\n\t\t\tthis.detachedMode = true;\n\t\t\tyarnClusterDescriptor.setDetachedMode(true);\n\t\t}\n\n\t\tif(cmd.hasOption(NAME.getOpt())) {\n\t\t\tyarnClusterDescriptor.setName(cmd.getOptionValue(NAME.getOpt()));\n\t\t} else {\n\t\t\t// set the default application name, if none is specified\n\t\t\tif(defaultApplicationName != null) {\n\t\t\t\tyarnClusterDescriptor.setName(defaultApplicationName);\n\t\t\t}\n\t\t}\n\n\t\tif (cmd.hasOption(ZOOKEEPER_NAMESPACE.getOpt())) {\n\t\t\tString zookeeperNamespace = cmd.getOptionValue(ZOOKEEPER_NAMESPACE.getOpt());\n\t\t\tyarnClusterDescriptor.setZookeeperNamespace(zookeeperNamespace);\n\t\t}\n\n\t\t// ----- Convenience -----\n\n\t\t// the number of slots available from YARN:\n\t\tint yarnTmSlots = yarnClusterDescriptor.getTaskManagerSlots();\n\t\tif (yarnTmSlots == -1) {\n\t\t\tyarnTmSlots = 1;\n\t\t\tyarnClusterDescriptor.setTaskManagerSlots(yarnTmSlots);\n\t\t}\n\n\t\tint maxSlots = yarnTmSlots * yarnClusterDescriptor.getTaskManagerCount();\n\t\tint userParallelism = Integer.valueOf(cmd.getOptionValue(CliFrontendParser.PARALLELISM_OPTION.getOpt(), \"-1\"));\n\t\tif (userParallelism != -1) {\n\t\t\tint slotsPerTM = (int) Math.ceil((double) userParallelism / yarnClusterDescriptor.getTaskManagerCount());\n\t\t\tString message = \"The YARN cluster has \" + maxSlots + \" slots available, \" +\n\t\t\t\t\"but the user requested a parallelism of \" + userParallelism + \" on YARN. \" +\n\t\t\t\t\"Each of the \" + yarnClusterDescriptor.getTaskManagerCount() + \" TaskManagers \" +\n\t\t\t\t\"will get \"+slotsPerTM+\" slots.\";\n\t\t\tlogAndSysout(message);\n\t\t\tyarnClusterDescriptor.setTaskManagerSlots(slotsPerTM);\n\t\t}\n\n\t\treturn yarnClusterDescriptor;\n\t}",
            " 257  \n 258  \n 259  \n 260  \n 261 +\n 262 +\n 263  \n 264 +\n 265  \n 266 +\n 267  \n 268  \n 269  \n 270 +\n 271 +\n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287 +\n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295 +\n 296 +\n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308 +\n 309 +\n 310  \n 311  \n 312  \n 313 +\n 314 +\n 315  \n 316  \n 317  \n 318  \n 319 +\n 320 +\n 321  \n 322  \n 323  \n 324 +\n 325 +\n 326  \n 327  \n 328  \n 329  \n 330 +\n 331 +\n 332  \n 333  \n 334  \n 335  \n 336  \n 337 +\n 338  \n 339  \n 340  \n 341  \n 342 +\n 343 +\n 344  \n 345  \n 346 +\n 347  \n 348  \n 349  \n 350  \n 351 +\n 352 +\n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372 +\n 373  \n 374  \n 375  \n 376  \n 377  \n 378  ",
            "\tpublic AbstractYarnClusterDescriptor createDescriptor(String defaultApplicationName, CommandLine cmd) {\n\n\t\tAbstractYarnClusterDescriptor yarnClusterDescriptor = getClusterDescriptor();\n\n\t\tif (!cmd.hasOption(container.getOpt())) { // number of containers is required option!\n\t\t\tLOG.error(\"Missing required argument {}\", container.getOpt());\n\t\t\tprintUsage();\n\t\t\tthrow new IllegalArgumentException(\"Missing required argument \" + container.getOpt());\n\t\t}\n\t\tyarnClusterDescriptor.setTaskManagerCount(Integer.valueOf(cmd.getOptionValue(container.getOpt())));\n\n\t\t// Jar Path\n\t\tPath localJarPath;\n\t\tif (cmd.hasOption(flinkJar.getOpt())) {\n\t\t\tString userPath = cmd.getOptionValue(flinkJar.getOpt());\n\t\t\tif (!userPath.startsWith(\"file://\")) {\n\t\t\t\tuserPath = \"file://\" + userPath;\n\t\t\t}\n\t\t\tlocalJarPath = new Path(userPath);\n\t\t} else {\n\t\t\tLOG.info(\"No path for the flink jar passed. Using the location of \"\n\t\t\t\t+ yarnClusterDescriptor.getClass() + \" to locate the jar\");\n\t\t\tString encodedJarPath =\n\t\t\t\tyarnClusterDescriptor.getClass().getProtectionDomain().getCodeSource().getLocation().getPath();\n\t\t\ttry {\n\t\t\t\t// we have to decode the url encoded parts of the path\n\t\t\t\tString decodedPath = URLDecoder.decode(encodedJarPath, Charset.defaultCharset().name());\n\t\t\t\tlocalJarPath = new Path(new File(decodedPath).toURI());\n\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\tthrow new RuntimeException(\"Couldn't decode the encoded Flink dist jar path: \" + encodedJarPath +\n\t\t\t\t\t\" Please supply a path manually via the -\" + flinkJar.getOpt() + \" option.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.setLocalJarPath(localJarPath);\n\n\t\tList<File> shipFiles = new ArrayList<>();\n\t\t// path to directory to ship\n\t\tif (cmd.hasOption(shipPath.getOpt())) {\n\t\t\tString shipPath = cmd.getOptionValue(this.shipPath.getOpt());\n\t\t\tFile shipDir = new File(shipPath);\n\t\t\tif (shipDir.isDirectory()) {\n\t\t\t\tshipFiles.add(shipDir);\n\t\t\t} else {\n\t\t\t\tLOG.warn(\"Ship directory is not a directory. Ignoring it.\");\n\t\t\t}\n\t\t}\n\n\t\tyarnClusterDescriptor.addShipFiles(shipFiles);\n\n\t\t// queue\n\t\tif (cmd.hasOption(queue.getOpt())) {\n\t\t\tyarnClusterDescriptor.setQueue(cmd.getOptionValue(queue.getOpt()));\n\t\t}\n\n\t\t// JobManager Memory\n\t\tif (cmd.hasOption(jmMemory.getOpt())) {\n\t\t\tint jmMemory = Integer.valueOf(cmd.getOptionValue(this.jmMemory.getOpt()));\n\t\t\tyarnClusterDescriptor.setJobManagerMemory(jmMemory);\n\t\t}\n\n\t\t// Task Managers memory\n\t\tif (cmd.hasOption(tmMemory.getOpt())) {\n\t\t\tint tmMemory = Integer.valueOf(cmd.getOptionValue(this.tmMemory.getOpt()));\n\t\t\tyarnClusterDescriptor.setTaskManagerMemory(tmMemory);\n\t\t}\n\n\t\tif (cmd.hasOption(slots.getOpt())) {\n\t\t\tint slots = Integer.valueOf(cmd.getOptionValue(this.slots.getOpt()));\n\t\t\tyarnClusterDescriptor.setTaskManagerSlots(slots);\n\t\t}\n\n\t\tString[] dynamicProperties = null;\n\t\tif (cmd.hasOption(dynamicproperties.getOpt())) {\n\t\t\tdynamicProperties = cmd.getOptionValues(dynamicproperties.getOpt());\n\t\t}\n\t\tString dynamicPropertiesEncoded = StringUtils.join(dynamicProperties, YARN_DYNAMIC_PROPERTIES_SEPARATOR);\n\n\t\tyarnClusterDescriptor.setDynamicPropertiesEncoded(dynamicPropertiesEncoded);\n\n\t\tif (cmd.hasOption(detached.getOpt()) || cmd.hasOption(CliFrontendParser.DETACHED_OPTION.getOpt())) {\n\t\t\tthis.detachedMode = true;\n\t\t\tyarnClusterDescriptor.setDetachedMode(true);\n\t\t}\n\n\t\tif (cmd.hasOption(name.getOpt())) {\n\t\t\tyarnClusterDescriptor.setName(cmd.getOptionValue(name.getOpt()));\n\t\t} else {\n\t\t\t// set the default application name, if none is specified\n\t\t\tif (defaultApplicationName != null) {\n\t\t\t\tyarnClusterDescriptor.setName(defaultApplicationName);\n\t\t\t}\n\t\t}\n\n\t\tif (cmd.hasOption(zookeeperNamespace.getOpt())) {\n\t\t\tString zookeeperNamespace = cmd.getOptionValue(this.zookeeperNamespace.getOpt());\n\t\t\tyarnClusterDescriptor.setZookeeperNamespace(zookeeperNamespace);\n\t\t}\n\n\t\t// ----- Convenience -----\n\n\t\t// the number of slots available from YARN:\n\t\tint yarnTmSlots = yarnClusterDescriptor.getTaskManagerSlots();\n\t\tif (yarnTmSlots == -1) {\n\t\t\tyarnTmSlots = 1;\n\t\t\tyarnClusterDescriptor.setTaskManagerSlots(yarnTmSlots);\n\t\t}\n\n\t\tint maxSlots = yarnTmSlots * yarnClusterDescriptor.getTaskManagerCount();\n\t\tint userParallelism = Integer.valueOf(cmd.getOptionValue(CliFrontendParser.PARALLELISM_OPTION.getOpt(), \"-1\"));\n\t\tif (userParallelism != -1) {\n\t\t\tint slotsPerTM = (int) Math.ceil((double) userParallelism / yarnClusterDescriptor.getTaskManagerCount());\n\t\t\tString message = \"The YARN cluster has \" + maxSlots + \" slots available, \" +\n\t\t\t\t\"but the user requested a parallelism of \" + userParallelism + \" on YARN. \" +\n\t\t\t\t\"Each of the \" + yarnClusterDescriptor.getTaskManagerCount() + \" TaskManagers \" +\n\t\t\t\t\"will get \" + slotsPerTM + \" slots.\";\n\t\t\tlogAndSysout(message);\n\t\t\tyarnClusterDescriptor.setTaskManagerSlots(slotsPerTM);\n\t\t}\n\n\t\treturn yarnClusterDescriptor;\n\t}"
        ],
        [
            "FlinkYarnSessionCli::printUsage()",
            " 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386 -\n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  ",
            "\tprivate void printUsage() {\n\t\tSystem.out.println(\"Usage:\");\n\t\tHelpFormatter formatter = new HelpFormatter();\n\t\tformatter.setWidth(200);\n\t\tformatter.setLeftPadding(5);\n\t\tformatter.setSyntaxPrefix(\"   Required\");\n\t\tOptions req = new Options();\n\t\treq.addOption(CONTAINER);\n\t\tformatter.printHelp(\" \", req);\n\n\t\tformatter.setSyntaxPrefix(\"   Optional\");\n\t\tOptions options = new Options();\n\t\taddGeneralOptions(options);\n\t\taddRunOptions(options);\n\t\tformatter.printHelp(\" \", options);\n\t}",
            " 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387 +\n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  ",
            "\tprivate void printUsage() {\n\t\tSystem.out.println(\"Usage:\");\n\t\tHelpFormatter formatter = new HelpFormatter();\n\t\tformatter.setWidth(200);\n\t\tformatter.setLeftPadding(5);\n\t\tformatter.setSyntaxPrefix(\"   Required\");\n\t\tOptions req = new Options();\n\t\treq.addOption(container);\n\t\tformatter.printHelp(\" \", req);\n\n\t\tformatter.setSyntaxPrefix(\"   Optional\");\n\t\tOptions options = new Options();\n\t\taddGeneralOptions(options);\n\t\taddRunOptions(options);\n\t\tformatter.printHelp(\" \", options);\n\t}"
        ],
        [
            "YarnPreConfiguredMasterHaServicesTest::initConfig()",
            "  85  \n  86  \n  87  \n  88 -\n  89  ",
            "\t@Before\n\tpublic void initConfig() {\n\t\thadoopConfig = new org.apache.hadoop.conf.Configuration();\n\t\thadoopConfig.set(org.apache.hadoop.fs.FileSystem.FS_DEFAULT_NAME_KEY, HDFS_ROOT_PATH.toString());\n\t}",
            "  87  \n  88  \n  89  \n  90 +\n  91  ",
            "\t@Before\n\tpublic void initConfig() {\n\t\thadoopConfig = new org.apache.hadoop.conf.Configuration();\n\t\thadoopConfig.set(org.apache.hadoop.fs.FileSystem.FS_DEFAULT_NAME_KEY, hdfsRootPath.toString());\n\t}"
        ],
        [
            "UtilsTest::testYarnFlinkResourceManagerJobManagerLostLeadership()",
            "  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102 -\n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206 -\n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  ",
            "\t@Test\n\tpublic void testYarnFlinkResourceManagerJobManagerLostLeadership() throws Exception {\n\t\tnew JavaTestKit(system) {{\n\n\t\t\tfinal Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow();\n\n\t\t\tConfiguration flinkConfig = new Configuration();\n\t\t\tYarnConfiguration yarnConfig = new YarnConfiguration();\n\t\t\tTestingLeaderRetrievalService leaderRetrievalService = new TestingLeaderRetrievalService(\n\t\t\t\tnull,\n\t\t\t\tnull);\n\t\t\tString applicationMasterHostName = \"localhost\";\n\t\t\tString webInterfaceURL = \"foobar\";\n\t\t\tContaineredTaskManagerParameters taskManagerParameters = new ContaineredTaskManagerParameters(\n\t\t\t\t1l, 1l, 1l, 1, new HashMap<String, String>());\n\t\t\tContainerLaunchContext taskManagerLaunchContext = mock(ContainerLaunchContext.class);\n\t\t\tint yarnHeartbeatIntervalMillis = 1000;\n\t\t\tint maxFailedContainers = 10;\n\t\t\tint numInitialTaskManagers = 5;\n\t\t\tfinal YarnResourceManagerCallbackHandler callbackHandler = new YarnResourceManagerCallbackHandler();\n\t\t\tAMRMClientAsync<AMRMClient.ContainerRequest> resourceManagerClient = mock(AMRMClientAsync.class);\n\t\t\tNMClient nodeManagerClient = mock(NMClient.class);\n\t\t\tUUID leaderSessionID = UUID.randomUUID();\n\n\t\t\tfinal List<Container> containerList = new ArrayList<>();\n\n\t\t\tfor (int i = 0; i < numInitialTaskManagers; i++) {\n\t\t\t\tcontainerList.add(new TestingContainer(\"container_\" + i, \"localhost\"));\n\t\t\t}\n\n\t\t\tdoAnswer(new Answer() {\n\t\t\t\tint counter = 0;\n\t\t\t\t@Override\n\t\t\t\tpublic Object answer(InvocationOnMock invocation) throws Throwable {\n\t\t\t\t\tif (counter < containerList.size()) {\n\t\t\t\t\t\tcallbackHandler.onContainersAllocated(\n\t\t\t\t\t\t\tCollections.singletonList(\n\t\t\t\t\t\t\t\tcontainerList.get(counter++)\n\t\t\t\t\t\t\t));\n\t\t\t\t\t}\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}).when(resourceManagerClient).addContainerRequest(Matchers.any(AMRMClient.ContainerRequest.class));\n\n\t\t\tActorRef resourceManager = null;\n\t\t\tActorRef leader1;\n\n\t\t\ttry {\n\t\t\t\tleader1 = system.actorOf(\n\t\t\t\t\tProps.create(\n\t\t\t\t\t\tTestingUtils.ForwardingActor.class,\n\t\t\t\t\t\tgetRef(),\n\t\t\t\t\t\tOption.apply(leaderSessionID)\n\t\t\t\t\t));\n\n\t\t\t\tresourceManager = system.actorOf(\n\t\t\t\t\tProps.create(\n\t\t\t\t\t\tTestingYarnFlinkResourceManager.class,\n\t\t\t\t\t\tflinkConfig,\n\t\t\t\t\t\tyarnConfig,\n\t\t\t\t\t\tleaderRetrievalService,\n\t\t\t\t\t\tapplicationMasterHostName,\n\t\t\t\t\t\twebInterfaceURL,\n\t\t\t\t\t\ttaskManagerParameters,\n\t\t\t\t\t\ttaskManagerLaunchContext,\n\t\t\t\t\t\tyarnHeartbeatIntervalMillis,\n\t\t\t\t\t\tmaxFailedContainers,\n\t\t\t\t\t\tnumInitialTaskManagers,\n\t\t\t\t\t\tcallbackHandler,\n\t\t\t\t\t\tresourceManagerClient,\n\t\t\t\t\t\tnodeManagerClient\n\t\t\t\t\t));\n\n\t\t\t\tleaderRetrievalService.notifyListener(leader1.path().toString(), leaderSessionID);\n\n\t\t\t\tfinal AkkaActorGateway leader1Gateway = new AkkaActorGateway(leader1, leaderSessionID);\n\t\t\t\tfinal AkkaActorGateway resourceManagerGateway = new AkkaActorGateway(resourceManager, leaderSessionID);\n\n\t\t\t\tdoAnswer(new Answer() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic Object answer(InvocationOnMock invocation) throws Throwable {\n\t\t\t\t\t\tContainer container = (Container) invocation.getArguments()[0];\n\t\t\t\t\t\tresourceManagerGateway.tell(new NotifyResourceStarted(YarnFlinkResourceManager.extractResourceID(container)),\n\t\t\t\t\t\t\tleader1Gateway);\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t}).when(nodeManagerClient).startContainer(Matchers.any(Container.class), Matchers.any(ContainerLaunchContext.class));\n\n\t\t\t\texpectMsgClass(deadline.timeLeft(), RegisterResourceManager.class);\n\n\t\t\t\tresourceManagerGateway.tell(new RegisterResourceManagerSuccessful(leader1, Collections.EMPTY_LIST));\n\n\t\t\t\tfor (int i = 0; i < containerList.size(); i++) {\n\t\t\t\t\texpectMsgClass(deadline.timeLeft(), Acknowledge.class);\n\t\t\t\t}\n\n\t\t\t\tFuture<Object> taskManagerRegisteredFuture = resourceManagerGateway.ask(new NotifyWhenResourcesRegistered(numInitialTaskManagers), deadline.timeLeft());\n\n\t\t\t\tAwait.ready(taskManagerRegisteredFuture, deadline.timeLeft());\n\n\t\t\t\tleaderRetrievalService.notifyListener(null, null);\n\n\t\t\t\tleaderRetrievalService.notifyListener(leader1.path().toString(), leaderSessionID);\n\n\t\t\t\texpectMsgClass(deadline.timeLeft(), RegisterResourceManager.class);\n\n\t\t\t\tresourceManagerGateway.tell(new RegisterResourceManagerSuccessful(leader1, Collections.EMPTY_LIST));\n\n\t\t\t\tfor (Container container: containerList) {\n\t\t\t\t\tresourceManagerGateway.tell(\n\t\t\t\t\t\tnew NotifyResourceStarted(YarnFlinkResourceManager.extractResourceID(container)),\n\t\t\t\t\t\tleader1Gateway);\n\t\t\t\t}\n\n\t\t\t\tfor (int i = 0; i < containerList.size(); i++) {\n\t\t\t\t\texpectMsgClass(deadline.timeLeft(), Acknowledge.class);\n\t\t\t\t}\n\n\t\t\t\tFuture<Object> numberOfRegisteredResourcesFuture = resourceManagerGateway.ask(RequestNumberOfRegisteredResources.Instance, deadline.timeLeft());\n\n\t\t\t\tint numberOfRegisteredResources = (Integer) Await.result(numberOfRegisteredResourcesFuture, deadline.timeLeft());\n\n\t\t\t\tassertEquals(numInitialTaskManagers, numberOfRegisteredResources);\n\t\t\t} finally {\n\t\t\t\tif (resourceManager != null) {\n\t\t\t\t\tresourceManager.tell(PoisonPill.getInstance(), ActorRef.noSender());\n\t\t\t\t}\n\t\t\t}\n\t\t}};\n\t}",
            "  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107 +\n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211 +\n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  ",
            "\t@Test\n\tpublic void testYarnFlinkResourceManagerJobManagerLostLeadership() throws Exception {\n\t\tnew JavaTestKit(system) {{\n\n\t\t\tfinal Deadline deadline = new FiniteDuration(3, TimeUnit.MINUTES).fromNow();\n\n\t\t\tConfiguration flinkConfig = new Configuration();\n\t\t\tYarnConfiguration yarnConfig = new YarnConfiguration();\n\t\t\tTestingLeaderRetrievalService leaderRetrievalService = new TestingLeaderRetrievalService(\n\t\t\t\tnull,\n\t\t\t\tnull);\n\t\t\tString applicationMasterHostName = \"localhost\";\n\t\t\tString webInterfaceURL = \"foobar\";\n\t\t\tContaineredTaskManagerParameters taskManagerParameters = new ContaineredTaskManagerParameters(\n\t\t\t\t1L, 1L, 1L, 1, new HashMap<String, String>());\n\t\t\tContainerLaunchContext taskManagerLaunchContext = mock(ContainerLaunchContext.class);\n\t\t\tint yarnHeartbeatIntervalMillis = 1000;\n\t\t\tint maxFailedContainers = 10;\n\t\t\tint numInitialTaskManagers = 5;\n\t\t\tfinal YarnResourceManagerCallbackHandler callbackHandler = new YarnResourceManagerCallbackHandler();\n\t\t\tAMRMClientAsync<AMRMClient.ContainerRequest> resourceManagerClient = mock(AMRMClientAsync.class);\n\t\t\tNMClient nodeManagerClient = mock(NMClient.class);\n\t\t\tUUID leaderSessionID = UUID.randomUUID();\n\n\t\t\tfinal List<Container> containerList = new ArrayList<>();\n\n\t\t\tfor (int i = 0; i < numInitialTaskManagers; i++) {\n\t\t\t\tcontainerList.add(new TestingContainer(\"container_\" + i, \"localhost\"));\n\t\t\t}\n\n\t\t\tdoAnswer(new Answer() {\n\t\t\t\tint counter = 0;\n\t\t\t\t@Override\n\t\t\t\tpublic Object answer(InvocationOnMock invocation) throws Throwable {\n\t\t\t\t\tif (counter < containerList.size()) {\n\t\t\t\t\t\tcallbackHandler.onContainersAllocated(\n\t\t\t\t\t\t\tCollections.singletonList(\n\t\t\t\t\t\t\t\tcontainerList.get(counter++)\n\t\t\t\t\t\t\t));\n\t\t\t\t\t}\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}).when(resourceManagerClient).addContainerRequest(Matchers.any(AMRMClient.ContainerRequest.class));\n\n\t\t\tActorRef resourceManager = null;\n\t\t\tActorRef leader1;\n\n\t\t\ttry {\n\t\t\t\tleader1 = system.actorOf(\n\t\t\t\t\tProps.create(\n\t\t\t\t\t\tTestingUtils.ForwardingActor.class,\n\t\t\t\t\t\tgetRef(),\n\t\t\t\t\t\tOption.apply(leaderSessionID)\n\t\t\t\t\t));\n\n\t\t\t\tresourceManager = system.actorOf(\n\t\t\t\t\tProps.create(\n\t\t\t\t\t\tTestingYarnFlinkResourceManager.class,\n\t\t\t\t\t\tflinkConfig,\n\t\t\t\t\t\tyarnConfig,\n\t\t\t\t\t\tleaderRetrievalService,\n\t\t\t\t\t\tapplicationMasterHostName,\n\t\t\t\t\t\twebInterfaceURL,\n\t\t\t\t\t\ttaskManagerParameters,\n\t\t\t\t\t\ttaskManagerLaunchContext,\n\t\t\t\t\t\tyarnHeartbeatIntervalMillis,\n\t\t\t\t\t\tmaxFailedContainers,\n\t\t\t\t\t\tnumInitialTaskManagers,\n\t\t\t\t\t\tcallbackHandler,\n\t\t\t\t\t\tresourceManagerClient,\n\t\t\t\t\t\tnodeManagerClient\n\t\t\t\t\t));\n\n\t\t\t\tleaderRetrievalService.notifyListener(leader1.path().toString(), leaderSessionID);\n\n\t\t\t\tfinal AkkaActorGateway leader1Gateway = new AkkaActorGateway(leader1, leaderSessionID);\n\t\t\t\tfinal AkkaActorGateway resourceManagerGateway = new AkkaActorGateway(resourceManager, leaderSessionID);\n\n\t\t\t\tdoAnswer(new Answer() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic Object answer(InvocationOnMock invocation) throws Throwable {\n\t\t\t\t\t\tContainer container = (Container) invocation.getArguments()[0];\n\t\t\t\t\t\tresourceManagerGateway.tell(new NotifyResourceStarted(YarnFlinkResourceManager.extractResourceID(container)),\n\t\t\t\t\t\t\tleader1Gateway);\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t}).when(nodeManagerClient).startContainer(Matchers.any(Container.class), Matchers.any(ContainerLaunchContext.class));\n\n\t\t\t\texpectMsgClass(deadline.timeLeft(), RegisterResourceManager.class);\n\n\t\t\t\tresourceManagerGateway.tell(new RegisterResourceManagerSuccessful(leader1, Collections.EMPTY_LIST));\n\n\t\t\t\tfor (int i = 0; i < containerList.size(); i++) {\n\t\t\t\t\texpectMsgClass(deadline.timeLeft(), Acknowledge.class);\n\t\t\t\t}\n\n\t\t\t\tFuture<Object> taskManagerRegisteredFuture = resourceManagerGateway.ask(new NotifyWhenResourcesRegistered(numInitialTaskManagers), deadline.timeLeft());\n\n\t\t\t\tAwait.ready(taskManagerRegisteredFuture, deadline.timeLeft());\n\n\t\t\t\tleaderRetrievalService.notifyListener(null, null);\n\n\t\t\t\tleaderRetrievalService.notifyListener(leader1.path().toString(), leaderSessionID);\n\n\t\t\t\texpectMsgClass(deadline.timeLeft(), RegisterResourceManager.class);\n\n\t\t\t\tresourceManagerGateway.tell(new RegisterResourceManagerSuccessful(leader1, Collections.EMPTY_LIST));\n\n\t\t\t\tfor (Container container: containerList) {\n\t\t\t\t\tresourceManagerGateway.tell(\n\t\t\t\t\t\tnew NotifyResourceStarted(YarnFlinkResourceManager.extractResourceID(container)),\n\t\t\t\t\t\tleader1Gateway);\n\t\t\t\t}\n\n\t\t\t\tfor (int i = 0; i < containerList.size(); i++) {\n\t\t\t\t\texpectMsgClass(deadline.timeLeft(), Acknowledge.class);\n\t\t\t\t}\n\n\t\t\t\tFuture<Object> numberOfRegisteredResourcesFuture = resourceManagerGateway.ask(RequestNumberOfRegisteredResources.INSTANCE, deadline.timeLeft());\n\n\t\t\t\tint numberOfRegisteredResources = (Integer) Await.result(numberOfRegisteredResourcesFuture, deadline.timeLeft());\n\n\t\t\t\tassertEquals(numInitialTaskManagers, numberOfRegisteredResources);\n\t\t\t} finally {\n\t\t\t\tif (resourceManager != null) {\n\t\t\t\t\tresourceManager.tell(PoisonPill.getInstance(), ActorRef.noSender());\n\t\t\t\t}\n\t\t\t}\n\t\t}};\n\t}"
        ],
        [
            "YarnResourceManager::onContainersAllocated(List)",
            " 253  \n 254  \n 255  \n 256  \n 257 -\n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267 -\n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  ",
            "\t@Override\n\tpublic void onContainersAllocated(List<Container> containers) {\n\t\tfor (Container container : containers) {\n\t\t\tnumPendingContainerRequests = Math.max(0, numPendingContainerRequests - 1);\n\t\t\tLOG.info(\"Received new container: {} - Remaining pending container requests: {}\",\n\t\t\t\t\tcontainer.getId(), numPendingContainerRequests);\n\t\t\ttry {\n\t\t\t\t/** Context information used to start a TaskExecutor Java process */\n\t\t\t\tContainerLaunchContext taskExecutorLaunchContext =\n\t\t\t\t\t\tcreateTaskExecutorLaunchContext(container.getResource(), container.getId().toString(), container.getNodeId().getHost());\n\t\t\t\tnodeManagerClient.startContainer(container, taskExecutorLaunchContext);\n\t\t\t}\n\t\t\tcatch (Throwable t) {\n\t\t\t\t// failed to launch the container, will release the failed one and ask for a new one\n\t\t\t\tLOG.error(\"Could not start TaskManager in container {},\", container, t);\n\t\t\t\tresourceManagerClient.releaseAssignedContainer(container.getId());\n\t\t\t\trequestYarnContainer(container.getResource(), container.getPriority());\n\t\t\t}\n\t\t}\n\t\tif (numPendingContainerRequests <= 0) {\n\t\t\tresourceManagerClient.setHeartbeatInterval(yarnHeartbeatIntervalMillis);\n\t\t}\n\t}",
            " 252  \n 253  \n 254  \n 255  \n 256 +\n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266 +\n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  ",
            "\t@Override\n\tpublic void onContainersAllocated(List<Container> containers) {\n\t\tfor (Container container : containers) {\n\t\t\tnumPendingContainerRequests = Math.max(0, numPendingContainerRequests - 1);\n\t\t\tlog.info(\"Received new container: {} - Remaining pending container requests: {}\",\n\t\t\t\t\tcontainer.getId(), numPendingContainerRequests);\n\t\t\ttry {\n\t\t\t\t/** Context information used to start a TaskExecutor Java process */\n\t\t\t\tContainerLaunchContext taskExecutorLaunchContext =\n\t\t\t\t\t\tcreateTaskExecutorLaunchContext(container.getResource(), container.getId().toString(), container.getNodeId().getHost());\n\t\t\t\tnodeManagerClient.startContainer(container, taskExecutorLaunchContext);\n\t\t\t}\n\t\t\tcatch (Throwable t) {\n\t\t\t\t// failed to launch the container, will release the failed one and ask for a new one\n\t\t\t\tlog.error(\"Could not start TaskManager in container {},\", container, t);\n\t\t\t\tresourceManagerClient.releaseAssignedContainer(container.getId());\n\t\t\t\trequestYarnContainer(container.getResource(), container.getPriority());\n\t\t\t}\n\t\t}\n\t\tif (numPendingContainerRequests <= 0) {\n\t\t\tresourceManagerClient.setHeartbeatInterval(yarnHeartbeatIntervalMillis);\n\t\t}\n\t}"
        ],
        [
            "YarnResourceManager::YarnResourceManager(RpcService,String,ResourceID,Configuration,Map,ResourceManagerConfiguration,HighAvailabilityServices,HeartbeatServices,SlotManager,MetricRegistry,JobLeaderIdService,FatalErrorHandler)",
            " 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136 -\n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  ",
            "\tpublic YarnResourceManager(\n\t\t\tRpcService rpcService,\n\t\t\tString resourceManagerEndpointId,\n\t\t\tResourceID resourceId,\n\t\t\tConfiguration flinkConfig,\n\t\t\tMap<String, String> env,\n\t\t\tResourceManagerConfiguration resourceManagerConfiguration,\n\t\t\tHighAvailabilityServices highAvailabilityServices,\n\t\t\tHeartbeatServices heartbeatServices,\n\t\t\tSlotManager slotManager,\n\t\t\tMetricRegistry metricRegistry,\n\t\t\tJobLeaderIdService jobLeaderIdService,\n\t\t\tFatalErrorHandler fatalErrorHandler) {\n\t\tsuper(\n\t\t\trpcService,\n\t\t\tresourceManagerEndpointId,\n\t\t\tresourceId,\n\t\t\tresourceManagerConfiguration,\n\t\t\thighAvailabilityServices,\n\t\t\theartbeatServices,\n\t\t\tslotManager,\n\t\t\tmetricRegistry,\n\t\t\tjobLeaderIdService,\n\t\t\tfatalErrorHandler);\n\t\tthis.flinkConfig  = flinkConfig;\n\t\tthis.yarnConfig = new YarnConfiguration();\n\t\tthis.ENV = env;\n\t\tfinal int yarnHeartbeatIntervalMS = flinkConfig.getInteger(\n\t\t\t\tConfigConstants.YARN_HEARTBEAT_DELAY_SECONDS, DEFAULT_YARN_HEARTBEAT_INTERVAL_MS / 1000) * 1000;\n\n\t\tfinal long yarnExpiryIntervalMS = yarnConfig.getLong(\n\t\t\t\tYarnConfiguration.RM_AM_EXPIRY_INTERVAL_MS,\n\t\t\t\tYarnConfiguration.DEFAULT_RM_AM_EXPIRY_INTERVAL_MS);\n\n\t\tif (yarnHeartbeatIntervalMS >= yarnExpiryIntervalMS) {\n\t\t\tlog.warn(\"The heartbeat interval of the Flink Application master ({}) is greater \" +\n\t\t\t\t\t\"than YARN's expiry interval ({}). The application is likely to be killed by YARN.\",\n\t\t\t\t\tyarnHeartbeatIntervalMS, yarnExpiryIntervalMS);\n\t\t}\n\t\tyarnHeartbeatIntervalMillis = yarnHeartbeatIntervalMS;\n\t\tnumPendingContainerRequests = 0;\n\t}",
            " 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135 +\n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  ",
            "\tpublic YarnResourceManager(\n\t\t\tRpcService rpcService,\n\t\t\tString resourceManagerEndpointId,\n\t\t\tResourceID resourceId,\n\t\t\tConfiguration flinkConfig,\n\t\t\tMap<String, String> env,\n\t\t\tResourceManagerConfiguration resourceManagerConfiguration,\n\t\t\tHighAvailabilityServices highAvailabilityServices,\n\t\t\tHeartbeatServices heartbeatServices,\n\t\t\tSlotManager slotManager,\n\t\t\tMetricRegistry metricRegistry,\n\t\t\tJobLeaderIdService jobLeaderIdService,\n\t\t\tFatalErrorHandler fatalErrorHandler) {\n\t\tsuper(\n\t\t\trpcService,\n\t\t\tresourceManagerEndpointId,\n\t\t\tresourceId,\n\t\t\tresourceManagerConfiguration,\n\t\t\thighAvailabilityServices,\n\t\t\theartbeatServices,\n\t\t\tslotManager,\n\t\t\tmetricRegistry,\n\t\t\tjobLeaderIdService,\n\t\t\tfatalErrorHandler);\n\t\tthis.flinkConfig  = flinkConfig;\n\t\tthis.yarnConfig = new YarnConfiguration();\n\t\tthis.env = env;\n\t\tfinal int yarnHeartbeatIntervalMS = flinkConfig.getInteger(\n\t\t\t\tConfigConstants.YARN_HEARTBEAT_DELAY_SECONDS, DEFAULT_YARN_HEARTBEAT_INTERVAL_MS / 1000) * 1000;\n\n\t\tfinal long yarnExpiryIntervalMS = yarnConfig.getLong(\n\t\t\t\tYarnConfiguration.RM_AM_EXPIRY_INTERVAL_MS,\n\t\t\t\tYarnConfiguration.DEFAULT_RM_AM_EXPIRY_INTERVAL_MS);\n\n\t\tif (yarnHeartbeatIntervalMS >= yarnExpiryIntervalMS) {\n\t\t\tlog.warn(\"The heartbeat interval of the Flink Application master ({}) is greater \" +\n\t\t\t\t\t\"than YARN's expiry interval ({}). The application is likely to be killed by YARN.\",\n\t\t\t\t\tyarnHeartbeatIntervalMS, yarnExpiryIntervalMS);\n\t\t}\n\t\tyarnHeartbeatIntervalMillis = yarnHeartbeatIntervalMS;\n\t\tnumPendingContainerRequests = 0;\n\t}"
        ],
        [
            "YarnIntraNonHaMasterServicesTest::destroyHDFS()",
            "  87  \n  88  \n  89 -\n  90 -\n  91  \n  92 -\n  93 -\n  94  ",
            "\t@AfterClass\n\tpublic static void destroyHDFS() {\n\t\tif (HDFS_CLUSTER != null) {\n\t\t\tHDFS_CLUSTER.shutdown();\n\t\t}\n\t\tHDFS_CLUSTER = null;\n\t\tHDFS_ROOT_PATH = null;\n\t}",
            "  88  \n  89  \n  90 +\n  91 +\n  92  \n  93 +\n  94 +\n  95  ",
            "\t@AfterClass\n\tpublic static void destroyHDFS() {\n\t\tif (hdfsCluster != null) {\n\t\t\thdfsCluster.shutdown();\n\t\t}\n\t\thdfsCluster = null;\n\t\thdfsRootPath = null;\n\t}"
        ],
        [
            "YarnResourceManager::shutDownApplication(ApplicationStatus,String)",
            " 202  \n 203  \n 204  \n 205  \n 206  \n 207 -\n 208  \n 209  \n 210  \n 211 -\n 212  \n 213  ",
            "\t@Override\n\tprotected void shutDownApplication(ApplicationStatus finalStatus, String optionalDiagnostics) {\n\n\t\t// first, de-register from YARN\n\t\tFinalApplicationStatus yarnStatus = getYarnStatus(finalStatus);\n\t\tLOG.info(\"Unregistering application from the YARN Resource Manager\");\n\t\ttry {\n\t\t\tresourceManagerClient.unregisterApplicationMaster(yarnStatus, optionalDiagnostics, \"\");\n\t\t} catch (Throwable t) {\n\t\t\tLOG.error(\"Could not unregister the application master.\", t);\n\t\t}\n\t}",
            " 201  \n 202  \n 203  \n 204  \n 205  \n 206 +\n 207  \n 208  \n 209  \n 210 +\n 211  \n 212  ",
            "\t@Override\n\tprotected void shutDownApplication(ApplicationStatus finalStatus, String optionalDiagnostics) {\n\n\t\t// first, de-register from YARN\n\t\tFinalApplicationStatus yarnStatus = getYarnStatus(finalStatus);\n\t\tlog.info(\"Unregistering application from the YARN Resource Manager\");\n\t\ttry {\n\t\t\tresourceManagerClient.unregisterApplicationMaster(yarnStatus, optionalDiagnostics, \"\");\n\t\t} catch (Throwable t) {\n\t\t\tlog.error(\"Could not unregister the application master.\", t);\n\t\t}\n\t}"
        ],
        [
            "FlinkYarnSessionCli::FlinkYarnSessionCli(String,String,boolean)",
            " 136  \n 137  \n 138  \n 139 -\n 140 -\n 141 -\n 142 -\n 143 -\n 144 -\n 145 -\n 146 -\n 147 -\n 148 -\n 149 -\n 150 -\n 151 -\n 152 -\n 153 -\n 154 -\n 155 -\n 156 -\n 157 -\n 158 -\n 159 -\n 160 -\n 161 -\n 162 -\n 163 -\n 164 -\n 165 -\n 166 -\n 167 -\n 168 -\n 169  ",
            "\tpublic FlinkYarnSessionCli(String shortPrefix, String longPrefix, boolean acceptInteractiveInput) {\n\t\tthis.acceptInteractiveInput = acceptInteractiveInput;\n\n\t\tQUERY = new Option(shortPrefix + \"q\", longPrefix + \"query\", false, \"Display available YARN resources (memory, cores)\");\n\t\tAPPLICATION_ID = new Option(shortPrefix + \"id\", longPrefix + \"applicationId\", true, \"Attach to running YARN session\");\n\t\tQUEUE = new Option(shortPrefix + \"qu\", longPrefix + \"queue\", true, \"Specify YARN queue.\");\n\t\tSHIP_PATH = new Option(shortPrefix + \"t\", longPrefix + \"ship\", true, \"Ship files in the specified directory (t for transfer)\");\n\t\tFLINK_JAR = new Option(shortPrefix + \"j\", longPrefix + \"jar\", true, \"Path to Flink jar file\");\n\t\tJM_MEMORY = new Option(shortPrefix + \"jm\", longPrefix + \"jobManagerMemory\", true, \"Memory for JobManager Container [in MB]\");\n\t\tTM_MEMORY = new Option(shortPrefix + \"tm\", longPrefix + \"taskManagerMemory\", true, \"Memory per TaskManager Container [in MB]\");\n\t\tCONTAINER = new Option(shortPrefix + \"n\", longPrefix + \"container\", true, \"Number of YARN container to allocate (=Number of Task Managers)\");\n\t\tSLOTS = new Option(shortPrefix + \"s\", longPrefix + \"slots\", true, \"Number of slots per TaskManager\");\n\t\tDYNAMIC_PROPERTIES = new Option(shortPrefix + \"D\", true, \"Dynamic properties\");\n\t\tDETACHED = new Option(shortPrefix + \"d\", longPrefix + \"detached\", false, \"Start detached\");\n\t\tSTREAMING = new Option(shortPrefix + \"st\", longPrefix + \"streaming\", false, \"Start Flink in streaming mode\");\n\t\tNAME = new Option(shortPrefix + \"nm\", longPrefix + \"name\", true, \"Set a custom name for the application on YARN\");\n\t\tZOOKEEPER_NAMESPACE = new Option(shortPrefix + \"z\", longPrefix + \"zookeeperNamespace\", true, \"Namespace to create the Zookeeper sub-paths for high availability mode\");\n\n\t\tALL_OPTIONS = new Options();\n\t\tALL_OPTIONS.addOption(FLINK_JAR);\n\t\tALL_OPTIONS.addOption(JM_MEMORY);\n\t\tALL_OPTIONS.addOption(TM_MEMORY);\n\t\tALL_OPTIONS.addOption(CONTAINER);\n\t\tALL_OPTIONS.addOption(QUEUE);\n\t\tALL_OPTIONS.addOption(QUERY);\n\t\tALL_OPTIONS.addOption(SHIP_PATH);\n\t\tALL_OPTIONS.addOption(SLOTS);\n\t\tALL_OPTIONS.addOption(DYNAMIC_PROPERTIES);\n\t\tALL_OPTIONS.addOption(DETACHED);\n\t\tALL_OPTIONS.addOption(STREAMING);\n\t\tALL_OPTIONS.addOption(NAME);\n\t\tALL_OPTIONS.addOption(APPLICATION_ID);\n\t\tALL_OPTIONS.addOption(ZOOKEEPER_NAMESPACE);\n\t}",
            " 138  \n 139  \n 140  \n 141 +\n 142 +\n 143 +\n 144 +\n 145 +\n 146 +\n 147 +\n 148 +\n 149 +\n 150 +\n 151 +\n 152 +\n 153 +\n 154 +\n 155 +\n 156 +\n 157 +\n 158 +\n 159 +\n 160 +\n 161 +\n 162 +\n 163 +\n 164 +\n 165 +\n 166 +\n 167 +\n 168 +\n 169 +\n 170 +\n 171  ",
            "\tpublic FlinkYarnSessionCli(String shortPrefix, String longPrefix, boolean acceptInteractiveInput) {\n\t\tthis.acceptInteractiveInput = acceptInteractiveInput;\n\n\t\tquery = new Option(shortPrefix + \"q\", longPrefix + \"query\", false, \"Display available YARN resources (memory, cores)\");\n\t\tapplicationId = new Option(shortPrefix + \"id\", longPrefix + \"applicationId\", true, \"Attach to running YARN session\");\n\t\tqueue = new Option(shortPrefix + \"qu\", longPrefix + \"queue\", true, \"Specify YARN queue.\");\n\t\tshipPath = new Option(shortPrefix + \"t\", longPrefix + \"ship\", true, \"Ship files in the specified directory (t for transfer)\");\n\t\tflinkJar = new Option(shortPrefix + \"j\", longPrefix + \"jar\", true, \"Path to Flink jar file\");\n\t\tjmMemory = new Option(shortPrefix + \"jm\", longPrefix + \"jobManagerMemory\", true, \"Memory for JobManager Container [in MB]\");\n\t\ttmMemory = new Option(shortPrefix + \"tm\", longPrefix + \"taskManagerMemory\", true, \"Memory per TaskManager Container [in MB]\");\n\t\tcontainer = new Option(shortPrefix + \"n\", longPrefix + \"container\", true, \"Number of YARN container to allocate (=Number of Task Managers)\");\n\t\tslots = new Option(shortPrefix + \"s\", longPrefix + \"slots\", true, \"Number of slots per TaskManager\");\n\t\tdynamicproperties = new Option(shortPrefix + \"D\", true, \"Dynamic properties\");\n\t\tdetached = new Option(shortPrefix + \"d\", longPrefix + \"detached\", false, \"Start detached\");\n\t\tstreaming = new Option(shortPrefix + \"st\", longPrefix + \"streaming\", false, \"Start Flink in streaming mode\");\n\t\tname = new Option(shortPrefix + \"nm\", longPrefix + \"name\", true, \"Set a custom name for the application on YARN\");\n\t\tzookeeperNamespace = new Option(shortPrefix + \"z\", longPrefix + \"zookeeperNamespace\", true, \"Namespace to create the Zookeeper sub-paths for high availability mode\");\n\n\t\tallOptions = new Options();\n\t\tallOptions.addOption(flinkJar);\n\t\tallOptions.addOption(jmMemory);\n\t\tallOptions.addOption(tmMemory);\n\t\tallOptions.addOption(container);\n\t\tallOptions.addOption(queue);\n\t\tallOptions.addOption(query);\n\t\tallOptions.addOption(shipPath);\n\t\tallOptions.addOption(slots);\n\t\tallOptions.addOption(dynamicproperties);\n\t\tallOptions.addOption(detached);\n\t\tallOptions.addOption(streaming);\n\t\tallOptions.addOption(name);\n\t\tallOptions.addOption(applicationId);\n\t\tallOptions.addOption(zookeeperNamespace);\n\t}"
        ],
        [
            "AbstractYarnFlinkApplicationMasterRunner::createConfiguration(String,Map)",
            " 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197 -\n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  ",
            "\t/**\n\t * @param baseDirectory  The working directory\n\t * @param additional Additional parameters\n\t * \n\t * @return The configuration to be used by the TaskExecutors.\n\t */\n\tprivate static Configuration createConfiguration(String baseDirectory, Map<String, String> additional) {\n\t\tLOG.info(\"Loading config from directory {}.\", baseDirectory);\n\n\t\tConfiguration configuration = GlobalConfiguration.loadConfiguration(baseDirectory);\n\n\t\t// add dynamic properties to JobManager configuration.\n\t\tfor (Map.Entry<String, String> property : additional.entrySet()) {\n\t\t\tconfiguration.setString(property.getKey(), property.getValue());\n\t\t}\n\n\t\t// override zookeeper namespace with user cli argument (if provided)\n\t\tString cliZKNamespace = ENV.get(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE);\n\t\tif (cliZKNamespace != null && !cliZKNamespace.isEmpty()) {\n\t\t\tconfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, cliZKNamespace);\n\t\t}\n\n\t\t// if a web monitor shall be started, set the port to random binding\n\t\tif (configuration.getInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0) >= 0) {\n\t\t\tconfiguration.setInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0);\n\t\t}\n\n\t\t// if the user has set the deprecated YARN-specific config keys, we add the \n\t\t// corresponding generic config keys instead. that way, later code needs not\n\t\t// deal with deprecated config keys\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_RATIO,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO);\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_MIN,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_MASTER_ENV_PREFIX);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_TASK_MANAGER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_TASK_MANAGER_ENV_PREFIX);\n\n\t\treturn configuration;\n\t}",
            " 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196 +\n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  ",
            "\t/**\n\t * @param baseDirectory  The working directory\n\t * @param additional Additional parameters\n\t *\n\t * @return The configuration to be used by the TaskExecutors.\n\t */\n\tprivate static Configuration createConfiguration(String baseDirectory, Map<String, String> additional) {\n\t\tLOG.info(\"Loading config from directory {}.\", baseDirectory);\n\n\t\tConfiguration configuration = GlobalConfiguration.loadConfiguration(baseDirectory);\n\n\t\t// add dynamic properties to JobManager configuration.\n\t\tfor (Map.Entry<String, String> property : additional.entrySet()) {\n\t\t\tconfiguration.setString(property.getKey(), property.getValue());\n\t\t}\n\n\t\t// override zookeeper namespace with user cli argument (if provided)\n\t\tString cliZKNamespace = ENV.get(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE);\n\t\tif (cliZKNamespace != null && !cliZKNamespace.isEmpty()) {\n\t\t\tconfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, cliZKNamespace);\n\t\t}\n\n\t\t// if a web monitor shall be started, set the port to random binding\n\t\tif (configuration.getInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0) >= 0) {\n\t\t\tconfiguration.setInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0);\n\t\t}\n\n\t\t// if the user has set the deprecated YARN-specific config keys, we add the\n\t\t// corresponding generic config keys instead. that way, later code needs not\n\t\t// deal with deprecated config keys\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_RATIO,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO);\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_MIN,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_MASTER_ENV_PREFIX);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_TASK_MANAGER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_TASK_MANAGER_ENV_PREFIX);\n\n\t\treturn configuration;\n\t}"
        ],
        [
            "FlinkYarnSessionCli::loadYarnPropertiesFile(CommandLine,Configuration)",
            " 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187 -\n 188 -\n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  ",
            "\t/**\n\t * Tries to load a Flink Yarn properties file and returns the Yarn application id if successful\n\t * @param cmdLine The command-line parameters\n\t * @param flinkConfiguration The flink configuration\n\t * @return Yarn application id or null if none could be retrieved\n\t */\n\tprivate String loadYarnPropertiesFile(CommandLine cmdLine, Configuration flinkConfiguration) {\n\n\t\tString jobManagerOption = cmdLine.getOptionValue(ADDRESS_OPTION.getOpt(), null);\n\t\tif (jobManagerOption != null) {\n\t\t\t// don't resume from properties file if a JobManager has been specified\n\t\t\treturn null;\n\t\t}\n\n\t\tfor (Option option : cmdLine.getOptions()) {\n\t\t\tif (ALL_OPTIONS.hasOption(option.getOpt())) {\n\t\t\t\tif (!option.getOpt().equals(DETACHED.getOpt())) {\n\t\t\t\t\t// don't resume from properties file if yarn options have been specified\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// load the YARN properties\n\t\tFile propertiesFile = getYarnPropertiesLocation(flinkConfiguration);\n\t\tif (!propertiesFile.exists()) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlogAndSysout(\"Found YARN properties file \" + propertiesFile.getAbsolutePath());\n\n\t\tProperties yarnProperties = new Properties();\n\t\ttry {\n\t\t\ttry (InputStream is = new FileInputStream(propertiesFile)) {\n\t\t\t\tyarnProperties.load(is);\n\t\t\t}\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\tthrow new RuntimeException(\"Cannot read the YARN properties file\", e);\n\t\t}\n\n\t\t// get the Yarn application id from the properties file\n\t\tString applicationID = yarnProperties.getProperty(YARN_APPLICATION_ID_KEY);\n\t\tif (applicationID == null) {\n\t\t\tthrow new IllegalConfigurationException(\"Yarn properties file found but doesn't contain a \" +\n\t\t\t\t\"Yarn application id. Please delete the file at \" + propertiesFile.getAbsolutePath());\n\t\t}\n\n\t\ttry {\n\t\t\t// try converting id to ApplicationId\n\t\t\tConverterUtils.toApplicationId(applicationID);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"YARN properties contains an invalid entry for \" +\n\t\t\t\t\"application id: \" + applicationID, e);\n\t\t}\n\n\t\tlogAndSysout(\"Using Yarn application id from YARN properties \" + applicationID);\n\n\t\t// configure the default parallelism from YARN\n\t\tString propParallelism = yarnProperties.getProperty(YARN_PROPERTIES_PARALLELISM);\n\t\tif (propParallelism != null) { // maybe the property is not set\n\t\t\ttry {\n\t\t\t\tint parallelism = Integer.parseInt(propParallelism);\n\t\t\t\tflinkConfiguration.setInteger(ConfigConstants.DEFAULT_PARALLELISM_KEY, parallelism);\n\n\t\t\t\tlogAndSysout(\"YARN properties set default parallelism to \" + parallelism);\n\t\t\t}\n\t\t\tcatch (NumberFormatException e) {\n\t\t\t\tthrow new RuntimeException(\"Error while parsing the YARN properties: \" +\n\t\t\t\t\t\"Property \" + YARN_PROPERTIES_PARALLELISM + \" is not an integer.\");\n\t\t\t}\n\t\t}\n\n\t\t// handle the YARN client's dynamic properties\n\t\tString dynamicPropertiesEncoded = yarnProperties.getProperty(YARN_PROPERTIES_DYNAMIC_PROPERTIES_STRING);\n\t\tMap<String, String> dynamicProperties = getDynamicProperties(dynamicPropertiesEncoded);\n\t\tfor (Map.Entry<String, String> dynamicProperty : dynamicProperties.entrySet()) {\n\t\t\tflinkConfiguration.setString(dynamicProperty.getKey(), dynamicProperty.getValue());\n\t\t}\n\n\t\treturn applicationID;\n\t}",
            " 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188 +\n 189 +\n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  ",
            "\t/**\n\t * Tries to load a Flink Yarn properties file and returns the Yarn application id if successful.\n\t * @param cmdLine The command-line parameters\n\t * @param flinkConfiguration The flink configuration\n\t * @return Yarn application id or null if none could be retrieved\n\t */\n\tprivate String loadYarnPropertiesFile(CommandLine cmdLine, Configuration flinkConfiguration) {\n\n\t\tString jobManagerOption = cmdLine.getOptionValue(ADDRESS_OPTION.getOpt(), null);\n\t\tif (jobManagerOption != null) {\n\t\t\t// don't resume from properties file if a JobManager has been specified\n\t\t\treturn null;\n\t\t}\n\n\t\tfor (Option option : cmdLine.getOptions()) {\n\t\t\tif (allOptions.hasOption(option.getOpt())) {\n\t\t\t\tif (!option.getOpt().equals(detached.getOpt())) {\n\t\t\t\t\t// don't resume from properties file if yarn options have been specified\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// load the YARN properties\n\t\tFile propertiesFile = getYarnPropertiesLocation(flinkConfiguration);\n\t\tif (!propertiesFile.exists()) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlogAndSysout(\"Found YARN properties file \" + propertiesFile.getAbsolutePath());\n\n\t\tProperties yarnProperties = new Properties();\n\t\ttry {\n\t\t\ttry (InputStream is = new FileInputStream(propertiesFile)) {\n\t\t\t\tyarnProperties.load(is);\n\t\t\t}\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\tthrow new RuntimeException(\"Cannot read the YARN properties file\", e);\n\t\t}\n\n\t\t// get the Yarn application id from the properties file\n\t\tString applicationID = yarnProperties.getProperty(YARN_APPLICATION_ID_KEY);\n\t\tif (applicationID == null) {\n\t\t\tthrow new IllegalConfigurationException(\"Yarn properties file found but doesn't contain a \" +\n\t\t\t\t\"Yarn application id. Please delete the file at \" + propertiesFile.getAbsolutePath());\n\t\t}\n\n\t\ttry {\n\t\t\t// try converting id to ApplicationId\n\t\t\tConverterUtils.toApplicationId(applicationID);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"YARN properties contains an invalid entry for \" +\n\t\t\t\t\"application id: \" + applicationID, e);\n\t\t}\n\n\t\tlogAndSysout(\"Using Yarn application id from YARN properties \" + applicationID);\n\n\t\t// configure the default parallelism from YARN\n\t\tString propParallelism = yarnProperties.getProperty(YARN_PROPERTIES_PARALLELISM);\n\t\tif (propParallelism != null) { // maybe the property is not set\n\t\t\ttry {\n\t\t\t\tint parallelism = Integer.parseInt(propParallelism);\n\t\t\t\tflinkConfiguration.setInteger(ConfigConstants.DEFAULT_PARALLELISM_KEY, parallelism);\n\n\t\t\t\tlogAndSysout(\"YARN properties set default parallelism to \" + parallelism);\n\t\t\t}\n\t\t\tcatch (NumberFormatException e) {\n\t\t\t\tthrow new RuntimeException(\"Error while parsing the YARN properties: \" +\n\t\t\t\t\t\"Property \" + YARN_PROPERTIES_PARALLELISM + \" is not an integer.\");\n\t\t\t}\n\t\t}\n\n\t\t// handle the YARN client's dynamic properties\n\t\tString dynamicPropertiesEncoded = yarnProperties.getProperty(YARN_PROPERTIES_DYNAMIC_PROPERTIES_STRING);\n\t\tMap<String, String> dynamicProperties = getDynamicProperties(dynamicPropertiesEncoded);\n\t\tfor (Map.Entry<String, String> dynamicProperty : dynamicProperties.entrySet()) {\n\t\t\tflinkConfiguration.setString(dynamicProperty.getKey(), dynamicProperty.getValue());\n\t\t}\n\n\t\treturn applicationID;\n\t}"
        ],
        [
            "YarnApplicationMasterRunner::createConfiguration(String,Map)",
            " 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525 -\n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  ",
            "\t/**\n\t * \n\t * @param baseDirectory\n\t * @param additional\n\t * \n\t * @return The configuration to be used by the TaskManagers.\n\t */\n\t@SuppressWarnings(\"deprecation\")\n\tprivate static Configuration createConfiguration(String baseDirectory, Map<String, String> additional) {\n\t\tLOG.info(\"Loading config from directory \" + baseDirectory);\n\n\t\tConfiguration configuration = GlobalConfiguration.loadConfiguration(baseDirectory);\n\n\t\t// add dynamic properties to JobManager configuration.\n\t\tfor (Map.Entry<String, String> property : additional.entrySet()) {\n\t\t\tconfiguration.setString(property.getKey(), property.getValue());\n\t\t}\n\n\t\t// override zookeeper namespace with user cli argument (if provided)\n\t\tString cliZKNamespace = ENV.get(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE);\n\t\tif (cliZKNamespace != null && !cliZKNamespace.isEmpty()) {\n\t\t\tconfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, cliZKNamespace);\n\t\t}\n\n\t\t// if a web monitor shall be started, set the port to random binding\n\t\tif (configuration.getInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0) >= 0) {\n\t\t\tconfiguration.setInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0);\n\t\t}\n\n\t\t// if the user has set the deprecated YARN-specific config keys, we add the \n\t\t// corresponding generic config keys instead. that way, later code needs not\n\t\t// deal with deprecated config keys\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_RATIO,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO);\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_MIN,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_MASTER_ENV_PREFIX);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_TASK_MANAGER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_TASK_MANAGER_ENV_PREFIX);\n\n\t\treturn configuration;\n\t}",
            " 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517 +\n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  ",
            "\t/**\n\t * Reads the global configuration from the given directory and adds the given parameters to it.\n\t *\n\t * @param baseDirectory directory to load the configuration from\n\t * @param additional additional parameters to be included in the configuration\n\t *\n\t * @return The configuration to be used by the TaskManagers.\n\t */\n\t@SuppressWarnings(\"deprecation\")\n\tprivate static Configuration createConfiguration(String baseDirectory, Map<String, String> additional) {\n\t\tLOG.info(\"Loading config from directory \" + baseDirectory);\n\n\t\tConfiguration configuration = GlobalConfiguration.loadConfiguration(baseDirectory);\n\n\t\t// add dynamic properties to JobManager configuration.\n\t\tfor (Map.Entry<String, String> property : additional.entrySet()) {\n\t\t\tconfiguration.setString(property.getKey(), property.getValue());\n\t\t}\n\n\t\t// override zookeeper namespace with user cli argument (if provided)\n\t\tString cliZKNamespace = ENV.get(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE);\n\t\tif (cliZKNamespace != null && !cliZKNamespace.isEmpty()) {\n\t\t\tconfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, cliZKNamespace);\n\t\t}\n\n\t\t// if a web monitor shall be started, set the port to random binding\n\t\tif (configuration.getInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0) >= 0) {\n\t\t\tconfiguration.setInteger(ConfigConstants.JOB_MANAGER_WEB_PORT_KEY, 0);\n\t\t}\n\n\t\t// if the user has set the deprecated YARN-specific config keys, we add the\n\t\t// corresponding generic config keys instead. that way, later code needs not\n\t\t// deal with deprecated config keys\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_RATIO,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_RATIO);\n\n\t\tBootstrapTools.substituteDeprecatedConfigKey(configuration,\n\t\t\tConfigConstants.YARN_HEAP_CUTOFF_MIN,\n\t\t\tConfigConstants.CONTAINERIZED_HEAP_CUTOFF_MIN);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_MASTER_ENV_PREFIX);\n\n\t\tBootstrapTools.substituteDeprecatedConfigPrefix(configuration,\n\t\t\tConfigConstants.YARN_TASK_MANAGER_ENV_PREFIX,\n\t\t\tConfigConstants.CONTAINERIZED_TASK_MANAGER_ENV_PREFIX);\n\n\t\treturn configuration;\n\t}"
        ],
        [
            "YarnClusterClient::disconnect()",
            " 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139 -\n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154 -\n 155  \n 156  \n 157  \n 158  \n 159  \n 160  ",
            "\t/**\n\t * Disconnect from the Yarn cluster\n\t */\n\tpublic void disconnect() {\n\n\t\tif (hasBeenShutDown.getAndSet(true)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif(!isConnected) {\n\t\t\tthrow new IllegalStateException(\"Can not disconnect from an unconnected cluster.\");\n\t\t}\n\n\t\tLOG.info(\"Disconnecting YarnClusterClient from ApplicationMaster\");\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().removeShutdownHook(clientShutdownHook);\n\t\t} catch (IllegalStateException e) {\n\t\t\t// we are already in the shutdown hook\n\t\t}\n\n\t\ttry {\n\t\t\tpollingRunner.stopRunner();\n\t\t\tpollingRunner.join(1000);\n\t\t} catch(InterruptedException e) {\n\t\t\tLOG.warn(\"Shutdown of the polling runner was interrupted\", e);\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\n\t\tisConnected = false;\n\t}",
            " 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141 +\n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156 +\n 157  \n 158  \n 159  \n 160  \n 161  \n 162  ",
            "\t/**\n\t * Disconnect from the Yarn cluster.\n\t */\n\tpublic void disconnect() {\n\n\t\tif (hasBeenShutDown.getAndSet(true)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (!isConnected) {\n\t\t\tthrow new IllegalStateException(\"Can not disconnect from an unconnected cluster.\");\n\t\t}\n\n\t\tLOG.info(\"Disconnecting YarnClusterClient from ApplicationMaster\");\n\n\t\ttry {\n\t\t\tRuntime.getRuntime().removeShutdownHook(clientShutdownHook);\n\t\t} catch (IllegalStateException e) {\n\t\t\t// we are already in the shutdown hook\n\t\t}\n\n\t\ttry {\n\t\t\tpollingRunner.stopRunner();\n\t\t\tpollingRunner.join(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tLOG.warn(\"Shutdown of the polling runner was interrupted\", e);\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\n\t\tisConnected = false;\n\t}"
        ],
        [
            "FlinkYarnCLI::FlinkYarnCLI(String,String)",
            "  77  \n  78  \n  79 -\n  80 -\n  81 -\n  82 -\n  83 -\n  84 -\n  85 -\n  86 -\n  87 -\n  88 -\n  89 -\n  90 -\n  91 -\n  92 -\n  93 -\n  94 -\n  95  ",
            "\tpublic FlinkYarnCLI(String shortPrefix, String longPrefix) {\n\n\t\tQUEUE = new Option(shortPrefix + \"qu\", longPrefix + \"queue\", true, \"Specify YARN queue.\");\n\t\tSHIP_PATH = new Option(shortPrefix + \"t\", longPrefix + \"ship\", true, \"Ship files in the specified directory (t for transfer)\");\n\t\tFLINK_JAR = new Option(shortPrefix + \"j\", longPrefix + \"jar\", true, \"Path to Flink jar file\");\n\t\tJM_MEMORY = new Option(shortPrefix + \"jm\", longPrefix + \"jobManagerMemory\", true, \"Memory for JobManager Container [in MB]\");\n\t\tDYNAMIC_PROPERTIES = new Option(shortPrefix + \"D\", true, \"Dynamic properties\");\n\t\tDETACHED = new Option(shortPrefix + \"a\", longPrefix + \"attached\", false, \"Start attached\");\n\t\tZOOKEEPER_NAMESPACE = new Option(shortPrefix + \"z\", longPrefix + \"zookeeperNamespace\", true, \"Namespace to create the Zookeeper sub-paths for high availability mode\");\n\n\t\tALL_OPTIONS = new Options();\n\t\tALL_OPTIONS.addOption(FLINK_JAR);\n\t\tALL_OPTIONS.addOption(JM_MEMORY);\n\t\tALL_OPTIONS.addOption(QUEUE);\n\t\tALL_OPTIONS.addOption(SHIP_PATH);\n\t\tALL_OPTIONS.addOption(DYNAMIC_PROPERTIES);\n\t\tALL_OPTIONS.addOption(DETACHED);\n\t\tALL_OPTIONS.addOption(ZOOKEEPER_NAMESPACE);\n\t}",
            "  79  \n  80  \n  81 +\n  82 +\n  83 +\n  84 +\n  85 +\n  86 +\n  87 +\n  88 +\n  89 +\n  90 +\n  91 +\n  92 +\n  93 +\n  94 +\n  95 +\n  96 +\n  97  ",
            "\tpublic FlinkYarnCLI(String shortPrefix, String longPrefix) {\n\n\t\tqueue = new Option(shortPrefix + \"qu\", longPrefix + \"queue\", true, \"Specify YARN queue.\");\n\t\tshipPath = new Option(shortPrefix + \"t\", longPrefix + \"ship\", true, \"Ship files in the specified directory (t for transfer)\");\n\t\tflinkJar = new Option(shortPrefix + \"j\", longPrefix + \"jar\", true, \"Path to Flink jar file\");\n\t\tjmMemory = new Option(shortPrefix + \"jm\", longPrefix + \"jobManagerMemory\", true, \"Memory for JobManager Container [in MB]\");\n\t\tdynamicProperties = new Option(shortPrefix + \"D\", true, \"Dynamic properties\");\n\t\tdetached = new Option(shortPrefix + \"a\", longPrefix + \"attached\", false, \"Start attached\");\n\t\tzookeeperNamespace = new Option(shortPrefix + \"z\", longPrefix + \"zookeeperNamespace\", true, \"Namespace to create the Zookeeper sub-paths for high availability mode\");\n\n\t\tallOptions = new Options();\n\t\tallOptions.addOption(flinkJar);\n\t\tallOptions.addOption(jmMemory);\n\t\tallOptions.addOption(queue);\n\t\tallOptions.addOption(shipPath);\n\t\tallOptions.addOption(dynamicProperties);\n\t\tallOptions.addOption(detached);\n\t\tallOptions.addOption(zookeeperNamespace);\n\t}"
        ],
        [
            "YarnResourceManager::initialize()",
            " 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164 -\n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  ",
            "\t@Override\n\tprotected void initialize() throws ResourceManagerException {\n\t\tresourceManagerClient = AMRMClientAsync.createAMRMClientAsync(yarnHeartbeatIntervalMillis, this);\n\t\tresourceManagerClient.init(yarnConfig);\n\t\tresourceManagerClient.start();\n\t\ttry {\n\t\t\t//TODO: change akka address to tcp host and port, the getAddress() interface should return a standard tcp address\n\t\t\tTuple2<String, Integer> hostPort = parseHostPort(getAddress());\n\t\t\t//TODO: the third paramter should be the webmonitor address\n\t\t\tresourceManagerClient.registerApplicationMaster(hostPort.f0, hostPort.f1, getAddress());\n\t\t} catch (Exception e) {\n\t\t\tLOG.info(\"registerApplicationMaster fail\", e);\n\t\t}\n\n\t\t// create the client to communicate with the node managers\n\t\tnodeManagerClient = NMClient.createNMClient();\n\t\tnodeManagerClient.init(yarnConfig);\n\t\tnodeManagerClient.start();\n\t\tnodeManagerClient.cleanupRunningContainersOnStop(true);\n\t}",
            " 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163 +\n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  ",
            "\t@Override\n\tprotected void initialize() throws ResourceManagerException {\n\t\tresourceManagerClient = AMRMClientAsync.createAMRMClientAsync(yarnHeartbeatIntervalMillis, this);\n\t\tresourceManagerClient.init(yarnConfig);\n\t\tresourceManagerClient.start();\n\t\ttry {\n\t\t\t//TODO: change akka address to tcp host and port, the getAddress() interface should return a standard tcp address\n\t\t\tTuple2<String, Integer> hostPort = parseHostPort(getAddress());\n\t\t\t//TODO: the third paramter should be the webmonitor address\n\t\t\tresourceManagerClient.registerApplicationMaster(hostPort.f0, hostPort.f1, getAddress());\n\t\t} catch (Exception e) {\n\t\t\tlog.info(\"registerApplicationMaster fail\", e);\n\t\t}\n\n\t\t// create the client to communicate with the node managers\n\t\tnodeManagerClient = NMClient.createNMClient();\n\t\tnodeManagerClient.init(yarnConfig);\n\t\tnodeManagerClient.start();\n\t\tnodeManagerClient.cleanupRunningContainersOnStop(true);\n\t}"
        ]
    ],
    "ac0facc8754ab8bf41f6be96b4241e0a9078f52f": [
        [
            "FlinkKafkaConsumerBase::run(SourceContext)",
            " 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550 -\n 551 -\n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559 -\n 560 -\n 561 -\n 562 -\n 563 -\n 564 -\n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603 -\n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626 -\n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643 -\n 644  \n 645  ",
            "\t@Override\n\tpublic void run(SourceContext<T> sourceContext) throws Exception {\n\t\tif (subscribedPartitionsToStartOffsets == null) {\n\t\t\tthrow new Exception(\"The partitions were not set for the consumer\");\n\t\t}\n\n\t\t// initialize commit metrics and default offset callback method\n\t\tthis.successfulCommits = this.getRuntimeContext().getMetricGroup().counter(COMMITS_SUCCEEDED_METRICS_COUNTER);\n\t\tthis.failedCommits =  this.getRuntimeContext().getMetricGroup().counter(COMMITS_FAILED_METRICS_COUNTER);\n\n\t\tthis.offsetCommitCallback = new KafkaCommitCallback() {\n\t\t\t@Override\n\t\t\tpublic void onSuccess() {\n\t\t\t\tsuccessfulCommits.inc();\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void onException(Throwable cause) {\n\t\t\t\tLOG.warn(\"Async Kafka commit failed.\", cause);\n\t\t\t\tfailedCommits.inc();\n\t\t\t}\n\t\t};\n\n\t\t// mark the subtask as temporarily idle if there are no initial seed partitions;\n\t\t// once this subtask discovers some partitions and starts collecting records, the subtask's\n\t\t// status will automatically be triggered back to be active.\n\t\tif (subscribedPartitionsToStartOffsets.isEmpty()) {\n\t\t\tsourceContext.markAsTemporarilyIdle();\n\t\t}\n\n\t\t// create the fetcher that will communicate with the Kafka brokers\n\t\tfinal AbstractFetcher<T, ?> fetcher = createFetcher(\n\t\t\t\tsourceContext,\n\t\t\t\tsubscribedPartitionsToStartOffsets,\n\t\t\t\tperiodicWatermarkAssigner,\n\t\t\t\tpunctuatedWatermarkAssigner,\n\t\t\t\t(StreamingRuntimeContext) getRuntimeContext(),\n\t\t\t\toffsetCommitMode);\n\n\t\t// publish the reference, for snapshot-, commit-, and cancel calls\n\t\t// IMPORTANT: We can only do that now, because only now will calls to\n\t\t//            the fetchers 'snapshotCurrentState()' method return at least\n\t\t//            the restored offsets\n\t\tthis.kafkaFetcher = fetcher;\n\n\t\tif (!running) {\n\t\t\treturn;\n\t\t}\n\n\t\t// depending on whether we were restored with the current state version (1.3),\n\t\t// remaining logic branches off into 2 paths:\n\t\t//  1) New state - partition discovery loop executed as separate thread, with this\n\t\t//                 thread running the main fetcher loop\n\t\t//  2) Old state - partition discovery is disabled and only the main fetcher loop is executed\n\n\t\tif (discoveryIntervalMillis != PARTITION_DISCOVERY_DISABLED) {\n\t\t\tfinal AtomicReference<Exception> discoveryLoopErrorRef = new AtomicReference<>();\n\t\t\tthis.discoveryLoopThread = new Thread(new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// --------------------- partition discovery loop ---------------------\n\n\t\t\t\t\t\tList<KafkaTopicPartition> discoveredPartitions;\n\n\t\t\t\t\t\t// throughout the loop, we always eagerly check if we are still running before\n\t\t\t\t\t\t// performing the next operation, so that we can escape the loop as soon as possible\n\n\t\t\t\t\t\twhile (running) {\n\t\t\t\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\t\t\t\tLOG.debug(\"Consumer subtask {} is trying to discover new partitions ...\");\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdiscoveredPartitions = partitionDiscoverer.discoverPartitions();\n\t\t\t\t\t\t\t} catch (AbstractPartitionDiscoverer.WakeupException | AbstractPartitionDiscoverer.ClosedException e) {\n\t\t\t\t\t\t\t\t// the partition discoverer may have been closed or woken up before or during the discovery;\n\t\t\t\t\t\t\t\t// this would only happen if the consumer was canceled; simply escape the loop\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// no need to add the discovered partitions if we were closed during the meantime\n\t\t\t\t\t\t\tif (running && !discoveredPartitions.isEmpty()) {\n\t\t\t\t\t\t\t\tfetcher.addDiscoveredPartitions(discoveredPartitions);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// do not waste any time sleeping if we're not running anymore\n\t\t\t\t\t\t\tif (running && discoveryIntervalMillis != 0) {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tThread.sleep(discoveryIntervalMillis);\n\t\t\t\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\t\t\t// may be interrupted if the consumer was canceled midway; simply escape the loop\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tdiscoveryLoopErrorRef.set(e);\n\t\t\t\t\t} finally {\n\t\t\t\t\t\t// calling cancel will also let the fetcher loop escape\n\t\t\t\t\t\tcancel();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tdiscoveryLoopThread.start();\n\t\t\tfetcher.runFetchLoop();\n\n\t\t\t// --------------------------------------------------------------------\n\n\t\t\t// make sure that the partition discoverer is properly closed\n\t\t\tpartitionDiscoverer.close();\n\t\t\tdiscoveryLoopThread.join();\n\n\t\t\t// rethrow any fetcher errors\n\t\t\tfinal Exception discoveryLoopError = discoveryLoopErrorRef.get();\n\t\t\tif (discoveryLoopError != null) {\n\t\t\t\tthrow new RuntimeException(discoveryLoopError);\n\t\t\t}\n\t\t} else {\n\t\t\t// won't be using the discoverer\n\t\t\tpartitionDiscoverer.close();\n\n\t\t\tfetcher.runFetchLoop();\n\t\t}\n\t}",
            " 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550 +\n 551 +\n 552 +\n 553 +\n 554 +\n 555 +\n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601 +\n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624 +\n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641 +\n 642  \n 643  ",
            "\t@Override\n\tpublic void run(SourceContext<T> sourceContext) throws Exception {\n\t\tif (subscribedPartitionsToStartOffsets == null) {\n\t\t\tthrow new Exception(\"The partitions were not set for the consumer\");\n\t\t}\n\n\t\t// initialize commit metrics and default offset callback method\n\t\tthis.successfulCommits = this.getRuntimeContext().getMetricGroup().counter(COMMITS_SUCCEEDED_METRICS_COUNTER);\n\t\tthis.failedCommits =  this.getRuntimeContext().getMetricGroup().counter(COMMITS_FAILED_METRICS_COUNTER);\n\n\t\tthis.offsetCommitCallback = new KafkaCommitCallback() {\n\t\t\t@Override\n\t\t\tpublic void onSuccess() {\n\t\t\t\tsuccessfulCommits.inc();\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void onException(Throwable cause) {\n\t\t\t\tLOG.warn(\"Async Kafka commit failed.\", cause);\n\t\t\t\tfailedCommits.inc();\n\t\t\t}\n\t\t};\n\n\t\t// mark the subtask as temporarily idle if there are no initial seed partitions;\n\t\t// once this subtask discovers some partitions and starts collecting records, the subtask's\n\t\t// status will automatically be triggered back to be active.\n\t\tif (subscribedPartitionsToStartOffsets.isEmpty()) {\n\t\t\tsourceContext.markAsTemporarilyIdle();\n\t\t}\n\n\t\t// from this point forward:\n\t\t//   - 'snapshotState' will draw offsets from the fetcher,\n\t\t//     instead of being built from `subscribedPartitionsToStartOffsets`\n\t\t//   - 'notifyCheckpointComplete' will start to do work (i.e. commit offsets to\n\t\t//     Kafka through the fetcher, if configured to do so)\n\t\tthis.kafkaFetcher = createFetcher(\n\t\t\t\tsourceContext,\n\t\t\t\tsubscribedPartitionsToStartOffsets,\n\t\t\t\tperiodicWatermarkAssigner,\n\t\t\t\tpunctuatedWatermarkAssigner,\n\t\t\t\t(StreamingRuntimeContext) getRuntimeContext(),\n\t\t\t\toffsetCommitMode);\n\n\t\tif (!running) {\n\t\t\treturn;\n\t\t}\n\n\t\t// depending on whether we were restored with the current state version (1.3),\n\t\t// remaining logic branches off into 2 paths:\n\t\t//  1) New state - partition discovery loop executed as separate thread, with this\n\t\t//                 thread running the main fetcher loop\n\t\t//  2) Old state - partition discovery is disabled and only the main fetcher loop is executed\n\n\t\tif (discoveryIntervalMillis != PARTITION_DISCOVERY_DISABLED) {\n\t\t\tfinal AtomicReference<Exception> discoveryLoopErrorRef = new AtomicReference<>();\n\t\t\tthis.discoveryLoopThread = new Thread(new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// --------------------- partition discovery loop ---------------------\n\n\t\t\t\t\t\tList<KafkaTopicPartition> discoveredPartitions;\n\n\t\t\t\t\t\t// throughout the loop, we always eagerly check if we are still running before\n\t\t\t\t\t\t// performing the next operation, so that we can escape the loop as soon as possible\n\n\t\t\t\t\t\twhile (running) {\n\t\t\t\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\t\t\t\tLOG.debug(\"Consumer subtask {} is trying to discover new partitions ...\");\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdiscoveredPartitions = partitionDiscoverer.discoverPartitions();\n\t\t\t\t\t\t\t} catch (AbstractPartitionDiscoverer.WakeupException | AbstractPartitionDiscoverer.ClosedException e) {\n\t\t\t\t\t\t\t\t// the partition discoverer may have been closed or woken up before or during the discovery;\n\t\t\t\t\t\t\t\t// this would only happen if the consumer was canceled; simply escape the loop\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// no need to add the discovered partitions if we were closed during the meantime\n\t\t\t\t\t\t\tif (running && !discoveredPartitions.isEmpty()) {\n\t\t\t\t\t\t\t\tkafkaFetcher.addDiscoveredPartitions(discoveredPartitions);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// do not waste any time sleeping if we're not running anymore\n\t\t\t\t\t\t\tif (running && discoveryIntervalMillis != 0) {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tThread.sleep(discoveryIntervalMillis);\n\t\t\t\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\t\t\t// may be interrupted if the consumer was canceled midway; simply escape the loop\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tdiscoveryLoopErrorRef.set(e);\n\t\t\t\t\t} finally {\n\t\t\t\t\t\t// calling cancel will also let the fetcher loop escape\n\t\t\t\t\t\tcancel();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tdiscoveryLoopThread.start();\n\t\t\tkafkaFetcher.runFetchLoop();\n\n\t\t\t// --------------------------------------------------------------------\n\n\t\t\t// make sure that the partition discoverer is properly closed\n\t\t\tpartitionDiscoverer.close();\n\t\t\tdiscoveryLoopThread.join();\n\n\t\t\t// rethrow any fetcher errors\n\t\t\tfinal Exception discoveryLoopError = discoveryLoopErrorRef.get();\n\t\t\tif (discoveryLoopError != null) {\n\t\t\t\tthrow new RuntimeException(discoveryLoopError);\n\t\t\t}\n\t\t} else {\n\t\t\t// won't be using the discoverer\n\t\t\tpartitionDiscoverer.close();\n\n\t\t\tkafkaFetcher.runFetchLoop();\n\t\t}\n\t}"
        ]
    ],
    "4debc6033cc2099b763d7fef86829b9f6734d91a": [
        [
            "DispatcherTest::testJobSubmission()",
            "  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90 -\n  91 -\n  92 -\n  93 -\n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  ",
            "\t/**\n\t * Tests that we can submit a job to the Dispatcher which then spawns a\n\t * new JobManagerRunner.\n\t */\n\t@Test\n\tpublic void testJobSubmission() throws Exception {\n\t\tTestingFatalErrorHandler fatalErrorHandler = new TestingFatalErrorHandler();\n\t\tHighAvailabilityServices haServices = new StandaloneHaServices(\n\t\t\t\"localhost\",\n\t\t\t\"localhost\",\n\t\t\t\"localhost\");\n\t\tHeartbeatServices heartbeatServices = new HeartbeatServices(1000L, 10000L);\n\t\tJobManagerRunner jobManagerRunner = mock(JobManagerRunner.class);\n\n\t\tfinal JobGraph jobGraph = mock(JobGraph.class);\n\t\tfinal JobID jobId = new JobID();\n\t\twhen(jobGraph.getJobID()).thenReturn(jobId);\n\n\t\tfinal TestingDispatcher dispatcher = new TestingDispatcher(\n\t\t\trpcService,\n\t\t\tDispatcher.DISPATCHER_NAME,\n\t\t\tnew Configuration(),\n\t\t\thaServices,\n\t\t\tmock(BlobServer.class),\n\t\t\theartbeatServices,\n\t\t\tmock(MetricRegistry.class),\n\t\t\tfatalErrorHandler,\n\t\t\tjobManagerRunner,\n\t\t\tjobId);\n\n\t\ttry {\n\t\t\tdispatcher.start();\n\n\t\t\tDispatcherGateway dispatcherGateway = dispatcher.getSelfGateway(DispatcherGateway.class);\n\n\t\t\tCompletableFuture<Acknowledge> acknowledgeFuture = dispatcherGateway.submitJob(jobGraph, timeout);\n\n\t\t\tacknowledgeFuture.get();\n\n\t\t\tverify(jobManagerRunner, Mockito.timeout(timeout.toMilliseconds())).start();\n\n\t\t\t// check that no error has occurred\n\t\t\tfatalErrorHandler.rethrowError();\n\t\t} finally {\n\t\t\tRpcUtils.terminateRpcEndpoint(dispatcher, timeout);\n\t\t}\n\t}",
            "  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90 +\n  91 +\n  92 +\n  93 +\n  94 +\n  95 +\n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118 +\n 119 +\n 120 +\n 121 +\n 122 +\n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  ",
            "\t/**\n\t * Tests that we can submit a job to the Dispatcher which then spawns a\n\t * new JobManagerRunner.\n\t */\n\t@Test\n\tpublic void testJobSubmission() throws Exception {\n\t\tTestingFatalErrorHandler fatalErrorHandler = new TestingFatalErrorHandler();\n\n\t\tTestingLeaderElectionService dispatcherLeaderElectionService = new TestingLeaderElectionService();\n\t\tTestingHighAvailabilityServices haServices = new TestingHighAvailabilityServices();\n\t\thaServices.setDispatcherLeaderElectionService(dispatcherLeaderElectionService);\n\t\thaServices.setSubmittedJobGraphStore(new StandaloneSubmittedJobGraphStore());\n\n\t\tHeartbeatServices heartbeatServices = new HeartbeatServices(1000L, 10000L);\n\t\tJobManagerRunner jobManagerRunner = mock(JobManagerRunner.class);\n\n\t\tfinal JobGraph jobGraph = mock(JobGraph.class);\n\t\tfinal JobID jobId = new JobID();\n\t\twhen(jobGraph.getJobID()).thenReturn(jobId);\n\n\t\tfinal TestingDispatcher dispatcher = new TestingDispatcher(\n\t\t\trpcService,\n\t\t\tDispatcher.DISPATCHER_NAME,\n\t\t\tnew Configuration(),\n\t\t\thaServices,\n\t\t\tmock(BlobServer.class),\n\t\t\theartbeatServices,\n\t\t\tmock(MetricRegistry.class),\n\t\t\tfatalErrorHandler,\n\t\t\tjobManagerRunner,\n\t\t\tjobId);\n\n\t\ttry {\n\t\t\tdispatcher.start();\n\n\t\t\tCompletableFuture<UUID> leaderFuture = dispatcherLeaderElectionService.isLeader(UUID.randomUUID());\n\n\t\t\t// wait for the leader to be elected\n\t\t\tleaderFuture.get();\n\n\t\t\tDispatcherGateway dispatcherGateway = dispatcher.getSelfGateway(DispatcherGateway.class);\n\n\t\t\tCompletableFuture<Acknowledge> acknowledgeFuture = dispatcherGateway.submitJob(jobGraph, timeout);\n\n\t\t\tacknowledgeFuture.get();\n\n\t\t\tverify(jobManagerRunner, Mockito.timeout(timeout.toMilliseconds())).start();\n\n\t\t\t// check that no error has occurred\n\t\t\tfatalErrorHandler.rethrowError();\n\t\t} finally {\n\t\t\tRpcUtils.terminateRpcEndpoint(dispatcher, timeout);\n\t\t}\n\t}"
        ]
    ],
    "3039df8099bc8d42b645d69deb360c884c94b83b": [
        [
            "AkkaRpcServiceUtils::createRpcService(String,int,Configuration)",
            "  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76 -\n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  ",
            "\t/**\n\t * Utility method to create RPC service from configuration and hostname, port.\n\t *\n\t * @param hostname   The hostname/address that describes the TaskManager's data location.\n\t * @param port           If true, the TaskManager will not initiate the TCP network stack.\n\t * @param configuration                 The configuration for the TaskManager.\n\t * @return   The rpc service which is used to start and connect to the TaskManager RpcEndpoint .\n\t * @throws IOException      Thrown, if the actor system can not bind to the address\n\t * @throws Exception      Thrown is some other error occurs while creating akka actor system\n\t */\n\tpublic static RpcService createRpcService(String hostname, int port, Configuration configuration) throws Exception {\n\t\tLOG.info(\"Starting AkkaRpcService at {}.\", NetUtils.hostAndPortToUrlString(hostname, port));\n\n\t\tfinal ActorSystem actorSystem;\n\n\t\ttry {\n\t\t\tConfig akkaConfig;\n\n\t\t\tif (hostname != null && !hostname.isEmpty()) {\n\t\t\t\t// remote akka config\n\t\t\t\takkaConfig = AkkaUtils.getAkkaConfig(configuration, hostname, port);\n\t\t\t} else {\n\t\t\t\t// local akka config\n\t\t\t\takkaConfig = AkkaUtils.getAkkaConfig(configuration);\n\t\t\t}\n\n\t\t\tLOG.debug(\"Using akka configuration \\n {}.\", akkaConfig);\n\n\t\t\tactorSystem = AkkaUtils.createActorSystem(akkaConfig);\n\t\t} catch (Throwable t) {\n\t\t\tif (t instanceof ChannelException) {\n\t\t\t\tThrowable cause = t.getCause();\n\t\t\t\tif (cause != null && t.getCause() instanceof java.net.BindException) {\n\t\t\t\t\tString address = NetUtils.hostAndPortToUrlString(hostname, port);\n\t\t\t\t\tthrow new IOException(\"Unable to bind AkkaRpcService actor system to address \" +\n\t\t\t\t\t\taddress + \" - \" + cause.getMessage(), t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow new Exception(\"Could not create TaskManager actor system\", t);\n\t\t}\n\n\t\tfinal Time timeout = Time.milliseconds(AkkaUtils.getTimeout(configuration).toMillis());\n\t\treturn new AkkaRpcService(actorSystem, timeout);\n\t}",
            "  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76 +\n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  ",
            "\t/**\n\t * Utility method to create RPC service from configuration and hostname, port.\n\t *\n\t * @param hostname   The hostname/address that describes the TaskManager's data location.\n\t * @param port           If true, the TaskManager will not initiate the TCP network stack.\n\t * @param configuration                 The configuration for the TaskManager.\n\t * @return   The rpc service which is used to start and connect to the TaskManager RpcEndpoint .\n\t * @throws IOException      Thrown, if the actor system can not bind to the address\n\t * @throws Exception      Thrown is some other error occurs while creating akka actor system\n\t */\n\tpublic static RpcService createRpcService(String hostname, int port, Configuration configuration) throws Exception {\n\t\tLOG.info(\"Starting AkkaRpcService at {}.\", NetUtils.unresolvedHostAndPortToNormalizedString(hostname, port));\n\n\t\tfinal ActorSystem actorSystem;\n\n\t\ttry {\n\t\t\tConfig akkaConfig;\n\n\t\t\tif (hostname != null && !hostname.isEmpty()) {\n\t\t\t\t// remote akka config\n\t\t\t\takkaConfig = AkkaUtils.getAkkaConfig(configuration, hostname, port);\n\t\t\t} else {\n\t\t\t\t// local akka config\n\t\t\t\takkaConfig = AkkaUtils.getAkkaConfig(configuration);\n\t\t\t}\n\n\t\t\tLOG.debug(\"Using akka configuration \\n {}.\", akkaConfig);\n\n\t\t\tactorSystem = AkkaUtils.createActorSystem(akkaConfig);\n\t\t} catch (Throwable t) {\n\t\t\tif (t instanceof ChannelException) {\n\t\t\t\tThrowable cause = t.getCause();\n\t\t\t\tif (cause != null && t.getCause() instanceof java.net.BindException) {\n\t\t\t\t\tString address = NetUtils.hostAndPortToUrlString(hostname, port);\n\t\t\t\t\tthrow new IOException(\"Unable to bind AkkaRpcService actor system to address \" +\n\t\t\t\t\t\taddress + \" - \" + cause.getMessage(), t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow new Exception(\"Could not create TaskManager actor system\", t);\n\t\t}\n\n\t\tfinal Time timeout = Time.milliseconds(AkkaUtils.getTimeout(configuration).toMillis());\n\t\treturn new AkkaRpcService(actorSystem, timeout);\n\t}"
        ],
        [
            "TaskManagerStartupTest::testStartupWhenTaskmanagerActorPortIsUsed()",
            "  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99 -\n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109 -\n 110 -\n 111 -\n 112 -\n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  ",
            "\t/**\n\t * Tests that the TaskManager fails synchronously when the actor system port\n\t * is in use.\n\t * \n\t * @throws Throwable\n\t */\n\t@Test(expected = BindException.class)\n\tpublic void testStartupWhenTaskmanagerActorPortIsUsed() throws Exception {\n\t\tServerSocket blocker = null;\n\n\t\ttry {\n\t\t\tfinal String localHostName = \"localhost\";\n\t\t\tfinal InetAddress localBindAddress = InetAddress.getByName(NetUtils.getWildcardIPAddress());\n\n\t\t\t// block some port\n\t\t\tblocker = new ServerSocket(0, 50, localBindAddress);\n\t\t\tfinal int port = blocker.getLocalPort();\n\n\t\t\tTaskManager.runTaskManager(\n\t\t\t\tlocalHostName,\n\t\t\t\tResourceID.generate(),\n\t\t\t\tport,\n\t\t\t\tnew Configuration(),\n\t\t\t\thighAvailabilityServices,\n\t\t\t\tTaskManager.class);\n\t\t\tfail(\"This should fail with an IOException\");\n\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\t// expected. validate the error message\n\t\t\tList<Throwable> causes = StartupUtils.getExceptionCauses(e, new ArrayList<Throwable>());\n\t\t\tfor (Throwable cause : causes) {\n\t\t\t\tif (cause instanceof BindException) {\n\t\t\t\t\tthrow (BindException) cause;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfail(\"This should fail with an exception caused by BindException\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\tfail(e.getMessage());\n\t\t}\n\t\tfinally {\n\t\t\tif (blocker != null) {\n\t\t\t\ttry {\n\t\t\t\t\tblocker.close();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t// no need to log here\n\t\t\t\t}\n\t\t\t}\n\n\t\t\thighAvailabilityServices.closeAndCleanupAllData();\n\t\t}\n\t}",
            "  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101 +\n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109 +\n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  ",
            "\t/**\n\t * Tests that the TaskManager fails synchronously when the actor system port\n\t * is in use.\n\t * \n\t * @throws Throwable\n\t */\n\t@Test(expected = BindException.class)\n\tpublic void testStartupWhenTaskmanagerActorPortIsUsed() throws Exception {\n\t\tServerSocket blocker = null;\n\n\t\ttry {\n\t\t\tfinal String localHostName = \"localhost\";\n\t\t\tfinal InetAddress localBindAddress = InetAddress.getByName(NetUtils.getWildcardIPAddress());\n\n\t\t\t// block some port\n\t\t\tblocker = new ServerSocket(0, 50, localBindAddress);\n\t\t\tfinal int port = blocker.getLocalPort();\n\n\t\t\tTaskManager.runTaskManager(\n\t\t\t\tlocalHostName,\n\t\t\t\tResourceID.generate(),\n\t\t\t\tport,\n\t\t\t\tnew Configuration(),\n\t\t\t\thighAvailabilityServices,\n\t\t\t\tTaskManager.class);\n\t\t\tfail(\"This should fail with an IOException\");\n\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t// expected. validate the error message\n\t\t\tList<Throwable> causes = StartupUtils.getExceptionCauses(e, new ArrayList<Throwable>());\n\t\t\tfor (Throwable cause : causes) {\n\t\t\t\tif (cause instanceof BindException) {\n\t\t\t\t\tthrow (BindException) cause;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfail(\"This should fail with an exception caused by BindException\");\n\t\t}\n\t\tfinally {\n\t\t\tif (blocker != null) {\n\t\t\t\ttry {\n\t\t\t\t\tblocker.close();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\t// no need to log here\n\t\t\t\t}\n\t\t\t}\n\n\t\t\thighAvailabilityServices.closeAndCleanupAllData();\n\t\t}\n\t}"
        ],
        [
            "BootstrapTools::startActorSystem(Configuration,String,int,Logger)",
            " 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143 -\n 144  \n 145  \n 146  \n 147  \n 148  \n 149 -\n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160 -\n 161  \n 162 -\n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  ",
            "\t/**\n\t * Starts an Actor System at a specific port.\n\t * @param configuration The Flink configuration.\n\t * @param listeningAddress The address to listen at.\n\t * @param listeningPort The port to listen at.\n\t * @param logger the logger to output log information.\n\t * @return The ActorSystem which has been started.\n\t * @throws Exception\n\t */\n\tpublic static ActorSystem startActorSystem(\n\t\t\t\tConfiguration configuration,\n\t\t\t\tString listeningAddress,\n\t\t\t\tint listeningPort,\n\t\t\t\tLogger logger) throws Exception {\n\n\t\tString hostPortUrl = listeningAddress + ':' + listeningPort;\n\t\tlogger.info(\"Trying to start actor system at {}\", hostPortUrl);\n\n\t\ttry {\n\t\t\tConfig akkaConfig = AkkaUtils.getAkkaConfig(\n\t\t\t\tconfiguration,\n\t\t\t\tnew scala.Some<>(new scala.Tuple2<String, Object>(listeningAddress, listeningPort))\n\t\t\t);\n\n\t\t\tlogger.debug(\"Using akka configuration\\n {}\", akkaConfig);\n\n\t\t\tActorSystem actorSystem = AkkaUtils.createActorSystem(akkaConfig);\n\n\t\t\tlogger.info(\"Actor system started at {}\", AkkaUtils.getAddress(actorSystem));\n\t\t\treturn actorSystem;\n\t\t}\n\t\tcatch (Throwable t) {\n\t\t\tif (t instanceof org.jboss.netty.channel.ChannelException) {\n\t\t\t\tThrowable cause = t.getCause();\n\t\t\t\tif (cause != null && t.getCause() instanceof java.net.BindException) {\n\t\t\t\t\tthrow new IOException(\"Unable to create ActorSystem at address \" + hostPortUrl +\n\t\t\t\t\t\t\t\" : \" + cause.getMessage(), t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow new Exception(\"Could not create actor system\", t);\n\t\t}\n\t}",
            " 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147 +\n 148  \n 149  \n 150  \n 151  \n 152  \n 153 +\n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164 +\n 165  \n 166 +\n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  ",
            "\t/**\n\t * Starts an Actor System at a specific port.\n\t * @param configuration The Flink configuration.\n\t * @param listeningAddress The address to listen at.\n\t * @param listeningPort The port to listen at.\n\t * @param logger the logger to output log information.\n\t * @return The ActorSystem which has been started.\n\t * @throws Exception\n\t */\n\tpublic static ActorSystem startActorSystem(\n\t\t\t\tConfiguration configuration,\n\t\t\t\tString listeningAddress,\n\t\t\t\tint listeningPort,\n\t\t\t\tLogger logger) throws Exception {\n\n\t\tString hostPortUrl = NetUtils.unresolvedHostAndPortToNormalizedString(listeningAddress, listeningPort);\n\t\tlogger.info(\"Trying to start actor system at {}\", hostPortUrl);\n\n\t\ttry {\n\t\t\tConfig akkaConfig = AkkaUtils.getAkkaConfig(\n\t\t\t\tconfiguration,\n\t\t\t\tnew Some<>(new Tuple2<>(listeningAddress, listeningPort))\n\t\t\t);\n\n\t\t\tlogger.debug(\"Using akka configuration\\n {}\", akkaConfig);\n\n\t\t\tActorSystem actorSystem = AkkaUtils.createActorSystem(akkaConfig);\n\n\t\t\tlogger.info(\"Actor system started at {}\", AkkaUtils.getAddress(actorSystem));\n\t\t\treturn actorSystem;\n\t\t}\n\t\tcatch (Throwable t) {\n\t\t\tif (t instanceof ChannelException) {\n\t\t\t\tThrowable cause = t.getCause();\n\t\t\t\tif (cause != null && t.getCause() instanceof BindException) {\n\t\t\t\t\tthrow new IOException(\"Unable to create ActorSystem at address \" + hostPortUrl +\n\t\t\t\t\t\t\t\" : \" + cause.getMessage(), t);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow new Exception(\"Could not create actor system\", t);\n\t\t}\n\t}"
        ],
        [
            "JobClient::startJobClientActorSystem(Configuration,String)",
            "  77  \n  78 -\n  79  \n  80  \n  81 -\n  82 -\n  83  \n  84 -\n  85 -\n  86 -\n  87 -\n  88 -\n  89 -\n  90 -\n  91 -\n  92  \n  93  \n  94  ",
            "\tpublic static ActorSystem startJobClientActorSystem(Configuration config, String hostname)\n\t\t\tthrows IOException {\n\t\tLOG.info(\"Starting JobClient actor system\");\n\n\t\tOption<Tuple2<String, Object>> remoting = new Some<>(new Tuple2<String, Object>(hostname, 0));\n\n\t\t// start a remote actor system to listen on an arbitrary port\n\t\tActorSystem system = AkkaUtils.createActorSystem(config, remoting);\n\t\tAddress address = system.provider().getDefaultAddress();\n\n\t\tString hostAddress = address.host().isDefined() ?\n\t\t\t\tNetUtils.ipAddressToUrlString(InetAddress.getByName(address.host().get())) :\n\t\t\t\t\"(unknown)\";\n\t\tint port = address.port().isDefined() ? ((Integer) address.port().get()) : -1;\n\t\tLOG.info(\"Started JobClient actor system at \" + hostAddress + ':' + port);\n\n\t\treturn system;\n\t}",
            "  74  \n  75 +\n  76  \n  77  \n  78  \n  79 +\n  80  \n  81  \n  82  ",
            "\tpublic static ActorSystem startJobClientActorSystem(Configuration config, String hostname)\n\t\t\tthrows Exception {\n\t\tLOG.info(\"Starting JobClient actor system\");\n\n\t\t// start a remote actor system to listen on an arbitrary port\n\t\tActorSystem system = BootstrapTools.startActorSystem(config, hostname, 0, LOG);\n\n\t\treturn system;\n\t}"
        ],
        [
            "ClusterClient::LazyActorSystemLoader::get()",
            " 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242 -\n 243  \n 244 -\n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  ",
            "\t\t/**\n\t\t * Creates a new ActorSystem or returns an existing one.\n\t\t * @return ActorSystem\n\t\t * @throws Exception if the ActorSystem could not be created\n\t\t */\n\t\tpublic ActorSystem get() throws FlinkException {\n\n\t\t\tif (!isLoaded()) {\n\t\t\t\t// start actor system\n\t\t\t\tlog.info(\"Starting client actor system.\");\n\n\t\t\t\tfinal InetAddress ownHostname;\n\t\t\t\ttry {\n\t\t\t\t\townHostname = LeaderRetrievalUtils.findConnectingAddress(\n\t\t\t\t\t\thighAvailabilityServices.getJobManagerLeaderRetriever(HighAvailabilityServices.DEFAULT_JOB_ID),\n\t\t\t\t\t\ttimeout);\n\t\t\t\t} catch (LeaderRetrievalException lre) {\n\t\t\t\t\tthrow new FlinkException(\"Could not find out our own hostname by connecting to the \" +\n\t\t\t\t\t\t\"leading JobManager. Please make sure that the Flink cluster has been started.\", lre);\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tactorSystem = AkkaUtils.createActorSystem(\n\t\t\t\t\t\tconfiguration,\n\t\t\t\t\t\tOption.apply(new Tuple2<String, Object>(ownHostname.getCanonicalHostName(), 0)));\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tthrow new FlinkException(\"Could not start the ActorSystem lazily.\", e);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn actorSystem;\n\t\t}",
            " 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242 +\n 243  \n 244 +\n 245 +\n 246 +\n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  ",
            "\t\t/**\n\t\t * Creates a new ActorSystem or returns an existing one.\n\t\t * @return ActorSystem\n\t\t * @throws Exception if the ActorSystem could not be created\n\t\t */\n\t\tpublic ActorSystem get() throws FlinkException {\n\n\t\t\tif (!isLoaded()) {\n\t\t\t\t// start actor system\n\t\t\t\tlog.info(\"Starting client actor system.\");\n\n\t\t\t\tfinal InetAddress ownHostname;\n\t\t\t\ttry {\n\t\t\t\t\townHostname = LeaderRetrievalUtils.findConnectingAddress(\n\t\t\t\t\t\thighAvailabilityServices.getJobManagerLeaderRetriever(HighAvailabilityServices.DEFAULT_JOB_ID),\n\t\t\t\t\t\ttimeout);\n\t\t\t\t} catch (LeaderRetrievalException lre) {\n\t\t\t\t\tthrow new FlinkException(\"Could not find out our own hostname by connecting to the \" +\n\t\t\t\t\t\t\"leading JobManager. Please make sure that the Flink cluster has been started.\", lre);\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tactorSystem = BootstrapTools.startActorSystem(\n\t\t\t\t\t\tconfiguration,\n\t\t\t\t\t\townHostname.getCanonicalHostName(),\n\t\t\t\t\t\t0,\n\t\t\t\t\t\tlog);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tthrow new FlinkException(\"Could not start the ActorSystem lazily.\", e);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn actorSystem;\n\t\t}"
        ]
    ],
    "c131546eaadd07baf950bd6a44d07ee42d109e4c": [
        [
            "FencedAkkaInvocationHandler::FencedAkkaInvocationHandler(String,String,ActorRef,Time,long,CompletableFuture,Supplier)",
            "  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63 -\n  64  \n  65  \n  66  \n  67  \n  68  ",
            "\tpublic FencedAkkaInvocationHandler(\n\t\t\tString address,\n\t\t\tString hostname,\n\t\t\tActorRef rpcEndpoint,\n\t\t\tTime timeout,\n\t\t\tlong maximumFramesize,\n\t\t\t@Nullable CompletableFuture<Boolean> terminationFuture,\n\t\t\tSupplier<F> fencingTokenSupplier) {\n\t\tsuper(address, hostname, rpcEndpoint, timeout, maximumFramesize, terminationFuture);\n\n\t\tthis.fencingTokenSupplier = Preconditions.checkNotNull(fencingTokenSupplier);\n\t}",
            "  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63 +\n  64  \n  65  \n  66  \n  67  \n  68  ",
            "\tpublic FencedAkkaInvocationHandler(\n\t\t\tString address,\n\t\t\tString hostname,\n\t\t\tActorRef rpcEndpoint,\n\t\t\tTime timeout,\n\t\t\tlong maximumFramesize,\n\t\t\t@Nullable CompletableFuture<Void> terminationFuture,\n\t\t\tSupplier<F> fencingTokenSupplier) {\n\t\tsuper(address, hostname, rpcEndpoint, timeout, maximumFramesize, terminationFuture);\n\n\t\tthis.fencingTokenSupplier = Preconditions.checkNotNull(fencingTokenSupplier);\n\t}"
        ],
        [
            "AkkaRpcActorTest::testPostStopExecutedByMainThread()",
            " 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268 -\n 269  \n 270  \n 271  \n 272  \n 273  ",
            "\t/**\n\t * Checks that the postStop callback is executed within the main thread.\n\t */\n\t@Test\n\tpublic void testPostStopExecutedByMainThread() throws Exception {\n\t\tSimpleRpcEndpoint simpleRpcEndpoint = new SimpleRpcEndpoint(akkaRpcService, \"SimpleRpcEndpoint\");\n\t\tsimpleRpcEndpoint.start();\n\n\t\tsimpleRpcEndpoint.shutDown();\n\n\t\tCompletableFuture<Boolean> terminationFuture = simpleRpcEndpoint.getTerminationFuture();\n\n\t\t// check that we executed the postStop method in the main thread, otherwise an exception\n\t\t// would be thrown here.\n\t\tterminationFuture.get();\n\t}",
            " 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268 +\n 269  \n 270  \n 271  \n 272  \n 273  ",
            "\t/**\n\t * Checks that the postStop callback is executed within the main thread.\n\t */\n\t@Test\n\tpublic void testPostStopExecutedByMainThread() throws Exception {\n\t\tSimpleRpcEndpoint simpleRpcEndpoint = new SimpleRpcEndpoint(akkaRpcService, \"SimpleRpcEndpoint\");\n\t\tsimpleRpcEndpoint.start();\n\n\t\tsimpleRpcEndpoint.shutDown();\n\n\t\tCompletableFuture<Void> terminationFuture = simpleRpcEndpoint.getTerminationFuture();\n\n\t\t// check that we executed the postStop method in the main thread, otherwise an exception\n\t\t// would be thrown here.\n\t\tterminationFuture.get();\n\t}"
        ],
        [
            "AkkaRpcActorTest::testPostStopExceptionPropagation()",
            " 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249 -\n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  ",
            "\t/**\n\t * Tests that exception thrown in the postStop method are returned by the termination\n\t * future.\n\t */\n\t@Test\n\tpublic void testPostStopExceptionPropagation() throws Exception {\n\t\tFailingPostStopEndpoint rpcEndpoint = new FailingPostStopEndpoint(akkaRpcService, \"FailingPostStopEndpoint\");\n\t\trpcEndpoint.start();\n\n\t\trpcEndpoint.shutDown();\n\n\t\tCompletableFuture<Boolean> terminationFuture = rpcEndpoint.getTerminationFuture();\n\n\t\ttry {\n\t\t\tterminationFuture.get();\n\t\t} catch (ExecutionException e) {\n\t\t\tassertTrue(e.getCause() instanceof FailingPostStopEndpoint.PostStopException);\n\t\t}\n\t}",
            " 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249 +\n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  ",
            "\t/**\n\t * Tests that exception thrown in the postStop method are returned by the termination\n\t * future.\n\t */\n\t@Test\n\tpublic void testPostStopExceptionPropagation() throws Exception {\n\t\tFailingPostStopEndpoint rpcEndpoint = new FailingPostStopEndpoint(akkaRpcService, \"FailingPostStopEndpoint\");\n\t\trpcEndpoint.start();\n\n\t\trpcEndpoint.shutDown();\n\n\t\tCompletableFuture<Void> terminationFuture = rpcEndpoint.getTerminationFuture();\n\n\t\ttry {\n\t\t\tterminationFuture.get();\n\t\t} catch (ExecutionException e) {\n\t\t\tassertTrue(e.getCause() instanceof FailingPostStopEndpoint.PostStopException);\n\t\t}\n\t}"
        ],
        [
            "AkkaRpcActorTest::testRpcEndpointTerminationFuture()",
            " 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188 -\n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  ",
            "\t/**\n\t * Tests that we can wait for a RpcEndpoint to terminate.\n\t *\n\t * @throws ExecutionException\n\t * @throws InterruptedException\n\t */\n\t@Test(timeout=5000)\n\tpublic void testRpcEndpointTerminationFuture() throws Exception {\n\t\tfinal DummyRpcEndpoint rpcEndpoint = new DummyRpcEndpoint(akkaRpcService);\n\t\trpcEndpoint.start();\n\n\t\tCompletableFuture<Boolean> terminationFuture = rpcEndpoint.getTerminationFuture();\n\n\t\tassertFalse(terminationFuture.isDone());\n\n\t\tCompletableFuture.runAsync(\n\t\t\t() -> rpcEndpoint.shutDown(),\n\t\t\tactorSystem.dispatcher());\n\n\t\t// wait until the rpc endpoint has terminated\n\t\tterminationFuture.get();\n\t}",
            " 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188 +\n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  ",
            "\t/**\n\t * Tests that we can wait for a RpcEndpoint to terminate.\n\t *\n\t * @throws ExecutionException\n\t * @throws InterruptedException\n\t */\n\t@Test(timeout=5000)\n\tpublic void testRpcEndpointTerminationFuture() throws Exception {\n\t\tfinal DummyRpcEndpoint rpcEndpoint = new DummyRpcEndpoint(akkaRpcService);\n\t\trpcEndpoint.start();\n\n\t\tCompletableFuture<Void> terminationFuture = rpcEndpoint.getTerminationFuture();\n\n\t\tassertFalse(terminationFuture.isDone());\n\n\t\tCompletableFuture.runAsync(\n\t\t\t() -> rpcEndpoint.shutDown(),\n\t\t\tactorSystem.dispatcher());\n\n\t\t// wait until the rpc endpoint has terminated\n\t\tterminationFuture.get();\n\t}"
        ],
        [
            "JobManagerRunner::shutdownInternally()",
            " 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228 -\n 229  \n 230  \n 231 -\n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  ",
            "\tprivate CompletableFuture<Void> shutdownInternally() {\n\t\tsynchronized (lock) {\n\t\t\tif (!shutdown) {\n\t\t\t\tshutdown = true;\n\n\t\t\t\tjobManager.shutDown();\n\n\t\t\t\tfinal CompletableFuture<Boolean> jobManagerTerminationFuture = jobManager.getTerminationFuture();\n\n\t\t\t\tjobManagerTerminationFuture.whenComplete(\n\t\t\t\t\t(Boolean ignored, Throwable throwable) -> {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tleaderElectionService.stop();\n\t\t\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\t\t\tthrowable = ExceptionUtils.firstOrSuppressed(t, ExceptionUtils.stripCompletionException(throwable));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// make all registered metrics go away\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tjobManagerMetricGroup.close();\n\t\t\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\t\t\tthrowable = ExceptionUtils.firstOrSuppressed(t, throwable);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (throwable != null) {\n\t\t\t\t\t\t\tterminationFuture.completeExceptionally(\n\t\t\t\t\t\t\t\tnew FlinkException(\"Could not properly shut down the JobManagerRunner\", throwable));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tterminationFuture.complete(null);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\n\t\t\t\tterminationFuture.whenComplete(\n\t\t\t\t\t(Void ignored, Throwable throwable) -> {\n\t\t\t\t\t\tresultFuture.completeExceptionally(new JobNotFinishedException(jobGraph.getJobID()));\n\t\t\t\t\t});\n\t\t\t}\n\n\t\t\treturn terminationFuture;\n\t\t}\n\t}",
            " 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228 +\n 229  \n 230  \n 231 +\n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  ",
            "\tprivate CompletableFuture<Void> shutdownInternally() {\n\t\tsynchronized (lock) {\n\t\t\tif (!shutdown) {\n\t\t\t\tshutdown = true;\n\n\t\t\t\tjobManager.shutDown();\n\n\t\t\t\tfinal CompletableFuture<Void> jobManagerTerminationFuture = jobManager.getTerminationFuture();\n\n\t\t\t\tjobManagerTerminationFuture.whenComplete(\n\t\t\t\t\t(Void ignored, Throwable throwable) -> {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tleaderElectionService.stop();\n\t\t\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\t\t\tthrowable = ExceptionUtils.firstOrSuppressed(t, ExceptionUtils.stripCompletionException(throwable));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// make all registered metrics go away\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tjobManagerMetricGroup.close();\n\t\t\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\t\t\tthrowable = ExceptionUtils.firstOrSuppressed(t, throwable);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (throwable != null) {\n\t\t\t\t\t\t\tterminationFuture.completeExceptionally(\n\t\t\t\t\t\t\t\tnew FlinkException(\"Could not properly shut down the JobManagerRunner\", throwable));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tterminationFuture.complete(null);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\n\t\t\t\tterminationFuture.whenComplete(\n\t\t\t\t\t(Void ignored, Throwable throwable) -> {\n\t\t\t\t\t\tresultFuture.completeExceptionally(new JobNotFinishedException(jobGraph.getJobID()));\n\t\t\t\t\t});\n\t\t\t}\n\n\t\t\treturn terminationFuture;\n\t\t}\n\t}"
        ],
        [
            "AkkaRpcActorTest::testActorTerminationWhenServiceShutdown()",
            " 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288 -\n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  ",
            "\t/**\n\t * Tests that actors are properly terminated when the AkkaRpcService is shut down.\n\t */\n\t@Test\n\tpublic void testActorTerminationWhenServiceShutdown() throws Exception {\n\t\tfinal ActorSystem rpcActorSystem = AkkaUtils.createDefaultActorSystem();\n\t\tfinal RpcService rpcService = new AkkaRpcService(rpcActorSystem, timeout);\n\n\t\ttry {\n\t\t\tSimpleRpcEndpoint rpcEndpoint = new SimpleRpcEndpoint(rpcService, SimpleRpcEndpoint.class.getSimpleName());\n\n\t\t\trpcEndpoint.start();\n\n\t\t\tCompletableFuture<Boolean> terminationFuture = rpcEndpoint.getTerminationFuture();\n\n\t\t\trpcService.stopService();\n\n\t\t\tterminationFuture.get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\t\t} finally {\n\t\t\trpcActorSystem.shutdown();\n\t\t\trpcActorSystem.awaitTermination(FutureUtils.toFiniteDuration(timeout));\n\t\t}\n\t}",
            " 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288 +\n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  ",
            "\t/**\n\t * Tests that actors are properly terminated when the AkkaRpcService is shut down.\n\t */\n\t@Test\n\tpublic void testActorTerminationWhenServiceShutdown() throws Exception {\n\t\tfinal ActorSystem rpcActorSystem = AkkaUtils.createDefaultActorSystem();\n\t\tfinal RpcService rpcService = new AkkaRpcService(rpcActorSystem, timeout);\n\n\t\ttry {\n\t\t\tSimpleRpcEndpoint rpcEndpoint = new SimpleRpcEndpoint(rpcService, SimpleRpcEndpoint.class.getSimpleName());\n\n\t\t\trpcEndpoint.start();\n\n\t\t\tCompletableFuture<Void> terminationFuture = rpcEndpoint.getTerminationFuture();\n\n\t\t\trpcService.stopService();\n\n\t\t\tterminationFuture.get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\t\t} finally {\n\t\t\trpcActorSystem.shutdown();\n\t\t\trpcActorSystem.awaitTermination(FutureUtils.toFiniteDuration(timeout));\n\t\t}\n\t}"
        ],
        [
            "RpcEndpoint::getTerminationFuture()",
            " 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231 -\n 232  \n 233  ",
            "\t/**\n\t * Return a future which is completed with true when the rpc endpoint has been terminated.\n\t * In case of a failure, this future is completed with the occurring exception.\n\t *\n\t * @return Future which is completed when the rpc endpoint has been terminated.\n\t */\n\tpublic CompletableFuture<Boolean> getTerminationFuture() {\n\t\treturn rpcServer.getTerminationFuture();\n\t}",
            " 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231 +\n 232  \n 233  ",
            "\t/**\n\t * Return a future which is completed with true when the rpc endpoint has been terminated.\n\t * In case of a failure, this future is completed with the occurring exception.\n\t *\n\t * @return Future which is completed when the rpc endpoint has been terminated.\n\t */\n\tpublic CompletableFuture<Void> getTerminationFuture() {\n\t\treturn rpcServer.getTerminationFuture();\n\t}"
        ],
        [
            "ClusterEntrypoint::runCluster(Configuration)",
            " 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216 -\n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  ",
            "\tprotected void runCluster(Configuration configuration) throws Exception {\n\t\tsynchronized (lock) {\n\t\t\tinitializeServices(configuration);\n\n\t\t\t// write host information into configuration\n\t\t\tconfiguration.setString(JobManagerOptions.ADDRESS, commonRpcService.getAddress());\n\t\t\tconfiguration.setInteger(JobManagerOptions.PORT, commonRpcService.getPort());\n\n\t\t\tstartClusterComponents(\n\t\t\t\tconfiguration,\n\t\t\t\tcommonRpcService,\n\t\t\t\thaServices,\n\t\t\t\tblobServer,\n\t\t\t\theartbeatServices,\n\t\t\t\tmetricRegistry);\n\n\t\t\t// TODO: Make shutDownAndTerminate non blocking to not use the global executor\n\t\t\tdispatcher.getTerminationFuture().whenCompleteAsync(\n\t\t\t\t(Boolean success, Throwable throwable) -> {\n\t\t\t\t\tif (throwable != null) {\n\t\t\t\t\t\tLOG.info(\"Could not properly terminate the Dispatcher.\", throwable);\n\t\t\t\t\t}\n\n\t\t\t\t\tshutDownAndTerminate(\n\t\t\t\t\t\tSUCCESS_RETURN_CODE,\n\t\t\t\t\t\tApplicationStatus.SUCCEEDED,\n\t\t\t\t\t\ttrue);\n\t\t\t\t});\n\t\t}\n\t}",
            " 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216 +\n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  ",
            "\tprotected void runCluster(Configuration configuration) throws Exception {\n\t\tsynchronized (lock) {\n\t\t\tinitializeServices(configuration);\n\n\t\t\t// write host information into configuration\n\t\t\tconfiguration.setString(JobManagerOptions.ADDRESS, commonRpcService.getAddress());\n\t\t\tconfiguration.setInteger(JobManagerOptions.PORT, commonRpcService.getPort());\n\n\t\t\tstartClusterComponents(\n\t\t\t\tconfiguration,\n\t\t\t\tcommonRpcService,\n\t\t\t\thaServices,\n\t\t\t\tblobServer,\n\t\t\t\theartbeatServices,\n\t\t\t\tmetricRegistry);\n\n\t\t\t// TODO: Make shutDownAndTerminate non blocking to not use the global executor\n\t\t\tdispatcher.getTerminationFuture().whenCompleteAsync(\n\t\t\t\t(Void value, Throwable throwable) -> {\n\t\t\t\t\tif (throwable != null) {\n\t\t\t\t\t\tLOG.info(\"Could not properly terminate the Dispatcher.\", throwable);\n\t\t\t\t\t}\n\n\t\t\t\t\tshutDownAndTerminate(\n\t\t\t\t\t\tSUCCESS_RETURN_CODE,\n\t\t\t\t\t\tApplicationStatus.SUCCEEDED,\n\t\t\t\t\t\ttrue);\n\t\t\t\t});\n\t\t}\n\t}"
        ],
        [
            "JobMaster::postStop()",
            " 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410 -\n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  ",
            "\t/**\n\t * Suspend the job and shutdown all other services including rpc.\n\t */\n\t@Override\n\tpublic void postStop() throws Exception {\n\t\tlog.info(\"Stopping the JobMaster for job \" + jobGraph.getName() + '(' + jobGraph.getJobID() + \").\");\n\n\t\t// disconnect from all registered TaskExecutors\n\t\tfinal Set<ResourceID> taskManagerResourceIds = new HashSet<>(registeredTaskManagers.keySet());\n\t\tfinal FlinkException cause = new FlinkException(\"Stopping JobMaster for job \" + jobGraph.getName() +\n\t\t\t'(' + jobGraph.getJobID() + \").\");\n\n\t\tfor (ResourceID taskManagerResourceId : taskManagerResourceIds) {\n\t\t\tdisconnectTaskManager(taskManagerResourceId, cause);\n\t\t}\n\n\t\ttaskManagerHeartbeatManager.stop();\n\t\tresourceManagerHeartbeatManager.stop();\n\n\t\t// make sure there is a graceful exit\n\t\tsuspendExecution(new FlinkException(\"JobManager is shutting down.\"));\n\n\t\t// shut down will internally release all registered slots\n\t\tslotPool.shutDown();\n\t\tCompletableFuture<Boolean> terminationFuture = slotPool.getTerminationFuture();\n\n\t\tException exception = null;\n\n\t\t// wait for the slot pool shut down\n\t\ttry {\n\t\t\tterminationFuture.get(rpcTimeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\t\t} catch (Exception e) {\n\t\t\texception = e;\n\t\t}\n\n\t\ttry {\n\t\t\tsuper.postStop();\n\t\t} catch (Exception e) {\n\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n\t\t}\n\n\t\tif (exception != null) {\n\t\t\tthrow exception;\n\t\t}\n\n\t\tlog.info(\"Stopped the JobMaster for job \" + jobGraph.getName() + '(' + jobGraph.getJobID() + \").\");\n\t}",
            " 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410 +\n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  ",
            "\t/**\n\t * Suspend the job and shutdown all other services including rpc.\n\t */\n\t@Override\n\tpublic void postStop() throws Exception {\n\t\tlog.info(\"Stopping the JobMaster for job \" + jobGraph.getName() + '(' + jobGraph.getJobID() + \").\");\n\n\t\t// disconnect from all registered TaskExecutors\n\t\tfinal Set<ResourceID> taskManagerResourceIds = new HashSet<>(registeredTaskManagers.keySet());\n\t\tfinal FlinkException cause = new FlinkException(\"Stopping JobMaster for job \" + jobGraph.getName() +\n\t\t\t'(' + jobGraph.getJobID() + \").\");\n\n\t\tfor (ResourceID taskManagerResourceId : taskManagerResourceIds) {\n\t\t\tdisconnectTaskManager(taskManagerResourceId, cause);\n\t\t}\n\n\t\ttaskManagerHeartbeatManager.stop();\n\t\tresourceManagerHeartbeatManager.stop();\n\n\t\t// make sure there is a graceful exit\n\t\tsuspendExecution(new FlinkException(\"JobManager is shutting down.\"));\n\n\t\t// shut down will internally release all registered slots\n\t\tslotPool.shutDown();\n\t\tCompletableFuture<Void> terminationFuture = slotPool.getTerminationFuture();\n\n\t\tException exception = null;\n\n\t\t// wait for the slot pool shut down\n\t\ttry {\n\t\t\tterminationFuture.get(rpcTimeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\t\t} catch (Exception e) {\n\t\t\texception = e;\n\t\t}\n\n\t\ttry {\n\t\t\tsuper.postStop();\n\t\t} catch (Exception e) {\n\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n\t\t}\n\n\t\tif (exception != null) {\n\t\t\tthrow exception;\n\t\t}\n\n\t\tlog.info(\"Stopped the JobMaster for job \" + jobGraph.getName() + '(' + jobGraph.getJobID() + \").\");\n\t}"
        ],
        [
            "AkkaRpcService::startServer(C)",
            " 194  \n 195  \n 196  \n 197  \n 198 -\n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  ",
            "\t@Override\n\tpublic <C extends RpcEndpoint & RpcGateway> RpcServer startServer(C rpcEndpoint) {\n\t\tcheckNotNull(rpcEndpoint, \"rpc endpoint\");\n\n\t\tCompletableFuture<Boolean> terminationFuture = new CompletableFuture<>();\n\t\tfinal Props akkaRpcActorProps;\n\n\t\tif (rpcEndpoint instanceof FencedRpcEndpoint) {\n\t\t\takkaRpcActorProps = Props.create(FencedAkkaRpcActor.class, rpcEndpoint, terminationFuture);\n\t\t} else {\n\t\t\takkaRpcActorProps = Props.create(AkkaRpcActor.class, rpcEndpoint, terminationFuture);\n\t\t}\n\n\t\tActorRef actorRef;\n\n\t\tsynchronized (lock) {\n\t\t\tcheckState(!stopped, \"RpcService is stopped\");\n\t\t\tactorRef = actorSystem.actorOf(akkaRpcActorProps, rpcEndpoint.getEndpointId());\n\t\t\tactors.put(actorRef, rpcEndpoint);\n\t\t}\n\n\t\tLOG.info(\"Starting RPC endpoint for {} at {} .\", rpcEndpoint.getClass().getName(), actorRef.path());\n\n\t\tfinal String akkaAddress = AkkaUtils.getAkkaURL(actorSystem, actorRef);\n\t\tfinal String hostname;\n\t\tOption<String> host = actorRef.path().address().host();\n\t\tif (host.isEmpty()) {\n\t\t\thostname = \"localhost\";\n\t\t} else {\n\t\t\thostname = host.get();\n\t\t}\n\n\t\tSet<Class<?>> implementedRpcGateways = new HashSet<>(RpcUtils.extractImplementedRpcGateways(rpcEndpoint.getClass()));\n\n\t\timplementedRpcGateways.add(RpcServer.class);\n\t\timplementedRpcGateways.add(AkkaBasedEndpoint.class);\n\n\t\tfinal InvocationHandler akkaInvocationHandler;\n\n\t\tif (rpcEndpoint instanceof FencedRpcEndpoint) {\n\t\t\t// a FencedRpcEndpoint needs a FencedAkkaInvocationHandler\n\t\t\takkaInvocationHandler = new FencedAkkaInvocationHandler<>(\n\t\t\t\takkaAddress,\n\t\t\t\thostname,\n\t\t\t\tactorRef,\n\t\t\t\ttimeout,\n\t\t\t\tmaximumFramesize,\n\t\t\t\tterminationFuture,\n\t\t\t\t((FencedRpcEndpoint<?>) rpcEndpoint)::getFencingToken);\n\n\t\t\timplementedRpcGateways.add(FencedMainThreadExecutable.class);\n\t\t} else {\n\t\t\takkaInvocationHandler = new AkkaInvocationHandler(\n\t\t\t\takkaAddress,\n\t\t\t\thostname,\n\t\t\t\tactorRef,\n\t\t\t\ttimeout,\n\t\t\t\tmaximumFramesize,\n\t\t\t\tterminationFuture);\n\t\t}\n\n\t\t// Rather than using the System ClassLoader directly, we derive the ClassLoader\n\t\t// from this class . That works better in cases where Flink runs embedded and all Flink\n\t\t// code is loaded dynamically (for example from an OSGI bundle) through a custom ClassLoader\n\t\tClassLoader classLoader = getClass().getClassLoader();\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tRpcServer server = (RpcServer) Proxy.newProxyInstance(\n\t\t\tclassLoader,\n\t\t\timplementedRpcGateways.toArray(new Class<?>[implementedRpcGateways.size()]),\n\t\t\takkaInvocationHandler);\n\n\t\treturn server;\n\t}",
            " 194  \n 195  \n 196  \n 197  \n 198 +\n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  ",
            "\t@Override\n\tpublic <C extends RpcEndpoint & RpcGateway> RpcServer startServer(C rpcEndpoint) {\n\t\tcheckNotNull(rpcEndpoint, \"rpc endpoint\");\n\n\t\tCompletableFuture<Void> terminationFuture = new CompletableFuture<>();\n\t\tfinal Props akkaRpcActorProps;\n\n\t\tif (rpcEndpoint instanceof FencedRpcEndpoint) {\n\t\t\takkaRpcActorProps = Props.create(FencedAkkaRpcActor.class, rpcEndpoint, terminationFuture);\n\t\t} else {\n\t\t\takkaRpcActorProps = Props.create(AkkaRpcActor.class, rpcEndpoint, terminationFuture);\n\t\t}\n\n\t\tActorRef actorRef;\n\n\t\tsynchronized (lock) {\n\t\t\tcheckState(!stopped, \"RpcService is stopped\");\n\t\t\tactorRef = actorSystem.actorOf(akkaRpcActorProps, rpcEndpoint.getEndpointId());\n\t\t\tactors.put(actorRef, rpcEndpoint);\n\t\t}\n\n\t\tLOG.info(\"Starting RPC endpoint for {} at {} .\", rpcEndpoint.getClass().getName(), actorRef.path());\n\n\t\tfinal String akkaAddress = AkkaUtils.getAkkaURL(actorSystem, actorRef);\n\t\tfinal String hostname;\n\t\tOption<String> host = actorRef.path().address().host();\n\t\tif (host.isEmpty()) {\n\t\t\thostname = \"localhost\";\n\t\t} else {\n\t\t\thostname = host.get();\n\t\t}\n\n\t\tSet<Class<?>> implementedRpcGateways = new HashSet<>(RpcUtils.extractImplementedRpcGateways(rpcEndpoint.getClass()));\n\n\t\timplementedRpcGateways.add(RpcServer.class);\n\t\timplementedRpcGateways.add(AkkaBasedEndpoint.class);\n\n\t\tfinal InvocationHandler akkaInvocationHandler;\n\n\t\tif (rpcEndpoint instanceof FencedRpcEndpoint) {\n\t\t\t// a FencedRpcEndpoint needs a FencedAkkaInvocationHandler\n\t\t\takkaInvocationHandler = new FencedAkkaInvocationHandler<>(\n\t\t\t\takkaAddress,\n\t\t\t\thostname,\n\t\t\t\tactorRef,\n\t\t\t\ttimeout,\n\t\t\t\tmaximumFramesize,\n\t\t\t\tterminationFuture,\n\t\t\t\t((FencedRpcEndpoint<?>) rpcEndpoint)::getFencingToken);\n\n\t\t\timplementedRpcGateways.add(FencedMainThreadExecutable.class);\n\t\t} else {\n\t\t\takkaInvocationHandler = new AkkaInvocationHandler(\n\t\t\t\takkaAddress,\n\t\t\t\thostname,\n\t\t\t\tactorRef,\n\t\t\t\ttimeout,\n\t\t\t\tmaximumFramesize,\n\t\t\t\tterminationFuture);\n\t\t}\n\n\t\t// Rather than using the System ClassLoader directly, we derive the ClassLoader\n\t\t// from this class . That works better in cases where Flink runs embedded and all Flink\n\t\t// code is loaded dynamically (for example from an OSGI bundle) through a custom ClassLoader\n\t\tClassLoader classLoader = getClass().getClassLoader();\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tRpcServer server = (RpcServer) Proxy.newProxyInstance(\n\t\t\tclassLoader,\n\t\t\timplementedRpcGateways.toArray(new Class<?>[implementedRpcGateways.size()]),\n\t\t\takkaInvocationHandler);\n\n\t\treturn server;\n\t}"
        ],
        [
            "AkkaInvocationHandler::getTerminationFuture()",
            " 343  \n 344 -\n 345  \n 346  ",
            "\t@Override\n\tpublic CompletableFuture<Boolean> getTerminationFuture() {\n\t\treturn terminationFuture;\n\t}",
            " 343  \n 344 +\n 345  \n 346  ",
            "\t@Override\n\tpublic CompletableFuture<Void> getTerminationFuture() {\n\t\treturn terminationFuture;\n\t}"
        ],
        [
            "TaskManagerRunner::getTerminationFuture()",
            " 201 -\n 202  \n 203  ",
            "\tpublic CompletableFuture<Boolean> getTerminationFuture() {\n\t\treturn taskManager.getTerminationFuture();\n\t}",
            " 201 +\n 202  \n 203  ",
            "\tpublic CompletableFuture<Void> getTerminationFuture() {\n\t\treturn taskManager.getTerminationFuture();\n\t}"
        ],
        [
            "MiniDispatcherTest::testJobResultRetrieval()",
            " 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225 -\n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  ",
            "\t/**\n\t * Tests that the {@link MiniDispatcher} only terminates in {@link ClusterEntrypoint.ExecutionMode#NORMAL}\n\t * after it has served the {@link org.apache.flink.runtime.jobmaster.JobResult} once.\n\t */\n\t@Test\n\tpublic void testJobResultRetrieval() throws Exception {\n\t\tfinal MiniDispatcher miniDispatcher = createMiniDispatcher(ClusterEntrypoint.ExecutionMode.NORMAL);\n\n\t\tminiDispatcher.start();\n\n\t\ttry {\n\t\t\t// wait until the Dispatcher is the leader\n\t\t\tdispatcherLeaderElectionService.isLeader(UUID.randomUUID()).get();\n\n\t\t\t// wait until we have submitted the job\n\t\t\tjobGraphFuture.get();\n\n\t\t\tresultFuture.complete(archivedExecutionGraph);\n\n\t\t\tfinal CompletableFuture<Boolean> terminationFuture = miniDispatcher.getTerminationFuture();\n\n\t\t\tassertThat(terminationFuture.isDone(), is(false));\n\n\t\t\tfinal DispatcherGateway dispatcherGateway = miniDispatcher.getSelfGateway(DispatcherGateway.class);\n\n\t\t\tfinal CompletableFuture<JobResult> jobResultFuture = dispatcherGateway.requestJobResult(jobGraph.getJobID(), timeout);\n\n\t\t\tfinal JobResult jobResult = jobResultFuture.get();\n\n\t\t\tassertThat(jobResult.getJobId(), is(jobGraph.getJobID()));\n\n\t\t\tterminationFuture.get();\n\t\t} finally {\n\t\t\tRpcUtils.terminateRpcEndpoint(miniDispatcher, timeout);\n\t\t}\n\t}",
            " 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225 +\n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  ",
            "\t/**\n\t * Tests that the {@link MiniDispatcher} only terminates in {@link ClusterEntrypoint.ExecutionMode#NORMAL}\n\t * after it has served the {@link org.apache.flink.runtime.jobmaster.JobResult} once.\n\t */\n\t@Test\n\tpublic void testJobResultRetrieval() throws Exception {\n\t\tfinal MiniDispatcher miniDispatcher = createMiniDispatcher(ClusterEntrypoint.ExecutionMode.NORMAL);\n\n\t\tminiDispatcher.start();\n\n\t\ttry {\n\t\t\t// wait until the Dispatcher is the leader\n\t\t\tdispatcherLeaderElectionService.isLeader(UUID.randomUUID()).get();\n\n\t\t\t// wait until we have submitted the job\n\t\t\tjobGraphFuture.get();\n\n\t\t\tresultFuture.complete(archivedExecutionGraph);\n\n\t\t\tfinal CompletableFuture<Void> terminationFuture = miniDispatcher.getTerminationFuture();\n\n\t\t\tassertThat(terminationFuture.isDone(), is(false));\n\n\t\t\tfinal DispatcherGateway dispatcherGateway = miniDispatcher.getSelfGateway(DispatcherGateway.class);\n\n\t\t\tfinal CompletableFuture<JobResult> jobResultFuture = dispatcherGateway.requestJobResult(jobGraph.getJobID(), timeout);\n\n\t\t\tfinal JobResult jobResult = jobResultFuture.get();\n\n\t\t\tassertThat(jobResult.getJobId(), is(jobGraph.getJobID()));\n\n\t\t\tterminationFuture.get();\n\t\t} finally {\n\t\t\tRpcUtils.terminateRpcEndpoint(miniDispatcher, timeout);\n\t\t}\n\t}"
        ],
        [
            "AkkaInvocationHandler::AkkaInvocationHandler(String,String,ActorRef,Time,long,CompletableFuture)",
            "  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95 -\n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  ",
            "\tAkkaInvocationHandler(\n\t\t\tString address,\n\t\t\tString hostname,\n\t\t\tActorRef rpcEndpoint,\n\t\t\tTime timeout,\n\t\t\tlong maximumFramesize,\n\t\t\t@Nullable CompletableFuture<Boolean> terminationFuture) {\n\n\t\tthis.address = Preconditions.checkNotNull(address);\n\t\tthis.hostname = Preconditions.checkNotNull(hostname);\n\t\tthis.rpcEndpoint = Preconditions.checkNotNull(rpcEndpoint);\n\t\tthis.isLocal = this.rpcEndpoint.path().address().hasLocalScope();\n\t\tthis.timeout = Preconditions.checkNotNull(timeout);\n\t\tthis.maximumFramesize = maximumFramesize;\n\t\tthis.terminationFuture = terminationFuture;\n\t}",
            "  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95 +\n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  ",
            "\tAkkaInvocationHandler(\n\t\t\tString address,\n\t\t\tString hostname,\n\t\t\tActorRef rpcEndpoint,\n\t\t\tTime timeout,\n\t\t\tlong maximumFramesize,\n\t\t\t@Nullable CompletableFuture<Void> terminationFuture) {\n\n\t\tthis.address = Preconditions.checkNotNull(address);\n\t\tthis.hostname = Preconditions.checkNotNull(hostname);\n\t\tthis.rpcEndpoint = Preconditions.checkNotNull(rpcEndpoint);\n\t\tthis.isLocal = this.rpcEndpoint.path().address().hasLocalScope();\n\t\tthis.timeout = Preconditions.checkNotNull(timeout);\n\t\tthis.maximumFramesize = maximumFramesize;\n\t\tthis.terminationFuture = terminationFuture;\n\t}"
        ]
    ],
    "107c8e04be86e9fd893a5c9e0f9c528d1453c3de": [
        [
            "SlotSharingManager::MultiTaskSlot::MultiTaskSlot(SlotRequestId,AbstractID,MultiTaskSlot,CompletableFuture,SlotRequestId)",
            " 418  \n 419  \n 420  \n 421 -\n 422  \n 423 -\n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  ",
            "\t\tprivate MultiTaskSlot(\n\t\t\t\tSlotRequestId slotRequestId,\n\t\t\t\t@Nullable AbstractID groupId,\n\t\t\t\tMultiTaskSlot parent,\n\t\t\t\tCompletableFuture<? extends SlotContext> slotContextFuture,\n\t\t\t\tSlotRequestId allocatedSlotRequestId) {\n\t\t\tsuper(slotRequestId, groupId);\n\n\t\t\tthis.parent = parent;\n\t\t\tthis.slotContextFuture = Preconditions.checkNotNull(slotContextFuture);\n\t\t\tthis.allocatedSlotRequestId = allocatedSlotRequestId;\n\n\t\t\tthis.children = new HashMap<>(16);\n\t\t\tthis.releasingChildren = false;\n\n\t\t\tslotContextFuture.whenComplete(\n\t\t\t\t(SlotContext ignored, Throwable throwable) -> {\n\t\t\t\t\tif (throwable != null) {\n\t\t\t\t\t\trelease(throwable);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t}",
            " 418  \n 419  \n 420  \n 421 +\n 422  \n 423 +\n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  ",
            "\t\tprivate MultiTaskSlot(\n\t\t\t\tSlotRequestId slotRequestId,\n\t\t\t\t@Nullable AbstractID groupId,\n\t\t\t\t@Nullable MultiTaskSlot parent,\n\t\t\t\tCompletableFuture<? extends SlotContext> slotContextFuture,\n\t\t\t\t@Nullable SlotRequestId allocatedSlotRequestId) {\n\t\t\tsuper(slotRequestId, groupId);\n\n\t\t\tthis.parent = parent;\n\t\t\tthis.slotContextFuture = Preconditions.checkNotNull(slotContextFuture);\n\t\t\tthis.allocatedSlotRequestId = allocatedSlotRequestId;\n\n\t\t\tthis.children = new HashMap<>(16);\n\t\t\tthis.releasingChildren = false;\n\n\t\t\tslotContextFuture.whenComplete(\n\t\t\t\t(SlotContext ignored, Throwable throwable) -> {\n\t\t\t\t\tif (throwable != null) {\n\t\t\t\t\t\trelease(throwable);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t}"
        ],
        [
            "SlotPool::requestSlotFromResourceManager(ResourceManagerGateway,PendingRequest)",
            " 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694 -\n 695 -\n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  ",
            "\tprivate void requestSlotFromResourceManager(\n\t\t\tfinal ResourceManagerGateway resourceManagerGateway,\n\t\t\tfinal PendingRequest pendingRequest) {\n\n\t\tcheckNotNull(resourceManagerGateway);\n\t\tcheckNotNull(pendingRequest);\n\n\t\tlog.info(\"Requesting slot with profile {} from resource manager (request = {}).\", pendingRequest.getResourceProfile(), pendingRequest.getSlotRequestId());\n\n\t\tfinal AllocationID allocationId = new AllocationID();\n\n\t\tpendingRequests.put(pendingRequest.getSlotRequestId(), allocationId, pendingRequest);\n\n\t\tpendingRequest.getAllocatedSlotFuture().whenComplete(\n\t\t\t(value, throwable) -> {\n\t\t\t\tif (throwable != null) {\n\t\t\t\t\tresourceManagerGateway.cancelSlotRequest(allocationId);\n\t\t\t\t}\n\t\t\t});\n\n\t\tCompletableFuture<Acknowledge> rmResponse = resourceManagerGateway.requestSlot(\n\t\t\tjobMasterId,\n\t\t\tnew SlotRequest(jobId, allocationId, pendingRequest.getResourceProfile(), jobManagerAddress),\n\t\t\trpcTimeout);\n\n\t\t// on failure, fail the request future\n\t\trmResponse.whenCompleteAsync(\n\t\t\t(Acknowledge ignored, Throwable failure) -> {\n\t\t\t\tif (failure != null) {\n\t\t\t\t\tslotRequestToResourceManagerFailed(pendingRequest.getSlotRequestId(), failure);\n\t\t\t\t}\n\t\t\t},\n\t\t\tgetMainThreadExecutor());\n\t}",
            " 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698 +\n 699 +\n 700 +\n 701 +\n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  ",
            "\tprivate void requestSlotFromResourceManager(\n\t\t\tfinal ResourceManagerGateway resourceManagerGateway,\n\t\t\tfinal PendingRequest pendingRequest) {\n\n\t\tcheckNotNull(resourceManagerGateway);\n\t\tcheckNotNull(pendingRequest);\n\n\t\tlog.info(\"Requesting slot with profile {} from resource manager (request = {}).\", pendingRequest.getResourceProfile(), pendingRequest.getSlotRequestId());\n\n\t\tfinal AllocationID allocationId = new AllocationID();\n\n\t\tpendingRequests.put(pendingRequest.getSlotRequestId(), allocationId, pendingRequest);\n\n\t\tpendingRequest.getAllocatedSlotFuture().whenComplete(\n\t\t\t(AllocatedSlot allocatedSlot, Throwable throwable) -> {\n\t\t\t\tif (throwable != null || allocationId.equals(allocatedSlot.getAllocationId())) {\n\t\t\t\t\t// cancel the slot request if there is a failure or if the pending request has\n\t\t\t\t\t// been completed with another allocated slot\n\t\t\t\t\tresourceManagerGateway.cancelSlotRequest(allocationId);\n\t\t\t\t}\n\t\t\t});\n\n\t\tCompletableFuture<Acknowledge> rmResponse = resourceManagerGateway.requestSlot(\n\t\t\tjobMasterId,\n\t\t\tnew SlotRequest(jobId, allocationId, pendingRequest.getResourceProfile(), jobManagerAddress),\n\t\t\trpcTimeout);\n\n\t\t// on failure, fail the request future\n\t\trmResponse.whenCompleteAsync(\n\t\t\t(Acknowledge ignored, Throwable failure) -> {\n\t\t\t\tif (failure != null) {\n\t\t\t\t\tslotRequestToResourceManagerFailed(pendingRequest.getSlotRequestId(), failure);\n\t\t\t\t}\n\t\t\t},\n\t\t\tgetMainThreadExecutor());\n\t}"
        ],
        [
            "SlotManager::unregisterSlotRequest(AllocationID)",
            " 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299 -\n 300  \n 301  \n 302  \n 303  ",
            "\t/**\n\t * Cancels and removes a pending slot request with the given allocation id. If there is no such\n\t * pending request, then nothing is done.\n\t *\n\t * @param allocationId identifying the pending slot request\n\t * @return True if a pending slot request was found; otherwise false\n\t */\n\tpublic boolean unregisterSlotRequest(AllocationID allocationId) {\n\t\tcheckInit();\n\n\t\tPendingSlotRequest pendingSlotRequest = pendingSlotRequests.remove(allocationId);\n\n\t\tif (null != pendingSlotRequest) {\n\t\t\tcancelPendingSlotRequest(pendingSlotRequest);\n\n\t\t\treturn true;\n\t\t} else {\n\t\t\tLOG.debug(\"No pending slot request with allocation id {} found.\", allocationId);\n\n\t\t\treturn false;\n\t\t}\n\t}",
            " 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295 +\n 296 +\n 297  \n 298  \n 299  \n 300  \n 301 +\n 302  \n 303  \n 304  \n 305  ",
            "\t/**\n\t * Cancels and removes a pending slot request with the given allocation id. If there is no such\n\t * pending request, then nothing is done.\n\t *\n\t * @param allocationId identifying the pending slot request\n\t * @return True if a pending slot request was found; otherwise false\n\t */\n\tpublic boolean unregisterSlotRequest(AllocationID allocationId) {\n\t\tcheckInit();\n\n\t\tPendingSlotRequest pendingSlotRequest = pendingSlotRequests.remove(allocationId);\n\n\t\tif (null != pendingSlotRequest) {\n\t\t\tLOG.debug(\"Cancel slot request {}.\", allocationId);\n\n\t\t\tcancelPendingSlotRequest(pendingSlotRequest);\n\n\t\t\treturn true;\n\t\t} else {\n\t\t\tLOG.debug(\"No pending slot request with allocation id {} found. Ignoring unregistration request.\", allocationId);\n\n\t\t\treturn false;\n\t\t}\n\t}"
        ],
        [
            "SlotPool::postStop()",
            " 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  ",
            "\t@Override\n\tpublic CompletableFuture<Void> postStop() {\n\t\t// cancel all pending allocations\n\t\tSet<AllocationID> allocationIds = pendingRequests.keySetB();\n\n\t\tfor (AllocationID allocationId : allocationIds) {\n\t\t\tresourceManagerGateway.cancelSlotRequest(allocationId);\n\t\t}\n\n\t\t// release all registered slots by releasing the corresponding TaskExecutors\n\t\tfor (ResourceID taskManagerResourceId : registeredTaskManagers) {\n\t\t\treleaseTaskManagerInternal(taskManagerResourceId);\n\t\t}\n\n\t\tclear();\n\n\t\treturn CompletableFuture.completedFuture(null);\n\t}",
            " 201  \n 202  \n 203 +\n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  ",
            "\t@Override\n\tpublic CompletableFuture<Void> postStop() {\n\t\tlog.info(\"Stopping SlotPool.\");\n\t\t// cancel all pending allocations\n\t\tSet<AllocationID> allocationIds = pendingRequests.keySetB();\n\n\t\tfor (AllocationID allocationId : allocationIds) {\n\t\t\tresourceManagerGateway.cancelSlotRequest(allocationId);\n\t\t}\n\n\t\t// release all registered slots by releasing the corresponding TaskExecutors\n\t\tfor (ResourceID taskManagerResourceId : registeredTaskManagers) {\n\t\t\treleaseTaskManagerInternal(taskManagerResourceId);\n\t\t}\n\n\t\tclear();\n\n\t\treturn CompletableFuture.completedFuture(null);\n\t}"
        ],
        [
            "SlotPool::releaseSlot(SlotRequestId,SlotSharingGroupId,Throwable)",
            " 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760 -\n 761  \n 762  \n 763 -\n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779 -\n 780  \n 781  \n 782  \n 783  \n 784  \n 785  ",
            "\t@Override\n\tpublic CompletableFuture<Acknowledge> releaseSlot(SlotRequestId slotRequestId, @Nullable SlotSharingGroupId slotSharingGroupId, Throwable cause) {\n\n\t\tif (slotSharingGroupId != null) {\n\t\t\tfinal SlotSharingManager multiTaskSlotManager = slotSharingManagers.get(slotSharingGroupId);\n\n\t\t\tif (multiTaskSlotManager != null) {\n\t\t\t\tfinal SlotSharingManager.TaskSlot taskSlot = multiTaskSlotManager.getTaskSlot(slotRequestId);\n\n\t\t\t\tif (taskSlot != null) {\n\t\t\t\t\ttaskSlot.release(cause);\n\t\t\t\t} else {\n\t\t\t\t\tlog.debug(\"Could not find slot {} in slot sharing group {}. Ignoring release slot request.\", slotRequestId, slotSharingGroupId, cause);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.debug(\"Could not find slot sharing group {}. Ignoring release slot request.\", slotSharingGroupId, cause);\n\t\t\t}\n\t\t} else {\n\t\t\tfinal PendingRequest pendingRequest = removePendingRequest(slotRequestId);\n\n\t\t\tif (pendingRequest != null) {\n\t\t\t\tfailPendingRequest(pendingRequest, new FlinkException(\"Pending slot request with \" + slotRequestId + \" has been released.\"));\n\t\t\t} else {\n\t\t\t\tfinal AllocatedSlot allocatedSlot = allocatedSlots.remove(slotRequestId);\n\n\t\t\t\tif (allocatedSlot != null) {\n\t\t\t\t\t// sanity check\n\t\t\t\t\tif (allocatedSlot.releasePayload(cause)) {\n\t\t\t\t\t\ttryFulfillSlotRequestOrMakeAvailable(allocatedSlot);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tlog.debug(\"There is no allocated slot with allocation id {}. Ignoring the release slot request.\", slotRequestId, cause);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn CompletableFuture.completedFuture(Acknowledge.get());\n\t}",
            " 754  \n 755  \n 756 +\n 757  \n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767 +\n 768  \n 769  \n 770 +\n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786 +\n 787  \n 788  \n 789  \n 790  \n 791  \n 792  ",
            "\t@Override\n\tpublic CompletableFuture<Acknowledge> releaseSlot(SlotRequestId slotRequestId, @Nullable SlotSharingGroupId slotSharingGroupId, Throwable cause) {\n\t\tlog.debug(\"Releasing slot with slot request id {}.\", slotRequestId, cause);\n\n\t\tif (slotSharingGroupId != null) {\n\t\t\tfinal SlotSharingManager multiTaskSlotManager = slotSharingManagers.get(slotSharingGroupId);\n\n\t\t\tif (multiTaskSlotManager != null) {\n\t\t\t\tfinal SlotSharingManager.TaskSlot taskSlot = multiTaskSlotManager.getTaskSlot(slotRequestId);\n\n\t\t\t\tif (taskSlot != null) {\n\t\t\t\t\ttaskSlot.release(cause);\n\t\t\t\t} else {\n\t\t\t\t\tlog.debug(\"Could not find slot {} in slot sharing group {}. Ignoring release slot request.\", slotRequestId, slotSharingGroupId);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.debug(\"Could not find slot sharing group {}. Ignoring release slot request.\", slotSharingGroupId);\n\t\t\t}\n\t\t} else {\n\t\t\tfinal PendingRequest pendingRequest = removePendingRequest(slotRequestId);\n\n\t\t\tif (pendingRequest != null) {\n\t\t\t\tfailPendingRequest(pendingRequest, new FlinkException(\"Pending slot request with \" + slotRequestId + \" has been released.\"));\n\t\t\t} else {\n\t\t\t\tfinal AllocatedSlot allocatedSlot = allocatedSlots.remove(slotRequestId);\n\n\t\t\t\tif (allocatedSlot != null) {\n\t\t\t\t\t// sanity check\n\t\t\t\t\tif (allocatedSlot.releasePayload(cause)) {\n\t\t\t\t\t\ttryFulfillSlotRequestOrMakeAvailable(allocatedSlot);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tlog.debug(\"There is no allocated slot with slot request id {}. Ignoring the release slot request.\", slotRequestId);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn CompletableFuture.completedFuture(Acknowledge.get());\n\t}"
        ],
        [
            "SlotPool::suspend()",
            " 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  ",
            "\t/**\n\t * Suspends this pool, meaning it has lost its authority to accept and distribute slots.\n\t */\n\t@Override\n\tpublic void suspend() {\n\t\tvalidateRunsInMainThread();\n\n\t\t// suspend this RPC endpoint\n\t\tstop();\n\n\t\t// do not accept any requests\n\t\tjobMasterId = null;\n\t\tresourceManagerGateway = null;\n\n\t\t// Clear (but not release!) the available slots. The TaskManagers should re-register them\n\t\t// at the new leader JobManager/SlotPool\n\t\tclear();\n\t}",
            " 221  \n 222  \n 223  \n 224  \n 225  \n 226 +\n 227 +\n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  ",
            "\t/**\n\t * Suspends this pool, meaning it has lost its authority to accept and distribute slots.\n\t */\n\t@Override\n\tpublic void suspend() {\n\t\tlog.info(\"Suspending SlotPool.\");\n\n\t\tvalidateRunsInMainThread();\n\n\t\t// suspend this RPC endpoint\n\t\tstop();\n\n\t\t// do not accept any requests\n\t\tjobMasterId = null;\n\t\tresourceManagerGateway = null;\n\n\t\t// Clear (but not release!) the available slots. The TaskManagers should re-register them\n\t\t// at the new leader JobManager/SlotPool\n\t\tclear();\n\t}"
        ]
    ],
    "ded464b8bd60d8f19221c0f1589346684c11c78d": [
        [
            "JavaSerializer::deserialize(DataInputView)",
            "  72  \n  73  \n  74 -\n  75  \n  76 -\n  77  \n  78  \n  79  \n  80  \n  81  ",
            "\t@Override\n\tpublic T deserialize(DataInputView source) throws IOException {\n\t\ttry {\n\t\t\treturn InstantiationUtil.deserializeObject(\n\t\t\t\t\tnew DataInputViewStream(source),\n\t\t\t\t\tThread.currentThread().getContextClassLoader());\n\t\t} catch (ClassNotFoundException e) {\n\t\t\tthrow new IOException(\"Could not deserialize object.\", e);\n\t\t}\n\t}",
            "  74  \n  75  \n  76 +\n  77  \n  78 +\n  79  \n  80  \n  81  \n  82  \n  83  ",
            "\t@Override\n\tpublic T deserialize(DataInputView source) throws IOException {\n\t\ttry (final DataInputViewStream inViewWrapper = new DataInputViewStream(source)) {\n\t\t\treturn InstantiationUtil.deserializeObject(\n\t\t\t\t\tinViewWrapper,\n\t\t\t\t\tThread.currentThread().getContextClassLoader());\n\t\t} catch (ClassNotFoundException e) {\n\t\t\tthrow new IOException(\"Could not deserialize object.\", e);\n\t\t}\n\t}"
        ],
        [
            "JavaSerializer::serialize(T,DataOutputView)",
            "  67  \n  68  \n  69 -\n  70  ",
            "\t@Override\n\tpublic void serialize(T record, DataOutputView target) throws IOException {\n\t\tInstantiationUtil.serializeObject(new DataOutputViewStream(target), record);\n\t}",
            "  67  \n  68  \n  69 +\n  70 +\n  71 +\n  72  ",
            "\t@Override\n\tpublic void serialize(T record, DataOutputView target) throws IOException {\n\t\ttry (final DataOutputViewStream outViewWrapper = new DataOutputViewStream(target)) {\n\t\t\tInstantiationUtil.serializeObject(outViewWrapper, record);\n\t\t}\n\t}"
        ],
        [
            "KryoRegistrationSerializerConfigSnapshot::KryoRegistrationSerializationProxy::write(DataOutputView)",
            " 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136 -\n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  ",
            "\t\t@Override\n\t\tpublic void write(DataOutputView out) throws IOException {\n\t\t\tout.writeUTF(kryoRegistration.getRegisteredClass().getName());\n\n\t\t\tfinal KryoRegistration.SerializerDefinitionType serializerDefinitionType = kryoRegistration.getSerializerDefinitionType();\n\n\t\t\tout.writeInt(serializerDefinitionType.ordinal());\n\t\t\tswitch (serializerDefinitionType) {\n\t\t\t\tcase UNSPECIFIED:\n\t\t\t\t\t// nothing else to write\n\t\t\t\t\tbreak;\n\t\t\t\tcase CLASS:\n\t\t\t\t\tout.writeUTF(kryoRegistration.getSerializerClass().getName());\n\t\t\t\t\tbreak;\n\t\t\t\tcase INSTANCE:\n\t\t\t\t\tInstantiationUtil.serializeObject(new DataOutputViewStream(out), kryoRegistration.getSerializableSerializerInstance());\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t// this should not happen; adding as a guard for the future\n\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\"Unrecognized Kryo registration serializer definition type: \" + serializerDefinitionType);\n\t\t\t}\n\t\t}",
            " 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136 +\n 137 +\n 138 +\n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  ",
            "\t\t@Override\n\t\tpublic void write(DataOutputView out) throws IOException {\n\t\t\tout.writeUTF(kryoRegistration.getRegisteredClass().getName());\n\n\t\t\tfinal KryoRegistration.SerializerDefinitionType serializerDefinitionType = kryoRegistration.getSerializerDefinitionType();\n\n\t\t\tout.writeInt(serializerDefinitionType.ordinal());\n\t\t\tswitch (serializerDefinitionType) {\n\t\t\t\tcase UNSPECIFIED:\n\t\t\t\t\t// nothing else to write\n\t\t\t\t\tbreak;\n\t\t\t\tcase CLASS:\n\t\t\t\t\tout.writeUTF(kryoRegistration.getSerializerClass().getName());\n\t\t\t\t\tbreak;\n\t\t\t\tcase INSTANCE:\n\t\t\t\t\ttry (final DataOutputViewStream outViewWrapper = new DataOutputViewStream(out)) {\n\t\t\t\t\t\tInstantiationUtil.serializeObject(outViewWrapper, kryoRegistration.getSerializableSerializerInstance());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t// this should not happen; adding as a guard for the future\n\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\"Unrecognized Kryo registration serializer definition type: \" + serializerDefinitionType);\n\t\t\t}\n\t\t}"
        ],
        [
            "GenericArraySerializerConfigSnapshot::read(DataInputView)",
            "  64  \n  65  \n  66  \n  67  \n  68 -\n  69 -\n  70  \n  71  \n  72  \n  73  ",
            "\t@Override\n\tpublic void read(DataInputView in) throws IOException {\n\t\tsuper.read(in);\n\n\t\ttry {\n\t\t\tcomponentClass = InstantiationUtil.deserializeObject(new DataInputViewStream(in), getUserCodeClassLoader());\n\t\t} catch (ClassNotFoundException e) {\n\t\t\tthrow new IOException(\"Could not find requested element class in classpath.\", e);\n\t\t}\n\t}",
            "  66  \n  67  \n  68  \n  69  \n  70 +\n  71 +\n  72  \n  73  \n  74  \n  75  ",
            "\t@Override\n\tpublic void read(DataInputView in) throws IOException {\n\t\tsuper.read(in);\n\n\t\ttry (final DataInputViewStream inViewWrapper = new DataInputViewStream(in)) {\n\t\t\tcomponentClass = InstantiationUtil.deserializeObject(inViewWrapper, getUserCodeClassLoader());\n\t\t} catch (ClassNotFoundException e) {\n\t\t\tthrow new IOException(\"Could not find requested element class in classpath.\", e);\n\t\t}\n\t}"
        ],
        [
            "TupleSerializerConfigSnapshot::write(DataOutputView)",
            "  50  \n  51  \n  52  \n  53  \n  54 -\n  55  ",
            "\t@Override\n\tpublic void write(DataOutputView out) throws IOException {\n\t\tsuper.write(out);\n\n\t\tInstantiationUtil.serializeObject(new DataOutputViewStream(out), tupleClass);\n\t}",
            "  50  \n  51  \n  52  \n  53  \n  54 +\n  55 +\n  56 +\n  57  ",
            "\t@Override\n\tpublic void write(DataOutputView out) throws IOException {\n\t\tsuper.write(out);\n\n\t\ttry (final DataOutputViewStream outViewWrapper = new DataOutputViewStream(out)) {\n\t\t\tInstantiationUtil.serializeObject(outViewWrapper, tupleClass);\n\t\t}\n\t}"
        ],
        [
            "TupleSerializerConfigSnapshot::read(DataInputView)",
            "  57  \n  58  \n  59  \n  60  \n  61 -\n  62 -\n  63  \n  64  \n  65  \n  66  ",
            "\t@Override\n\tpublic void read(DataInputView in) throws IOException {\n\t\tsuper.read(in);\n\n\t\ttry {\n\t\t\ttupleClass = InstantiationUtil.deserializeObject(new DataInputViewStream(in), getUserCodeClassLoader());\n\t\t} catch (ClassNotFoundException e) {\n\t\t\tthrow new IOException(\"Could not find requested tuple class in classpath.\", e);\n\t\t}\n\t}",
            "  59  \n  60  \n  61  \n  62  \n  63 +\n  64 +\n  65  \n  66  \n  67  \n  68  ",
            "\t@Override\n\tpublic void read(DataInputView in) throws IOException {\n\t\tsuper.read(in);\n\n\t\ttry (final DataInputViewStream inViewWrapper = new DataInputViewStream(in)) {\n\t\t\ttupleClass = InstantiationUtil.deserializeObject(inViewWrapper, getUserCodeClassLoader());\n\t\t} catch (ClassNotFoundException e) {\n\t\t\tthrow new IOException(\"Could not find requested tuple class in classpath.\", e);\n\t\t}\n\t}"
        ],
        [
            "GenericArraySerializerConfigSnapshot::write(DataOutputView)",
            "  57  \n  58  \n  59  \n  60  \n  61 -\n  62  ",
            "\t@Override\n\tpublic void write(DataOutputView out) throws IOException {\n\t\tsuper.write(out);\n\n\t\tInstantiationUtil.serializeObject(new DataOutputViewStream(out), componentClass);\n\t}",
            "  57  \n  58  \n  59  \n  60  \n  61 +\n  62 +\n  63 +\n  64  ",
            "\t@Override\n\tpublic void write(DataOutputView out) throws IOException {\n\t\tsuper.write(out);\n\n\t\ttry (final DataOutputViewStream outViewWrapper = new DataOutputViewStream(out)) {\n\t\t\tInstantiationUtil.serializeObject(outViewWrapper, componentClass);\n\t\t}\n\t}"
        ],
        [
            "KryoRegistrationSerializerConfigSnapshot::KryoRegistrationSerializationProxy::read(DataInputView)",
            " 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187 -\n 188 -\n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  ",
            "\t\t@SuppressWarnings(\"unchecked\")\n\t\t@Override\n\t\tpublic void read(DataInputView in) throws IOException {\n\t\t\tString registeredClassname = in.readUTF();\n\n\t\t\tClass<RC> registeredClass;\n\t\t\ttry {\n\t\t\t\tregisteredClass = (Class<RC>) Class.forName(registeredClassname, true, userCodeClassLoader);\n\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\tLOG.warn(\"Cannot find registered class \" + registeredClassname + \" for Kryo serialization in classpath;\" +\n\t\t\t\t\t\" using a dummy class as a placeholder.\", e);\n\n\t\t\t\tregisteredClass = (Class) DummyRegisteredClass.class;\n\t\t\t}\n\n\t\t\tfinal KryoRegistration.SerializerDefinitionType serializerDefinitionType =\n\t\t\t\tKryoRegistration.SerializerDefinitionType.values()[in.readInt()];\n\n\t\t\tswitch (serializerDefinitionType) {\n\t\t\t\tcase UNSPECIFIED:\n\t\t\t\t\tkryoRegistration = new KryoRegistration(registeredClass);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CLASS:\n\t\t\t\t\tString serializerClassname = in.readUTF();\n\n\t\t\t\t\tClass serializerClass;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tserializerClass = Class.forName(serializerClassname, true, userCodeClassLoader);\n\t\t\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\t\t\tLOG.warn(\"Cannot find registered Kryo serializer class for class \" + registeredClassname +\n\t\t\t\t\t\t\t\t\" in classpath; using a dummy Kryo serializer that should be replaced as soon as\" +\n\t\t\t\t\t\t\t\t\" a new Kryo serializer for the class is present\", e);\n\n\t\t\t\t\t\tserializerClass = DummyKryoSerializerClass.class;\n\t\t\t\t\t}\n\n\t\t\t\t\tkryoRegistration = new KryoRegistration(registeredClass, serializerClass);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase INSTANCE:\n\t\t\t\t\tExecutionConfig.SerializableSerializer<? extends Serializer<RC>> serializerInstance;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tserializerInstance = InstantiationUtil.deserializeObject(new DataInputViewStream(in), userCodeClassLoader);\n\t\t\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\t\t\tLOG.warn(\"Cannot find registered Kryo serializer class for class \" + registeredClassname +\n\t\t\t\t\t\t\t\t\" in classpath; using a dummy Kryo serializer that should be replaced as soon as\" +\n\t\t\t\t\t\t\t\t\" a new Kryo serializer for the class is present\", e);\n\n\t\t\t\t\t\tserializerInstance = new ExecutionConfig.SerializableSerializer<>(new DummyKryoSerializerClass<RC>());\n\t\t\t\t\t} catch (InvalidClassException e) {\n\t\t\t\t\t\tLOG.warn(\"The registered Kryo serializer class for class \" + registeredClassname +\n\t\t\t\t\t\t\t\t\" has changed and is no longer valid; using a dummy Kryo serializer that should be replaced\" +\n\t\t\t\t\t\t\t\t\" as soon as a new Kryo serializer for the class is present.\", e);\n\n\t\t\t\t\t\tserializerInstance = new ExecutionConfig.SerializableSerializer<>(new DummyKryoSerializerClass<RC>());\n\t\t\t\t\t}\n\n\t\t\t\t\tkryoRegistration = new KryoRegistration(registeredClass, serializerInstance);\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t// this should not happen; adding as a guard for the future\n\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\"Unrecognized Kryo registration serializer definition type: \" + serializerDefinitionType);\n\t\t\t}\n\t\t}",
            " 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189 +\n 190 +\n 191 +\n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  ",
            "\t\t@SuppressWarnings(\"unchecked\")\n\t\t@Override\n\t\tpublic void read(DataInputView in) throws IOException {\n\t\t\tString registeredClassname = in.readUTF();\n\n\t\t\tClass<RC> registeredClass;\n\t\t\ttry {\n\t\t\t\tregisteredClass = (Class<RC>) Class.forName(registeredClassname, true, userCodeClassLoader);\n\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\tLOG.warn(\"Cannot find registered class \" + registeredClassname + \" for Kryo serialization in classpath;\" +\n\t\t\t\t\t\" using a dummy class as a placeholder.\", e);\n\n\t\t\t\tregisteredClass = (Class) DummyRegisteredClass.class;\n\t\t\t}\n\n\t\t\tfinal KryoRegistration.SerializerDefinitionType serializerDefinitionType =\n\t\t\t\tKryoRegistration.SerializerDefinitionType.values()[in.readInt()];\n\n\t\t\tswitch (serializerDefinitionType) {\n\t\t\t\tcase UNSPECIFIED:\n\t\t\t\t\tkryoRegistration = new KryoRegistration(registeredClass);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CLASS:\n\t\t\t\t\tString serializerClassname = in.readUTF();\n\n\t\t\t\t\tClass serializerClass;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tserializerClass = Class.forName(serializerClassname, true, userCodeClassLoader);\n\t\t\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\t\t\tLOG.warn(\"Cannot find registered Kryo serializer class for class \" + registeredClassname +\n\t\t\t\t\t\t\t\t\" in classpath; using a dummy Kryo serializer that should be replaced as soon as\" +\n\t\t\t\t\t\t\t\t\" a new Kryo serializer for the class is present\", e);\n\n\t\t\t\t\t\tserializerClass = DummyKryoSerializerClass.class;\n\t\t\t\t\t}\n\n\t\t\t\t\tkryoRegistration = new KryoRegistration(registeredClass, serializerClass);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase INSTANCE:\n\t\t\t\t\tExecutionConfig.SerializableSerializer<? extends Serializer<RC>> serializerInstance;\n\n\t\t\t\t\ttry (final DataInputViewStream inViewWrapper = new DataInputViewStream(in)) {\n\t\t\t\t\t\tserializerInstance = InstantiationUtil.deserializeObject(inViewWrapper, userCodeClassLoader);\n\t\t\t\t\t} catch (ClassNotFoundException e) {\n\t\t\t\t\t\tLOG.warn(\"Cannot find registered Kryo serializer class for class \" + registeredClassname +\n\t\t\t\t\t\t\t\t\" in classpath; using a dummy Kryo serializer that should be replaced as soon as\" +\n\t\t\t\t\t\t\t\t\" a new Kryo serializer for the class is present\", e);\n\n\t\t\t\t\t\tserializerInstance = new ExecutionConfig.SerializableSerializer<>(new DummyKryoSerializerClass<RC>());\n\t\t\t\t\t} catch (InvalidClassException e) {\n\t\t\t\t\t\tLOG.warn(\"The registered Kryo serializer class for class \" + registeredClassname +\n\t\t\t\t\t\t\t\t\" has changed and is no longer valid; using a dummy Kryo serializer that should be replaced\" +\n\t\t\t\t\t\t\t\t\" as soon as a new Kryo serializer for the class is present.\", e);\n\n\t\t\t\t\t\tserializerInstance = new ExecutionConfig.SerializableSerializer<>(new DummyKryoSerializerClass<RC>());\n\t\t\t\t\t}\n\n\t\t\t\t\tkryoRegistration = new KryoRegistration(registeredClass, serializerInstance);\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t// this should not happen; adding as a guard for the future\n\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\"Unrecognized Kryo registration serializer definition type: \" + serializerDefinitionType);\n\t\t\t}\n\t\t}"
        ]
    ],
    "b550ac67fbf525863d5812d9d2a1010672a0169b": [
        [
            "YARNSessionFIFOSecuredITCase::testDetachedMode()",
            " 102  \n 103  \n 104  \n 105 -\n 106 -\n 107 -\n 108 -\n 109 -\n 110 -\n 111  ",
            "\t@Override\n\tpublic void testDetachedMode() throws InterruptedException, IOException {\n\t\tsuper.testDetachedMode();\n\t\tif (!verifyStringsInNamedLogFiles(\n\t\t\t\tnew String[]{\"Login successful for user\", \"using keytab file\"}, \"jobmanager.log\") ||\n\t\t\t\t!verifyStringsInNamedLogFiles(\n\t\t\t\t\t\tnew String[]{\"Login successful for user\", \"using keytab file\"}, \"taskmanager.log\")) {\n\t\t\tAssert.fail(\"Can not find expected strings in log files.\");\n\t\t}\n\t}",
            " 103  \n 104  \n 105  \n 106 +\n 107 +\n 108 +\n 109 +\n 110 +\n 111 +\n 112 +\n 113 +\n 114 +\n 115 +\n 116 +\n 117  ",
            "\t@Override\n\tpublic void testDetachedMode() throws InterruptedException, IOException {\n\t\tsuper.testDetachedMode();\n\t\tfinal String[] mustHave = {\"Login successful for user\", \"using keytab file\"};\n\t\tfinal boolean jobManagerRunsWithKerberos = verifyStringsInNamedLogFiles(\n\t\t\tmustHave,\n\t\t\t\"jobmanager.log\");\n\t\tfinal boolean taskManagerRunsWithKerberos = verifyStringsInNamedLogFiles(\n\t\t\tmustHave, \"taskmanager.log\");\n\n\t\tAssert.assertThat(\n\t\t\t\"The JobManager and the TaskManager should both run with Kerberos.\",\n\t\t\tjobManagerRunsWithKerberos && taskManagerRunsWithKerberos,\n\t\t\tMatchers.is(true));\n\t}"
        ],
        [
            "YarnConfigurationITCase::testFlinkContainerMemory()",
            "  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81 -\n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  ",
            "\t/**\n\t * Tests that the Flink components are started with the correct\n\t * memory settings.\n\t */\n\t@Test(timeout = 60000)\n\tpublic void testFlinkContainerMemory() throws Exception {\n\t\tfinal YarnClient yarnClient = getYarnClient();\n\t\tfinal Configuration configuration = new Configuration(flinkConfiguration.clone());\n\n\t\tfinal int masterMemory = 64;\n\t\tfinal int taskManagerMemory = 128;\n\t\tfinal int slotsPerTaskManager = 3;\n\n\t\t// disable heap cutoff min\n\t\tconfiguration.setInteger(ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN, 0);\n\t\tconfiguration.setLong(TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MIN, (1L << 20));\n\t\tconfiguration.setLong(TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MAX, (4L << 20));\n\n\t\tfinal YarnConfiguration yarnConfiguration = getYarnConfiguration();\n\t\tfinal Flip6YarnClusterDescriptor clusterDescriptor = new Flip6YarnClusterDescriptor(\n\t\t\tconfiguration,\n\t\t\tyarnConfiguration,\n\t\t\tCliFrontend.getConfigurationDirectoryFromEnv(),\n\t\t\tyarnClient,\n\t\t\ttrue);\n\n\t\tclusterDescriptor.setLocalJarPath(new Path(flinkUberjar.getAbsolutePath()));\n\t\tclusterDescriptor.addShipFiles(Arrays.asList(flinkLibFolder.listFiles()));\n\n\t\tfinal File streamingWordCountFile = new File(\"target/programs/WindowJoin.jar\");\n\n\t\tassertThat(streamingWordCountFile.exists(), is(true));\n\n\t\tfinal PackagedProgram packagedProgram = new PackagedProgram(streamingWordCountFile);\n\t\tfinal JobGraph jobGraph = PackagedProgramUtils.createJobGraph(packagedProgram, configuration, 1);\n\n\t\ttry {\n\t\t\tfinal ClusterSpecification clusterSpecification = new ClusterSpecification.ClusterSpecificationBuilder()\n\t\t\t\t.setMasterMemoryMB(masterMemory)\n\t\t\t\t.setTaskManagerMemoryMB(taskManagerMemory)\n\t\t\t\t.setSlotsPerTaskManager(slotsPerTaskManager)\n\t\t\t\t.createClusterSpecification();\n\n\t\t\tfinal ClusterClient<ApplicationId> clusterClient = clusterDescriptor.deployJobCluster(clusterSpecification, jobGraph, true);\n\n\t\t\tfinal ApplicationId clusterId = clusterClient.getClusterId();\n\n\t\t\tfinal RestClient restClient = new RestClient(RestClientConfiguration.fromConfiguration(configuration), TestingUtils.defaultExecutor());\n\n\t\t\ttry {\n\t\t\t\tfinal ApplicationReport applicationReport = yarnClient.getApplicationReport(clusterId);\n\n\t\t\t\tfinal ApplicationAttemptId currentApplicationAttemptId = applicationReport.getCurrentApplicationAttemptId();\n\n\t\t\t\t// wait until we have second container allocated\n\t\t\t\tList<ContainerReport> containers = yarnClient.getContainers(currentApplicationAttemptId);\n\n\t\t\t\twhile (containers.size() < 2) {\n\t\t\t\t\t// this is nasty but Yarn does not offer a better way to wait\n\t\t\t\t\tThread.sleep(50L);\n\t\t\t\t\tcontainers = yarnClient.getContainers(currentApplicationAttemptId);\n\t\t\t\t}\n\n\t\t\t\tfor (ContainerReport container : containers) {\n\t\t\t\t\tif (container.getContainerId().getId() == 1) {\n\t\t\t\t\t\t// this should be the application master\n\t\t\t\t\t\tassertThat(container.getAllocatedResource().getMemory(), is(masterMemory));\n\t\t\t\t\t} else {\n\t\t\t\t\t\tassertThat(container.getAllocatedResource().getMemory(), is(taskManagerMemory));\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfinal URI webURI = new URI(clusterClient.getWebInterfaceURL());\n\n\t\t\t\tCompletableFuture<TaskManagersInfo> taskManagersInfoCompletableFuture;\n\t\t\t\tCollection<TaskManagerInfo> taskManagerInfos;\n\n\t\t\t\twhile (true) {\n\t\t\t\t\ttaskManagersInfoCompletableFuture = restClient.sendRequest(\n\t\t\t\t\t\twebURI.getHost(),\n\t\t\t\t\t\twebURI.getPort(),\n\t\t\t\t\t\tTaskManagersHeaders.getInstance(),\n\t\t\t\t\t\tEmptyMessageParameters.getInstance(),\n\t\t\t\t\t\tEmptyRequestBody.getInstance());\n\n\t\t\t\t\tfinal TaskManagersInfo taskManagersInfo = taskManagersInfoCompletableFuture.get();\n\n\t\t\t\t\ttaskManagerInfos = taskManagersInfo.getTaskManagerInfos();\n\n\t\t\t\t\tif (taskManagerInfos.isEmpty()) {\n\t\t\t\t\t\tThread.sleep(100L);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// there should be at least one TaskManagerInfo\n\t\t\t\tfinal TaskManagerInfo taskManagerInfo = taskManagerInfos.iterator().next();\n\n\t\t\t\tassertThat(taskManagerInfo.getNumberSlots(), is(slotsPerTaskManager));\n\n\t\t\t\tfinal ContaineredTaskManagerParameters containeredTaskManagerParameters = ContaineredTaskManagerParameters.create(\n\t\t\t\t\tconfiguration,\n\t\t\t\t\ttaskManagerMemory,\n\t\t\t\t\tslotsPerTaskManager);\n\n\t\t\t\tfinal long expectedHeadSize = containeredTaskManagerParameters.taskManagerHeapSizeMB() << 20L;\n\n\t\t\t\tassertThat((double) taskManagerInfo.getHardwareDescription().getSizeOfJvmHeap() / (double) expectedHeadSize, is(closeTo(1.0, 0.1)));\n\t\t\t} finally {\n\t\t\t\trestClient.shutdown(TIMEOUT);\n\t\t\t\tclusterClient.shutdown();\n\t\t\t}\n\n\t\t\tclusterDescriptor.terminateCluster(clusterId);\n\n\t\t} finally {\n\t\t\tclusterDescriptor.close();\n\t\t}\n\t}",
            "  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81 +\n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  ",
            "\t/**\n\t * Tests that the Flink components are started with the correct\n\t * memory settings.\n\t */\n\t@Test(timeout = 60000)\n\tpublic void testFlinkContainerMemory() throws Exception {\n\t\tfinal YarnClient yarnClient = getYarnClient();\n\t\tfinal Configuration configuration = new Configuration(flinkConfiguration);\n\n\t\tfinal int masterMemory = 64;\n\t\tfinal int taskManagerMemory = 128;\n\t\tfinal int slotsPerTaskManager = 3;\n\n\t\t// disable heap cutoff min\n\t\tconfiguration.setInteger(ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN, 0);\n\t\tconfiguration.setLong(TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MIN, (1L << 20));\n\t\tconfiguration.setLong(TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MAX, (4L << 20));\n\n\t\tfinal YarnConfiguration yarnConfiguration = getYarnConfiguration();\n\t\tfinal Flip6YarnClusterDescriptor clusterDescriptor = new Flip6YarnClusterDescriptor(\n\t\t\tconfiguration,\n\t\t\tyarnConfiguration,\n\t\t\tCliFrontend.getConfigurationDirectoryFromEnv(),\n\t\t\tyarnClient,\n\t\t\ttrue);\n\n\t\tclusterDescriptor.setLocalJarPath(new Path(flinkUberjar.getAbsolutePath()));\n\t\tclusterDescriptor.addShipFiles(Arrays.asList(flinkLibFolder.listFiles()));\n\n\t\tfinal File streamingWordCountFile = new File(\"target/programs/WindowJoin.jar\");\n\n\t\tassertThat(streamingWordCountFile.exists(), is(true));\n\n\t\tfinal PackagedProgram packagedProgram = new PackagedProgram(streamingWordCountFile);\n\t\tfinal JobGraph jobGraph = PackagedProgramUtils.createJobGraph(packagedProgram, configuration, 1);\n\n\t\ttry {\n\t\t\tfinal ClusterSpecification clusterSpecification = new ClusterSpecification.ClusterSpecificationBuilder()\n\t\t\t\t.setMasterMemoryMB(masterMemory)\n\t\t\t\t.setTaskManagerMemoryMB(taskManagerMemory)\n\t\t\t\t.setSlotsPerTaskManager(slotsPerTaskManager)\n\t\t\t\t.createClusterSpecification();\n\n\t\t\tfinal ClusterClient<ApplicationId> clusterClient = clusterDescriptor.deployJobCluster(clusterSpecification, jobGraph, true);\n\n\t\t\tfinal ApplicationId clusterId = clusterClient.getClusterId();\n\n\t\t\tfinal RestClient restClient = new RestClient(RestClientConfiguration.fromConfiguration(configuration), TestingUtils.defaultExecutor());\n\n\t\t\ttry {\n\t\t\t\tfinal ApplicationReport applicationReport = yarnClient.getApplicationReport(clusterId);\n\n\t\t\t\tfinal ApplicationAttemptId currentApplicationAttemptId = applicationReport.getCurrentApplicationAttemptId();\n\n\t\t\t\t// wait until we have second container allocated\n\t\t\t\tList<ContainerReport> containers = yarnClient.getContainers(currentApplicationAttemptId);\n\n\t\t\t\twhile (containers.size() < 2) {\n\t\t\t\t\t// this is nasty but Yarn does not offer a better way to wait\n\t\t\t\t\tThread.sleep(50L);\n\t\t\t\t\tcontainers = yarnClient.getContainers(currentApplicationAttemptId);\n\t\t\t\t}\n\n\t\t\t\tfor (ContainerReport container : containers) {\n\t\t\t\t\tif (container.getContainerId().getId() == 1) {\n\t\t\t\t\t\t// this should be the application master\n\t\t\t\t\t\tassertThat(container.getAllocatedResource().getMemory(), is(masterMemory));\n\t\t\t\t\t} else {\n\t\t\t\t\t\tassertThat(container.getAllocatedResource().getMemory(), is(taskManagerMemory));\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfinal URI webURI = new URI(clusterClient.getWebInterfaceURL());\n\n\t\t\t\tCompletableFuture<TaskManagersInfo> taskManagersInfoCompletableFuture;\n\t\t\t\tCollection<TaskManagerInfo> taskManagerInfos;\n\n\t\t\t\twhile (true) {\n\t\t\t\t\ttaskManagersInfoCompletableFuture = restClient.sendRequest(\n\t\t\t\t\t\twebURI.getHost(),\n\t\t\t\t\t\twebURI.getPort(),\n\t\t\t\t\t\tTaskManagersHeaders.getInstance(),\n\t\t\t\t\t\tEmptyMessageParameters.getInstance(),\n\t\t\t\t\t\tEmptyRequestBody.getInstance());\n\n\t\t\t\t\tfinal TaskManagersInfo taskManagersInfo = taskManagersInfoCompletableFuture.get();\n\n\t\t\t\t\ttaskManagerInfos = taskManagersInfo.getTaskManagerInfos();\n\n\t\t\t\t\tif (taskManagerInfos.isEmpty()) {\n\t\t\t\t\t\tThread.sleep(100L);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// there should be at least one TaskManagerInfo\n\t\t\t\tfinal TaskManagerInfo taskManagerInfo = taskManagerInfos.iterator().next();\n\n\t\t\t\tassertThat(taskManagerInfo.getNumberSlots(), is(slotsPerTaskManager));\n\n\t\t\t\tfinal ContaineredTaskManagerParameters containeredTaskManagerParameters = ContaineredTaskManagerParameters.create(\n\t\t\t\t\tconfiguration,\n\t\t\t\t\ttaskManagerMemory,\n\t\t\t\t\tslotsPerTaskManager);\n\n\t\t\t\tfinal long expectedHeadSize = containeredTaskManagerParameters.taskManagerHeapSizeMB() << 20L;\n\n\t\t\t\tassertThat((double) taskManagerInfo.getHardwareDescription().getSizeOfJvmHeap() / (double) expectedHeadSize, is(closeTo(1.0, 0.1)));\n\t\t\t} finally {\n\t\t\t\trestClient.shutdown(TIMEOUT);\n\t\t\t\tclusterClient.shutdown();\n\t\t\t}\n\n\t\t\tclusterDescriptor.terminateCluster(clusterId);\n\n\t\t} finally {\n\t\t\tclusterDescriptor.close();\n\t\t}\n\t}"
        ],
        [
            "YarnTestBase::checkClusterEmpty()",
            " 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  ",
            "\t@Before\n\tpublic void checkClusterEmpty() throws IOException, YarnException {\n\t\tif (yarnClient == null) {\n\t\t\tyarnClient = YarnClient.createYarnClient();\n\t\t\tyarnClient.init(getYarnConfiguration());\n\t\t\tyarnClient.start();\n\t\t}\n\n\t\tList<ApplicationReport> apps = yarnClient.getApplications();\n\t\tfor (ApplicationReport app : apps) {\n\t\t\tif (app.getYarnApplicationState() != YarnApplicationState.FINISHED\n\t\t\t\t\t&& app.getYarnApplicationState() != YarnApplicationState.KILLED\n\t\t\t\t\t&& app.getYarnApplicationState() != YarnApplicationState.FAILED) {\n\t\t\t\tAssert.fail(\"There is at least one application on the cluster is not finished.\" +\n\t\t\t\t\t\t\"App \" + app.getApplicationId() + \" is in state \" + app.getYarnApplicationState());\n\t\t\t}\n\t\t}\n\n\t\tflip6 = CoreOptions.FLIP6_MODE.equalsIgnoreCase(flinkConfiguration.getString(CoreOptions.MODE));\n\t}",
            " 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222 +\n 223  \n 224  ",
            "\t@Before\n\tpublic void checkClusterEmpty() throws IOException, YarnException {\n\t\tif (yarnClient == null) {\n\t\t\tyarnClient = YarnClient.createYarnClient();\n\t\t\tyarnClient.init(getYarnConfiguration());\n\t\t\tyarnClient.start();\n\t\t}\n\n\t\tList<ApplicationReport> apps = yarnClient.getApplications();\n\t\tfor (ApplicationReport app : apps) {\n\t\t\tif (app.getYarnApplicationState() != YarnApplicationState.FINISHED\n\t\t\t\t\t&& app.getYarnApplicationState() != YarnApplicationState.KILLED\n\t\t\t\t\t&& app.getYarnApplicationState() != YarnApplicationState.FAILED) {\n\t\t\t\tAssert.fail(\"There is at least one application on the cluster is not finished.\" +\n\t\t\t\t\t\t\"App \" + app.getApplicationId() + \" is in state \" + app.getYarnApplicationState());\n\t\t\t}\n\t\t}\n\n\t\tflinkConfiguration = new org.apache.flink.configuration.Configuration(globalConfiguration);\n\t\tflip6 = CoreOptions.FLIP6_MODE.equalsIgnoreCase(flinkConfiguration.getString(CoreOptions.MODE));\n\t}"
        ],
        [
            "YarnTestBase::start(YarnConfiguration,String,String)",
            " 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515 -\n 516 -\n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523 -\n 524  \n 525  \n 526 -\n 527 -\n 528 -\n 529  \n 530 -\n 531 -\n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  ",
            "\tprivate static void start(YarnConfiguration conf, String principal, String keytab) {\n\t\t// set the home directory to a temp directory. Flink on YARN is using the home dir to distribute the file\n\t\tFile homeDir = null;\n\t\ttry {\n\t\t\thomeDir = tmp.newFolder();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\tAssert.fail(e.getMessage());\n\t\t}\n\t\tSystem.setProperty(\"user.home\", homeDir.getAbsolutePath());\n\t\tString uberjarStartLoc = \"..\";\n\t\tLOG.info(\"Trying to locate uberjar in {}\", new File(uberjarStartLoc));\n\t\tflinkUberjar = findFile(uberjarStartLoc, new RootDirFilenameFilter());\n\t\tAssert.assertNotNull(\"Flink uberjar not found\", flinkUberjar);\n\t\tString flinkDistRootDir = flinkUberjar.getParentFile().getParent();\n\t\tflinkLibFolder = flinkUberjar.getParentFile(); // the uberjar is located in lib/\n\t\tAssert.assertNotNull(\"Flink flinkLibFolder not found\", flinkLibFolder);\n\t\tAssert.assertTrue(\"lib folder not found\", flinkLibFolder.exists());\n\t\tAssert.assertTrue(\"lib folder not found\", flinkLibFolder.isDirectory());\n\n\t\tif (!flinkUberjar.exists()) {\n\t\t\tAssert.fail(\"Unable to locate yarn-uberjar.jar\");\n\t\t}\n\n\t\ttry {\n\t\t\tLOG.info(\"Starting up MiniYARNCluster\");\n\t\t\tif (yarnCluster == null) {\n\t\t\t\tfinal String testName = conf.get(YarnTestBase.TEST_CLUSTER_NAME_KEY);\n\t\t\t\tyarnCluster = new MiniYARNCluster(\n\t\t\t\t\ttestName == null ? \"YarnTest_\" + UUID.randomUUID() : testName,\n\t\t\t\t\tNUM_NODEMANAGERS,\n\t\t\t\t\t1,\n\t\t\t\t\t1);\n\n\t\t\t\tyarnCluster.init(conf);\n\t\t\t\tyarnCluster.start();\n\t\t\t}\n\n\t\t\tMap<String, String> map = new HashMap<String, String>(System.getenv());\n\n\t\t\tFile flinkConfDirPath = findFile(flinkDistRootDir, new ContainsName(new String[]{\"flink-conf.yaml\"}));\n\t\t\tAssert.assertNotNull(flinkConfDirPath);\n\t\t\tflinkConfiguration =\n\t\t\t\t\tGlobalConfiguration.loadConfiguration();\n\n\t\t\tif (!StringUtils.isBlank(principal) && !StringUtils.isBlank(keytab)) {\n\n\t\t\t\t//copy conf dir to test temporary workspace location\n\t\t\t\ttempConfPathForSecureRun = tmp.newFolder(\"conf\");\n\n\t\t\t\tString confDirPath = flinkConfDirPath.getParentFile().getAbsolutePath();\n\t\t\t\tFileUtils.copyDirectory(new File(confDirPath), tempConfPathForSecureRun);\n\n\t\t\t\tflinkConfiguration.setString(SecurityOptions.KERBEROS_LOGIN_KEYTAB.key(), keytab);\n\t\t\t\tflinkConfiguration.setString(SecurityOptions.KERBEROS_LOGIN_PRINCIPAL.key(), principal);\n\t\t\t\tflinkConfiguration.setString(CoreOptions.MODE.key(), OLD_MODE);\n\n\t\t\t\tBootstrapTools.writeConfiguration(flinkConfiguration,\n\t\t\t\t\t\tnew File(tempConfPathForSecureRun, \"flink-conf.yaml\"));\n\n\t\t\t\tString configDir = tempConfPathForSecureRun.getAbsolutePath();\n\n\t\t\t\tLOG.info(\"Temporary Flink configuration directory to be used for secure test: {}\", configDir);\n\n\t\t\t\tAssert.assertNotNull(configDir);\n\n\t\t\t\tmap.put(ConfigConstants.ENV_FLINK_CONF_DIR, configDir);\n\n\t\t\t} else {\n\t\t\t\tmap.put(ConfigConstants.ENV_FLINK_CONF_DIR, flinkConfDirPath.getParent());\n\t\t\t}\n\n\t\t\tFile yarnConfFile = writeYarnSiteConfigXML(conf);\n\t\t\tmap.put(\"YARN_CONF_DIR\", yarnConfFile.getParentFile().getAbsolutePath());\n\t\t\tmap.put(\"IN_TESTS\", \"yes we are in tests\"); // see YarnClusterDescriptor() for more infos\n\t\t\tTestBaseUtils.setEnv(map);\n\n\t\t\tAssert.assertTrue(yarnCluster.getServiceState() == Service.STATE.STARTED);\n\n\t\t\t// wait for the nodeManagers to connect\n\t\t\twhile (!yarnCluster.waitForNodeManagersToConnect(500)) {\n\t\t\t\tLOG.info(\"Waiting for Nodemanagers to connect\");\n\t\t\t}\n\t\t} catch (Exception ex) {\n\t\t\tex.printStackTrace();\n\t\t\tLOG.error(\"setup failure\", ex);\n\t\t\tAssert.fail();\n\t\t}\n\n\t}",
            " 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518 +\n 519 +\n 520 +\n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529 +\n 530 +\n 531 +\n 532  \n 533 +\n 534 +\n 535 +\n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  ",
            "\tprivate static void start(YarnConfiguration conf, String principal, String keytab) {\n\t\t// set the home directory to a temp directory. Flink on YARN is using the home dir to distribute the file\n\t\tFile homeDir = null;\n\t\ttry {\n\t\t\thomeDir = tmp.newFolder();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\tAssert.fail(e.getMessage());\n\t\t}\n\t\tSystem.setProperty(\"user.home\", homeDir.getAbsolutePath());\n\t\tString uberjarStartLoc = \"..\";\n\t\tLOG.info(\"Trying to locate uberjar in {}\", new File(uberjarStartLoc));\n\t\tflinkUberjar = findFile(uberjarStartLoc, new RootDirFilenameFilter());\n\t\tAssert.assertNotNull(\"Flink uberjar not found\", flinkUberjar);\n\t\tString flinkDistRootDir = flinkUberjar.getParentFile().getParent();\n\t\tflinkLibFolder = flinkUberjar.getParentFile(); // the uberjar is located in lib/\n\t\tAssert.assertNotNull(\"Flink flinkLibFolder not found\", flinkLibFolder);\n\t\tAssert.assertTrue(\"lib folder not found\", flinkLibFolder.exists());\n\t\tAssert.assertTrue(\"lib folder not found\", flinkLibFolder.isDirectory());\n\n\t\tif (!flinkUberjar.exists()) {\n\t\t\tAssert.fail(\"Unable to locate yarn-uberjar.jar\");\n\t\t}\n\n\t\ttry {\n\t\t\tLOG.info(\"Starting up MiniYARNCluster\");\n\t\t\tif (yarnCluster == null) {\n\t\t\t\tfinal String testName = conf.get(YarnTestBase.TEST_CLUSTER_NAME_KEY);\n\t\t\t\tyarnCluster = new MiniYARNCluster(\n\t\t\t\t\ttestName == null ? \"YarnTest_\" + UUID.randomUUID() : testName,\n\t\t\t\t\tNUM_NODEMANAGERS,\n\t\t\t\t\t1,\n\t\t\t\t\t1);\n\n\t\t\t\tyarnCluster.init(conf);\n\t\t\t\tyarnCluster.start();\n\t\t\t}\n\n\t\t\tMap<String, String> map = new HashMap<String, String>(System.getenv());\n\n\t\t\tFile flinkConfDirPath = findFile(flinkDistRootDir, new ContainsName(new String[]{\"flink-conf.yaml\"}));\n\t\t\tAssert.assertNotNull(flinkConfDirPath);\n\n\t\t\tfinal String confDirPath = flinkConfDirPath.getParentFile().getAbsolutePath();\n\t\t\tglobalConfiguration = GlobalConfiguration.loadConfiguration(confDirPath);\n\n\t\t\tif (!StringUtils.isBlank(principal) && !StringUtils.isBlank(keytab)) {\n\n\t\t\t\t//copy conf dir to test temporary workspace location\n\t\t\t\ttempConfPathForSecureRun = tmp.newFolder(\"conf\");\n\n\t\t\t\tFileUtils.copyDirectory(new File(confDirPath), tempConfPathForSecureRun);\n\n\t\t\t\tglobalConfiguration.setString(SecurityOptions.KERBEROS_LOGIN_KEYTAB.key(), keytab);\n\t\t\t\tglobalConfiguration.setString(SecurityOptions.KERBEROS_LOGIN_PRINCIPAL.key(), principal);\n\t\t\t\tglobalConfiguration.setString(CoreOptions.MODE.key(), OLD_MODE);\n\n\t\t\t\tBootstrapTools.writeConfiguration(\n\t\t\t\t\tglobalConfiguration,\n\t\t\t\t\tnew File(tempConfPathForSecureRun, \"flink-conf.yaml\"));\n\n\t\t\t\tString configDir = tempConfPathForSecureRun.getAbsolutePath();\n\n\t\t\t\tLOG.info(\"Temporary Flink configuration directory to be used for secure test: {}\", configDir);\n\n\t\t\t\tAssert.assertNotNull(configDir);\n\n\t\t\t\tmap.put(ConfigConstants.ENV_FLINK_CONF_DIR, configDir);\n\n\t\t\t} else {\n\t\t\t\tmap.put(ConfigConstants.ENV_FLINK_CONF_DIR, flinkConfDirPath.getParent());\n\t\t\t}\n\n\t\t\tFile yarnConfFile = writeYarnSiteConfigXML(conf);\n\t\t\tmap.put(\"YARN_CONF_DIR\", yarnConfFile.getParentFile().getAbsolutePath());\n\t\t\tmap.put(\"IN_TESTS\", \"yes we are in tests\"); // see YarnClusterDescriptor() for more infos\n\t\t\tTestBaseUtils.setEnv(map);\n\n\t\t\tAssert.assertTrue(yarnCluster.getServiceState() == Service.STATE.STARTED);\n\n\t\t\t// wait for the nodeManagers to connect\n\t\t\twhile (!yarnCluster.waitForNodeManagersToConnect(500)) {\n\t\t\t\tLOG.info(\"Waiting for Nodemanagers to connect\");\n\t\t\t}\n\t\t} catch (Exception ex) {\n\t\t\tex.printStackTrace();\n\t\t\tLOG.error(\"setup failure\", ex);\n\t\t\tAssert.fail();\n\t\t}\n\n\t}"
        ]
    ],
    "21cf59d5fffdca9e8335e1990c75e0c3cd684212": [
        [
            "RocksDBKeyedStateBackend::RocksDBFullSnapshotOperation::writeKVStateMetaData()",
            "1947  \n1948  \n1949 -\n1950 -\n1951 -\n1952 -\n1953  \n1954  \n1955  \n1956  \n1957  \n1958  \n1959  \n1960 -\n1961 -\n1962 -\n1963 -\n1964  \n1965  \n1966 -\n1967  \n1968  \n1969  \n1970  \n1971  \n1972  \n1973  \n1974 -\n1975  \n1976  \n1977  \n1978  \n1979  \n1980  ",
            "\t\tprivate void writeKVStateMetaData() throws IOException {\n\n\t\t\tList<RegisteredKeyedBackendStateMetaInfo.Snapshot<?, ?>> metaInfoSnapshots =\n\t\t\t\tnew ArrayList<>(kvStateInformationCopy.size());\n\n\t\t\tthis.kvStateIterators = new ArrayList<>(kvStateInformationCopy.size());\n\n\t\t\tint kvStateId = 0;\n\n\t\t\t//retrieve iterator for this k/v states\n\t\t\treadOptions = new ReadOptions();\n\t\t\treadOptions.setSnapshot(snapshot);\n\n\t\t\tfor (Tuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>> column :\n\t\t\t\tkvStateInformationCopy) {\n\n\t\t\t\tmetaInfoSnapshots.add(column.f1.snapshot());\n\n\t\t\t\tkvStateIterators.add(\n\t\t\t\t\tnew Tuple2<>(stateBackend.db.newIterator(column.f0, readOptions), kvStateId));\n\n\t\t\t\t++kvStateId;\n\t\t\t}\n\n\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(\n\t\t\t\t\tstateBackend.getKeySerializer(),\n\t\t\t\t\tmetaInfoSnapshots,\n\t\t\t\t\t!Objects.equals(\n\t\t\t\t\t\tUncompressedStreamCompressionDecorator.INSTANCE,\n\t\t\t\t\t\tstateBackend.keyGroupCompressionDecorator));\n\n\t\t\tserializationProxy.write(outputView);\n\t\t}",
            "1965  \n1966  \n1967 +\n1968  \n1969  \n1970  \n1971  \n1972  \n1973  \n1974  \n1975 +\n1976  \n1977  \n1978 +\n1979  \n1980  \n1981  \n1982  \n1983  \n1984  \n1985  \n1986 +\n1987  \n1988  \n1989  \n1990  \n1991  \n1992  ",
            "\t\tprivate void writeKVStateMetaData() throws IOException {\n\n\t\t\tthis.kvStateIterators = new ArrayList<>(copiedColumnFamilyHandles.size());\n\n\t\t\tint kvStateId = 0;\n\n\t\t\t//retrieve iterator for this k/v states\n\t\t\treadOptions = new ReadOptions();\n\t\t\treadOptions.setSnapshot(snapshot);\n\n\t\t\tfor (ColumnFamilyHandle columnFamilyHandle : copiedColumnFamilyHandles) {\n\n\t\t\t\tkvStateIterators.add(\n\t\t\t\t\tnew Tuple2<>(stateBackend.db.newIterator(columnFamilyHandle, readOptions), kvStateId));\n\n\t\t\t\t++kvStateId;\n\t\t\t}\n\n\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(\n\t\t\t\t\tstateBackend.getKeySerializer(),\n\t\t\t\t\tstateMetaInfoSnapshots,\n\t\t\t\t\t!Objects.equals(\n\t\t\t\t\t\tUncompressedStreamCompressionDecorator.INSTANCE,\n\t\t\t\t\t\tstateBackend.keyGroupCompressionDecorator));\n\n\t\t\tserializationProxy.write(outputView);\n\t\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBFullSnapshotOperation::takeDBSnapShot()",
            "1857  \n1858  \n1859  \n1860  \n1861  \n1862  \n1863 -\n1864  \n1865  ",
            "\t\t/**\n\t\t * 1) Create a snapshot object from RocksDB.\n\t\t *\n\t\t */\n\t\tpublic void takeDBSnapShot() {\n\t\t\tPreconditions.checkArgument(snapshot == null, \"Only one ongoing snapshot allowed!\");\n\t\t\tthis.kvStateInformationCopy = new ArrayList<>(stateBackend.kvStateInformation.values());\n\t\t\tthis.snapshot = stateBackend.db.getSnapshot();\n\t\t}",
            "1863  \n1864  \n1865  \n1866  \n1867  \n1868  \n1869 +\n1870 +\n1871 +\n1872 +\n1873 +\n1874 +\n1875 +\n1876 +\n1877 +\n1878 +\n1879 +\n1880 +\n1881 +\n1882  \n1883  ",
            "\t\t/**\n\t\t * 1) Create a snapshot object from RocksDB.\n\t\t *\n\t\t */\n\t\tpublic void takeDBSnapShot() {\n\t\t\tPreconditions.checkArgument(snapshot == null, \"Only one ongoing snapshot allowed!\");\n\n\t\t\tthis.stateMetaInfoSnapshots = new ArrayList<>(stateBackend.kvStateInformation.size());\n\n\t\t\tthis.copiedColumnFamilyHandles = new ArrayList<>(stateBackend.kvStateInformation.size());\n\n\t\t\tfor (Tuple2<ColumnFamilyHandle, RegisteredKeyedBackendStateMetaInfo<?, ?>> tuple2 :\n\t\t\t\tstateBackend.kvStateInformation.values()) {\n\t\t\t\t// snapshot meta info\n\t\t\t\tthis.stateMetaInfoSnapshots.add(tuple2.f1.snapshot());\n\n\t\t\t\t// copy column family handle\n\t\t\t\tthis.copiedColumnFamilyHandles.add(tuple2.f0);\n\t\t\t}\n\t\t\tthis.snapshot = stateBackend.db.getSnapshot();\n\t\t}"
        ]
    ],
    "727370aacf63cefc6aed7c46dc2d63517e4b708d": [
        [
            "CheckpointCoordinator::restoreSavepoint(String,boolean,Map,ClassLoader)",
            "1059  \n1060  \n1061  \n1062  \n1063  \n1064  \n1065  \n1066  \n1067  \n1068  \n1069  \n1070  \n1071  \n1072  \n1073  \n1074  \n1075  \n1076  \n1077  \n1078  \n1079 -\n1080 -\n1081  \n1082  \n1083  \n1084  \n1085  \n1086  \n1087  \n1088  \n1089  \n1090  \n1091  \n1092  \n1093  \n1094 -\n1095  \n1096  \n1097  ",
            "\t/**\n\t * Restore the state with given savepoint.\n\t *\n\t * @param savepointPointer The pointer to the savepoint.\n\t * @param allowNonRestored True if allowing checkpoint state that cannot be\n\t *                         mapped to any job vertex in tasks.\n\t * @param tasks            Map of job vertices to restore. State for these\n\t *                         vertices is restored via\n\t *                         {@link Execution#setInitialState(JobManagerTaskRestore)}.\n\t * @param userClassLoader  The class loader to resolve serialized classes in\n\t *                         legacy savepoint versions.\n\t */\n\tpublic boolean restoreSavepoint(\n\t\t\tString savepointPointer,\n\t\t\tboolean allowNonRestored,\n\t\t\tMap<JobVertexID, ExecutionJobVertex> tasks,\n\t\t\tClassLoader userClassLoader) throws Exception {\n\n\t\tPreconditions.checkNotNull(savepointPointer, \"The savepoint path cannot be null.\");\n\n\t\tLOG.info(\"Starting job from savepoint {} ({})\",\n\t\t\t\tsavepointPointer, (allowNonRestored ? \"allowing non restored state\" : \"\"));\n\n\t\tfinal CompletedCheckpointStorageLocation checkpointLocation = checkpointStorage.resolveCheckpoint(savepointPointer);\n\n\t\t// Load the savepoint as a checkpoint into the system\n\t\tCompletedCheckpoint savepoint = Checkpoints.loadAndValidateCheckpoint(\n\t\t\t\tjob, tasks, checkpointLocation, userClassLoader, allowNonRestored);\n\n\t\tcompletedCheckpointStore.addCheckpoint(savepoint);\n\n\t\t// Reset the checkpoint ID counter\n\t\tlong nextCheckpointId = savepoint.getCheckpointID() + 1;\n\t\tcheckpointIdCounter.setCount(nextCheckpointId);\n\n\t\tLOG.info(\"Reset the checkpoint ID to {}.\", nextCheckpointId);\n\n\t\treturn restoreLatestCheckpointedState(tasks, true, allowNonRestored);\n\t}",
            "1064  \n1065  \n1066  \n1067  \n1068  \n1069  \n1070  \n1071  \n1072  \n1073  \n1074  \n1075  \n1076  \n1077  \n1078  \n1079  \n1080  \n1081  \n1082  \n1083  \n1084 +\n1085 +\n1086  \n1087  \n1088  \n1089  \n1090  \n1091  \n1092  \n1093  \n1094  \n1095  \n1096  \n1097  \n1098  \n1099 +\n1100  \n1101  \n1102  ",
            "\t/**\n\t * Restore the state with given savepoint.\n\t *\n\t * @param savepointPointer The pointer to the savepoint.\n\t * @param allowNonRestored True if allowing checkpoint state that cannot be\n\t *                         mapped to any job vertex in tasks.\n\t * @param tasks            Map of job vertices to restore. State for these\n\t *                         vertices is restored via\n\t *                         {@link Execution#setInitialState(JobManagerTaskRestore)}.\n\t * @param userClassLoader  The class loader to resolve serialized classes in\n\t *                         legacy savepoint versions.\n\t */\n\tpublic boolean restoreSavepoint(\n\t\t\tString savepointPointer,\n\t\t\tboolean allowNonRestored,\n\t\t\tMap<JobVertexID, ExecutionJobVertex> tasks,\n\t\t\tClassLoader userClassLoader) throws Exception {\n\n\t\tPreconditions.checkNotNull(savepointPointer, \"The savepoint path cannot be null.\");\n\n\t\tLOG.info(\"Starting job {} from savepoint {} ({})\",\n\t\t\t\tjob, savepointPointer, (allowNonRestored ? \"allowing non restored state\" : \"\"));\n\n\t\tfinal CompletedCheckpointStorageLocation checkpointLocation = checkpointStorage.resolveCheckpoint(savepointPointer);\n\n\t\t// Load the savepoint as a checkpoint into the system\n\t\tCompletedCheckpoint savepoint = Checkpoints.loadAndValidateCheckpoint(\n\t\t\t\tjob, tasks, checkpointLocation, userClassLoader, allowNonRestored);\n\n\t\tcompletedCheckpointStore.addCheckpoint(savepoint);\n\n\t\t// Reset the checkpoint ID counter\n\t\tlong nextCheckpointId = savepoint.getCheckpointID() + 1;\n\t\tcheckpointIdCounter.setCount(nextCheckpointId);\n\n\t\tLOG.info(\"Reset the checkpoint ID of job {} to {}.\", job, nextCheckpointId);\n\n\t\treturn restoreLatestCheckpointedState(tasks, true, allowNonRestored);\n\t}"
        ],
        [
            "CheckpointCoordinator::receiveDeclineMessage(DeclineCheckpoint)",
            " 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676 -\n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687 -\n 688 -\n 689  \n 690  \n 691 -\n 692 -\n 693  \n 694  \n 695  \n 696  ",
            "\t/**\n\t * Receives a {@link DeclineCheckpoint} message for a pending checkpoint.\n\t *\n\t * @param message Checkpoint decline from the task manager\n\t */\n\tpublic void receiveDeclineMessage(DeclineCheckpoint message) {\n\t\tif (shutdown || message == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (!job.equals(message.getJob())) {\n\t\t\tthrow new IllegalArgumentException(\"Received DeclineCheckpoint message for job \" +\n\t\t\t\tmessage.getJob() + \" while this coordinator handles job \" + job);\n\t\t}\n\n\t\tfinal long checkpointId = message.getCheckpointId();\n\t\tfinal String reason = (message.getReason() != null ? message.getReason().getMessage() : \"\");\n\n\t\tPendingCheckpoint checkpoint;\n\n\t\tsynchronized (lock) {\n\t\t\t// we need to check inside the lock for being shutdown as well, otherwise we\n\t\t\t// get races and invalid error log messages\n\t\t\tif (shutdown) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tcheckpoint = pendingCheckpoints.remove(checkpointId);\n\n\t\t\tif (checkpoint != null && !checkpoint.isDiscarded()) {\n\t\t\t\tLOG.info(\"Decline checkpoint {} by task {}.\", checkpointId, message.getTaskExecutionId());\n\t\t\t\tdiscardCheckpoint(checkpoint, message.getReason());\n\t\t\t}\n\t\t\telse if (checkpoint != null) {\n\t\t\t\t// this should not happen\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\"Received message for discarded but non-removed checkpoint \" + checkpointId);\n\t\t\t}\n\t\t\telse if (LOG.isDebugEnabled()) {\n\t\t\t\tif (recentPendingCheckpoints.contains(checkpointId)) {\n\t\t\t\t\t// message is for an unknown checkpoint, or comes too late (checkpoint disposed)\n\t\t\t\t\tLOG.debug(\"Received another decline message for now expired checkpoint attempt {} : {}\",\n\t\t\t\t\t\t\tcheckpointId, reason);\n\t\t\t\t} else {\n\t\t\t\t\t// message is for an unknown checkpoint. might be so old that we don't even remember it any more\n\t\t\t\t\tLOG.debug(\"Received decline message for unknown (too old?) checkpoint attempt {} : {}\",\n\t\t\t\t\t\t\tcheckpointId, reason);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
            " 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681 +\n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692 +\n 693 +\n 694  \n 695  \n 696 +\n 697 +\n 698  \n 699  \n 700  \n 701  ",
            "\t/**\n\t * Receives a {@link DeclineCheckpoint} message for a pending checkpoint.\n\t *\n\t * @param message Checkpoint decline from the task manager\n\t */\n\tpublic void receiveDeclineMessage(DeclineCheckpoint message) {\n\t\tif (shutdown || message == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (!job.equals(message.getJob())) {\n\t\t\tthrow new IllegalArgumentException(\"Received DeclineCheckpoint message for job \" +\n\t\t\t\tmessage.getJob() + \" while this coordinator handles job \" + job);\n\t\t}\n\n\t\tfinal long checkpointId = message.getCheckpointId();\n\t\tfinal String reason = (message.getReason() != null ? message.getReason().getMessage() : \"\");\n\n\t\tPendingCheckpoint checkpoint;\n\n\t\tsynchronized (lock) {\n\t\t\t// we need to check inside the lock for being shutdown as well, otherwise we\n\t\t\t// get races and invalid error log messages\n\t\t\tif (shutdown) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tcheckpoint = pendingCheckpoints.remove(checkpointId);\n\n\t\t\tif (checkpoint != null && !checkpoint.isDiscarded()) {\n\t\t\t\tLOG.info(\"Decline checkpoint {} by task {} of job {}.\", checkpointId, message.getTaskExecutionId(), job);\n\t\t\t\tdiscardCheckpoint(checkpoint, message.getReason());\n\t\t\t}\n\t\t\telse if (checkpoint != null) {\n\t\t\t\t// this should not happen\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\"Received message for discarded but non-removed checkpoint \" + checkpointId);\n\t\t\t}\n\t\t\telse if (LOG.isDebugEnabled()) {\n\t\t\t\tif (recentPendingCheckpoints.contains(checkpointId)) {\n\t\t\t\t\t// message is for an unknown checkpoint, or comes too late (checkpoint disposed)\n\t\t\t\t\tLOG.debug(\"Received another decline message for now expired checkpoint attempt {} of job {} : {}\",\n\t\t\t\t\t\t\tcheckpointId, job, reason);\n\t\t\t\t} else {\n\t\t\t\t\t// message is for an unknown checkpoint. might be so old that we don't even remember it any more\n\t\t\t\t\tLOG.debug(\"Received decline message for unknown (too old?) checkpoint attempt {} of job {} : {}\",\n\t\t\t\t\t\t\tcheckpointId, job, reason);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "CheckpointCoordinator::discardCheckpoint(PendingCheckpoint,Throwable)",
            "1222  \n1223  \n1224  \n1225  \n1226  \n1227  \n1228  \n1229  \n1230  \n1231  \n1232  \n1233  \n1234  \n1235  \n1236 -\n1237  \n1238  \n1239  \n1240  \n1241  \n1242  \n1243  \n1244  \n1245  \n1246  \n1247  \n1248  \n1249  \n1250  \n1251  \n1252  \n1253  \n1254  \n1255  \n1256  ",
            "\t/**\n\t * Discards the given pending checkpoint because of the given cause.\n\t *\n\t * @param pendingCheckpoint to discard\n\t * @param cause for discarding the checkpoint\n\t */\n\tprivate void discardCheckpoint(PendingCheckpoint pendingCheckpoint, @Nullable Throwable cause) {\n\t\tassert(Thread.holdsLock(lock));\n\t\tPreconditions.checkNotNull(pendingCheckpoint);\n\n\t\tfinal long checkpointId = pendingCheckpoint.getCheckpointId();\n\n\t\tfinal String reason = (cause != null) ? cause.getMessage() : \"\";\n\n\t\tLOG.info(\"Discarding checkpoint {} because: {}\", checkpointId, reason);\n\n\t\tpendingCheckpoint.abortDeclined();\n\t\trememberRecentCheckpointId(checkpointId);\n\n\t\t// we don't have to schedule another \"dissolving\" checkpoint any more because the\n\t\t// cancellation barriers take care of breaking downstream alignments\n\t\t// we only need to make sure that suspended queued requests are resumed\n\n\t\tboolean haveMoreRecentPending = false;\n\t\tfor (PendingCheckpoint p : pendingCheckpoints.values()) {\n\t\t\tif (!p.isDiscarded() && p.getCheckpointId() >= pendingCheckpoint.getCheckpointId()) {\n\t\t\t\thaveMoreRecentPending = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!haveMoreRecentPending) {\n\t\t\ttriggerQueuedRequests();\n\t\t}\n\t}",
            "1227  \n1228  \n1229  \n1230  \n1231  \n1232  \n1233  \n1234  \n1235  \n1236  \n1237  \n1238  \n1239  \n1240  \n1241 +\n1242  \n1243  \n1244  \n1245  \n1246  \n1247  \n1248  \n1249  \n1250  \n1251  \n1252  \n1253  \n1254  \n1255  \n1256  \n1257  \n1258  \n1259  \n1260  \n1261  ",
            "\t/**\n\t * Discards the given pending checkpoint because of the given cause.\n\t *\n\t * @param pendingCheckpoint to discard\n\t * @param cause for discarding the checkpoint\n\t */\n\tprivate void discardCheckpoint(PendingCheckpoint pendingCheckpoint, @Nullable Throwable cause) {\n\t\tassert(Thread.holdsLock(lock));\n\t\tPreconditions.checkNotNull(pendingCheckpoint);\n\n\t\tfinal long checkpointId = pendingCheckpoint.getCheckpointId();\n\n\t\tfinal String reason = (cause != null) ? cause.getMessage() : \"\";\n\n\t\tLOG.info(\"Discarding checkpoint {} of job {} because: {}\", checkpointId, job, reason);\n\n\t\tpendingCheckpoint.abortDeclined();\n\t\trememberRecentCheckpointId(checkpointId);\n\n\t\t// we don't have to schedule another \"dissolving\" checkpoint any more because the\n\t\t// cancellation barriers take care of breaking downstream alignments\n\t\t// we only need to make sure that suspended queued requests are resumed\n\n\t\tboolean haveMoreRecentPending = false;\n\t\tfor (PendingCheckpoint p : pendingCheckpoints.values()) {\n\t\t\tif (!p.isDiscarded() && p.getCheckpointId() >= pendingCheckpoint.getCheckpointId()) {\n\t\t\t\thaveMoreRecentPending = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!haveMoreRecentPending) {\n\t\t\ttriggerQueuedRequests();\n\t\t}\n\t}"
        ],
        [
            "CheckpointCoordinator::triggerCheckpoint(long,CheckpointProperties,String,boolean)",
            " 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417 -\n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458 -\n 459 -\n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473 -\n 474 -\n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501 -\n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529 -\n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550 -\n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582 -\n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623 -\n 624 -\n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  ",
            "\t@VisibleForTesting\n\tpublic CheckpointTriggerResult triggerCheckpoint(\n\t\t\tlong timestamp,\n\t\t\tCheckpointProperties props,\n\t\t\t@Nullable String externalSavepointLocation,\n\t\t\tboolean isPeriodic) {\n\n\t\t// make some eager pre-checks\n\t\tsynchronized (lock) {\n\t\t\t// abort if the coordinator has been shutdown in the meantime\n\t\t\tif (shutdown) {\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.COORDINATOR_SHUTDOWN);\n\t\t\t}\n\n\t\t\t// Don't allow periodic checkpoint if scheduling has been disabled\n\t\t\tif (isPeriodic && !periodicScheduling) {\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.PERIODIC_SCHEDULER_SHUTDOWN);\n\t\t\t}\n\n\t\t\t// validate whether the checkpoint can be triggered, with respect to the limit of\n\t\t\t// concurrent checkpoints, and the minimum time between checkpoints.\n\t\t\t// these checks are not relevant for savepoints\n\t\t\tif (!props.forceCheckpoint()) {\n\t\t\t\t// sanity check: there should never be more than one trigger request queued\n\t\t\t\tif (triggerRequestQueued) {\n\t\t\t\t\tLOG.warn(\"Trying to trigger another checkpoint while one was queued already\");\n\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.ALREADY_QUEUED);\n\t\t\t\t}\n\n\t\t\t\t// if too many checkpoints are currently in progress, we need to mark that a request is queued\n\t\t\t\tif (pendingCheckpoints.size() >= maxConcurrentCheckpointAttempts) {\n\t\t\t\t\ttriggerRequestQueued = true;\n\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t}\n\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.TOO_MANY_CONCURRENT_CHECKPOINTS);\n\t\t\t\t}\n\n\t\t\t\t// make sure the minimum interval between checkpoints has passed\n\t\t\t\tfinal long earliestNext = lastCheckpointCompletionNanos + minPauseBetweenCheckpointsNanos;\n\t\t\t\tfinal long durationTillNextMillis = (earliestNext - System.nanoTime()) / 1_000_000;\n\n\t\t\t\tif (durationTillNextMillis > 0) {\n\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t}\n\t\t\t\t\t// Reassign the new trigger to the currentPeriodicTrigger\n\t\t\t\t\tcurrentPeriodicTrigger = timer.scheduleAtFixedRate(\n\t\t\t\t\t\t\tnew ScheduledTrigger(),\n\t\t\t\t\t\t\tdurationTillNextMillis, baseInterval, TimeUnit.MILLISECONDS);\n\n\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.MINIMUM_TIME_BETWEEN_CHECKPOINTS);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// check if all tasks that we need to trigger are running.\n\t\t// if not, abort the checkpoint\n\t\tExecution[] executions = new Execution[tasksToTrigger.length];\n\t\tfor (int i = 0; i < tasksToTrigger.length; i++) {\n\t\t\tExecution ee = tasksToTrigger[i].getCurrentExecutionAttempt();\n\t\t\tif (ee != null && ee.getState() == ExecutionState.RUNNING) {\n\t\t\t\texecutions[i] = ee;\n\t\t\t} else {\n\t\t\t\tLOG.info(\"Checkpoint triggering task {} is not being executed at the moment. Aborting checkpoint.\",\n\t\t\t\t\t\ttasksToTrigger[i].getTaskNameWithSubtaskIndex());\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.NOT_ALL_REQUIRED_TASKS_RUNNING);\n\t\t\t}\n\t\t}\n\n\t\t// next, check if all tasks that need to acknowledge the checkpoint are running.\n\t\t// if not, abort the checkpoint\n\t\tMap<ExecutionAttemptID, ExecutionVertex> ackTasks = new HashMap<>(tasksToWaitFor.length);\n\n\t\tfor (ExecutionVertex ev : tasksToWaitFor) {\n\t\t\tExecution ee = ev.getCurrentExecutionAttempt();\n\t\t\tif (ee != null) {\n\t\t\t\tackTasks.put(ee.getAttemptId(), ev);\n\t\t\t} else {\n\t\t\t\tLOG.info(\"Checkpoint acknowledging task {} is not being executed at the moment. Aborting checkpoint.\",\n\t\t\t\t\t\tev.getTaskNameWithSubtaskIndex());\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.NOT_ALL_REQUIRED_TASKS_RUNNING);\n\t\t\t}\n\t\t}\n\n\t\t// we will actually trigger this checkpoint!\n\n\t\t// we lock with a special lock to make sure that trigger requests do not overtake each other.\n\t\t// this is not done with the coordinator-wide lock, because the 'checkpointIdCounter'\n\t\t// may issue blocking operations. Using a different lock than the coordinator-wide lock,\n\t\t// we avoid blocking the processing of 'acknowledge/decline' messages during that time.\n\t\tsynchronized (triggerLock) {\n\n\t\t\tfinal CheckpointStorageLocation checkpointStorageLocation;\n\t\t\tfinal long checkpointID;\n\n\t\t\ttry {\n\t\t\t\t// this must happen outside the coordinator-wide lock, because it communicates\n\t\t\t\t// with external services (in HA mode) and may block for a while.\n\t\t\t\tcheckpointID = checkpointIdCounter.getAndIncrement();\n\n\t\t\t\tcheckpointStorageLocation = props.isSavepoint() ?\n\t\t\t\t\t\tcheckpointStorage.initializeLocationForSavepoint(checkpointID, externalSavepointLocation) :\n\t\t\t\t\t\tcheckpointStorage.initializeLocationForCheckpoint(checkpointID);\n\t\t\t}\n\t\t\tcatch (Throwable t) {\n\t\t\t\tint numUnsuccessful = numUnsuccessfulCheckpointsTriggers.incrementAndGet();\n\t\t\t\tLOG.warn(\"Failed to trigger checkpoint (\" + numUnsuccessful + \" consecutive failed attempts so far)\", t);\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.EXCEPTION);\n\t\t\t}\n\n\t\t\tfinal PendingCheckpoint checkpoint = new PendingCheckpoint(\n\t\t\t\tjob,\n\t\t\t\tcheckpointID,\n\t\t\t\ttimestamp,\n\t\t\t\tackTasks,\n\t\t\t\tprops,\n\t\t\t\tcheckpointStorageLocation,\n\t\t\t\texecutor);\n\n\t\t\tif (statsTracker != null) {\n\t\t\t\tPendingCheckpointStats callback = statsTracker.reportPendingCheckpoint(\n\t\t\t\t\tcheckpointID,\n\t\t\t\t\ttimestamp,\n\t\t\t\t\tprops);\n\n\t\t\t\tcheckpoint.setStatsCallback(callback);\n\t\t\t}\n\n\t\t\t// schedule the timer that will clean up the expired checkpoints\n\t\t\tfinal Runnable canceller = () -> {\n\t\t\t\tsynchronized (lock) {\n\t\t\t\t\t// only do the work if the checkpoint is not discarded anyways\n\t\t\t\t\t// note that checkpoint completion discards the pending checkpoint object\n\t\t\t\t\tif (!checkpoint.isDiscarded()) {\n\t\t\t\t\t\tLOG.info(\"Checkpoint \" + checkpointID + \" expired before completing.\");\n\n\t\t\t\t\t\tcheckpoint.abortExpired();\n\t\t\t\t\t\tpendingCheckpoints.remove(checkpointID);\n\t\t\t\t\t\trememberRecentCheckpointId(checkpointID);\n\n\t\t\t\t\t\ttriggerQueuedRequests();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\t// re-acquire the coordinator-wide lock\n\t\t\t\tsynchronized (lock) {\n\t\t\t\t\t// since we released the lock in the meantime, we need to re-check\n\t\t\t\t\t// that the conditions still hold.\n\t\t\t\t\tif (shutdown) {\n\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.COORDINATOR_SHUTDOWN);\n\t\t\t\t\t}\n\t\t\t\t\telse if (!props.forceCheckpoint()) {\n\t\t\t\t\t\tif (triggerRequestQueued) {\n\t\t\t\t\t\t\tLOG.warn(\"Trying to trigger another checkpoint while one was queued already\");\n\t\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.ALREADY_QUEUED);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (pendingCheckpoints.size() >= maxConcurrentCheckpointAttempts) {\n\t\t\t\t\t\t\ttriggerRequestQueued = true;\n\t\t\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.TOO_MANY_CONCURRENT_CHECKPOINTS);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// make sure the minimum interval between checkpoints has passed\n\t\t\t\t\t\tfinal long earliestNext = lastCheckpointCompletionNanos + minPauseBetweenCheckpointsNanos;\n\t\t\t\t\t\tfinal long durationTillNextMillis = (earliestNext - System.nanoTime()) / 1_000_000;\n\n\t\t\t\t\t\tif (durationTillNextMillis > 0) {\n\t\t\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Reassign the new trigger to the currentPeriodicTrigger\n\t\t\t\t\t\t\tcurrentPeriodicTrigger = timer.scheduleAtFixedRate(\n\t\t\t\t\t\t\t\t\tnew ScheduledTrigger(),\n\t\t\t\t\t\t\t\t\tdurationTillNextMillis, baseInterval, TimeUnit.MILLISECONDS);\n\n\t\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.MINIMUM_TIME_BETWEEN_CHECKPOINTS);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tLOG.info(\"Triggering checkpoint \" + checkpointID + \" @ \" + timestamp);\n\n\t\t\t\t\tpendingCheckpoints.put(checkpointID, checkpoint);\n\n\t\t\t\t\tScheduledFuture<?> cancellerHandle = timer.schedule(\n\t\t\t\t\t\t\tcanceller,\n\t\t\t\t\t\t\tcheckpointTimeout, TimeUnit.MILLISECONDS);\n\n\t\t\t\t\tif (!checkpoint.setCancellerHandle(cancellerHandle)) {\n\t\t\t\t\t\t// checkpoint is already disposed!\n\t\t\t\t\t\tcancellerHandle.cancel(false);\n\t\t\t\t\t}\n\n\t\t\t\t\t// trigger the master hooks for the checkpoint\n\t\t\t\t\tfinal List<MasterState> masterStates = MasterHooks.triggerMasterHooks(masterHooks.values(),\n\t\t\t\t\t\t\tcheckpointID, timestamp, executor, Time.milliseconds(checkpointTimeout));\n\t\t\t\t\tfor (MasterState s : masterStates) {\n\t\t\t\t\t\tcheckpoint.addMasterState(s);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// end of lock scope\n\n\t\t\t\tfinal CheckpointOptions checkpointOptions = new CheckpointOptions(\n\t\t\t\t\t\tprops.getCheckpointType(),\n\t\t\t\t\t\tcheckpointStorageLocation.getLocationReference());\n\n\t\t\t\t// send the messages to the tasks that trigger their checkpoint\n\t\t\t\tfor (Execution execution: executions) {\n\t\t\t\t\texecution.triggerCheckpoint(checkpointID, timestamp, checkpointOptions);\n\t\t\t\t}\n\n\t\t\t\tnumUnsuccessfulCheckpointsTriggers.set(0);\n\t\t\t\treturn new CheckpointTriggerResult(checkpoint);\n\t\t\t}\n\t\t\tcatch (Throwable t) {\n\t\t\t\t// guard the map against concurrent modifications\n\t\t\t\tsynchronized (lock) {\n\t\t\t\t\tpendingCheckpoints.remove(checkpointID);\n\t\t\t\t}\n\n\t\t\t\tint numUnsuccessful = numUnsuccessfulCheckpointsTriggers.incrementAndGet();\n\t\t\t\tLOG.warn(\"Failed to trigger checkpoint {}. ({} consecutive failed attempts so far)\",\n\t\t\t\t\t\tcheckpointID, numUnsuccessful, t);\n\n\t\t\t\tif (!checkpoint.isDiscarded()) {\n\t\t\t\t\tcheckpoint.abortError(new Exception(\"Failed to trigger checkpoint\", t));\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tcheckpointStorageLocation.disposeOnFailure();\n\t\t\t\t}\n\t\t\t\tcatch (Throwable t2) {\n\t\t\t\t\tLOG.warn(\"Cannot dispose failed checkpoint storage location {}\", checkpointStorageLocation, t2);\n\t\t\t\t}\n\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.EXCEPTION);\n\t\t\t}\n\n\t\t} // end trigger lock\n\t}",
            " 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417 +\n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458 +\n 459 +\n 460 +\n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474 +\n 475 +\n 476 +\n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503 +\n 504 +\n 505 +\n 506 +\n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534 +\n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555 +\n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587 +\n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628 +\n 629 +\n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  ",
            "\t@VisibleForTesting\n\tpublic CheckpointTriggerResult triggerCheckpoint(\n\t\t\tlong timestamp,\n\t\t\tCheckpointProperties props,\n\t\t\t@Nullable String externalSavepointLocation,\n\t\t\tboolean isPeriodic) {\n\n\t\t// make some eager pre-checks\n\t\tsynchronized (lock) {\n\t\t\t// abort if the coordinator has been shutdown in the meantime\n\t\t\tif (shutdown) {\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.COORDINATOR_SHUTDOWN);\n\t\t\t}\n\n\t\t\t// Don't allow periodic checkpoint if scheduling has been disabled\n\t\t\tif (isPeriodic && !periodicScheduling) {\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.PERIODIC_SCHEDULER_SHUTDOWN);\n\t\t\t}\n\n\t\t\t// validate whether the checkpoint can be triggered, with respect to the limit of\n\t\t\t// concurrent checkpoints, and the minimum time between checkpoints.\n\t\t\t// these checks are not relevant for savepoints\n\t\t\tif (!props.forceCheckpoint()) {\n\t\t\t\t// sanity check: there should never be more than one trigger request queued\n\t\t\t\tif (triggerRequestQueued) {\n\t\t\t\t\tLOG.warn(\"Trying to trigger another checkpoint for job {} while one was queued already.\", job);\n\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.ALREADY_QUEUED);\n\t\t\t\t}\n\n\t\t\t\t// if too many checkpoints are currently in progress, we need to mark that a request is queued\n\t\t\t\tif (pendingCheckpoints.size() >= maxConcurrentCheckpointAttempts) {\n\t\t\t\t\ttriggerRequestQueued = true;\n\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t}\n\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.TOO_MANY_CONCURRENT_CHECKPOINTS);\n\t\t\t\t}\n\n\t\t\t\t// make sure the minimum interval between checkpoints has passed\n\t\t\t\tfinal long earliestNext = lastCheckpointCompletionNanos + minPauseBetweenCheckpointsNanos;\n\t\t\t\tfinal long durationTillNextMillis = (earliestNext - System.nanoTime()) / 1_000_000;\n\n\t\t\t\tif (durationTillNextMillis > 0) {\n\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t}\n\t\t\t\t\t// Reassign the new trigger to the currentPeriodicTrigger\n\t\t\t\t\tcurrentPeriodicTrigger = timer.scheduleAtFixedRate(\n\t\t\t\t\t\t\tnew ScheduledTrigger(),\n\t\t\t\t\t\t\tdurationTillNextMillis, baseInterval, TimeUnit.MILLISECONDS);\n\n\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.MINIMUM_TIME_BETWEEN_CHECKPOINTS);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// check if all tasks that we need to trigger are running.\n\t\t// if not, abort the checkpoint\n\t\tExecution[] executions = new Execution[tasksToTrigger.length];\n\t\tfor (int i = 0; i < tasksToTrigger.length; i++) {\n\t\t\tExecution ee = tasksToTrigger[i].getCurrentExecutionAttempt();\n\t\t\tif (ee != null && ee.getState() == ExecutionState.RUNNING) {\n\t\t\t\texecutions[i] = ee;\n\t\t\t} else {\n\t\t\t\tLOG.info(\"Checkpoint triggering task {} of job {} is not being executed at the moment. Aborting checkpoint.\",\n\t\t\t\t\t\ttasksToTrigger[i].getTaskNameWithSubtaskIndex(),\n\t\t\t\t\t\tjob);\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.NOT_ALL_REQUIRED_TASKS_RUNNING);\n\t\t\t}\n\t\t}\n\n\t\t// next, check if all tasks that need to acknowledge the checkpoint are running.\n\t\t// if not, abort the checkpoint\n\t\tMap<ExecutionAttemptID, ExecutionVertex> ackTasks = new HashMap<>(tasksToWaitFor.length);\n\n\t\tfor (ExecutionVertex ev : tasksToWaitFor) {\n\t\t\tExecution ee = ev.getCurrentExecutionAttempt();\n\t\t\tif (ee != null) {\n\t\t\t\tackTasks.put(ee.getAttemptId(), ev);\n\t\t\t} else {\n\t\t\t\tLOG.info(\"Checkpoint acknowledging task {} of job {} is not being executed at the moment. Aborting checkpoint.\",\n\t\t\t\t\t\tev.getTaskNameWithSubtaskIndex(),\n\t\t\t\t\t\tjob);\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.NOT_ALL_REQUIRED_TASKS_RUNNING);\n\t\t\t}\n\t\t}\n\n\t\t// we will actually trigger this checkpoint!\n\n\t\t// we lock with a special lock to make sure that trigger requests do not overtake each other.\n\t\t// this is not done with the coordinator-wide lock, because the 'checkpointIdCounter'\n\t\t// may issue blocking operations. Using a different lock than the coordinator-wide lock,\n\t\t// we avoid blocking the processing of 'acknowledge/decline' messages during that time.\n\t\tsynchronized (triggerLock) {\n\n\t\t\tfinal CheckpointStorageLocation checkpointStorageLocation;\n\t\t\tfinal long checkpointID;\n\n\t\t\ttry {\n\t\t\t\t// this must happen outside the coordinator-wide lock, because it communicates\n\t\t\t\t// with external services (in HA mode) and may block for a while.\n\t\t\t\tcheckpointID = checkpointIdCounter.getAndIncrement();\n\n\t\t\t\tcheckpointStorageLocation = props.isSavepoint() ?\n\t\t\t\t\t\tcheckpointStorage.initializeLocationForSavepoint(checkpointID, externalSavepointLocation) :\n\t\t\t\t\t\tcheckpointStorage.initializeLocationForCheckpoint(checkpointID);\n\t\t\t}\n\t\t\tcatch (Throwable t) {\n\t\t\t\tint numUnsuccessful = numUnsuccessfulCheckpointsTriggers.incrementAndGet();\n\t\t\t\tLOG.warn(\"Failed to trigger checkpoint for job {} ({} consecutive failed attempts so far).\",\n\t\t\t\t\t\tjob,\n\t\t\t\t\t\tnumUnsuccessful,\n\t\t\t\t\t\tt);\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.EXCEPTION);\n\t\t\t}\n\n\t\t\tfinal PendingCheckpoint checkpoint = new PendingCheckpoint(\n\t\t\t\tjob,\n\t\t\t\tcheckpointID,\n\t\t\t\ttimestamp,\n\t\t\t\tackTasks,\n\t\t\t\tprops,\n\t\t\t\tcheckpointStorageLocation,\n\t\t\t\texecutor);\n\n\t\t\tif (statsTracker != null) {\n\t\t\t\tPendingCheckpointStats callback = statsTracker.reportPendingCheckpoint(\n\t\t\t\t\tcheckpointID,\n\t\t\t\t\ttimestamp,\n\t\t\t\t\tprops);\n\n\t\t\t\tcheckpoint.setStatsCallback(callback);\n\t\t\t}\n\n\t\t\t// schedule the timer that will clean up the expired checkpoints\n\t\t\tfinal Runnable canceller = () -> {\n\t\t\t\tsynchronized (lock) {\n\t\t\t\t\t// only do the work if the checkpoint is not discarded anyways\n\t\t\t\t\t// note that checkpoint completion discards the pending checkpoint object\n\t\t\t\t\tif (!checkpoint.isDiscarded()) {\n\t\t\t\t\t\tLOG.info(\"Checkpoint {} of job {} expired before completing.\", checkpointID, job);\n\n\t\t\t\t\t\tcheckpoint.abortExpired();\n\t\t\t\t\t\tpendingCheckpoints.remove(checkpointID);\n\t\t\t\t\t\trememberRecentCheckpointId(checkpointID);\n\n\t\t\t\t\t\ttriggerQueuedRequests();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\t// re-acquire the coordinator-wide lock\n\t\t\t\tsynchronized (lock) {\n\t\t\t\t\t// since we released the lock in the meantime, we need to re-check\n\t\t\t\t\t// that the conditions still hold.\n\t\t\t\t\tif (shutdown) {\n\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.COORDINATOR_SHUTDOWN);\n\t\t\t\t\t}\n\t\t\t\t\telse if (!props.forceCheckpoint()) {\n\t\t\t\t\t\tif (triggerRequestQueued) {\n\t\t\t\t\t\t\tLOG.warn(\"Trying to trigger another checkpoint for job {} while one was queued already.\", job);\n\t\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.ALREADY_QUEUED);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (pendingCheckpoints.size() >= maxConcurrentCheckpointAttempts) {\n\t\t\t\t\t\t\ttriggerRequestQueued = true;\n\t\t\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.TOO_MANY_CONCURRENT_CHECKPOINTS);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// make sure the minimum interval between checkpoints has passed\n\t\t\t\t\t\tfinal long earliestNext = lastCheckpointCompletionNanos + minPauseBetweenCheckpointsNanos;\n\t\t\t\t\t\tfinal long durationTillNextMillis = (earliestNext - System.nanoTime()) / 1_000_000;\n\n\t\t\t\t\t\tif (durationTillNextMillis > 0) {\n\t\t\t\t\t\t\tif (currentPeriodicTrigger != null) {\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger.cancel(false);\n\t\t\t\t\t\t\t\tcurrentPeriodicTrigger = null;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Reassign the new trigger to the currentPeriodicTrigger\n\t\t\t\t\t\t\tcurrentPeriodicTrigger = timer.scheduleAtFixedRate(\n\t\t\t\t\t\t\t\t\tnew ScheduledTrigger(),\n\t\t\t\t\t\t\t\t\tdurationTillNextMillis, baseInterval, TimeUnit.MILLISECONDS);\n\n\t\t\t\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.MINIMUM_TIME_BETWEEN_CHECKPOINTS);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tLOG.info(\"Triggering checkpoint {} @ {} for job {}.\", checkpointID, timestamp, job);\n\n\t\t\t\t\tpendingCheckpoints.put(checkpointID, checkpoint);\n\n\t\t\t\t\tScheduledFuture<?> cancellerHandle = timer.schedule(\n\t\t\t\t\t\t\tcanceller,\n\t\t\t\t\t\t\tcheckpointTimeout, TimeUnit.MILLISECONDS);\n\n\t\t\t\t\tif (!checkpoint.setCancellerHandle(cancellerHandle)) {\n\t\t\t\t\t\t// checkpoint is already disposed!\n\t\t\t\t\t\tcancellerHandle.cancel(false);\n\t\t\t\t\t}\n\n\t\t\t\t\t// trigger the master hooks for the checkpoint\n\t\t\t\t\tfinal List<MasterState> masterStates = MasterHooks.triggerMasterHooks(masterHooks.values(),\n\t\t\t\t\t\t\tcheckpointID, timestamp, executor, Time.milliseconds(checkpointTimeout));\n\t\t\t\t\tfor (MasterState s : masterStates) {\n\t\t\t\t\t\tcheckpoint.addMasterState(s);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// end of lock scope\n\n\t\t\t\tfinal CheckpointOptions checkpointOptions = new CheckpointOptions(\n\t\t\t\t\t\tprops.getCheckpointType(),\n\t\t\t\t\t\tcheckpointStorageLocation.getLocationReference());\n\n\t\t\t\t// send the messages to the tasks that trigger their checkpoint\n\t\t\t\tfor (Execution execution: executions) {\n\t\t\t\t\texecution.triggerCheckpoint(checkpointID, timestamp, checkpointOptions);\n\t\t\t\t}\n\n\t\t\t\tnumUnsuccessfulCheckpointsTriggers.set(0);\n\t\t\t\treturn new CheckpointTriggerResult(checkpoint);\n\t\t\t}\n\t\t\tcatch (Throwable t) {\n\t\t\t\t// guard the map against concurrent modifications\n\t\t\t\tsynchronized (lock) {\n\t\t\t\t\tpendingCheckpoints.remove(checkpointID);\n\t\t\t\t}\n\n\t\t\t\tint numUnsuccessful = numUnsuccessfulCheckpointsTriggers.incrementAndGet();\n\t\t\t\tLOG.warn(\"Failed to trigger checkpoint {} for job {}. ({} consecutive failed attempts so far)\",\n\t\t\t\t\t\tcheckpointID, job, numUnsuccessful, t);\n\n\t\t\t\tif (!checkpoint.isDiscarded()) {\n\t\t\t\t\tcheckpoint.abortError(new Exception(\"Failed to trigger checkpoint\", t));\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tcheckpointStorageLocation.disposeOnFailure();\n\t\t\t\t}\n\t\t\t\tcatch (Throwable t2) {\n\t\t\t\t\tLOG.warn(\"Cannot dispose failed checkpoint storage location {}\", checkpointStorageLocation, t2);\n\t\t\t\t}\n\n\t\t\t\treturn new CheckpointTriggerResult(CheckpointDeclineReason.EXCEPTION);\n\t\t\t}\n\n\t\t} // end trigger lock\n\t}"
        ],
        [
            "CheckpointCoordinator::completePendingCheckpoint(PendingCheckpoint)",
            " 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837 -\n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854  \n 855  \n 856  \n 857  \n 858  \n 859  \n 860 -\n 861  \n 862  \n 863  \n 864  \n 865  \n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  ",
            "\t/**\n\t * Try to complete the given pending checkpoint.\n\t *\n\t * <p>Important: This method should only be called in the checkpoint lock scope.\n\t *\n\t * @param pendingCheckpoint to complete\n\t * @throws CheckpointException if the completion failed\n\t */\n\tprivate void completePendingCheckpoint(PendingCheckpoint pendingCheckpoint) throws CheckpointException {\n\t\tfinal long checkpointId = pendingCheckpoint.getCheckpointId();\n\t\tfinal CompletedCheckpoint completedCheckpoint;\n\n\t\t// As a first step to complete the checkpoint, we register its state with the registry\n\t\tMap<OperatorID, OperatorState> operatorStates = pendingCheckpoint.getOperatorStates();\n\t\tsharedStateRegistry.registerAll(operatorStates.values());\n\n\t\ttry {\n\t\t\ttry {\n\t\t\t\tcompletedCheckpoint = pendingCheckpoint.finalizeCheckpoint();\n\t\t\t}\n\t\t\tcatch (Exception e1) {\n\t\t\t\t// abort the current pending checkpoint if we fails to finalize the pending checkpoint.\n\t\t\t\tif (!pendingCheckpoint.isDiscarded()) {\n\t\t\t\t\tpendingCheckpoint.abortError(e1);\n\t\t\t\t}\n\n\t\t\t\tthrow new CheckpointException(\"Could not finalize the pending checkpoint \" + checkpointId + '.', e1);\n\t\t\t}\n\n\t\t\t// the pending checkpoint must be discarded after the finalization\n\t\t\tPreconditions.checkState(pendingCheckpoint.isDiscarded() && completedCheckpoint != null);\n\n\t\t\t// TODO: add savepoints to completed checkpoint store once FLINK-4815 has been completed\n\t\t\tif (!completedCheckpoint.getProperties().isSavepoint()) {\n\t\t\t\ttry {\n\t\t\t\t\tcompletedCheckpointStore.addCheckpoint(completedCheckpoint);\n\t\t\t\t} catch (Exception exception) {\n\t\t\t\t\t// we failed to store the completed checkpoint. Let's clean up\n\t\t\t\t\texecutor.execute(new Runnable() {\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tcompletedCheckpoint.discardOnFailedStoring();\n\t\t\t\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\t\t\t\tLOG.warn(\"Could not properly discard completed checkpoint {}.\", completedCheckpoint.getCheckpointID(), t);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\n\t\t\t\t\tthrow new CheckpointException(\"Could not complete the pending checkpoint \" + checkpointId + '.', exception);\n\t\t\t\t}\n\n\t\t\t\t// drop those pending checkpoints that are at prior to the completed one\n\t\t\t\tdropSubsumedCheckpoints(checkpointId);\n\t\t\t}\n\t\t} finally {\n\t\t\tpendingCheckpoints.remove(checkpointId);\n\n\t\t\ttriggerQueuedRequests();\n\t\t}\n\n\t\trememberRecentCheckpointId(checkpointId);\n\n\t\t// record the time when this was completed, to calculate\n\t\t// the 'min delay between checkpoints'\n\t\tlastCheckpointCompletionNanos = System.nanoTime();\n\n\t\tLOG.info(\"Completed checkpoint {} ({} bytes in {} ms).\", checkpointId,\n\t\t\tcompletedCheckpoint.getStateSize(), completedCheckpoint.getDuration());\n\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tStringBuilder builder = new StringBuilder();\n\t\t\tbuilder.append(\"Checkpoint state: \");\n\t\t\tfor (OperatorState state : completedCheckpoint.getOperatorStates().values()) {\n\t\t\t\tbuilder.append(state);\n\t\t\t\tbuilder.append(\", \");\n\t\t\t}\n\t\t\t// Remove last two chars \", \"\n\t\t\tbuilder.setLength(builder.length() - 2);\n\n\t\t\tLOG.debug(builder.toString());\n\t\t}\n\n\t\t// send the \"notify complete\" call to all vertices\n\t\tfinal long timestamp = completedCheckpoint.getTimestamp();\n\n\t\tfor (ExecutionVertex ev : tasksToCommitTo) {\n\t\t\tExecution ee = ev.getCurrentExecutionAttempt();\n\t\t\tif (ee != null) {\n\t\t\t\tee.notifyCheckpointComplete(checkpointId, timestamp);\n\t\t\t}\n\t\t}\n\t}",
            " 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842 +\n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854  \n 855  \n 856  \n 857  \n 858  \n 859  \n 860  \n 861  \n 862  \n 863  \n 864  \n 865 +\n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  ",
            "\t/**\n\t * Try to complete the given pending checkpoint.\n\t *\n\t * <p>Important: This method should only be called in the checkpoint lock scope.\n\t *\n\t * @param pendingCheckpoint to complete\n\t * @throws CheckpointException if the completion failed\n\t */\n\tprivate void completePendingCheckpoint(PendingCheckpoint pendingCheckpoint) throws CheckpointException {\n\t\tfinal long checkpointId = pendingCheckpoint.getCheckpointId();\n\t\tfinal CompletedCheckpoint completedCheckpoint;\n\n\t\t// As a first step to complete the checkpoint, we register its state with the registry\n\t\tMap<OperatorID, OperatorState> operatorStates = pendingCheckpoint.getOperatorStates();\n\t\tsharedStateRegistry.registerAll(operatorStates.values());\n\n\t\ttry {\n\t\t\ttry {\n\t\t\t\tcompletedCheckpoint = pendingCheckpoint.finalizeCheckpoint();\n\t\t\t}\n\t\t\tcatch (Exception e1) {\n\t\t\t\t// abort the current pending checkpoint if we fails to finalize the pending checkpoint.\n\t\t\t\tif (!pendingCheckpoint.isDiscarded()) {\n\t\t\t\t\tpendingCheckpoint.abortError(e1);\n\t\t\t\t}\n\n\t\t\t\tthrow new CheckpointException(\"Could not finalize the pending checkpoint \" + checkpointId + '.', e1);\n\t\t\t}\n\n\t\t\t// the pending checkpoint must be discarded after the finalization\n\t\t\tPreconditions.checkState(pendingCheckpoint.isDiscarded() && completedCheckpoint != null);\n\n\t\t\t// TODO: add savepoints to completed checkpoint store once FLINK-4815 has been completed\n\t\t\tif (!completedCheckpoint.getProperties().isSavepoint()) {\n\t\t\t\ttry {\n\t\t\t\t\tcompletedCheckpointStore.addCheckpoint(completedCheckpoint);\n\t\t\t\t} catch (Exception exception) {\n\t\t\t\t\t// we failed to store the completed checkpoint. Let's clean up\n\t\t\t\t\texecutor.execute(new Runnable() {\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tcompletedCheckpoint.discardOnFailedStoring();\n\t\t\t\t\t\t\t} catch (Throwable t) {\n\t\t\t\t\t\t\t\tLOG.warn(\"Could not properly discard completed checkpoint {} of job {}.\", completedCheckpoint.getCheckpointID(), job, t);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\n\t\t\t\t\tthrow new CheckpointException(\"Could not complete the pending checkpoint \" + checkpointId + '.', exception);\n\t\t\t\t}\n\n\t\t\t\t// drop those pending checkpoints that are at prior to the completed one\n\t\t\t\tdropSubsumedCheckpoints(checkpointId);\n\t\t\t}\n\t\t} finally {\n\t\t\tpendingCheckpoints.remove(checkpointId);\n\n\t\t\ttriggerQueuedRequests();\n\t\t}\n\n\t\trememberRecentCheckpointId(checkpointId);\n\n\t\t// record the time when this was completed, to calculate\n\t\t// the 'min delay between checkpoints'\n\t\tlastCheckpointCompletionNanos = System.nanoTime();\n\n\t\tLOG.info(\"Completed checkpoint {} for job {} ({} bytes in {} ms).\", checkpointId, job,\n\t\t\tcompletedCheckpoint.getStateSize(), completedCheckpoint.getDuration());\n\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tStringBuilder builder = new StringBuilder();\n\t\t\tbuilder.append(\"Checkpoint state: \");\n\t\t\tfor (OperatorState state : completedCheckpoint.getOperatorStates().values()) {\n\t\t\t\tbuilder.append(state);\n\t\t\t\tbuilder.append(\", \");\n\t\t\t}\n\t\t\t// Remove last two chars \", \"\n\t\t\tbuilder.setLength(builder.length() - 2);\n\n\t\t\tLOG.debug(builder.toString());\n\t\t}\n\n\t\t// send the \"notify complete\" call to all vertices\n\t\tfinal long timestamp = completedCheckpoint.getTimestamp();\n\n\t\tfor (ExecutionVertex ev : tasksToCommitTo) {\n\t\t\tExecution ee = ev.getCurrentExecutionAttempt();\n\t\t\tif (ee != null) {\n\t\t\t\tee.notifyCheckpointComplete(checkpointId, timestamp);\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "CheckpointCoordinator::ScheduledTrigger::run()",
            "1211  \n1212  \n1213  \n1214  \n1215  \n1216  \n1217 -\n1218  \n1219  ",
            "\t\t@Override\n\t\tpublic void run() {\n\t\t\ttry {\n\t\t\t\ttriggerCheckpoint(System.currentTimeMillis(), true);\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tLOG.error(\"Exception while triggering checkpoint.\", e);\n\t\t\t}\n\t\t}",
            "1216  \n1217  \n1218  \n1219  \n1220  \n1221  \n1222 +\n1223  \n1224  ",
            "\t\t@Override\n\t\tpublic void run() {\n\t\t\ttry {\n\t\t\t\ttriggerCheckpoint(System.currentTimeMillis(), true);\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tLOG.error(\"Exception while triggering checkpoint for job {}.\", job, e);\n\t\t\t}\n\t\t}"
        ],
        [
            "CheckpointCoordinator::restoreLatestCheckpointedState(Map,boolean,boolean)",
            " 964  \n 965  \n 966  \n 967  \n 968  \n 969  \n 970  \n 971  \n 972  \n 973  \n 974  \n 975  \n 976  \n 977  \n 978  \n 979  \n 980  \n 981  \n 982  \n 983  \n 984  \n 985  \n 986  \n 987  \n 988  \n 989  \n 990  \n 991  \n 992  \n 993  \n 994  \n 995  \n 996  \n 997  \n 998  \n 999  \n1000  \n1001  \n1002  \n1003  \n1004  \n1005  \n1006  \n1007  \n1008  \n1009  \n1010 -\n1011  \n1012  \n1013  \n1014  \n1015  \n1016  \n1017  \n1018  \n1019  \n1020  \n1021  \n1022  \n1023 -\n1024  \n1025  \n1026  \n1027  \n1028  \n1029  \n1030  \n1031  \n1032  \n1033  \n1034  \n1035  \n1036  \n1037  \n1038  \n1039  \n1040  \n1041  \n1042  \n1043  \n1044  \n1045  \n1046  \n1047  \n1048  \n1049  \n1050  \n1051  \n1052  \n1053  \n1054  \n1055  \n1056  \n1057  ",
            "\t/**\n\t * Restores the latest checkpointed state.\n\t *\n\t * @param tasks Map of job vertices to restore. State for these vertices is\n\t * restored via {@link Execution#setInitialState(JobManagerTaskRestore)}.\n\t * @param errorIfNoCheckpoint Fail if no completed checkpoint is available to\n\t * restore from.\n\t * @param allowNonRestoredState Allow checkpoint state that cannot be mapped\n\t * to any job vertex in tasks.\n\t * @return <code>true</code> if state was restored, <code>false</code> otherwise.\n\t * @throws IllegalStateException If the CheckpointCoordinator is shut down.\n\t * @throws IllegalStateException If no completed checkpoint is available and\n\t *                               the <code>failIfNoCheckpoint</code> flag has been set.\n\t * @throws IllegalStateException If the checkpoint contains state that cannot be\n\t *                               mapped to any job vertex in <code>tasks</code> and the\n\t *                               <code>allowNonRestoredState</code> flag has not been set.\n\t * @throws IllegalStateException If the max parallelism changed for an operator\n\t *                               that restores state from this checkpoint.\n\t * @throws IllegalStateException If the parallelism changed for an operator\n\t *                               that restores <i>non-partitioned</i> state from this\n\t *                               checkpoint.\n\t */\n\tpublic boolean restoreLatestCheckpointedState(\n\t\t\tMap<JobVertexID, ExecutionJobVertex> tasks,\n\t\t\tboolean errorIfNoCheckpoint,\n\t\t\tboolean allowNonRestoredState) throws Exception {\n\n\t\tsynchronized (lock) {\n\t\t\tif (shutdown) {\n\t\t\t\tthrow new IllegalStateException(\"CheckpointCoordinator is shut down\");\n\t\t\t}\n\n\t\t\t// We create a new shared state registry object, so that all pending async disposal requests from previous\n\t\t\t// runs will go against the old object (were they can do no harm).\n\t\t\t// This must happen under the checkpoint lock.\n\t\t\tsharedStateRegistry.close();\n\t\t\tsharedStateRegistry = sharedStateRegistryFactory.create(executor);\n\n\t\t\t// Recover the checkpoints, TODO this could be done only when there is a new leader, not on each recovery\n\t\t\tcompletedCheckpointStore.recover();\n\n\t\t\t// Now, we re-register all (shared) states from the checkpoint store with the new registry\n\t\t\tfor (CompletedCheckpoint completedCheckpoint : completedCheckpointStore.getAllCheckpoints()) {\n\t\t\t\tcompletedCheckpoint.registerSharedStatesAfterRestored(sharedStateRegistry);\n\t\t\t}\n\n\t\t\tLOG.debug(\"Status of the shared state registry after restore: {}.\", sharedStateRegistry);\n\n\t\t\t// Restore from the latest checkpoint\n\t\t\tCompletedCheckpoint latest = completedCheckpointStore.getLatestCheckpoint();\n\n\t\t\tif (latest == null) {\n\t\t\t\tif (errorIfNoCheckpoint) {\n\t\t\t\t\tthrow new IllegalStateException(\"No completed checkpoint available\");\n\t\t\t\t} else {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tLOG.info(\"Restoring from latest valid checkpoint: {}.\", latest);\n\n\t\t\t// re-assign the task states\n\t\t\tfinal Map<OperatorID, OperatorState> operatorStates = latest.getOperatorStates();\n\n\t\t\tStateAssignmentOperation stateAssignmentOperation =\n\t\t\t\t\tnew StateAssignmentOperation(latest.getCheckpointID(), tasks, operatorStates, allowNonRestoredState);\n\n\t\t\tstateAssignmentOperation.assignStates();\n\n\t\t\t// call master hooks for restore\n\n\t\t\tMasterHooks.restoreMasterHooks(\n\t\t\t\t\tmasterHooks,\n\t\t\t\t\tlatest.getMasterHookStates(),\n\t\t\t\t\tlatest.getCheckpointID(),\n\t\t\t\t\tallowNonRestoredState,\n\t\t\t\t\tLOG);\n\n\t\t\t// update metrics\n\n\t\t\tif (statsTracker != null) {\n\t\t\t\tlong restoreTimestamp = System.currentTimeMillis();\n\t\t\t\tRestoredCheckpointStats restored = new RestoredCheckpointStats(\n\t\t\t\t\tlatest.getCheckpointID(),\n\t\t\t\t\tlatest.getProperties(),\n\t\t\t\t\trestoreTimestamp,\n\t\t\t\t\tlatest.getExternalPointer());\n\n\t\t\t\tstatsTracker.reportRestoredCheckpoint(restored);\n\t\t\t}\n\n\t\t\treturn true;\n\t\t}\n\t}",
            " 969  \n 970  \n 971  \n 972  \n 973  \n 974  \n 975  \n 976  \n 977  \n 978  \n 979  \n 980  \n 981  \n 982  \n 983  \n 984  \n 985  \n 986  \n 987  \n 988  \n 989  \n 990  \n 991  \n 992  \n 993  \n 994  \n 995  \n 996  \n 997  \n 998  \n 999  \n1000  \n1001  \n1002  \n1003  \n1004  \n1005  \n1006  \n1007  \n1008  \n1009  \n1010  \n1011  \n1012  \n1013  \n1014  \n1015 +\n1016  \n1017  \n1018  \n1019  \n1020  \n1021  \n1022  \n1023  \n1024  \n1025  \n1026  \n1027  \n1028 +\n1029  \n1030  \n1031  \n1032  \n1033  \n1034  \n1035  \n1036  \n1037  \n1038  \n1039  \n1040  \n1041  \n1042  \n1043  \n1044  \n1045  \n1046  \n1047  \n1048  \n1049  \n1050  \n1051  \n1052  \n1053  \n1054  \n1055  \n1056  \n1057  \n1058  \n1059  \n1060  \n1061  \n1062  ",
            "\t/**\n\t * Restores the latest checkpointed state.\n\t *\n\t * @param tasks Map of job vertices to restore. State for these vertices is\n\t * restored via {@link Execution#setInitialState(JobManagerTaskRestore)}.\n\t * @param errorIfNoCheckpoint Fail if no completed checkpoint is available to\n\t * restore from.\n\t * @param allowNonRestoredState Allow checkpoint state that cannot be mapped\n\t * to any job vertex in tasks.\n\t * @return <code>true</code> if state was restored, <code>false</code> otherwise.\n\t * @throws IllegalStateException If the CheckpointCoordinator is shut down.\n\t * @throws IllegalStateException If no completed checkpoint is available and\n\t *                               the <code>failIfNoCheckpoint</code> flag has been set.\n\t * @throws IllegalStateException If the checkpoint contains state that cannot be\n\t *                               mapped to any job vertex in <code>tasks</code> and the\n\t *                               <code>allowNonRestoredState</code> flag has not been set.\n\t * @throws IllegalStateException If the max parallelism changed for an operator\n\t *                               that restores state from this checkpoint.\n\t * @throws IllegalStateException If the parallelism changed for an operator\n\t *                               that restores <i>non-partitioned</i> state from this\n\t *                               checkpoint.\n\t */\n\tpublic boolean restoreLatestCheckpointedState(\n\t\t\tMap<JobVertexID, ExecutionJobVertex> tasks,\n\t\t\tboolean errorIfNoCheckpoint,\n\t\t\tboolean allowNonRestoredState) throws Exception {\n\n\t\tsynchronized (lock) {\n\t\t\tif (shutdown) {\n\t\t\t\tthrow new IllegalStateException(\"CheckpointCoordinator is shut down\");\n\t\t\t}\n\n\t\t\t// We create a new shared state registry object, so that all pending async disposal requests from previous\n\t\t\t// runs will go against the old object (were they can do no harm).\n\t\t\t// This must happen under the checkpoint lock.\n\t\t\tsharedStateRegistry.close();\n\t\t\tsharedStateRegistry = sharedStateRegistryFactory.create(executor);\n\n\t\t\t// Recover the checkpoints, TODO this could be done only when there is a new leader, not on each recovery\n\t\t\tcompletedCheckpointStore.recover();\n\n\t\t\t// Now, we re-register all (shared) states from the checkpoint store with the new registry\n\t\t\tfor (CompletedCheckpoint completedCheckpoint : completedCheckpointStore.getAllCheckpoints()) {\n\t\t\t\tcompletedCheckpoint.registerSharedStatesAfterRestored(sharedStateRegistry);\n\t\t\t}\n\n\t\t\tLOG.debug(\"Status of the shared state registry of job {} after restore: {}.\", job, sharedStateRegistry);\n\n\t\t\t// Restore from the latest checkpoint\n\t\t\tCompletedCheckpoint latest = completedCheckpointStore.getLatestCheckpoint();\n\n\t\t\tif (latest == null) {\n\t\t\t\tif (errorIfNoCheckpoint) {\n\t\t\t\t\tthrow new IllegalStateException(\"No completed checkpoint available\");\n\t\t\t\t} else {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tLOG.info(\"Restoring job {} from latest valid checkpoint: {}.\", job, latest);\n\n\t\t\t// re-assign the task states\n\t\t\tfinal Map<OperatorID, OperatorState> operatorStates = latest.getOperatorStates();\n\n\t\t\tStateAssignmentOperation stateAssignmentOperation =\n\t\t\t\t\tnew StateAssignmentOperation(latest.getCheckpointID(), tasks, operatorStates, allowNonRestoredState);\n\n\t\t\tstateAssignmentOperation.assignStates();\n\n\t\t\t// call master hooks for restore\n\n\t\t\tMasterHooks.restoreMasterHooks(\n\t\t\t\t\tmasterHooks,\n\t\t\t\t\tlatest.getMasterHookStates(),\n\t\t\t\t\tlatest.getCheckpointID(),\n\t\t\t\t\tallowNonRestoredState,\n\t\t\t\t\tLOG);\n\n\t\t\t// update metrics\n\n\t\t\tif (statsTracker != null) {\n\t\t\t\tlong restoreTimestamp = System.currentTimeMillis();\n\t\t\t\tRestoredCheckpointStats restored = new RestoredCheckpointStats(\n\t\t\t\t\tlatest.getCheckpointID(),\n\t\t\t\t\tlatest.getProperties(),\n\t\t\t\t\trestoreTimestamp,\n\t\t\t\t\tlatest.getExternalPointer());\n\n\t\t\t\tstatsTracker.reportRestoredCheckpoint(restored);\n\t\t\t}\n\n\t\t\treturn true;\n\t\t}\n\t}"
        ],
        [
            "CheckpointCoordinator::shutdown(JobStatus)",
            " 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319 -\n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  ",
            "\t/**\n\t * Shuts down the checkpoint coordinator.\n\t *\n\t * <p>After this method has been called, the coordinator does not accept\n\t * and further messages and cannot trigger any further checkpoints.\n\t */\n\tpublic void shutdown(JobStatus jobStatus) throws Exception {\n\t\tsynchronized (lock) {\n\t\t\tif (!shutdown) {\n\t\t\t\tshutdown = true;\n\t\t\t\tLOG.info(\"Stopping checkpoint coordinator for job \" + job);\n\n\t\t\t\tperiodicScheduling = false;\n\t\t\t\ttriggerRequestQueued = false;\n\n\t\t\t\t// shut down the thread that handles the timeouts and pending triggers\n\t\t\t\ttimer.shutdownNow();\n\n\t\t\t\t// clear and discard all pending checkpoints\n\t\t\t\tfor (PendingCheckpoint pending : pendingCheckpoints.values()) {\n\t\t\t\t\tpending.abortError(new Exception(\"Checkpoint Coordinator is shutting down\"));\n\t\t\t\t}\n\t\t\t\tpendingCheckpoints.clear();\n\n\t\t\t\tcompletedCheckpointStore.shutdown(jobStatus);\n\t\t\t\tcheckpointIdCounter.shutdown(jobStatus);\n\t\t\t}\n\t\t}\n\t}",
            " 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319 +\n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  ",
            "\t/**\n\t * Shuts down the checkpoint coordinator.\n\t *\n\t * <p>After this method has been called, the coordinator does not accept\n\t * and further messages and cannot trigger any further checkpoints.\n\t */\n\tpublic void shutdown(JobStatus jobStatus) throws Exception {\n\t\tsynchronized (lock) {\n\t\t\tif (!shutdown) {\n\t\t\t\tshutdown = true;\n\t\t\t\tLOG.info(\"Stopping checkpoint coordinator for job {}.\", job);\n\n\t\t\t\tperiodicScheduling = false;\n\t\t\t\ttriggerRequestQueued = false;\n\n\t\t\t\t// shut down the thread that handles the timeouts and pending triggers\n\t\t\t\ttimer.shutdownNow();\n\n\t\t\t\t// clear and discard all pending checkpoints\n\t\t\t\tfor (PendingCheckpoint pending : pendingCheckpoints.values()) {\n\t\t\t\t\tpending.abortError(new Exception(\"Checkpoint Coordinator is shutting down\"));\n\t\t\t\t}\n\t\t\t\tpendingCheckpoints.clear();\n\n\t\t\t\tcompletedCheckpointStore.shutdown(jobStatus);\n\t\t\t\tcheckpointIdCounter.shutdown(jobStatus);\n\t\t\t}\n\t\t}\n\t}"
        ]
    ],
    "4b89b5d0abe4684dbeacd9a01fe3297621050eb7": [
        [
            "AbstractYarnClusterDescriptor::startAppMaster(Configuration,String,JobGraph,YarnClient,YarnClientApplication,ClusterSpecification)",
            " 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786  \n 787  \n 788  \n 789  \n 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854  \n 855  \n 856  \n 857  \n 858  \n 859  \n 860  \n 861  \n 862  \n 863  \n 864  \n 865  \n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  \n 891  \n 892  \n 893  \n 894  \n 895  \n 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  \n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932  \n 933  \n 934  \n 935  \n 936  \n 937  \n 938  \n 939  \n 940  \n 941  \n 942  \n 943  \n 944  \n 945  \n 946  \n 947  \n 948  \n 949  \n 950  \n 951  \n 952  \n 953  \n 954  \n 955  \n 956  \n 957  \n 958  \n 959  \n 960  \n 961  \n 962  \n 963  \n 964  \n 965  \n 966  \n 967  \n 968  \n 969  \n 970  \n 971  \n 972  \n 973  \n 974  \n 975  \n 976  \n 977  \n 978  \n 979  \n 980  \n 981  \n 982  \n 983  \n 984  \n 985  \n 986  \n 987  \n 988  \n 989  \n 990  \n 991  \n 992  \n 993  \n 994  \n 995  \n 996  \n 997  \n 998  \n 999  \n1000  \n1001  \n1002  \n1003  \n1004  \n1005  \n1006  \n1007  \n1008  \n1009  \n1010  \n1011  \n1012  \n1013  \n1014  \n1015  \n1016  \n1017  \n1018  \n1019  \n1020  \n1021  \n1022  \n1023  \n1024  \n1025  \n1026  \n1027  \n1028  \n1029  \n1030  \n1031  \n1032  \n1033  \n1034  \n1035  \n1036  \n1037  \n1038  \n1039  \n1040  \n1041  \n1042  ",
            "\tpublic ApplicationReport startAppMaster(\n\t\t\tConfiguration configuration,\n\t\t\tString yarnClusterEntrypoint,\n\t\t\tJobGraph jobGraph,\n\t\t\tYarnClient yarnClient,\n\t\t\tYarnClientApplication yarnApplication,\n\t\t\tClusterSpecification clusterSpecification) throws Exception {\n\n\t\t// ------------------ Initialize the file systems -------------------------\n\n\t\ttry {\n\t\t\torg.apache.flink.core.fs.FileSystem.initialize(configuration);\n\t\t} catch (IOException e) {\n\t\t\tthrow new IOException(\"Error while setting the default \" +\n\t\t\t\t\t\"filesystem scheme from configuration.\", e);\n\t\t}\n\n\t\t// initialize file system\n\t\t// Copy the application master jar to the filesystem\n\t\t// Create a local resource to point to the destination jar path\n\t\tfinal FileSystem fs = FileSystem.get(yarnConfiguration);\n\t\tfinal Path homeDir = fs.getHomeDirectory();\n\n\t\t// hard coded check for the GoogleHDFS client because its not overriding the getScheme() method.\n\t\tif (!fs.getClass().getSimpleName().equals(\"GoogleHadoopFileSystem\") &&\n\t\t\t\tfs.getScheme().startsWith(\"file\")) {\n\t\t\tLOG.warn(\"The file system scheme is '\" + fs.getScheme() + \"'. This indicates that the \"\n\t\t\t\t\t+ \"specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values.\"\n\t\t\t\t\t+ \"The Flink YARN client needs to store its files in a distributed file system\");\n\t\t}\n\n\t\tApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext();\n\t\tSet<File> systemShipFiles = new HashSet<>(shipFiles.size());\n\t\tfor (File file : shipFiles) {\n\t\t\tsystemShipFiles.add(file.getAbsoluteFile());\n\t\t}\n\n\t\t//check if there is a logback or log4j file\n\t\tFile logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME);\n\t\tfinal boolean hasLogback = logbackFile.exists();\n\t\tif (hasLogback) {\n\t\t\tsystemShipFiles.add(logbackFile);\n\t\t}\n\n\t\tFile log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME);\n\t\tfinal boolean hasLog4j = log4jFile.exists();\n\t\tif (hasLog4j) {\n\t\t\tsystemShipFiles.add(log4jFile);\n\t\t\tif (hasLogback) {\n\t\t\t\t// this means there is already a logback configuration file --> fail\n\t\t\t\tLOG.warn(\"The configuration directory ('\" + configurationDirectory + \"') contains both LOG4J and \" +\n\t\t\t\t\t\"Logback configuration files. Please delete or rename one of them.\");\n\t\t\t}\n\t\t}\n\n\t\taddLibFolderToShipFiles(systemShipFiles);\n\n\t\t// Set-up ApplicationSubmissionContext for the application\n\n\t\tfinal ApplicationId appId = appContext.getApplicationId();\n\n\t\t// ------------------ Add Zookeeper namespace to local flinkConfiguraton ------\n\t\tString zkNamespace = getZookeeperNamespace();\n\t\t// no user specified cli argument for namespace?\n\t\tif (zkNamespace == null || zkNamespace.isEmpty()) {\n\t\t\t// namespace defined in config? else use applicationId as default.\n\t\t\tzkNamespace = configuration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId));\n\t\t\tsetZookeeperNamespace(zkNamespace);\n\t\t}\n\n\t\tconfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace);\n\n\t\tif (HighAvailabilityMode.isHighAvailabilityModeActivated(configuration)) {\n\t\t\t// activate re-execution of failed applications\n\t\t\tappContext.setMaxAppAttempts(\n\t\t\t\tconfiguration.getInteger(\n\t\t\t\t\tYarnConfigOptions.APPLICATION_ATTEMPTS.key(),\n\t\t\t\t\tYarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS));\n\n\t\t\tactivateHighAvailabilitySupport(appContext);\n\t\t} else {\n\t\t\t// set number of application retries to 1 in the default case\n\t\t\tappContext.setMaxAppAttempts(\n\t\t\t\tconfiguration.getInteger(\n\t\t\t\t\tYarnConfigOptions.APPLICATION_ATTEMPTS.key(),\n\t\t\t\t\t1));\n\t\t}\n\n\t\tif (jobGraph != null) {\n\t\t\t// add the user code jars from the provided JobGraph\n\t\t\tfor (org.apache.flink.core.fs.Path path : jobGraph.getUserJars()) {\n\t\t\t\tuserJarFiles.add(new File(path.toUri()));\n\t\t\t}\n\t\t}\n\n\t\t// local resource map for Yarn\n\t\tfinal Map<String, LocalResource> localResources = new HashMap<>(2 + systemShipFiles.size() + userJarFiles.size());\n\t\t// list of remote paths (after upload)\n\t\tfinal List<Path> paths = new ArrayList<>(2 + systemShipFiles.size() + userJarFiles.size());\n\t\t// ship list that enables reuse of resources for task manager containers\n\t\tStringBuilder envShipFileList = new StringBuilder();\n\n\t\t// upload and register ship files\n\t\tList<String> systemClassPaths = uploadAndRegisterFiles(\n\t\t\tsystemShipFiles,\n\t\t\tfs,\n\t\t\thomeDir,\n\t\t\tappId,\n\t\t\tpaths,\n\t\t\tlocalResources,\n\t\t\tenvShipFileList);\n\n\t\tList<String> userClassPaths;\n\t\tif (userJarInclusion != YarnConfigOptions.UserJarInclusion.DISABLED) {\n\t\t\tuserClassPaths = uploadAndRegisterFiles(\n\t\t\t\tuserJarFiles,\n\t\t\t\tfs,\n\t\t\t\thomeDir,\n\t\t\t\tappId,\n\t\t\t\tpaths,\n\t\t\t\tlocalResources,\n\t\t\t\tenvShipFileList);\n\t\t} else {\n\t\t\tuserClassPaths = Collections.emptyList();\n\t\t}\n\n\t\tif (userJarInclusion == YarnConfigOptions.UserJarInclusion.ORDER) {\n\t\t\tsystemClassPaths.addAll(userClassPaths);\n\t\t}\n\n\t\t// normalize classpath by sorting\n\t\tCollections.sort(systemClassPaths);\n\t\tCollections.sort(userClassPaths);\n\n\t\t// classpath assembler\n\t\tStringBuilder classPathBuilder = new StringBuilder();\n\t\tif (userJarInclusion == YarnConfigOptions.UserJarInclusion.FIRST) {\n\t\t\tfor (String userClassPath : userClassPaths) {\n\t\t\t\tclassPathBuilder.append(userClassPath).append(File.pathSeparator);\n\t\t\t}\n\t\t}\n\t\tfor (String classPath : systemClassPaths) {\n\t\t\tclassPathBuilder.append(classPath).append(File.pathSeparator);\n\t\t}\n\t\tif (userJarInclusion == YarnConfigOptions.UserJarInclusion.LAST) {\n\t\t\tfor (String userClassPath : userClassPaths) {\n\t\t\t\tclassPathBuilder.append(userClassPath).append(File.pathSeparator);\n\t\t\t}\n\t\t}\n\n\t\t// Setup jar for ApplicationMaster\n\t\tPath remotePathJar = setupSingleLocalResource(\n\t\t\t\"flink.jar\",\n\t\t\tfs,\n\t\t\tappId,\n\t\t\tflinkJarPath,\n\t\t\tlocalResources,\n\t\t\thomeDir,\n\t\t\t\"\");\n\n\t\t// Upload the flink configuration\n\t\t// write out configuration file\n\t\tFile tmpConfigurationFile = File.createTempFile(appId + \"-flink-conf.yaml\", null);\n\t\ttmpConfigurationFile.deleteOnExit();\n\t\tBootstrapTools.writeConfiguration(configuration, tmpConfigurationFile);\n\n\t\tPath remotePathConf = setupSingleLocalResource(\n\t\t\t\"flink-conf.yaml\",\n\t\t\tfs,\n\t\t\tappId,\n\t\t\tnew Path(tmpConfigurationFile.getAbsolutePath()),\n\t\t\tlocalResources,\n\t\t\thomeDir,\n\t\t\t\"\");\n\n\t\tpaths.add(remotePathJar);\n\t\tclassPathBuilder.append(\"flink.jar\").append(File.pathSeparator);\n\t\tpaths.add(remotePathConf);\n\t\tclassPathBuilder.append(\"flink-conf.yaml\").append(File.pathSeparator);\n\n\t\t// write job graph to tmp file and add it to local resource\n\t\t// TODO: server use user main method to generate job graph\n\t\tif (jobGraph != null) {\n\t\t\ttry {\n\t\t\t\tFile fp = File.createTempFile(appId.toString(), null);\n\t\t\t\tfp.deleteOnExit();\n\t\t\t\ttry (FileOutputStream output = new FileOutputStream(fp);\n\t\t\t\t\tObjectOutputStream obOutput = new ObjectOutputStream(output);){\n\t\t\t\t\tobOutput.writeObject(jobGraph);\n\t\t\t\t}\n\n\t\t\t\tPath pathFromYarnURL = setupSingleLocalResource(\n\t\t\t\t\t\"job.graph\",\n\t\t\t\t\tfs,\n\t\t\t\t\tappId,\n\t\t\t\t\tnew Path(fp.toURI()),\n\t\t\t\t\tlocalResources,\n\t\t\t\t\thomeDir,\n\t\t\t\t\t\"\");\n\t\t\t\tpaths.add(pathFromYarnURL);\n\t\t\t\tclassPathBuilder.append(\"job.graph\").append(File.pathSeparator);\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.warn(\"Add job graph to local resource fail\");\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\n\t\tPath yarnFilesDir = new Path(homeDir, \".flink/\" + appId + '/');\n\n\t\tFsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n\t\tfs.setPermission(yarnFilesDir, permission); // set permission for path.\n\n\t\t//To support Yarn Secure Integration Test Scenario\n\t\t//In Integration test setup, the Yarn containers created by YarnMiniCluster does not have the Yarn site XML\n\t\t//and KRB5 configuration files. We are adding these files as container local resources for the container\n\t\t//applications (JM/TMs) to have proper secure cluster setup\n\t\tPath remoteKrb5Path = null;\n\t\tPath remoteYarnSiteXmlPath = null;\n\t\tboolean hasKrb5 = false;\n\t\tif (System.getenv(\"IN_TESTS\") != null) {\n\t\t\tString krb5Config = System.getProperty(\"java.security.krb5.conf\");\n\t\t\tif (krb5Config != null && krb5Config.length() != 0) {\n\t\t\t\tFile krb5 = new File(krb5Config);\n\t\t\t\tLOG.info(\"Adding KRB5 configuration {} to the AM container local resource bucket\", krb5.getAbsolutePath());\n\t\t\t\tPath krb5ConfPath = new Path(krb5.getAbsolutePath());\n\t\t\t\tremoteKrb5Path = setupSingleLocalResource(\n\t\t\t\t\tUtils.KRB5_FILE_NAME,\n\t\t\t\t\tfs,\n\t\t\t\t\tappId,\n\t\t\t\t\tkrb5ConfPath,\n\t\t\t\t\tlocalResources,\n\t\t\t\t\thomeDir,\n\t\t\t\t\t\"\");\n\n\t\t\t\tFile f = new File(System.getenv(\"YARN_CONF_DIR\"), Utils.YARN_SITE_FILE_NAME);\n\t\t\t\tLOG.info(\"Adding Yarn configuration {} to the AM container local resource bucket\", f.getAbsolutePath());\n\t\t\t\tPath yarnSitePath = new Path(f.getAbsolutePath());\n\t\t\t\tremoteYarnSiteXmlPath = setupSingleLocalResource(\n\t\t\t\t\tUtils.YARN_SITE_FILE_NAME,\n\t\t\t\t\tfs,\n\t\t\t\t\tappId,\n\t\t\t\t\tyarnSitePath,\n\t\t\t\t\tlocalResources,\n\t\t\t\t\thomeDir,\n\t\t\t\t\t\"\");\n\t\t\t\thasKrb5 = true;\n\t\t\t}\n\t\t}\n\n\t\t// setup security tokens\n\t\tPath remotePathKeytab = null;\n\t\tString keytab = configuration.getString(SecurityOptions.KERBEROS_LOGIN_KEYTAB);\n\t\tif (keytab != null) {\n\t\t\tLOG.info(\"Adding keytab {} to the AM container local resource bucket\", keytab);\n\t\t\tremotePathKeytab = setupSingleLocalResource(\n\t\t\t\tUtils.KEYTAB_FILE_NAME,\n\t\t\t\tfs,\n\t\t\t\tappId,\n\t\t\t\tnew Path(keytab),\n\t\t\t\tlocalResources,\n\t\t\t\thomeDir,\n\t\t\t\t\"\");\n\t\t}\n\n\t\tfinal ContainerLaunchContext amContainer = setupApplicationMasterContainer(\n\t\t\tyarnClusterEntrypoint,\n\t\t\thasLogback,\n\t\t\thasLog4j,\n\t\t\thasKrb5,\n\t\t\tclusterSpecification.getMasterMemoryMB());\n\n\t\tif (UserGroupInformation.isSecurityEnabled()) {\n\t\t\t// set HDFS delegation tokens when security is enabled\n\t\t\tLOG.info(\"Adding delegation token to the AM container..\");\n\t\t\tUtils.setTokensFor(amContainer, paths, yarnConfiguration);\n\t\t}\n\n\t\tamContainer.setLocalResources(localResources);\n\t\tfs.close();\n\n\t\t// Setup CLASSPATH and environment variables for ApplicationMaster\n\t\tfinal Map<String, String> appMasterEnv = new HashMap<>();\n\t\t// set user specified app master environment variables\n\t\tappMasterEnv.putAll(Utils.getEnvironmentVariables(ResourceManagerOptions.CONTAINERIZED_MASTER_ENV_PREFIX, configuration));\n\t\t// set Flink app class path\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString());\n\n\t\t// set Flink on YARN internal configuration values\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(clusterSpecification.getNumberTaskManagers()));\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(clusterSpecification.getTaskManagerMemoryMB()));\n\t\tappMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, homeDir.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(clusterSpecification.getSlotsPerTaskManager()));\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached));\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace());\n\t\tappMasterEnv.put(YarnConfigKeys.FLINK_YARN_FILES, yarnFilesDir.toUri().toString());\n\n\t\t// https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/markdown/YarnApplicationSecurity.md#identity-on-an-insecure-cluster-hadoop_user_name\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName());\n\n\t\tif (remotePathKeytab != null) {\n\t\t\tappMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString());\n\t\t\tString principal = configuration.getString(SecurityOptions.KERBEROS_LOGIN_PRINCIPAL);\n\t\t\tappMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal);\n\t\t}\n\n\t\t//To support Yarn Secure Integration Test Scenario\n\t\tif (remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {\n\t\t\tappMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString());\n\t\t\tappMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString());\n\t\t}\n\n\t\tif (dynamicPropertiesEncoded != null) {\n\t\t\tappMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded);\n\t\t}\n\n\t\t// set classpath from YARN configuration\n\t\tUtils.setupYarnClassPath(yarnConfiguration, appMasterEnv);\n\n\t\tamContainer.setEnvironment(appMasterEnv);\n\n\t\t// Set up resource type requirements for ApplicationMaster\n\t\tResource capability = Records.newRecord(Resource.class);\n\t\tcapability.setMemory(clusterSpecification.getMasterMemoryMB());\n\t\tcapability.setVirtualCores(1);\n\n\t\tString name;\n\t\tif (customName == null) {\n\t\t\tname = \"Flink session with \" + clusterSpecification.getNumberTaskManagers() + \" TaskManagers\";\n\t\t\tif (detached) {\n\t\t\t\tname += \" (detached)\";\n\t\t\t}\n\t\t} else {\n\t\t\tname = customName;\n\t\t}\n\n\t\tappContext.setApplicationName(name);\n\t\tappContext.setApplicationType(\"Apache Flink\");\n\t\tappContext.setAMContainerSpec(amContainer);\n\t\tappContext.setResource(capability);\n\t\tif (yarnQueue != null) {\n\t\t\tappContext.setQueue(yarnQueue);\n\t\t}\n\n\t\tsetApplicationTags(appContext);\n\n\t\t// add a hook to clean up in case deployment fails\n\t\tThread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication, yarnFilesDir);\n\t\tRuntime.getRuntime().addShutdownHook(deploymentFailureHook);\n\t\tLOG.info(\"Submitting application master \" + appId);\n\t\tyarnClient.submitApplication(appContext);\n\n\t\tLOG.info(\"Waiting for the cluster to be allocated\");\n\t\tfinal long startTime = System.currentTimeMillis();\n\t\tApplicationReport report;\n\t\tYarnApplicationState lastAppState = YarnApplicationState.NEW;\n\t\tloop: while (true) {\n\t\t\ttry {\n\t\t\t\treport = yarnClient.getApplicationReport(appId);\n\t\t\t} catch (IOException e) {\n\t\t\t\tthrow new YarnDeploymentException(\"Failed to deploy the cluster.\", e);\n\t\t\t}\n\t\t\tYarnApplicationState appState = report.getYarnApplicationState();\n\t\t\tLOG.debug(\"Application State: {}\", appState);\n\t\t\tswitch(appState) {\n\t\t\t\tcase FAILED:\n\t\t\t\tcase FINISHED: //TODO: the finished state may be valid in flip-6\n\t\t\t\tcase KILLED:\n\t\t\t\t\tthrow new YarnDeploymentException(\"The YARN application unexpectedly switched to state \"\n\t\t\t\t\t\t+ appState + \" during deployment. \\n\" +\n\t\t\t\t\t\t\"Diagnostics from YARN: \" + report.getDiagnostics() + \"\\n\" +\n\t\t\t\t\t\t\"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\\n\" +\n\t\t\t\t\t\t\"yarn logs -applicationId \" + appId);\n\t\t\t\t\t//break ..\n\t\t\t\tcase RUNNING:\n\t\t\t\t\tLOG.info(\"YARN application has been deployed successfully.\");\n\t\t\t\t\tbreak loop;\n\t\t\t\tdefault:\n\t\t\t\t\tif (appState != lastAppState) {\n\t\t\t\t\t\tLOG.info(\"Deploying cluster, current state \" + appState);\n\t\t\t\t\t}\n\t\t\t\t\tif (System.currentTimeMillis() - startTime > 60000) {\n\t\t\t\t\t\tLOG.info(\"Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster\");\n\t\t\t\t\t}\n\n\t\t\t}\n\t\t\tlastAppState = appState;\n\t\t\tThread.sleep(250);\n\t\t}\n\t\t// print the application id for user to cancel themselves.\n\t\tif (isDetachedMode()) {\n\t\t\tLOG.info(\"The Flink YARN client has been started in detached mode. In order to stop \" +\n\t\t\t\t\t\"Flink on YARN, use the following command or a YARN web interface to stop \" +\n\t\t\t\t\t\"it:\\nyarn application -kill \" + appId + \"\\nPlease also note that the \" +\n\t\t\t\t\t\"temporary files of the YARN session in the home directoy will not be removed.\");\n\t\t}\n\t\t// since deployment was successful, remove the hook\n\t\ttry {\n\t\t\tRuntime.getRuntime().removeShutdownHook(deploymentFailureHook);\n\t\t} catch (IllegalStateException e) {\n\t\t\t// we're already in the shut down hook.\n\t\t}\n\t\treturn report;\n\t}",
            " 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786  \n 787  \n 788  \n 789  \n 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797 +\n 798 +\n 799 +\n 800 +\n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854  \n 855  \n 856  \n 857  \n 858  \n 859  \n 860  \n 861  \n 862  \n 863  \n 864  \n 865  \n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  \n 891  \n 892  \n 893  \n 894  \n 895  \n 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  \n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932  \n 933  \n 934  \n 935  \n 936  \n 937  \n 938  \n 939  \n 940  \n 941  \n 942  \n 943  \n 944  \n 945  \n 946  \n 947  \n 948  \n 949  \n 950  \n 951  \n 952  \n 953  \n 954  \n 955  \n 956  \n 957  \n 958  \n 959  \n 960  \n 961  \n 962  \n 963  \n 964  \n 965  \n 966  \n 967  \n 968  \n 969  \n 970  \n 971  \n 972  \n 973  \n 974  \n 975  \n 976  \n 977  \n 978  \n 979  \n 980  \n 981  \n 982  \n 983  \n 984  \n 985  \n 986  \n 987  \n 988  \n 989  \n 990  \n 991  \n 992  \n 993  \n 994  \n 995  \n 996  \n 997  \n 998  \n 999  \n1000  \n1001  \n1002  \n1003  \n1004  \n1005  \n1006  \n1007  \n1008  \n1009  \n1010  \n1011  \n1012  \n1013  \n1014  \n1015  \n1016  \n1017  \n1018  \n1019  \n1020  \n1021  \n1022  \n1023  \n1024  \n1025  \n1026  \n1027  \n1028  \n1029  \n1030  \n1031  \n1032  \n1033  \n1034  \n1035  \n1036  \n1037  \n1038  \n1039  \n1040  \n1041  \n1042  \n1043  \n1044  \n1045  \n1046  ",
            "\tpublic ApplicationReport startAppMaster(\n\t\t\tConfiguration configuration,\n\t\t\tString yarnClusterEntrypoint,\n\t\t\tJobGraph jobGraph,\n\t\t\tYarnClient yarnClient,\n\t\t\tYarnClientApplication yarnApplication,\n\t\t\tClusterSpecification clusterSpecification) throws Exception {\n\n\t\t// ------------------ Initialize the file systems -------------------------\n\n\t\ttry {\n\t\t\torg.apache.flink.core.fs.FileSystem.initialize(configuration);\n\t\t} catch (IOException e) {\n\t\t\tthrow new IOException(\"Error while setting the default \" +\n\t\t\t\t\t\"filesystem scheme from configuration.\", e);\n\t\t}\n\n\t\t// initialize file system\n\t\t// Copy the application master jar to the filesystem\n\t\t// Create a local resource to point to the destination jar path\n\t\tfinal FileSystem fs = FileSystem.get(yarnConfiguration);\n\t\tfinal Path homeDir = fs.getHomeDirectory();\n\n\t\t// hard coded check for the GoogleHDFS client because its not overriding the getScheme() method.\n\t\tif (!fs.getClass().getSimpleName().equals(\"GoogleHadoopFileSystem\") &&\n\t\t\t\tfs.getScheme().startsWith(\"file\")) {\n\t\t\tLOG.warn(\"The file system scheme is '\" + fs.getScheme() + \"'. This indicates that the \"\n\t\t\t\t\t+ \"specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values.\"\n\t\t\t\t\t+ \"The Flink YARN client needs to store its files in a distributed file system\");\n\t\t}\n\n\t\tApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext();\n\t\tSet<File> systemShipFiles = new HashSet<>(shipFiles.size());\n\t\tfor (File file : shipFiles) {\n\t\t\tsystemShipFiles.add(file.getAbsoluteFile());\n\t\t}\n\n\t\t//check if there is a logback or log4j file\n\t\tFile logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME);\n\t\tfinal boolean hasLogback = logbackFile.exists();\n\t\tif (hasLogback) {\n\t\t\tsystemShipFiles.add(logbackFile);\n\t\t}\n\n\t\tFile log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME);\n\t\tfinal boolean hasLog4j = log4jFile.exists();\n\t\tif (hasLog4j) {\n\t\t\tsystemShipFiles.add(log4jFile);\n\t\t\tif (hasLogback) {\n\t\t\t\t// this means there is already a logback configuration file --> fail\n\t\t\t\tLOG.warn(\"The configuration directory ('\" + configurationDirectory + \"') contains both LOG4J and \" +\n\t\t\t\t\t\"Logback configuration files. Please delete or rename one of them.\");\n\t\t\t}\n\t\t}\n\n\t\taddLibFolderToShipFiles(systemShipFiles);\n\n\t\t// Set-up ApplicationSubmissionContext for the application\n\n\t\tfinal ApplicationId appId = appContext.getApplicationId();\n\n\t\t// ------------------ Add Zookeeper namespace to local flinkConfiguraton ------\n\t\tString zkNamespace = getZookeeperNamespace();\n\t\t// no user specified cli argument for namespace?\n\t\tif (zkNamespace == null || zkNamespace.isEmpty()) {\n\t\t\t// namespace defined in config? else use applicationId as default.\n\t\t\tzkNamespace = configuration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId));\n\t\t\tsetZookeeperNamespace(zkNamespace);\n\t\t}\n\n\t\tconfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace);\n\n\t\tif (HighAvailabilityMode.isHighAvailabilityModeActivated(configuration)) {\n\t\t\t// activate re-execution of failed applications\n\t\t\tappContext.setMaxAppAttempts(\n\t\t\t\tconfiguration.getInteger(\n\t\t\t\t\tYarnConfigOptions.APPLICATION_ATTEMPTS.key(),\n\t\t\t\t\tYarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS));\n\n\t\t\tactivateHighAvailabilitySupport(appContext);\n\t\t} else {\n\t\t\t// set number of application retries to 1 in the default case\n\t\t\tappContext.setMaxAppAttempts(\n\t\t\t\tconfiguration.getInteger(\n\t\t\t\t\tYarnConfigOptions.APPLICATION_ATTEMPTS.key(),\n\t\t\t\t\t1));\n\t\t}\n\n\t\tif (jobGraph != null) {\n\t\t\t// add the user code jars from the provided JobGraph\n\t\t\tfor (org.apache.flink.core.fs.Path path : jobGraph.getUserJars()) {\n\t\t\t\tuserJarFiles.add(new File(path.toUri()));\n\t\t\t}\n\t\t}\n\n\t\t// local resource map for Yarn\n\t\tfinal Map<String, LocalResource> localResources = new HashMap<>(2 + systemShipFiles.size() + userJarFiles.size());\n\t\t// list of remote paths (after upload)\n\t\tfinal List<Path> paths = new ArrayList<>(2 + systemShipFiles.size() + userJarFiles.size());\n\t\t// ship list that enables reuse of resources for task manager containers\n\t\tStringBuilder envShipFileList = new StringBuilder();\n\n\t\t// upload and register ship files\n\t\tList<String> systemClassPaths = uploadAndRegisterFiles(\n\t\t\tsystemShipFiles,\n\t\t\tfs,\n\t\t\thomeDir,\n\t\t\tappId,\n\t\t\tpaths,\n\t\t\tlocalResources,\n\t\t\tenvShipFileList);\n\n\t\tList<String> userClassPaths;\n\t\tif (userJarInclusion != YarnConfigOptions.UserJarInclusion.DISABLED) {\n\t\t\tuserClassPaths = uploadAndRegisterFiles(\n\t\t\t\tuserJarFiles,\n\t\t\t\tfs,\n\t\t\t\thomeDir,\n\t\t\t\tappId,\n\t\t\t\tpaths,\n\t\t\t\tlocalResources,\n\t\t\t\tenvShipFileList);\n\t\t} else {\n\t\t\tuserClassPaths = Collections.emptyList();\n\t\t}\n\n\t\tif (userJarInclusion == YarnConfigOptions.UserJarInclusion.ORDER) {\n\t\t\tsystemClassPaths.addAll(userClassPaths);\n\t\t}\n\n\t\t// normalize classpath by sorting\n\t\tCollections.sort(systemClassPaths);\n\t\tCollections.sort(userClassPaths);\n\n\t\t// classpath assembler\n\t\tStringBuilder classPathBuilder = new StringBuilder();\n\t\tif (userJarInclusion == YarnConfigOptions.UserJarInclusion.FIRST) {\n\t\t\tfor (String userClassPath : userClassPaths) {\n\t\t\t\tclassPathBuilder.append(userClassPath).append(File.pathSeparator);\n\t\t\t}\n\t\t}\n\t\tfor (String classPath : systemClassPaths) {\n\t\t\tclassPathBuilder.append(classPath).append(File.pathSeparator);\n\t\t}\n\t\tif (userJarInclusion == YarnConfigOptions.UserJarInclusion.LAST) {\n\t\t\tfor (String userClassPath : userClassPaths) {\n\t\t\t\tclassPathBuilder.append(userClassPath).append(File.pathSeparator);\n\t\t\t}\n\t\t}\n\n\t\t// Setup jar for ApplicationMaster\n\t\tPath remotePathJar = setupSingleLocalResource(\n\t\t\t\"flink.jar\",\n\t\t\tfs,\n\t\t\tappId,\n\t\t\tflinkJarPath,\n\t\t\tlocalResources,\n\t\t\thomeDir,\n\t\t\t\"\");\n\n\t\tconfiguration.setInteger(\n\t\t\tConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS,\n\t\t\tclusterSpecification.getSlotsPerTaskManager());\n\n\t\t// Upload the flink configuration\n\t\t// write out configuration file\n\t\tFile tmpConfigurationFile = File.createTempFile(appId + \"-flink-conf.yaml\", null);\n\t\ttmpConfigurationFile.deleteOnExit();\n\t\tBootstrapTools.writeConfiguration(configuration, tmpConfigurationFile);\n\n\t\tPath remotePathConf = setupSingleLocalResource(\n\t\t\t\"flink-conf.yaml\",\n\t\t\tfs,\n\t\t\tappId,\n\t\t\tnew Path(tmpConfigurationFile.getAbsolutePath()),\n\t\t\tlocalResources,\n\t\t\thomeDir,\n\t\t\t\"\");\n\n\t\tpaths.add(remotePathJar);\n\t\tclassPathBuilder.append(\"flink.jar\").append(File.pathSeparator);\n\t\tpaths.add(remotePathConf);\n\t\tclassPathBuilder.append(\"flink-conf.yaml\").append(File.pathSeparator);\n\n\t\t// write job graph to tmp file and add it to local resource\n\t\t// TODO: server use user main method to generate job graph\n\t\tif (jobGraph != null) {\n\t\t\ttry {\n\t\t\t\tFile fp = File.createTempFile(appId.toString(), null);\n\t\t\t\tfp.deleteOnExit();\n\t\t\t\ttry (FileOutputStream output = new FileOutputStream(fp);\n\t\t\t\t\tObjectOutputStream obOutput = new ObjectOutputStream(output);){\n\t\t\t\t\tobOutput.writeObject(jobGraph);\n\t\t\t\t}\n\n\t\t\t\tPath pathFromYarnURL = setupSingleLocalResource(\n\t\t\t\t\t\"job.graph\",\n\t\t\t\t\tfs,\n\t\t\t\t\tappId,\n\t\t\t\t\tnew Path(fp.toURI()),\n\t\t\t\t\tlocalResources,\n\t\t\t\t\thomeDir,\n\t\t\t\t\t\"\");\n\t\t\t\tpaths.add(pathFromYarnURL);\n\t\t\t\tclassPathBuilder.append(\"job.graph\").append(File.pathSeparator);\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.warn(\"Add job graph to local resource fail\");\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\n\t\tPath yarnFilesDir = new Path(homeDir, \".flink/\" + appId + '/');\n\n\t\tFsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n\t\tfs.setPermission(yarnFilesDir, permission); // set permission for path.\n\n\t\t//To support Yarn Secure Integration Test Scenario\n\t\t//In Integration test setup, the Yarn containers created by YarnMiniCluster does not have the Yarn site XML\n\t\t//and KRB5 configuration files. We are adding these files as container local resources for the container\n\t\t//applications (JM/TMs) to have proper secure cluster setup\n\t\tPath remoteKrb5Path = null;\n\t\tPath remoteYarnSiteXmlPath = null;\n\t\tboolean hasKrb5 = false;\n\t\tif (System.getenv(\"IN_TESTS\") != null) {\n\t\t\tString krb5Config = System.getProperty(\"java.security.krb5.conf\");\n\t\t\tif (krb5Config != null && krb5Config.length() != 0) {\n\t\t\t\tFile krb5 = new File(krb5Config);\n\t\t\t\tLOG.info(\"Adding KRB5 configuration {} to the AM container local resource bucket\", krb5.getAbsolutePath());\n\t\t\t\tPath krb5ConfPath = new Path(krb5.getAbsolutePath());\n\t\t\t\tremoteKrb5Path = setupSingleLocalResource(\n\t\t\t\t\tUtils.KRB5_FILE_NAME,\n\t\t\t\t\tfs,\n\t\t\t\t\tappId,\n\t\t\t\t\tkrb5ConfPath,\n\t\t\t\t\tlocalResources,\n\t\t\t\t\thomeDir,\n\t\t\t\t\t\"\");\n\n\t\t\t\tFile f = new File(System.getenv(\"YARN_CONF_DIR\"), Utils.YARN_SITE_FILE_NAME);\n\t\t\t\tLOG.info(\"Adding Yarn configuration {} to the AM container local resource bucket\", f.getAbsolutePath());\n\t\t\t\tPath yarnSitePath = new Path(f.getAbsolutePath());\n\t\t\t\tremoteYarnSiteXmlPath = setupSingleLocalResource(\n\t\t\t\t\tUtils.YARN_SITE_FILE_NAME,\n\t\t\t\t\tfs,\n\t\t\t\t\tappId,\n\t\t\t\t\tyarnSitePath,\n\t\t\t\t\tlocalResources,\n\t\t\t\t\thomeDir,\n\t\t\t\t\t\"\");\n\t\t\t\thasKrb5 = true;\n\t\t\t}\n\t\t}\n\n\t\t// setup security tokens\n\t\tPath remotePathKeytab = null;\n\t\tString keytab = configuration.getString(SecurityOptions.KERBEROS_LOGIN_KEYTAB);\n\t\tif (keytab != null) {\n\t\t\tLOG.info(\"Adding keytab {} to the AM container local resource bucket\", keytab);\n\t\t\tremotePathKeytab = setupSingleLocalResource(\n\t\t\t\tUtils.KEYTAB_FILE_NAME,\n\t\t\t\tfs,\n\t\t\t\tappId,\n\t\t\t\tnew Path(keytab),\n\t\t\t\tlocalResources,\n\t\t\t\thomeDir,\n\t\t\t\t\"\");\n\t\t}\n\n\t\tfinal ContainerLaunchContext amContainer = setupApplicationMasterContainer(\n\t\t\tyarnClusterEntrypoint,\n\t\t\thasLogback,\n\t\t\thasLog4j,\n\t\t\thasKrb5,\n\t\t\tclusterSpecification.getMasterMemoryMB());\n\n\t\tif (UserGroupInformation.isSecurityEnabled()) {\n\t\t\t// set HDFS delegation tokens when security is enabled\n\t\t\tLOG.info(\"Adding delegation token to the AM container..\");\n\t\t\tUtils.setTokensFor(amContainer, paths, yarnConfiguration);\n\t\t}\n\n\t\tamContainer.setLocalResources(localResources);\n\t\tfs.close();\n\n\t\t// Setup CLASSPATH and environment variables for ApplicationMaster\n\t\tfinal Map<String, String> appMasterEnv = new HashMap<>();\n\t\t// set user specified app master environment variables\n\t\tappMasterEnv.putAll(Utils.getEnvironmentVariables(ResourceManagerOptions.CONTAINERIZED_MASTER_ENV_PREFIX, configuration));\n\t\t// set Flink app class path\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString());\n\n\t\t// set Flink on YARN internal configuration values\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(clusterSpecification.getNumberTaskManagers()));\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(clusterSpecification.getTaskManagerMemoryMB()));\n\t\tappMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, homeDir.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString());\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(clusterSpecification.getSlotsPerTaskManager()));\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached));\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace());\n\t\tappMasterEnv.put(YarnConfigKeys.FLINK_YARN_FILES, yarnFilesDir.toUri().toString());\n\n\t\t// https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/markdown/YarnApplicationSecurity.md#identity-on-an-insecure-cluster-hadoop_user_name\n\t\tappMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName());\n\n\t\tif (remotePathKeytab != null) {\n\t\t\tappMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString());\n\t\t\tString principal = configuration.getString(SecurityOptions.KERBEROS_LOGIN_PRINCIPAL);\n\t\t\tappMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal);\n\t\t}\n\n\t\t//To support Yarn Secure Integration Test Scenario\n\t\tif (remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {\n\t\t\tappMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString());\n\t\t\tappMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString());\n\t\t}\n\n\t\tif (dynamicPropertiesEncoded != null) {\n\t\t\tappMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded);\n\t\t}\n\n\t\t// set classpath from YARN configuration\n\t\tUtils.setupYarnClassPath(yarnConfiguration, appMasterEnv);\n\n\t\tamContainer.setEnvironment(appMasterEnv);\n\n\t\t// Set up resource type requirements for ApplicationMaster\n\t\tResource capability = Records.newRecord(Resource.class);\n\t\tcapability.setMemory(clusterSpecification.getMasterMemoryMB());\n\t\tcapability.setVirtualCores(1);\n\n\t\tString name;\n\t\tif (customName == null) {\n\t\t\tname = \"Flink session with \" + clusterSpecification.getNumberTaskManagers() + \" TaskManagers\";\n\t\t\tif (detached) {\n\t\t\t\tname += \" (detached)\";\n\t\t\t}\n\t\t} else {\n\t\t\tname = customName;\n\t\t}\n\n\t\tappContext.setApplicationName(name);\n\t\tappContext.setApplicationType(\"Apache Flink\");\n\t\tappContext.setAMContainerSpec(amContainer);\n\t\tappContext.setResource(capability);\n\t\tif (yarnQueue != null) {\n\t\t\tappContext.setQueue(yarnQueue);\n\t\t}\n\n\t\tsetApplicationTags(appContext);\n\n\t\t// add a hook to clean up in case deployment fails\n\t\tThread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication, yarnFilesDir);\n\t\tRuntime.getRuntime().addShutdownHook(deploymentFailureHook);\n\t\tLOG.info(\"Submitting application master \" + appId);\n\t\tyarnClient.submitApplication(appContext);\n\n\t\tLOG.info(\"Waiting for the cluster to be allocated\");\n\t\tfinal long startTime = System.currentTimeMillis();\n\t\tApplicationReport report;\n\t\tYarnApplicationState lastAppState = YarnApplicationState.NEW;\n\t\tloop: while (true) {\n\t\t\ttry {\n\t\t\t\treport = yarnClient.getApplicationReport(appId);\n\t\t\t} catch (IOException e) {\n\t\t\t\tthrow new YarnDeploymentException(\"Failed to deploy the cluster.\", e);\n\t\t\t}\n\t\t\tYarnApplicationState appState = report.getYarnApplicationState();\n\t\t\tLOG.debug(\"Application State: {}\", appState);\n\t\t\tswitch(appState) {\n\t\t\t\tcase FAILED:\n\t\t\t\tcase FINISHED: //TODO: the finished state may be valid in flip-6\n\t\t\t\tcase KILLED:\n\t\t\t\t\tthrow new YarnDeploymentException(\"The YARN application unexpectedly switched to state \"\n\t\t\t\t\t\t+ appState + \" during deployment. \\n\" +\n\t\t\t\t\t\t\"Diagnostics from YARN: \" + report.getDiagnostics() + \"\\n\" +\n\t\t\t\t\t\t\"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\\n\" +\n\t\t\t\t\t\t\"yarn logs -applicationId \" + appId);\n\t\t\t\t\t//break ..\n\t\t\t\tcase RUNNING:\n\t\t\t\t\tLOG.info(\"YARN application has been deployed successfully.\");\n\t\t\t\t\tbreak loop;\n\t\t\t\tdefault:\n\t\t\t\t\tif (appState != lastAppState) {\n\t\t\t\t\t\tLOG.info(\"Deploying cluster, current state \" + appState);\n\t\t\t\t\t}\n\t\t\t\t\tif (System.currentTimeMillis() - startTime > 60000) {\n\t\t\t\t\t\tLOG.info(\"Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster\");\n\t\t\t\t\t}\n\n\t\t\t}\n\t\t\tlastAppState = appState;\n\t\t\tThread.sleep(250);\n\t\t}\n\t\t// print the application id for user to cancel themselves.\n\t\tif (isDetachedMode()) {\n\t\t\tLOG.info(\"The Flink YARN client has been started in detached mode. In order to stop \" +\n\t\t\t\t\t\"Flink on YARN, use the following command or a YARN web interface to stop \" +\n\t\t\t\t\t\"it:\\nyarn application -kill \" + appId + \"\\nPlease also note that the \" +\n\t\t\t\t\t\"temporary files of the YARN session in the home directoy will not be removed.\");\n\t\t}\n\t\t// since deployment was successful, remove the hook\n\t\ttry {\n\t\t\tRuntime.getRuntime().removeShutdownHook(deploymentFailureHook);\n\t\t} catch (IllegalStateException e) {\n\t\t\t// we're already in the shut down hook.\n\t\t}\n\t\treturn report;\n\t}"
        ],
        [
            "AbstractYarnClusterDescriptor::deployInternal(ClusterSpecification,String,JobGraph,boolean)",
            " 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485 -\n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  ",
            "\t/**\n\t * This method will block until the ApplicationMaster/JobManager have been\n\t * deployed on YARN.\n\t *\n\t * @param clusterSpecification Initial cluster specification for the to be deployed Flink cluster\n\t * @param yarnClusterEntrypoint Class name of the Yarn cluster entry point.\n\t * @param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none\n\t * @param detached True if the cluster should be started in detached mode\n\t */\n\tprotected ClusterClient<ApplicationId> deployInternal(\n\t\t\tClusterSpecification clusterSpecification,\n\t\t\tString yarnClusterEntrypoint,\n\t\t\t@Nullable JobGraph jobGraph,\n\t\t\tboolean detached) throws Exception {\n\n\t\tif (UserGroupInformation.isSecurityEnabled()) {\n\t\t\t// note: UGI::hasKerberosCredentials inaccurately reports false\n\t\t\t// for logins based on a keytab (fixed in Hadoop 2.6.1, see HADOOP-10786),\n\t\t\t// so we check only in ticket cache scenario.\n\t\t\tboolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE);\n\n\t\t\tUserGroupInformation loginUser = UserGroupInformation.getCurrentUser();\n\t\t\tif (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS\n\t\t\t\t&& useTicketCache && !loginUser.hasKerberosCredentials()) {\n\t\t\t\tLOG.error(\"Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials\");\n\t\t\t\tthrow new RuntimeException(\"Hadoop security with Kerberos is enabled but the login user \" +\n\t\t\t\t\t\"does not have Kerberos credentials\");\n\t\t\t}\n\t\t}\n\n\t\tisReadyForDeployment(clusterSpecification);\n\n\t\t// ------------------ Check if the specified queue exists --------------------\n\n\t\tcheckYarnQueues(yarnClient);\n\n\t\t// ------------------ Add dynamic properties to local flinkConfiguraton ------\n\t\tMap<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded);\n\t\tfor (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {\n\t\t\tflinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue());\n\t\t}\n\n\t\t// ------------------ Check if the YARN ClusterClient has the requested resources --------------\n\n\t\t// Create application via yarnClient\n\t\tfinal YarnClientApplication yarnApplication = yarnClient.createApplication();\n\t\tfinal GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse();\n\n\t\tResource maxRes = appResponse.getMaximumResourceCapability();\n\n\t\tfinal ClusterResourceDescription freeClusterMem;\n\t\ttry {\n\t\t\tfreeClusterMem = getCurrentFreeClusterResources(yarnClient);\n\t\t} catch (YarnException | IOException e) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow new YarnDeploymentException(\"Could not retrieve information about free cluster resources.\", e);\n\t\t}\n\n\t\tfinal int yarnMinAllocationMB = yarnConfiguration.getInt(\"yarn.scheduler.minimum-allocation-mb\", 0);\n\n\t\tfinal ClusterSpecification validClusterSpecification;\n\t\ttry {\n\t\t\tvalidClusterSpecification = validateClusterResources(\n\t\t\t\tclusterSpecification,\n\t\t\t\tyarnMinAllocationMB,\n\t\t\t\tmaxRes,\n\t\t\t\tfreeClusterMem);\n\t\t} catch (YarnDeploymentException yde) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow yde;\n\t\t}\n\n\t\tLOG.info(\"Cluster specification: {}\", validClusterSpecification);\n\n\t\tfinal ClusterEntrypoint.ExecutionMode executionMode = detached ?\n\t\t\tClusterEntrypoint.ExecutionMode.DETACHED\n\t\t\t: ClusterEntrypoint.ExecutionMode.NORMAL;\n\n\t\tflinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString());\n\n\t\tApplicationReport report = startAppMaster(\n\t\t\tflinkConfiguration,\n\t\t\tyarnClusterEntrypoint,\n\t\t\tjobGraph,\n\t\t\tyarnClient,\n\t\t\tyarnApplication,\n\t\t\tclusterSpecification);\n\n\t\tString host = report.getHost();\n\t\tint port = report.getRpcPort();\n\n\t\t// Correctly initialize the Flink config\n\t\tflinkConfiguration.setString(JobManagerOptions.ADDRESS, host);\n\t\tflinkConfiguration.setInteger(JobManagerOptions.PORT, port);\n\n\t\tflinkConfiguration.setString(RestOptions.REST_ADDRESS, host);\n\t\tflinkConfiguration.setInteger(RestOptions.REST_PORT, port);\n\n\t\t// the Flink cluster is deployed in YARN. Represent cluster\n\t\treturn createYarnClusterClient(\n\t\t\tthis,\n\t\t\tclusterSpecification.getNumberTaskManagers(),\n\t\t\tclusterSpecification.getSlotsPerTaskManager(),\n\t\t\treport,\n\t\t\tflinkConfiguration,\n\t\t\ttrue);\n\t}",
            " 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485 +\n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  ",
            "\t/**\n\t * This method will block until the ApplicationMaster/JobManager have been\n\t * deployed on YARN.\n\t *\n\t * @param clusterSpecification Initial cluster specification for the to be deployed Flink cluster\n\t * @param yarnClusterEntrypoint Class name of the Yarn cluster entry point.\n\t * @param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none\n\t * @param detached True if the cluster should be started in detached mode\n\t */\n\tprotected ClusterClient<ApplicationId> deployInternal(\n\t\t\tClusterSpecification clusterSpecification,\n\t\t\tString yarnClusterEntrypoint,\n\t\t\t@Nullable JobGraph jobGraph,\n\t\t\tboolean detached) throws Exception {\n\n\t\tif (UserGroupInformation.isSecurityEnabled()) {\n\t\t\t// note: UGI::hasKerberosCredentials inaccurately reports false\n\t\t\t// for logins based on a keytab (fixed in Hadoop 2.6.1, see HADOOP-10786),\n\t\t\t// so we check only in ticket cache scenario.\n\t\t\tboolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE);\n\n\t\t\tUserGroupInformation loginUser = UserGroupInformation.getCurrentUser();\n\t\t\tif (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS\n\t\t\t\t&& useTicketCache && !loginUser.hasKerberosCredentials()) {\n\t\t\t\tLOG.error(\"Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials\");\n\t\t\t\tthrow new RuntimeException(\"Hadoop security with Kerberos is enabled but the login user \" +\n\t\t\t\t\t\"does not have Kerberos credentials\");\n\t\t\t}\n\t\t}\n\n\t\tisReadyForDeployment(clusterSpecification);\n\n\t\t// ------------------ Check if the specified queue exists --------------------\n\n\t\tcheckYarnQueues(yarnClient);\n\n\t\t// ------------------ Add dynamic properties to local flinkConfiguraton ------\n\t\tMap<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded);\n\t\tfor (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {\n\t\t\tflinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue());\n\t\t}\n\n\t\t// ------------------ Check if the YARN ClusterClient has the requested resources --------------\n\n\t\t// Create application via yarnClient\n\t\tfinal YarnClientApplication yarnApplication = yarnClient.createApplication();\n\t\tfinal GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse();\n\n\t\tResource maxRes = appResponse.getMaximumResourceCapability();\n\n\t\tfinal ClusterResourceDescription freeClusterMem;\n\t\ttry {\n\t\t\tfreeClusterMem = getCurrentFreeClusterResources(yarnClient);\n\t\t} catch (YarnException | IOException e) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow new YarnDeploymentException(\"Could not retrieve information about free cluster resources.\", e);\n\t\t}\n\n\t\tfinal int yarnMinAllocationMB = yarnConfiguration.getInt(\"yarn.scheduler.minimum-allocation-mb\", 0);\n\n\t\tfinal ClusterSpecification validClusterSpecification;\n\t\ttry {\n\t\t\tvalidClusterSpecification = validateClusterResources(\n\t\t\t\tclusterSpecification,\n\t\t\t\tyarnMinAllocationMB,\n\t\t\t\tmaxRes,\n\t\t\t\tfreeClusterMem);\n\t\t} catch (YarnDeploymentException yde) {\n\t\t\tfailSessionDuringDeployment(yarnClient, yarnApplication);\n\t\t\tthrow yde;\n\t\t}\n\n\t\tLOG.info(\"Cluster specification: {}\", validClusterSpecification);\n\n\t\tfinal ClusterEntrypoint.ExecutionMode executionMode = detached ?\n\t\t\tClusterEntrypoint.ExecutionMode.DETACHED\n\t\t\t: ClusterEntrypoint.ExecutionMode.NORMAL;\n\n\t\tflinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString());\n\n\t\tApplicationReport report = startAppMaster(\n\t\t\tnew Configuration(flinkConfiguration),\n\t\t\tyarnClusterEntrypoint,\n\t\t\tjobGraph,\n\t\t\tyarnClient,\n\t\t\tyarnApplication,\n\t\t\tclusterSpecification);\n\n\t\tString host = report.getHost();\n\t\tint port = report.getRpcPort();\n\n\t\t// Correctly initialize the Flink config\n\t\tflinkConfiguration.setString(JobManagerOptions.ADDRESS, host);\n\t\tflinkConfiguration.setInteger(JobManagerOptions.PORT, port);\n\n\t\tflinkConfiguration.setString(RestOptions.REST_ADDRESS, host);\n\t\tflinkConfiguration.setInteger(RestOptions.REST_PORT, port);\n\n\t\t// the Flink cluster is deployed in YARN. Represent cluster\n\t\treturn createYarnClusterClient(\n\t\t\tthis,\n\t\t\tclusterSpecification.getNumberTaskManagers(),\n\t\t\tclusterSpecification.getSlotsPerTaskManager(),\n\t\t\treport,\n\t\t\tflinkConfiguration,\n\t\t\ttrue);\n\t}"
        ]
    ],
    "8ea02ec2af5491a172fbe795d5f39b5835b7a83a": [
        [
            "Task::stopExecution()",
            " 940  \n 941  \n 942  \n 943  \n 944  \n 945  \n 946  \n 947  \n 948  \n 949 -\n 950 -\n 951 -\n 952 -\n 953 -\n 954 -\n 955 -\n 956 -\n 957 -\n 958 -\n 959 -\n 960  \n 961 -\n 962 -\n 963 -\n 964  \n 965 -\n 966  \n 967  ",
            "\t/**\n\t * Stops the executing task by calling {@link StoppableTask#stop()}.\n\t * <p>\n\t * This method never blocks.\n\t * </p>\n\t *\n\t * @throws UnsupportedOperationException\n\t *             if the {@link AbstractInvokable} does not implement {@link StoppableTask}\n\t */\n\tpublic void stopExecution() throws UnsupportedOperationException {\n\t\tLOG.info(\"Attempting to stop task {} ({}).\", taskNameWithSubtask, executionId);\n\t\tif (invokable instanceof StoppableTask) {\n\t\t\tRunnable runnable = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t((StoppableTask) invokable).stop();\n\t\t\t\t\t} catch (RuntimeException e) {\n\t\t\t\t\t\tLOG.error(\"Stopping task {} ({}) failed.\", taskNameWithSubtask, executionId, e);\n\t\t\t\t\t\ttaskManagerActions.failTask(executionId, e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\texecuteAsyncCallRunnable(runnable, String.format(\"Stopping source task %s (%s).\", taskNameWithSubtask, executionId));\n\t\t} else {\n\t\t\tthrow new UnsupportedOperationException(String.format(\"Stopping not supported by task %s (%s).\", taskNameWithSubtask, executionId));\n\t\t}\n\t}",
            " 939  \n 940  \n 941  \n 942  \n 943  \n 944  \n 945  \n 946  \n 947  \n 948 +\n 949 +\n 950 +\n 951 +\n 952 +\n 953 +\n 954 +\n 955 +\n 956 +\n 957 +\n 958 +\n 959 +\n 960 +\n 961  \n 962 +\n 963 +\n 964 +\n 965 +\n 966 +\n 967  \n 968 +\n 969 +\n 970 +\n 971 +\n 972 +\n 973  \n 974  ",
            "\t/**\n\t * Stops the executing task by calling {@link StoppableTask#stop()}.\n\t * <p>\n\t * This method never blocks.\n\t * </p>\n\t *\n\t * @throws UnsupportedOperationException if the {@link AbstractInvokable} does not implement {@link StoppableTask}\n\t * @throws IllegalStateException if the {@link Task} is not yet running\n\t */\n\tpublic void stopExecution() {\n\t\tif (invokable != null) {\n\t\t\tLOG.info(\"Attempting to stop task {} ({}).\", taskNameWithSubtask, executionId);\n\t\t\tif (invokable instanceof StoppableTask) {\n\t\t\t\tRunnable runnable = new Runnable() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t((StoppableTask) invokable).stop();\n\t\t\t\t\t\t} catch (RuntimeException e) {\n\t\t\t\t\t\t\tLOG.error(\"Stopping task {} ({}) failed.\", taskNameWithSubtask, executionId, e);\n\t\t\t\t\t\t\ttaskManagerActions.failTask(executionId, e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t\texecuteAsyncCallRunnable(runnable, String.format(\"Stopping source task %s (%s).\", taskNameWithSubtask, executionId));\n\t\t\t} else {\n\t\t\t\tthrow new UnsupportedOperationException(String.format(\"Stopping not supported by task %s (%s).\", taskNameWithSubtask, executionId));\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\tString.format(\n\t\t\t\t\t\"Cannot stop task %s (%s) because it is not yet running.\",\n\t\t\t\t\ttaskNameWithSubtask,\n\t\t\t\t\texecutionId));\n\t\t}\n\t}"
        ],
        [
            "TaskManagerTest::testStopTaskFailure()",
            "1687  \n1688  \n1689  \n1690  \n1691  \n1692  \n1693  \n1694  \n1695  \n1696  \n1697  \n1698  \n1699  \n1700  \n1701  \n1702  \n1703  \n1704  \n1705  \n1706  \n1707  \n1708  \n1709  \n1710  \n1711  \n1712  \n1713  \n1714  \n1715  \n1716  \n1717  \n1718  \n1719  \n1720  \n1721  \n1722  \n1723  \n1724  \n1725  \n1726  \n1727  \n1728  \n1729  \n1730  \n1731  \n1732  \n1733  \n1734  \n1735  \n1736  \n1737  \n1738  \n1739  \n1740  \n1741  \n1742  \n1743  \n1744  \n1745  \n1746  \n1747  \n1748  \n1749  \n1750  ",
            "\t/**\n\t * Tests that the TaskManager sends a proper exception back to the sender if the stop task\n\t * message fails.\n\t */\n\t@Test\n\tpublic void testStopTaskFailure() throws Exception {\n\t\tActorGateway jobManager = null;\n\t\tActorGateway taskManager = null;\n\n\t\ttry {\n\t\t\tfinal ExecutionAttemptID executionAttemptId = new ExecutionAttemptID();\n\n\t\t\tActorRef jm = system.actorOf(Props.create(SimpleJobManager.class, leaderSessionID));\n\t\t\tjobManager = new AkkaActorGateway(jm, leaderSessionID);\n\n\t\t\thighAvailabilityServices.setJobMasterLeaderRetriever(\n\t\t\t\tHighAvailabilityServices.DEFAULT_JOB_ID,\n\t\t\t\tnew StandaloneLeaderRetrievalService(jobManager.path(), jobManager.leaderSessionID()));\n\n\t\t\ttaskManager = TestingUtils.createTaskManager(\n\t\t\t\tsystem,\n\t\t\t\thighAvailabilityServices,\n\t\t\t\tnew Configuration(),\n\t\t\t\ttrue,\n\t\t\t\ttrue);\n\n\t\t\tTaskDeploymentDescriptor tdd = createTaskDeploymentDescriptor(\n\t\t\t\tnew JobID(),\n\t\t\t\t\"test job\",\n\t\t\t\tnew JobVertexID(),\n\t\t\t\texecutionAttemptId,\n\t\t\t\tnew SerializedValue<>(new ExecutionConfig()),\n\t\t\t\t\"test task\",\n\t\t\t\t1,\n\t\t\t\t0,\n\t\t\t\t1,\n\t\t\t\t0,\n\t\t\t\tnew Configuration(),\n\t\t\t\tnew Configuration(),\n\t\t\t\tBlockingNoOpInvokable.class.getName(),\n\t\t\t\tCollections.<ResultPartitionDeploymentDescriptor>emptyList(),\n\t\t\t\tCollections.<InputGateDeploymentDescriptor>emptyList(),\n\t\t\t\tCollections.emptyList(),\n\t\t\t\tCollections.emptyList(),\n\t\t\t\t0);\n\n\t\t\tFuture<Object> submitResponse = taskManager.ask(new SubmitTask(tdd), timeout);\n\n\t\t\tAwait.result(submitResponse, timeout);\n\n\t\t\tFuture<Object> stopResponse = taskManager.ask(new StopTask(executionAttemptId), timeout);\n\n\t\t\ttry {\n\t\t\t\tAwait.result(stopResponse, timeout);\n\n\t\t\t\tfail(\"The stop task message should have failed.\");\n\t\t\t} catch (UnsupportedOperationException e) {\n\t\t\t\t// expected\n\t\t\t}\n\t\t} finally {\n\t\t\tTestingUtils.stopActor(jobManager);\n\t\t\tTestingUtils.stopActor(taskManager);\n\t\t}\n\t}",
            "1687  \n1688  \n1689  \n1690  \n1691  \n1692  \n1693  \n1694  \n1695  \n1696  \n1697  \n1698  \n1699  \n1700  \n1701  \n1702  \n1703  \n1704  \n1705  \n1706  \n1707  \n1708  \n1709  \n1710  \n1711  \n1712  \n1713  \n1714  \n1715  \n1716  \n1717  \n1718  \n1719  \n1720  \n1721  \n1722  \n1723  \n1724  \n1725  \n1726  \n1727  \n1728  \n1729  \n1730  \n1731  \n1732  \n1733  \n1734  \n1735  \n1736  \n1737 +\n1738 +\n1739 +\n1740 +\n1741  \n1742  \n1743  \n1744  \n1745  \n1746  \n1747  \n1748  \n1749  \n1750  \n1751  \n1752  \n1753  \n1754  ",
            "\t/**\n\t * Tests that the TaskManager sends a proper exception back to the sender if the stop task\n\t * message fails.\n\t */\n\t@Test\n\tpublic void testStopTaskFailure() throws Exception {\n\t\tActorGateway jobManager = null;\n\t\tActorGateway taskManager = null;\n\n\t\ttry {\n\t\t\tfinal ExecutionAttemptID executionAttemptId = new ExecutionAttemptID();\n\n\t\t\tActorRef jm = system.actorOf(Props.create(SimpleJobManager.class, leaderSessionID));\n\t\t\tjobManager = new AkkaActorGateway(jm, leaderSessionID);\n\n\t\t\thighAvailabilityServices.setJobMasterLeaderRetriever(\n\t\t\t\tHighAvailabilityServices.DEFAULT_JOB_ID,\n\t\t\t\tnew StandaloneLeaderRetrievalService(jobManager.path(), jobManager.leaderSessionID()));\n\n\t\t\ttaskManager = TestingUtils.createTaskManager(\n\t\t\t\tsystem,\n\t\t\t\thighAvailabilityServices,\n\t\t\t\tnew Configuration(),\n\t\t\t\ttrue,\n\t\t\t\ttrue);\n\n\t\t\tTaskDeploymentDescriptor tdd = createTaskDeploymentDescriptor(\n\t\t\t\tnew JobID(),\n\t\t\t\t\"test job\",\n\t\t\t\tnew JobVertexID(),\n\t\t\t\texecutionAttemptId,\n\t\t\t\tnew SerializedValue<>(new ExecutionConfig()),\n\t\t\t\t\"test task\",\n\t\t\t\t1,\n\t\t\t\t0,\n\t\t\t\t1,\n\t\t\t\t0,\n\t\t\t\tnew Configuration(),\n\t\t\t\tnew Configuration(),\n\t\t\t\tBlockingNoOpInvokable.class.getName(),\n\t\t\t\tCollections.<ResultPartitionDeploymentDescriptor>emptyList(),\n\t\t\t\tCollections.<InputGateDeploymentDescriptor>emptyList(),\n\t\t\t\tCollections.emptyList(),\n\t\t\t\tCollections.emptyList(),\n\t\t\t\t0);\n\n\t\t\tFuture<Object> submitResponse = taskManager.ask(new SubmitTask(tdd), timeout);\n\n\t\t\tAwait.result(submitResponse, timeout);\n\n\t\t\tfinal Future<Object> taskRunning = taskManager.ask(new TestingTaskManagerMessages.NotifyWhenTaskIsRunning(executionAttemptId), timeout);\n\n\t\t\tAwait.result(taskRunning, timeout);\n\n\t\t\tFuture<Object> stopResponse = taskManager.ask(new StopTask(executionAttemptId), timeout);\n\n\t\t\ttry {\n\t\t\t\tAwait.result(stopResponse, timeout);\n\n\t\t\t\tfail(\"The stop task message should have failed.\");\n\t\t\t} catch (UnsupportedOperationException e) {\n\t\t\t\t// expected\n\t\t\t}\n\t\t} finally {\n\t\t\tTestingUtils.stopActor(jobManager);\n\t\t\tTestingUtils.stopActor(taskManager);\n\t\t}\n\t}"
        ]
    ],
    "97f556ebd122dfe16dd8e148d3ac7c5386fd08ac": [
        [
            "HeapKeyedStateBackend::HeapKeyedStateBackend(TaskKvStateRegistry,TypeSerializer,ClassLoader,int,KeyGroupRange,boolean,ExecutionConfig,LocalRecoveryConfig,HeapPriorityQueueSetFactory,TtlTimeProvider)",
            " 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176 -\n 177  \n 178  ",
            "\tpublic HeapKeyedStateBackend(\n\t\t\tTaskKvStateRegistry kvStateRegistry,\n\t\t\tTypeSerializer<K> keySerializer,\n\t\t\tClassLoader userCodeClassLoader,\n\t\t\tint numberOfKeyGroups,\n\t\t\tKeyGroupRange keyGroupRange,\n\t\t\tboolean asynchronousSnapshots,\n\t\t\tExecutionConfig executionConfig,\n\t\t\tLocalRecoveryConfig localRecoveryConfig,\n\t\t\tHeapPriorityQueueSetFactory priorityQueueSetFactory,\n\t\t\tTtlTimeProvider ttlTimeProvider) {\n\n\t\tsuper(kvStateRegistry, keySerializer, userCodeClassLoader,\n\t\t\tnumberOfKeyGroups, keyGroupRange, executionConfig, ttlTimeProvider);\n\n\t\tthis.registeredKVStates = new HashMap<>();\n\t\tthis.registeredPQStates = new HashMap<>();\n\t\tthis.localRecoveryConfig = Preconditions.checkNotNull(localRecoveryConfig);\n\n\t\tSnapshotStrategySynchronicityBehavior<K> synchronicityTrait = asynchronousSnapshots ?\n\t\t\tnew AsyncSnapshotStrategySynchronicityBehavior() :\n\t\t\tnew SyncSnapshotStrategySynchronicityBehavior();\n\n\t\tthis.snapshotStrategy = new HeapSnapshotStrategy(synchronicityTrait);\n\t\tLOG.info(\"Initializing heap keyed state backend with stream factory.\");\n\t\tthis.restoredStateMetaInfo = new HashMap<>();\n\t\tthis.priorityQueueSetFactory = priorityQueueSetFactory;\n\t}",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  ",
            "\tpublic HeapKeyedStateBackend(\n\t\t\tTaskKvStateRegistry kvStateRegistry,\n\t\t\tTypeSerializer<K> keySerializer,\n\t\t\tClassLoader userCodeClassLoader,\n\t\t\tint numberOfKeyGroups,\n\t\t\tKeyGroupRange keyGroupRange,\n\t\t\tboolean asynchronousSnapshots,\n\t\t\tExecutionConfig executionConfig,\n\t\t\tLocalRecoveryConfig localRecoveryConfig,\n\t\t\tHeapPriorityQueueSetFactory priorityQueueSetFactory,\n\t\t\tTtlTimeProvider ttlTimeProvider) {\n\n\t\tsuper(kvStateRegistry, keySerializer, userCodeClassLoader,\n\t\t\tnumberOfKeyGroups, keyGroupRange, executionConfig, ttlTimeProvider);\n\n\t\tthis.registeredKVStates = new HashMap<>();\n\t\tthis.registeredPQStates = new HashMap<>();\n\t\tthis.localRecoveryConfig = Preconditions.checkNotNull(localRecoveryConfig);\n\n\t\tSnapshotStrategySynchronicityBehavior<K> synchronicityTrait = asynchronousSnapshots ?\n\t\t\tnew AsyncSnapshotStrategySynchronicityBehavior() :\n\t\t\tnew SyncSnapshotStrategySynchronicityBehavior();\n\n\t\tthis.snapshotStrategy = new HeapSnapshotStrategy(synchronicityTrait);\n\t\tLOG.info(\"Initializing heap keyed state backend with stream factory.\");\n\t\tthis.priorityQueueSetFactory = priorityQueueSetFactory;\n\t}"
        ],
        [
            "DefaultOperatorStateBackend::getBroadcastState(MapStateDescriptor)",
            " 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229 -\n 230  \n 231  \n 232 -\n 233 -\n 234 -\n 235  \n 236 -\n 237  \n 238  \n 239  \n 240  \n 241 -\n 242 -\n 243 -\n 244  \n 245 -\n 246  \n 247  \n 248  \n 249  \n 250 -\n 251 -\n 252 -\n 253 -\n 254 -\n 255 -\n 256 -\n 257  \n 258  \n 259  \n 260  \n 261  ",
            "\t@SuppressWarnings(\"unchecked\")\n\t@Override\n\tpublic <K, V> BroadcastState<K, V> getBroadcastState(final MapStateDescriptor<K, V> stateDescriptor) throws StateMigrationException {\n\n\t\tPreconditions.checkNotNull(stateDescriptor);\n\t\tString name = Preconditions.checkNotNull(stateDescriptor.getName());\n\n\t\tBackendWritableBroadcastState<K, V> previous =\n\t\t\t(BackendWritableBroadcastState<K, V>) accessedBroadcastStatesByName.get(name);\n\n\t\tif (previous != null) {\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tprevious.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tprevious.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST);\n\t\t\treturn previous;\n\t\t}\n\n\t\tstateDescriptor.initializeSerializerUnlessSet(getExecutionConfig());\n\t\tTypeSerializer<K> broadcastStateKeySerializer = Preconditions.checkNotNull(stateDescriptor.getKeySerializer());\n\t\tTypeSerializer<V> broadcastStateValueSerializer = Preconditions.checkNotNull(stateDescriptor.getValueSerializer());\n\n\t\tBackendWritableBroadcastState<K, V> broadcastState =\n\t\t\t(BackendWritableBroadcastState<K, V>) registeredBroadcastStates.get(name);\n\n\t\tif (broadcastState == null) {\n\t\t\tbroadcastState = new HeapBroadcastState<>(\n\t\t\t\t\tnew RegisteredBroadcastStateBackendMetaInfo<>(\n\t\t\t\t\t\t\tname,\n\t\t\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST,\n\t\t\t\t\t\t\tbroadcastStateKeySerializer,\n\t\t\t\t\t\t\tbroadcastStateValueSerializer));\n\t\t\tregisteredBroadcastStates.put(name, broadcastState);\n\t\t} else {\n\t\t\t// has restored state; check compatibility of new state access\n\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tbroadcastState.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tbroadcastState.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST);\n\n\t\t\tfinal StateMetaInfoSnapshot metaInfoSnapshot = restoredBroadcastStateMetaInfos.get(name);\n\n\t\t\t// check whether new serializers are incompatible\n\t\t\tTypeSerializerSnapshot<K> keySerializerSnapshot = Preconditions.checkNotNull(\n\t\t\t\t(TypeSerializerSnapshot<K>) metaInfoSnapshot.getTypeSerializerConfigSnapshot(StateMetaInfoSnapshot.CommonSerializerKeys.KEY_SERIALIZER));\n\n\t\t\tTypeSerializerSchemaCompatibility<K> keyCompatibility =\n\t\t\t\tkeySerializerSnapshot.resolveSchemaCompatibility(broadcastStateKeySerializer);\n\t\t\tif (keyCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"The new key serializer for broadcast state must not be incompatible.\");\n\t\t\t}\n\n\t\t\tTypeSerializerSnapshot<V> valueSerializerSnapshot = Preconditions.checkNotNull(\n\t\t\t\t(TypeSerializerSnapshot<V>) metaInfoSnapshot.getTypeSerializerConfigSnapshot(StateMetaInfoSnapshot.CommonSerializerKeys.VALUE_SERIALIZER));\n\n\t\t\tTypeSerializerSchemaCompatibility<V> valueCompatibility =\n\t\t\t\tvalueSerializerSnapshot.resolveSchemaCompatibility(broadcastStateValueSerializer);\n\t\t\tif (valueCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"The new value serializer for broadcast state must not be incompatible.\");\n\t\t\t}\n\n\t\t\t// new serializer is compatible; use it to replace the old serializer\n\t\t\tbroadcastState.setStateMetaInfo(\n\t\t\t\t\tnew RegisteredBroadcastStateBackendMetaInfo<>(\n\t\t\t\t\t\t\tname,\n\t\t\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST,\n\t\t\t\t\t\t\tbroadcastStateKeySerializer,\n\t\t\t\t\t\t\tbroadcastStateValueSerializer));\n\t\t}\n\n\t\taccessedBroadcastStatesByName.put(name, broadcastState);\n\t\treturn broadcastState;\n\t}",
            " 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213 +\n 214  \n 215  \n 216  \n 217 +\n 218  \n 219  \n 220  \n 221  \n 222  \n 223 +\n 224  \n 225  \n 226  \n 227  \n 228 +\n 229  \n 230  \n 231  \n 232  \n 233  ",
            "\t@SuppressWarnings(\"unchecked\")\n\t@Override\n\tpublic <K, V> BroadcastState<K, V> getBroadcastState(final MapStateDescriptor<K, V> stateDescriptor) throws StateMigrationException {\n\n\t\tPreconditions.checkNotNull(stateDescriptor);\n\t\tString name = Preconditions.checkNotNull(stateDescriptor.getName());\n\n\t\tBackendWritableBroadcastState<K, V> previous =\n\t\t\t(BackendWritableBroadcastState<K, V>) accessedBroadcastStatesByName.get(name);\n\n\t\tif (previous != null) {\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tprevious.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tprevious.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST);\n\t\t\treturn previous;\n\t\t}\n\n\t\tstateDescriptor.initializeSerializerUnlessSet(getExecutionConfig());\n\t\tTypeSerializer<K> broadcastStateKeySerializer = Preconditions.checkNotNull(stateDescriptor.getKeySerializer());\n\t\tTypeSerializer<V> broadcastStateValueSerializer = Preconditions.checkNotNull(stateDescriptor.getValueSerializer());\n\n\t\tBackendWritableBroadcastState<K, V> broadcastState =\n\t\t\t(BackendWritableBroadcastState<K, V>) registeredBroadcastStates.get(name);\n\n\t\tif (broadcastState == null) {\n\t\t\tbroadcastState = new HeapBroadcastState<>(\n\t\t\t\t\tnew RegisteredBroadcastStateBackendMetaInfo<>(\n\t\t\t\t\t\t\tname,\n\t\t\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST,\n\t\t\t\t\t\t\tbroadcastStateKeySerializer,\n\t\t\t\t\t\t\tbroadcastStateValueSerializer));\n\t\t\tregisteredBroadcastStates.put(name, broadcastState);\n\t\t} else {\n\t\t\t// has restored state; check compatibility of new state access\n\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tbroadcastState.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tbroadcastState.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tOperatorStateHandle.Mode.BROADCAST);\n\n\t\t\tRegisteredBroadcastStateBackendMetaInfo<K, V> restoredBroadcastStateMetaInfo = broadcastState.getStateMetaInfo();\n\n\t\t\t// check whether new serializers are incompatible\n\t\t\tTypeSerializerSchemaCompatibility<K> keyCompatibility =\n\t\t\t\trestoredBroadcastStateMetaInfo.updateKeySerializer(broadcastStateKeySerializer);\n\t\t\tif (keyCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"The new key serializer for broadcast state must not be incompatible.\");\n\t\t\t}\n\n\t\t\tTypeSerializerSchemaCompatibility<V> valueCompatibility =\n\t\t\t\trestoredBroadcastStateMetaInfo.updateValueSerializer(broadcastStateValueSerializer);\n\t\t\tif (valueCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"The new value serializer for broadcast state must not be incompatible.\");\n\t\t\t}\n\n\t\t\tbroadcastState.setStateMetaInfo(restoredBroadcastStateMetaInfo);\n\t\t}\n\n\t\taccessedBroadcastStatesByName.put(name, broadcastState);\n\t\treturn broadcastState;\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBIncrementalRestoreOperation::createAndRegisterColumnFamilyDescriptors(List)",
            "1153  \n1154  \n1155  \n1156  \n1157  \n1158  \n1159  \n1160  \n1161  \n1162  \n1163  \n1164  \n1165  \n1166  \n1167  \n1168  \n1169 -\n1170  \n1171  \n1172  ",
            "\t\t/**\n\t\t * This method recreates and registers all {@link ColumnFamilyDescriptor} from Flink's state meta data snapshot.\n\t\t */\n\t\tprivate List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors(\n\t\t\tList<StateMetaInfoSnapshot> stateMetaInfoSnapshots) {\n\n\t\t\tList<ColumnFamilyDescriptor> columnFamilyDescriptors =\n\t\t\t\tnew ArrayList<>(stateMetaInfoSnapshots.size());\n\n\t\t\tfor (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {\n\n\t\t\t\tColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\t\tstateMetaInfoSnapshot.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),\n\t\t\t\t\tstateBackend.columnOptions);\n\n\t\t\t\tcolumnFamilyDescriptors.add(columnFamilyDescriptor);\n\t\t\t\tstateBackend.restoredKvStateMetaInfos.put(stateMetaInfoSnapshot.getName(), stateMetaInfoSnapshot);\n\t\t\t}\n\t\t\treturn columnFamilyDescriptors;\n\t\t}",
            "1139  \n1140  \n1141  \n1142  \n1143  \n1144  \n1145  \n1146  \n1147  \n1148  \n1149  \n1150  \n1151  \n1152  \n1153  \n1154  \n1155  \n1156  \n1157  ",
            "\t\t/**\n\t\t * This method recreates and registers all {@link ColumnFamilyDescriptor} from Flink's state meta data snapshot.\n\t\t */\n\t\tprivate List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors(\n\t\t\tList<StateMetaInfoSnapshot> stateMetaInfoSnapshots) {\n\n\t\t\tList<ColumnFamilyDescriptor> columnFamilyDescriptors =\n\t\t\t\tnew ArrayList<>(stateMetaInfoSnapshots.size());\n\n\t\t\tfor (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {\n\n\t\t\t\tColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\t\tstateMetaInfoSnapshot.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),\n\t\t\t\t\tstateBackend.columnOptions);\n\n\t\t\t\tcolumnFamilyDescriptors.add(columnFamilyDescriptor);\n\t\t\t}\n\t\t\treturn columnFamilyDescriptors;\n\t\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBKeyedStateBackend(String,ClassLoader,File,DBOptions,ColumnFamilyOptions,TaskKvStateRegistry,TypeSerializer,int,KeyGroupRange,ExecutionConfig,boolean,LocalRecoveryConfig,RocksDBStateBackend,TtlTimeProvider,RocksDBNativeMetricOptions,MetricGroup)",
            " 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299 -\n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  ",
            "\tpublic RocksDBKeyedStateBackend(\n\t\tString operatorIdentifier,\n\t\tClassLoader userCodeClassLoader,\n\t\tFile instanceBasePath,\n\t\tDBOptions dbOptions,\n\t\tColumnFamilyOptions columnFamilyOptions,\n\t\tTaskKvStateRegistry kvStateRegistry,\n\t\tTypeSerializer<K> keySerializer,\n\t\tint numberOfKeyGroups,\n\t\tKeyGroupRange keyGroupRange,\n\t\tExecutionConfig executionConfig,\n\t\tboolean enableIncrementalCheckpointing,\n\t\tLocalRecoveryConfig localRecoveryConfig,\n\t\tRocksDBStateBackend.PriorityQueueStateType priorityQueueStateType,\n\t\tTtlTimeProvider ttlTimeProvider,\n\t\tRocksDBNativeMetricOptions metricOptions,\n\t\tMetricGroup metricGroup\n\t) throws IOException {\n\n\t\tsuper(kvStateRegistry, keySerializer, userCodeClassLoader,\n\t\t\tnumberOfKeyGroups, keyGroupRange, executionConfig, ttlTimeProvider);\n\n\t\tthis.operatorIdentifier = Preconditions.checkNotNull(operatorIdentifier);\n\n\t\tthis.enableIncrementalCheckpointing = enableIncrementalCheckpointing;\n\t\tthis.rocksDBResourceGuard = new ResourceGuard();\n\n\t\t// ensure that we use the right merge operator, because other code relies on this\n\t\tthis.columnOptions = Preconditions.checkNotNull(columnFamilyOptions)\n\t\t\t.setMergeOperatorName(MERGE_OPERATOR_NAME);\n\n\t\tthis.dbOptions = Preconditions.checkNotNull(dbOptions);\n\n\t\tthis.instanceBasePath = Preconditions.checkNotNull(instanceBasePath);\n\t\tthis.instanceRocksDBPath = new File(instanceBasePath, \"db\");\n\n\t\tcheckAndCreateDirectory(instanceBasePath);\n\n\t\tif (instanceRocksDBPath.exists()) {\n\t\t\t// Clear the base directory when the backend is created\n\t\t\t// in case something crashed and the backend never reached dispose()\n\t\t\tcleanInstanceBasePath();\n\t\t}\n\n\t\tthis.localRecoveryConfig = Preconditions.checkNotNull(localRecoveryConfig);\n\t\tthis.keyGroupPrefixBytes =\n\t\t\tRocksDBKeySerializationUtils.computeRequiredBytesInKeyGroupPrefix(getNumberOfKeyGroups());\n\t\tthis.kvStateInformation = new LinkedHashMap<>();\n\t\tthis.restoredKvStateMetaInfos = new HashMap<>();\n\n\t\tthis.writeOptions = new WriteOptions().setDisableWAL(true);\n\n\t\tthis.metricOptions = metricOptions;\n\t\tthis.metricGroup = metricGroup;\n\n\t\tswitch (priorityQueueStateType) {\n\t\t\tcase HEAP:\n\t\t\t\tthis.priorityQueueFactory = new HeapPriorityQueueSetFactory(keyGroupRange, numberOfKeyGroups, 128);\n\t\t\t\tbreak;\n\t\t\tcase ROCKSDB:\n\t\t\t\tthis.priorityQueueFactory = new RocksDBPriorityQueueSetFactory();\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new IllegalArgumentException(\"Unknown priority queue state type: \" + priorityQueueStateType);\n\t\t}\n\t}",
            " 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  ",
            "\tpublic RocksDBKeyedStateBackend(\n\t\tString operatorIdentifier,\n\t\tClassLoader userCodeClassLoader,\n\t\tFile instanceBasePath,\n\t\tDBOptions dbOptions,\n\t\tColumnFamilyOptions columnFamilyOptions,\n\t\tTaskKvStateRegistry kvStateRegistry,\n\t\tTypeSerializer<K> keySerializer,\n\t\tint numberOfKeyGroups,\n\t\tKeyGroupRange keyGroupRange,\n\t\tExecutionConfig executionConfig,\n\t\tboolean enableIncrementalCheckpointing,\n\t\tLocalRecoveryConfig localRecoveryConfig,\n\t\tRocksDBStateBackend.PriorityQueueStateType priorityQueueStateType,\n\t\tTtlTimeProvider ttlTimeProvider,\n\t\tRocksDBNativeMetricOptions metricOptions,\n\t\tMetricGroup metricGroup\n\t) throws IOException {\n\n\t\tsuper(kvStateRegistry, keySerializer, userCodeClassLoader,\n\t\t\tnumberOfKeyGroups, keyGroupRange, executionConfig, ttlTimeProvider);\n\n\t\tthis.operatorIdentifier = Preconditions.checkNotNull(operatorIdentifier);\n\n\t\tthis.enableIncrementalCheckpointing = enableIncrementalCheckpointing;\n\t\tthis.rocksDBResourceGuard = new ResourceGuard();\n\n\t\t// ensure that we use the right merge operator, because other code relies on this\n\t\tthis.columnOptions = Preconditions.checkNotNull(columnFamilyOptions)\n\t\t\t.setMergeOperatorName(MERGE_OPERATOR_NAME);\n\n\t\tthis.dbOptions = Preconditions.checkNotNull(dbOptions);\n\n\t\tthis.instanceBasePath = Preconditions.checkNotNull(instanceBasePath);\n\t\tthis.instanceRocksDBPath = new File(instanceBasePath, \"db\");\n\n\t\tcheckAndCreateDirectory(instanceBasePath);\n\n\t\tif (instanceRocksDBPath.exists()) {\n\t\t\t// Clear the base directory when the backend is created\n\t\t\t// in case something crashed and the backend never reached dispose()\n\t\t\tcleanInstanceBasePath();\n\t\t}\n\n\t\tthis.localRecoveryConfig = Preconditions.checkNotNull(localRecoveryConfig);\n\t\tthis.keyGroupPrefixBytes =\n\t\t\tRocksDBKeySerializationUtils.computeRequiredBytesInKeyGroupPrefix(getNumberOfKeyGroups());\n\t\tthis.kvStateInformation = new LinkedHashMap<>();\n\n\t\tthis.writeOptions = new WriteOptions().setDisableWAL(true);\n\n\t\tthis.metricOptions = metricOptions;\n\t\tthis.metricGroup = metricGroup;\n\n\t\tswitch (priorityQueueStateType) {\n\t\t\tcase HEAP:\n\t\t\t\tthis.priorityQueueFactory = new HeapPriorityQueueSetFactory(keyGroupRange, numberOfKeyGroups, 128);\n\t\t\t\tbreak;\n\t\t\tcase ROCKSDB:\n\t\t\t\tthis.priorityQueueFactory = new RocksDBPriorityQueueSetFactory();\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new IllegalArgumentException(\"Unknown priority queue state type: \" + priorityQueueStateType);\n\t\t}\n\t}"
        ],
        [
            "DefaultOperatorStateBackend::restore(Collection)",
            " 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348 -\n 349 -\n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384 -\n 385 -\n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  ",
            "\tpublic void restore(Collection<OperatorStateHandle> restoreSnapshots) throws Exception {\n\n\t\tif (null == restoreSnapshots || restoreSnapshots.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\n\t\tfor (OperatorStateHandle stateHandle : restoreSnapshots) {\n\n\t\t\tif (stateHandle == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tFSDataInputStream in = stateHandle.openInputStream();\n\t\t\tcloseStreamOnCancelRegistry.registerCloseable(in);\n\n\t\t\tClassLoader restoreClassLoader = Thread.currentThread().getContextClassLoader();\n\n\t\t\ttry {\n\t\t\t\tThread.currentThread().setContextClassLoader(userClassloader);\n\t\t\t\tOperatorBackendSerializationProxy backendSerializationProxy =\n\t\t\t\t\t\tnew OperatorBackendSerializationProxy(userClassloader);\n\n\t\t\t\tbackendSerializationProxy.read(new DataInputViewStreamWrapper(in));\n\n\t\t\t\tList<StateMetaInfoSnapshot> restoredOperatorMetaInfoSnapshots =\n\t\t\t\t\t\tbackendSerializationProxy.getOperatorStateMetaInfoSnapshots();\n\n\t\t\t\t// Recreate all PartitionableListStates from the meta info\n\t\t\t\tfor (StateMetaInfoSnapshot restoredSnapshot : restoredOperatorMetaInfoSnapshots) {\n\n\t\t\t\t\tfinal RegisteredOperatorStateBackendMetaInfo<?> restoredMetaInfo =\n\t\t\t\t\t\tnew RegisteredOperatorStateBackendMetaInfo<>(restoredSnapshot);\n\n\t\t\t\t\tif (restoredMetaInfo.getPartitionStateSerializer() instanceof UnloadableDummyTypeSerializer) {\n\n\t\t\t\t\t\t// must fail now if the previous serializer cannot be restored because there is no serializer\n\t\t\t\t\t\t// capable of reading previous state\n\t\t\t\t\t\t// TODO when eager state registration is in place, we can try to get a convert deserializer\n\t\t\t\t\t\t// TODO from the newly registered serializer instead of simply failing here\n\n\t\t\t\t\t\tthrow new IOException(\"Unable to restore operator state [\" + restoredSnapshot.getName() + \"].\" +\n\t\t\t\t\t\t\t\" The previous serializer of the operator state must be present; the serializer could\" +\n\t\t\t\t\t\t\t\" have been removed from the classpath, or its implementation have changed and could\" +\n\t\t\t\t\t\t\t\" not be loaded. This is a temporary restriction that will be fixed in future versions.\");\n\t\t\t\t\t}\n\n\t\t\t\t\trestoredOperatorStateMetaInfos.put(restoredSnapshot.getName(), restoredSnapshot);\n\n\t\t\t\t\tPartitionableListState<?> listState = registeredOperatorStates.get(restoredSnapshot.getName());\n\n\t\t\t\t\tif (null == listState) {\n\t\t\t\t\t\tlistState = new PartitionableListState<>(restoredMetaInfo);\n\n\t\t\t\t\t\tregisteredOperatorStates.put(listState.getStateMetaInfo().getName(), listState);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// ... and then get back the broadcast state.\n\t\t\t\tList<StateMetaInfoSnapshot> restoredBroadcastMetaInfoSnapshots =\n\t\t\t\t\t\tbackendSerializationProxy.getBroadcastStateMetaInfoSnapshots();\n\n\t\t\t\tfor (StateMetaInfoSnapshot restoredSnapshot : restoredBroadcastMetaInfoSnapshots) {\n\n\t\t\t\t\tfinal RegisteredBroadcastStateBackendMetaInfo<?, ?> restoredMetaInfo =\n\t\t\t\t\t\tnew RegisteredBroadcastStateBackendMetaInfo<>(restoredSnapshot);\n\n\t\t\t\t\tif (restoredMetaInfo.getKeySerializer() instanceof UnloadableDummyTypeSerializer ||\n\t\t\t\t\t\trestoredMetaInfo.getValueSerializer() instanceof UnloadableDummyTypeSerializer) {\n\n\t\t\t\t\t\t// must fail now if the previous serializer cannot be restored because there is no serializer\n\t\t\t\t\t\t// capable of reading previous state\n\t\t\t\t\t\t// TODO when eager state registration is in place, we can try to get a convert deserializer\n\t\t\t\t\t\t// TODO from the newly registered serializer instead of simply failing here\n\n\t\t\t\t\t\tthrow new IOException(\"Unable to restore broadcast state [\" + restoredSnapshot.getName() + \"].\" +\n\t\t\t\t\t\t\t\t\" The previous key and value serializers of the state must be present; the serializers could\" +\n\t\t\t\t\t\t\t\t\" have been removed from the classpath, or their implementations have changed and could\" +\n\t\t\t\t\t\t\t\t\" not be loaded. This is a temporary restriction that will be fixed in future versions.\");\n\t\t\t\t\t}\n\n\t\t\t\t\trestoredBroadcastStateMetaInfos.put(restoredSnapshot.getName(), restoredSnapshot);\n\n\t\t\t\t\tBackendWritableBroadcastState<? ,?> broadcastState = registeredBroadcastStates.get(restoredSnapshot.getName());\n\n\t\t\t\t\tif (broadcastState == null) {\n\t\t\t\t\t\tbroadcastState = new HeapBroadcastState<>(restoredMetaInfo);\n\n\t\t\t\t\t\tregisteredBroadcastStates.put(broadcastState.getStateMetaInfo().getName(), broadcastState);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Restore all the states\n\t\t\t\tfor (Map.Entry<String, OperatorStateHandle.StateMetaInfo> nameToOffsets :\n\t\t\t\t\t\tstateHandle.getStateNameToPartitionOffsets().entrySet()) {\n\n\t\t\t\t\tfinal String stateName = nameToOffsets.getKey();\n\n\t\t\t\t\tPartitionableListState<?> listStateForName = registeredOperatorStates.get(stateName);\n\t\t\t\t\tif (listStateForName == null) {\n\t\t\t\t\t\tBackendWritableBroadcastState<?, ?> broadcastStateForName = registeredBroadcastStates.get(stateName);\n\t\t\t\t\t\tPreconditions.checkState(broadcastStateForName != null, \"Found state without \" +\n\t\t\t\t\t\t\t\t\"corresponding meta info: \" + stateName);\n\t\t\t\t\t\tdeserializeBroadcastStateValues(broadcastStateForName, in, nameToOffsets.getValue());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdeserializeOperatorStateValues(listStateForName, in, nameToOffsets.getValue());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t} finally {\n\t\t\t\tThread.currentThread().setContextClassLoader(restoreClassLoader);\n\t\t\t\tif (closeStreamOnCancelRegistry.unregisterCloseable(in)) {\n\t\t\t\t\tIOUtils.closeQuietly(in);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
            " 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  ",
            "\tpublic void restore(Collection<OperatorStateHandle> restoreSnapshots) throws Exception {\n\n\t\tif (null == restoreSnapshots || restoreSnapshots.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\n\t\tfor (OperatorStateHandle stateHandle : restoreSnapshots) {\n\n\t\t\tif (stateHandle == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tFSDataInputStream in = stateHandle.openInputStream();\n\t\t\tcloseStreamOnCancelRegistry.registerCloseable(in);\n\n\t\t\tClassLoader restoreClassLoader = Thread.currentThread().getContextClassLoader();\n\n\t\t\ttry {\n\t\t\t\tThread.currentThread().setContextClassLoader(userClassloader);\n\t\t\t\tOperatorBackendSerializationProxy backendSerializationProxy =\n\t\t\t\t\t\tnew OperatorBackendSerializationProxy(userClassloader);\n\n\t\t\t\tbackendSerializationProxy.read(new DataInputViewStreamWrapper(in));\n\n\t\t\t\tList<StateMetaInfoSnapshot> restoredOperatorMetaInfoSnapshots =\n\t\t\t\t\t\tbackendSerializationProxy.getOperatorStateMetaInfoSnapshots();\n\n\t\t\t\t// Recreate all PartitionableListStates from the meta info\n\t\t\t\tfor (StateMetaInfoSnapshot restoredSnapshot : restoredOperatorMetaInfoSnapshots) {\n\n\t\t\t\t\tfinal RegisteredOperatorStateBackendMetaInfo<?> restoredMetaInfo =\n\t\t\t\t\t\tnew RegisteredOperatorStateBackendMetaInfo<>(restoredSnapshot);\n\n\t\t\t\t\tif (restoredMetaInfo.getPartitionStateSerializer() instanceof UnloadableDummyTypeSerializer) {\n\n\t\t\t\t\t\t// must fail now if the previous serializer cannot be restored because there is no serializer\n\t\t\t\t\t\t// capable of reading previous state\n\t\t\t\t\t\t// TODO when eager state registration is in place, we can try to get a convert deserializer\n\t\t\t\t\t\t// TODO from the newly registered serializer instead of simply failing here\n\n\t\t\t\t\t\tthrow new IOException(\"Unable to restore operator state [\" + restoredSnapshot.getName() + \"].\" +\n\t\t\t\t\t\t\t\" The previous serializer of the operator state must be present; the serializer could\" +\n\t\t\t\t\t\t\t\" have been removed from the classpath, or its implementation have changed and could\" +\n\t\t\t\t\t\t\t\" not be loaded. This is a temporary restriction that will be fixed in future versions.\");\n\t\t\t\t\t}\n\n\t\t\t\t\tPartitionableListState<?> listState = registeredOperatorStates.get(restoredSnapshot.getName());\n\n\t\t\t\t\tif (null == listState) {\n\t\t\t\t\t\tlistState = new PartitionableListState<>(restoredMetaInfo);\n\n\t\t\t\t\t\tregisteredOperatorStates.put(listState.getStateMetaInfo().getName(), listState);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// ... and then get back the broadcast state.\n\t\t\t\tList<StateMetaInfoSnapshot> restoredBroadcastMetaInfoSnapshots =\n\t\t\t\t\t\tbackendSerializationProxy.getBroadcastStateMetaInfoSnapshots();\n\n\t\t\t\tfor (StateMetaInfoSnapshot restoredSnapshot : restoredBroadcastMetaInfoSnapshots) {\n\n\t\t\t\t\tfinal RegisteredBroadcastStateBackendMetaInfo<?, ?> restoredMetaInfo =\n\t\t\t\t\t\tnew RegisteredBroadcastStateBackendMetaInfo<>(restoredSnapshot);\n\n\t\t\t\t\tif (restoredMetaInfo.getKeySerializer() instanceof UnloadableDummyTypeSerializer ||\n\t\t\t\t\t\trestoredMetaInfo.getValueSerializer() instanceof UnloadableDummyTypeSerializer) {\n\n\t\t\t\t\t\t// must fail now if the previous serializer cannot be restored because there is no serializer\n\t\t\t\t\t\t// capable of reading previous state\n\t\t\t\t\t\t// TODO when eager state registration is in place, we can try to get a convert deserializer\n\t\t\t\t\t\t// TODO from the newly registered serializer instead of simply failing here\n\n\t\t\t\t\t\tthrow new IOException(\"Unable to restore broadcast state [\" + restoredSnapshot.getName() + \"].\" +\n\t\t\t\t\t\t\t\t\" The previous key and value serializers of the state must be present; the serializers could\" +\n\t\t\t\t\t\t\t\t\" have been removed from the classpath, or their implementations have changed and could\" +\n\t\t\t\t\t\t\t\t\" not be loaded. This is a temporary restriction that will be fixed in future versions.\");\n\t\t\t\t\t}\n\n\t\t\t\t\tBackendWritableBroadcastState<? ,?> broadcastState = registeredBroadcastStates.get(restoredSnapshot.getName());\n\n\t\t\t\t\tif (broadcastState == null) {\n\t\t\t\t\t\tbroadcastState = new HeapBroadcastState<>(restoredMetaInfo);\n\n\t\t\t\t\t\tregisteredBroadcastStates.put(broadcastState.getStateMetaInfo().getName(), broadcastState);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Restore all the states\n\t\t\t\tfor (Map.Entry<String, OperatorStateHandle.StateMetaInfo> nameToOffsets :\n\t\t\t\t\t\tstateHandle.getStateNameToPartitionOffsets().entrySet()) {\n\n\t\t\t\t\tfinal String stateName = nameToOffsets.getKey();\n\n\t\t\t\t\tPartitionableListState<?> listStateForName = registeredOperatorStates.get(stateName);\n\t\t\t\t\tif (listStateForName == null) {\n\t\t\t\t\t\tBackendWritableBroadcastState<?, ?> broadcastStateForName = registeredBroadcastStates.get(stateName);\n\t\t\t\t\t\tPreconditions.checkState(broadcastStateForName != null, \"Found state without \" +\n\t\t\t\t\t\t\t\t\"corresponding meta info: \" + stateName);\n\t\t\t\t\t\tdeserializeBroadcastStateValues(broadcastStateForName, in, nameToOffsets.getValue());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdeserializeOperatorStateValues(listStateForName, in, nameToOffsets.getValue());\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t} finally {\n\t\t\t\tThread.currentThread().setContextClassLoader(restoreClassLoader);\n\t\t\t\tif (closeStreamOnCancelRegistry.unregisterCloseable(in)) {\n\t\t\t\t\tIOUtils.closeQuietly(in);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::restore(Collection)",
            " 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513 -\n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  ",
            "\t@Override\n\tpublic void restore(Collection<KeyedStateHandle> restoreState) throws Exception {\n\n\t\tLOG.info(\"Initializing RocksDB keyed state backend.\");\n\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tLOG.debug(\"Restoring snapshot from state handles: {}.\", restoreState);\n\t\t}\n\n\t\t// clear all meta data\n\t\tkvStateInformation.clear();\n\t\trestoredKvStateMetaInfos.clear();\n\n\t\ttry {\n\t\t\tRocksDBIncrementalRestoreOperation<K> incrementalRestoreOperation = null;\n\t\t\tif (restoreState == null || restoreState.isEmpty()) {\n\t\t\t\tcreateDB();\n\t\t\t} else {\n\t\t\t\tKeyedStateHandle firstStateHandle = restoreState.iterator().next();\n\t\t\t\tif (firstStateHandle instanceof IncrementalKeyedStateHandle\n\t\t\t\t\t|| firstStateHandle instanceof IncrementalLocalKeyedStateHandle) {\n\t\t\t\t\tincrementalRestoreOperation = new RocksDBIncrementalRestoreOperation<>(this);\n\t\t\t\t\tincrementalRestoreOperation.restore(restoreState);\n\t\t\t\t} else {\n\t\t\t\t\tRocksDBFullRestoreOperation<K> fullRestoreOperation = new RocksDBFullRestoreOperation<>(this);\n\t\t\t\t\tfullRestoreOperation.doRestore(restoreState);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tinitializeSnapshotStrategy(incrementalRestoreOperation);\n\t\t} catch (Exception ex) {\n\t\t\tdispose();\n\t\t\tthrow ex;\n\t\t}\n\t}",
            " 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  ",
            "\t@Override\n\tpublic void restore(Collection<KeyedStateHandle> restoreState) throws Exception {\n\n\t\tLOG.info(\"Initializing RocksDB keyed state backend.\");\n\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tLOG.debug(\"Restoring snapshot from state handles: {}.\", restoreState);\n\t\t}\n\n\t\t// clear all meta data\n\t\tkvStateInformation.clear();\n\n\t\ttry {\n\t\t\tRocksDBIncrementalRestoreOperation<K> incrementalRestoreOperation = null;\n\t\t\tif (restoreState == null || restoreState.isEmpty()) {\n\t\t\t\tcreateDB();\n\t\t\t} else {\n\t\t\t\tKeyedStateHandle firstStateHandle = restoreState.iterator().next();\n\t\t\t\tif (firstStateHandle instanceof IncrementalKeyedStateHandle\n\t\t\t\t\t|| firstStateHandle instanceof IncrementalLocalKeyedStateHandle) {\n\t\t\t\t\tincrementalRestoreOperation = new RocksDBIncrementalRestoreOperation<>(this);\n\t\t\t\t\tincrementalRestoreOperation.restore(restoreState);\n\t\t\t\t} else {\n\t\t\t\t\tRocksDBFullRestoreOperation<K> fullRestoreOperation = new RocksDBFullRestoreOperation<>(this);\n\t\t\t\t\tfullRestoreOperation.doRestore(restoreState);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tinitializeSnapshotStrategy(incrementalRestoreOperation);\n\t\t} catch (Exception ex) {\n\t\t\tdispose();\n\t\t\tthrow ex;\n\t\t}\n\t}"
        ],
        [
            "DefaultOperatorStateBackend::DefaultOperatorStateBackend(ClassLoader,ExecutionConfig,boolean)",
            " 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151 -\n 152 -\n 153  \n 154  ",
            "\tpublic DefaultOperatorStateBackend(\n\t\tClassLoader userClassLoader,\n\t\tExecutionConfig executionConfig,\n\t\tboolean asynchronousSnapshots) {\n\n\t\tthis.closeStreamOnCancelRegistry = new CloseableRegistry();\n\t\tthis.userClassloader = Preconditions.checkNotNull(userClassLoader);\n\t\tthis.executionConfig = executionConfig;\n\t\tthis.javaSerializer = new JavaSerializer<>();\n\t\tthis.registeredOperatorStates = new HashMap<>();\n\t\tthis.registeredBroadcastStates = new HashMap<>();\n\t\tthis.asynchronousSnapshots = asynchronousSnapshots;\n\t\tthis.accessedStatesByName = new HashMap<>();\n\t\tthis.accessedBroadcastStatesByName = new HashMap<>();\n\t\tthis.restoredOperatorStateMetaInfos = new HashMap<>();\n\t\tthis.restoredBroadcastStateMetaInfos = new HashMap<>();\n\t\tthis.snapshotStrategy = new DefaultOperatorStateBackendSnapshotStrategy();\n\t}",
            " 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  ",
            "\tpublic DefaultOperatorStateBackend(\n\t\tClassLoader userClassLoader,\n\t\tExecutionConfig executionConfig,\n\t\tboolean asynchronousSnapshots) {\n\n\t\tthis.closeStreamOnCancelRegistry = new CloseableRegistry();\n\t\tthis.userClassloader = Preconditions.checkNotNull(userClassLoader);\n\t\tthis.executionConfig = executionConfig;\n\t\tthis.javaSerializer = new JavaSerializer<>();\n\t\tthis.registeredOperatorStates = new HashMap<>();\n\t\tthis.registeredBroadcastStates = new HashMap<>();\n\t\tthis.asynchronousSnapshots = asynchronousSnapshots;\n\t\tthis.accessedStatesByName = new HashMap<>();\n\t\tthis.accessedBroadcastStatesByName = new HashMap<>();\n\t\tthis.snapshotStrategy = new DefaultOperatorStateBackendSnapshotStrategy();\n\t}"
        ],
        [
            "HeapKeyedStateBackend::createOrCheckStateForMetaInfo(List,Map)",
            " 534  \n 535  \n 536  \n 537  \n 538  \n 539 -\n 540 -\n 541 -\n 542 -\n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  ",
            "\tprivate void createOrCheckStateForMetaInfo(\n\t\tList<StateMetaInfoSnapshot> restoredMetaInfo,\n\t\tMap<Integer, StateMetaInfoSnapshot> kvStatesById) {\n\n\t\tfor (StateMetaInfoSnapshot metaInfoSnapshot : restoredMetaInfo) {\n\t\t\trestoredStateMetaInfo.put(\n\t\t\t\tStateUID.of(metaInfoSnapshot.getName(), metaInfoSnapshot.getBackendStateType()),\n\t\t\t\tmetaInfoSnapshot);\n\n\t\t\tfinal StateSnapshotRestore registeredState;\n\n\t\t\tswitch (metaInfoSnapshot.getBackendStateType()) {\n\t\t\t\tcase KEY_VALUE:\n\t\t\t\t\tregisteredState = registeredKVStates.get(metaInfoSnapshot.getName());\n\t\t\t\t\tif (registeredState == null) {\n\t\t\t\t\t\tRegisteredKeyValueStateBackendMetaInfo<?, ?> registeredKeyedBackendStateMetaInfo =\n\t\t\t\t\t\t\tnew RegisteredKeyValueStateBackendMetaInfo<>(metaInfoSnapshot);\n\t\t\t\t\t\tregisteredKVStates.put(\n\t\t\t\t\t\t\tmetaInfoSnapshot.getName(),\n\t\t\t\t\t\t\tsnapshotStrategy.newStateTable(registeredKeyedBackendStateMetaInfo));\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase PRIORITY_QUEUE:\n\t\t\t\t\tregisteredState = registeredPQStates.get(metaInfoSnapshot.getName());\n\t\t\t\t\tif (registeredState == null) {\n\t\t\t\t\t\tcreateInternal(new RegisteredPriorityQueueStateBackendMetaInfo<>(metaInfoSnapshot));\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new IllegalStateException(\"Unexpected state type: \" +\n\t\t\t\t\t\tmetaInfoSnapshot.getBackendStateType() + \".\");\n\t\t\t}\n\n\t\t\tif (registeredState == null) {\n\t\t\t\tkvStatesById.put(kvStatesById.size(), metaInfoSnapshot);\n\t\t\t}\n\t\t}\n\t}",
            " 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  ",
            "\tprivate void createOrCheckStateForMetaInfo(\n\t\tList<StateMetaInfoSnapshot> restoredMetaInfo,\n\t\tMap<Integer, StateMetaInfoSnapshot> kvStatesById) {\n\n\t\tfor (StateMetaInfoSnapshot metaInfoSnapshot : restoredMetaInfo) {\n\t\t\tfinal StateSnapshotRestore registeredState;\n\n\t\t\tswitch (metaInfoSnapshot.getBackendStateType()) {\n\t\t\t\tcase KEY_VALUE:\n\t\t\t\t\tregisteredState = registeredKVStates.get(metaInfoSnapshot.getName());\n\t\t\t\t\tif (registeredState == null) {\n\t\t\t\t\t\tRegisteredKeyValueStateBackendMetaInfo<?, ?> registeredKeyedBackendStateMetaInfo =\n\t\t\t\t\t\t\tnew RegisteredKeyValueStateBackendMetaInfo<>(metaInfoSnapshot);\n\t\t\t\t\t\tregisteredKVStates.put(\n\t\t\t\t\t\t\tmetaInfoSnapshot.getName(),\n\t\t\t\t\t\t\tsnapshotStrategy.newStateTable(registeredKeyedBackendStateMetaInfo));\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase PRIORITY_QUEUE:\n\t\t\t\t\tregisteredState = registeredPQStates.get(metaInfoSnapshot.getName());\n\t\t\t\t\tif (registeredState == null) {\n\t\t\t\t\t\tcreateInternal(new RegisteredPriorityQueueStateBackendMetaInfo<>(metaInfoSnapshot));\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new IllegalStateException(\"Unexpected state type: \" +\n\t\t\t\t\t\tmetaInfoSnapshot.getBackendStateType() + \".\");\n\t\t\t}\n\n\t\t\tif (registeredState == null) {\n\t\t\t\tkvStatesById.put(kvStatesById.size(), metaInfoSnapshot);\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "HeapKeyedStateBackend::tryRegisterStateTable(TypeSerializer,StateDescriptor,StateSnapshotTransformer)",
            " 252  \n 253  \n 254  \n 255 -\n 256  \n 257  \n 258  \n 259  \n 260  \n 261 -\n 262 -\n 263 -\n 264 -\n 265 -\n 266 -\n 267  \n 268  \n 269 -\n 270 -\n 271 -\n 272 -\n 273 -\n 274 -\n 275 -\n 276 -\n 277 -\n 278  \n 279 -\n 280 -\n 281 -\n 282 -\n 283  \n 284  \n 285 -\n 286  \n 287  \n 288  \n 289  \n 290 -\n 291 -\n 292 -\n 293 -\n 294 -\n 295 -\n 296  \n 297  \n 298 -\n 299  \n 300  \n 301  \n 302  \n 303  \n 304 -\n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  ",
            "\tprivate <N, V> StateTable<K, N, V> tryRegisterStateTable(\n\t\t\tTypeSerializer<N> namespaceSerializer,\n\t\t\tStateDescriptor<?, V> stateDesc,\n\t\t\tStateSnapshotTransformer<V> snapshotTransformer) throws StateMigrationException {\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tStateTable<K, N, V> stateTable = (StateTable<K, N, V>) registeredKVStates.get(stateDesc.getName());\n\n\t\tTypeSerializer<V> newStateSerializer = stateDesc.getSerializer();\n\t\tRegisteredKeyValueStateBackendMetaInfo<N, V> newMetaInfo = new RegisteredKeyValueStateBackendMetaInfo<>(\n\t\t\tstateDesc.getType(),\n\t\t\tstateDesc.getName(),\n\t\t\tnamespaceSerializer,\n\t\t\tnewStateSerializer,\n\t\t\tsnapshotTransformer);\n\n\t\tif (stateTable != null) {\n\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\tStateMetaInfoSnapshot restoredMetaInfoSnapshot =\n\t\t\t\trestoredStateMetaInfo.get(\n\t\t\t\t\tStateUID.of(stateDesc.getName(), StateMetaInfoSnapshot.BackendStateType.KEY_VALUE));\n\n\t\t\tPreconditions.checkState(\n\t\t\t\trestoredMetaInfoSnapshot != null,\n\t\t\t\t\"Requested to check compatibility of a restored RegisteredKeyedBackendStateMetaInfo,\" +\n\t\t\t\t\t\" but its corresponding restored snapshot cannot be found.\");\n\n\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\tTypeSerializerSnapshot<N> namespaceSerializerSnapshot = Preconditions.checkNotNull(\n\t\t\t\t(TypeSerializerSnapshot<N>) restoredMetaInfoSnapshot.getTypeSerializerConfigSnapshot(\n\t\t\t\t\tStateMetaInfoSnapshot.CommonSerializerKeys.NAMESPACE_SERIALIZER.toString()));\n\n\t\t\tTypeSerializerSchemaCompatibility<N> namespaceCompatibility =\n\t\t\t\tnamespaceSerializerSnapshot.resolveSchemaCompatibility(namespaceSerializer);\n\t\t\tif (!namespaceCompatibility.isCompatibleAsIs()) {\n\t\t\t\tthrow new StateMigrationException(\"For heap backends, the new namespace serializer must be compatible.\");\n\t\t\t}\n\n\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\tTypeSerializerSnapshot<V> stateSerializerSnapshot = Preconditions.checkNotNull(\n\t\t\t\t(TypeSerializerSnapshot<V>) restoredMetaInfoSnapshot.getTypeSerializerConfigSnapshot(\n\t\t\t\t\tStateMetaInfoSnapshot.CommonSerializerKeys.VALUE_SERIALIZER.toString()));\n\n\t\t\tRegisteredKeyValueStateBackendMetaInfo.checkStateMetaInfo(restoredMetaInfoSnapshot, stateDesc);\n\n\t\t\tTypeSerializerSchemaCompatibility<V> stateCompatibility =\n\t\t\t\tstateSerializerSnapshot.resolveSchemaCompatibility(newStateSerializer);\n\n\t\t\tif (stateCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"For heap backends, the new state serializer must not be incompatible.\");\n\t\t\t}\n\n\t\t\tstateTable.setMetaInfo(newMetaInfo);\n\t\t} else {\n\t\t\tstateTable = snapshotStrategy.newStateTable(newMetaInfo);\n\t\t\tregisteredKVStates.put(stateDesc.getName(), stateTable);\n\t\t}\n\n\t\treturn stateTable;\n\t}",
            " 229  \n 230  \n 231  \n 232 +\n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240 +\n 241  \n 242 +\n 243  \n 244  \n 245 +\n 246  \n 247  \n 248  \n 249  \n 250 +\n 251  \n 252  \n 253 +\n 254  \n 255  \n 256  \n 257  \n 258  \n 259 +\n 260  \n 261 +\n 262 +\n 263 +\n 264 +\n 265 +\n 266 +\n 267 +\n 268  \n 269  \n 270  \n 271  \n 272  \n 273  ",
            "\tprivate <N, V> StateTable<K, N, V> tryRegisterStateTable(\n\t\t\tTypeSerializer<N> namespaceSerializer,\n\t\t\tStateDescriptor<?, V> stateDesc,\n\t\t\t@Nullable StateSnapshotTransformer<V> snapshotTransformer) throws StateMigrationException {\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tStateTable<K, N, V> stateTable = (StateTable<K, N, V>) registeredKVStates.get(stateDesc.getName());\n\n\t\tTypeSerializer<V> newStateSerializer = stateDesc.getSerializer();\n\n\t\tif (stateTable != null) {\n\t\t\tRegisteredKeyValueStateBackendMetaInfo<N, V> restoredKvMetaInfo = stateTable.getMetaInfo();\n\n\t\t\trestoredKvMetaInfo.updateSnapshotTransformer(snapshotTransformer);\n\n\t\t\tTypeSerializerSchemaCompatibility<N> namespaceCompatibility =\n\t\t\t\trestoredKvMetaInfo.updateNamespaceSerializer(namespaceSerializer);\n\t\t\tif (!namespaceCompatibility.isCompatibleAsIs()) {\n\t\t\t\tthrow new StateMigrationException(\"For heap backends, the new namespace serializer must be compatible.\");\n\t\t\t}\n\n\t\t\trestoredKvMetaInfo.checkStateMetaInfo(stateDesc);\n\n\t\t\tTypeSerializerSchemaCompatibility<V> stateCompatibility =\n\t\t\t\trestoredKvMetaInfo.updateStateSerializer(newStateSerializer);\n\n\t\t\tif (stateCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"For heap backends, the new state serializer must not be incompatible.\");\n\t\t\t}\n\n\t\t\tstateTable.setMetaInfo(restoredKvMetaInfo);\n\t\t} else {\n\t\t\tRegisteredKeyValueStateBackendMetaInfo<N, V> newMetaInfo = new RegisteredKeyValueStateBackendMetaInfo<>(\n\t\t\t\tstateDesc.getType(),\n\t\t\t\tstateDesc.getName(),\n\t\t\t\tnamespaceSerializer,\n\t\t\t\tnewStateSerializer,\n\t\t\t\tsnapshotTransformer);\n\n\t\t\tstateTable = snapshotStrategy.newStateTable(newMetaInfo);\n\t\t\tregisteredKVStates.put(stateDesc.getName(), stateTable);\n\t\t}\n\n\t\treturn stateTable;\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::RocksDBFullRestoreOperation::restoreKVStateMetaData()",
            " 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756 -\n 757 -\n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  ",
            "\t\t/**\n\t\t * Restore the KV-state / ColumnFamily meta data for all key-groups referenced by the current state handle.\n\t\t */\n\t\tprivate void restoreKVStateMetaData() throws IOException, StateMigrationException, RocksDBException {\n\n\t\t\t// isSerializerPresenceRequired flag is set to false, since for the RocksDB state backend,\n\t\t\t// deserialization of state happens lazily during runtime; we depend on the fact\n\t\t\t// that the new serializer for states could be compatible, and therefore the restore can continue\n\t\t\t// without old serializers required to be present.\n\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(rocksDBKeyedStateBackend.userCodeClassLoader);\n\n\t\t\tserializationProxy.read(currentStateHandleInView);\n\n\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\tif (!serializationProxy.getKeySerializerConfigSnapshot()\n\t\t\t\t\t.resolveSchemaCompatibility(rocksDBKeyedStateBackend.keySerializer).isCompatibleAsIs()) {\n\t\t\t\tthrow new StateMigrationException(\"The new key serializer must be compatible.\");\n\t\t\t}\n\n\t\t\tthis.keygroupStreamCompressionDecorator = serializationProxy.isUsingKeyGroupCompression() ?\n\t\t\t\tSnappyStreamCompressionDecorator.INSTANCE : UncompressedStreamCompressionDecorator.INSTANCE;\n\n\t\t\tList<StateMetaInfoSnapshot> restoredMetaInfos =\n\t\t\t\tserializationProxy.getStateMetaInfoSnapshots();\n\t\t\tcurrentStateHandleKVStateColumnFamilies = new ArrayList<>(restoredMetaInfos.size());\n\n\t\t\tfor (StateMetaInfoSnapshot restoredMetaInfo : restoredMetaInfos) {\n\n\t\t\t\tTuple2<ColumnFamilyHandle, RegisteredStateMetaInfoBase> registeredColumn =\n\t\t\t\t\trocksDBKeyedStateBackend.kvStateInformation.get(restoredMetaInfo.getName());\n\n\t\t\t\tif (registeredColumn == null) {\n\t\t\t\t\tbyte[] nameBytes = restoredMetaInfo.getName().getBytes(ConfigConstants.DEFAULT_CHARSET);\n\n\t\t\t\t\tColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\t\t\tnameBytes,\n\t\t\t\t\t\trocksDBKeyedStateBackend.columnOptions);\n\n\t\t\t\t\trocksDBKeyedStateBackend.restoredKvStateMetaInfos.put(restoredMetaInfo.getName(), restoredMetaInfo);\n\n\t\t\t\t\tColumnFamilyHandle columnFamily = rocksDBKeyedStateBackend.db.createColumnFamily(columnFamilyDescriptor);\n\n\t\t\t\t\t// create a meta info for the state on restore;\n\t\t\t\t\t// this allows us to retain the state in future snapshots even if it wasn't accessed\n\t\t\t\t\tRegisteredStateMetaInfoBase stateMetaInfo =\n\t\t\t\t\t\tRegisteredStateMetaInfoBase.fromMetaInfoSnapshot(restoredMetaInfo);\n\t\t\t\t\tregisteredColumn = new Tuple2<>(columnFamily, stateMetaInfo);\n\t\t\t\t\trocksDBKeyedStateBackend.kvStateInformation.put(restoredMetaInfo.getName(), registeredColumn);\n\n\t\t\t\t} else {\n\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t}\n\t\t\t\tcurrentStateHandleKVStateColumnFamilies.add(registeredColumn.f0);\n\t\t\t}\n\t\t}",
            " 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  ",
            "\t\t/**\n\t\t * Restore the KV-state / ColumnFamily meta data for all key-groups referenced by the current state handle.\n\t\t */\n\t\tprivate void restoreKVStateMetaData() throws IOException, StateMigrationException, RocksDBException {\n\n\t\t\t// isSerializerPresenceRequired flag is set to false, since for the RocksDB state backend,\n\t\t\t// deserialization of state happens lazily during runtime; we depend on the fact\n\t\t\t// that the new serializer for states could be compatible, and therefore the restore can continue\n\t\t\t// without old serializers required to be present.\n\t\t\tKeyedBackendSerializationProxy<K> serializationProxy =\n\t\t\t\tnew KeyedBackendSerializationProxy<>(rocksDBKeyedStateBackend.userCodeClassLoader);\n\n\t\t\tserializationProxy.read(currentStateHandleInView);\n\n\t\t\t// check for key serializer compatibility; this also reconfigures the\n\t\t\t// key serializer to be compatible, if it is required and is possible\n\t\t\tif (!serializationProxy.getKeySerializerConfigSnapshot()\n\t\t\t\t\t.resolveSchemaCompatibility(rocksDBKeyedStateBackend.keySerializer).isCompatibleAsIs()) {\n\t\t\t\tthrow new StateMigrationException(\"The new key serializer must be compatible.\");\n\t\t\t}\n\n\t\t\tthis.keygroupStreamCompressionDecorator = serializationProxy.isUsingKeyGroupCompression() ?\n\t\t\t\tSnappyStreamCompressionDecorator.INSTANCE : UncompressedStreamCompressionDecorator.INSTANCE;\n\n\t\t\tList<StateMetaInfoSnapshot> restoredMetaInfos =\n\t\t\t\tserializationProxy.getStateMetaInfoSnapshots();\n\t\t\tcurrentStateHandleKVStateColumnFamilies = new ArrayList<>(restoredMetaInfos.size());\n\n\t\t\tfor (StateMetaInfoSnapshot restoredMetaInfo : restoredMetaInfos) {\n\n\t\t\t\tTuple2<ColumnFamilyHandle, RegisteredStateMetaInfoBase> registeredColumn =\n\t\t\t\t\trocksDBKeyedStateBackend.kvStateInformation.get(restoredMetaInfo.getName());\n\n\t\t\t\tif (registeredColumn == null) {\n\t\t\t\t\tbyte[] nameBytes = restoredMetaInfo.getName().getBytes(ConfigConstants.DEFAULT_CHARSET);\n\n\t\t\t\t\tColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(\n\t\t\t\t\t\tnameBytes,\n\t\t\t\t\t\trocksDBKeyedStateBackend.columnOptions);\n\n\t\t\t\t\tColumnFamilyHandle columnFamily = rocksDBKeyedStateBackend.db.createColumnFamily(columnFamilyDescriptor);\n\n\t\t\t\t\t// create a meta info for the state on restore;\n\t\t\t\t\t// this allows us to retain the state in future snapshots even if it wasn't accessed\n\t\t\t\t\tRegisteredStateMetaInfoBase stateMetaInfo =\n\t\t\t\t\t\tRegisteredStateMetaInfoBase.fromMetaInfoSnapshot(restoredMetaInfo);\n\t\t\t\t\tregisteredColumn = new Tuple2<>(columnFamily, stateMetaInfo);\n\t\t\t\t\trocksDBKeyedStateBackend.kvStateInformation.put(restoredMetaInfo.getName(), registeredColumn);\n\n\t\t\t\t} else {\n\t\t\t\t\t// TODO with eager state registration in place, check here for serializer migration strategies\n\t\t\t\t}\n\t\t\t\tcurrentStateHandleKVStateColumnFamilies.add(registeredColumn.f0);\n\t\t\t}\n\t\t}"
        ],
        [
            "HeapKeyedStateBackend::create(String,TypeSerializer)",
            " 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197 -\n 198 -\n 199 -\n 200 -\n 201 -\n 202 -\n 203 -\n 204 -\n 205 -\n 206 -\n 207 -\n 208 -\n 209 -\n 210 -\n 211  \n 212  \n 213 -\n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  ",
            "\t@SuppressWarnings(\"unchecked\")\n\t@Nonnull\n\t@Override\n\tpublic <T extends HeapPriorityQueueElement & PriorityComparable & Keyed> KeyGroupedInternalPriorityQueue<T> create(\n\t\t@Nonnull String stateName,\n\t\t@Nonnull TypeSerializer<T> byteOrderedElementSerializer) {\n\n\t\tfinal HeapPriorityQueueSnapshotRestoreWrapper existingState = registeredPQStates.get(stateName);\n\n\t\tif (existingState != null) {\n\t\t\t// TODO we implement the simple way of supporting the current functionality, mimicking keyed state\n\t\t\t// because this should be reworked in FLINK-9376 and then we should have a common algorithm over\n\t\t\t// StateMetaInfoSnapshot that avoids this code duplication.\n\t\t\tStateMetaInfoSnapshot restoredMetaInfoSnapshot =\n\t\t\t\trestoredStateMetaInfo.get(StateUID.of(stateName, StateMetaInfoSnapshot.BackendStateType.PRIORITY_QUEUE));\n\n\t\t\tPreconditions.checkState(\n\t\t\t\trestoredMetaInfoSnapshot != null,\n\t\t\t\t\"Requested to check compatibility of a restored RegisteredKeyedBackendStateMetaInfo,\" +\n\t\t\t\t\t\" but its corresponding restored snapshot cannot be found.\");\n\n\t\t\tStateMetaInfoSnapshot.CommonSerializerKeys serializerKey =\n\t\t\t\tStateMetaInfoSnapshot.CommonSerializerKeys.VALUE_SERIALIZER;\n\n\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\tTypeSerializerSnapshot<T> serializerSnapshot = Preconditions.checkNotNull(\n\t\t\t\t(TypeSerializerSnapshot<T>) restoredMetaInfoSnapshot.getTypeSerializerConfigSnapshot(serializerKey));\n\n\t\t\tTypeSerializerSchemaCompatibility<T> compatibilityResult =\n\t\t\t\tserializerSnapshot.resolveSchemaCompatibility(byteOrderedElementSerializer);\n\n\t\t\tif (compatibilityResult.isIncompatible()) {\n\t\t\t\tthrow new FlinkRuntimeException(new StateMigrationException(\"For heap backends, the new priority queue serializer must not be incompatible.\"));\n\t\t\t} else {\n\t\t\t\tregisteredPQStates.put(\n\t\t\t\t\tstateName,\n\t\t\t\t\texistingState.forUpdatedSerializer(byteOrderedElementSerializer));\n\t\t\t}\n\n\t\t\treturn existingState.getPriorityQueue();\n\t\t} else {\n\t\t\tfinal RegisteredPriorityQueueStateBackendMetaInfo<T> metaInfo =\n\t\t\t\tnew RegisteredPriorityQueueStateBackendMetaInfo<>(stateName, byteOrderedElementSerializer);\n\t\t\treturn createInternal(metaInfo);\n\t\t}\n\t}",
            " 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190 +\n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  ",
            "\t@SuppressWarnings(\"unchecked\")\n\t@Nonnull\n\t@Override\n\tpublic <T extends HeapPriorityQueueElement & PriorityComparable & Keyed> KeyGroupedInternalPriorityQueue<T> create(\n\t\t@Nonnull String stateName,\n\t\t@Nonnull TypeSerializer<T> byteOrderedElementSerializer) {\n\n\t\tfinal HeapPriorityQueueSnapshotRestoreWrapper existingState = registeredPQStates.get(stateName);\n\n\t\tif (existingState != null) {\n\t\t\t// TODO we implement the simple way of supporting the current functionality, mimicking keyed state\n\t\t\t// because this should be reworked in FLINK-9376 and then we should have a common algorithm over\n\t\t\t// StateMetaInfoSnapshot that avoids this code duplication.\n\n\t\t\tTypeSerializerSchemaCompatibility<T> compatibilityResult =\n\t\t\t\texistingState.getMetaInfo().updateElementSerializer(byteOrderedElementSerializer);\n\n\t\t\tif (compatibilityResult.isIncompatible()) {\n\t\t\t\tthrow new FlinkRuntimeException(new StateMigrationException(\"For heap backends, the new priority queue serializer must not be incompatible.\"));\n\t\t\t} else {\n\t\t\t\tregisteredPQStates.put(\n\t\t\t\t\tstateName,\n\t\t\t\t\texistingState.forUpdatedSerializer(byteOrderedElementSerializer));\n\t\t\t}\n\n\t\t\treturn existingState.getPriorityQueue();\n\t\t} else {\n\t\t\tfinal RegisteredPriorityQueueStateBackendMetaInfo<T> metaInfo =\n\t\t\t\tnew RegisteredPriorityQueueStateBackendMetaInfo<>(stateName, byteOrderedElementSerializer);\n\t\t\treturn createInternal(metaInfo);\n\t\t}\n\t}"
        ],
        [
            "DefaultOperatorStateBackend::getListState(ListStateDescriptor,OperatorStateHandle)",
            " 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593 -\n 594 -\n 595 -\n 596  \n 597 -\n 598  \n 599  \n 600 -\n 601 -\n 602 -\n 603 -\n 604  \n 605 -\n 606  \n 607  \n 608  \n 609  \n 610 -\n 611 -\n 612  \n 613  \n 614  \n 615  \n 616  ",
            "\tprivate <S> ListState<S> getListState(\n\t\t\tListStateDescriptor<S> stateDescriptor,\n\t\t\tOperatorStateHandle.Mode mode) throws StateMigrationException {\n\n\t\tPreconditions.checkNotNull(stateDescriptor);\n\t\tString name = Preconditions.checkNotNull(stateDescriptor.getName());\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tPartitionableListState<S> previous = (PartitionableListState<S>) accessedStatesByName.get(name);\n\t\tif (previous != null) {\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tprevious.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tprevious.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tmode);\n\t\t\treturn previous;\n\t\t}\n\n\t\t// end up here if its the first time access after execution for the\n\t\t// provided state name; check compatibility of restored state, if any\n\t\t// TODO with eager registration in place, these checks should be moved to restore()\n\n\t\tstateDescriptor.initializeSerializerUnlessSet(getExecutionConfig());\n\t\tTypeSerializer<S> partitionStateSerializer = Preconditions.checkNotNull(stateDescriptor.getElementSerializer());\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tPartitionableListState<S> partitionableListState = (PartitionableListState<S>) registeredOperatorStates.get(name);\n\n\t\tif (null == partitionableListState) {\n\t\t\t// no restored state for the state name; simply create new state holder\n\n\t\t\tpartitionableListState = new PartitionableListState<>(\n\t\t\t\tnew RegisteredOperatorStateBackendMetaInfo<>(\n\t\t\t\t\tname,\n\t\t\t\t\tpartitionStateSerializer,\n\t\t\t\t\tmode));\n\n\t\t\tregisteredOperatorStates.put(name, partitionableListState);\n\t\t} else {\n\t\t\t// has restored state; check compatibility of new state access\n\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tpartitionableListState.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tpartitionableListState.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tmode);\n\n\t\t\tStateMetaInfoSnapshot restoredSnapshot = restoredOperatorStateMetaInfos.get(name);\n\t\t\tRegisteredOperatorStateBackendMetaInfo<S> metaInfo =\n\t\t\t\tnew RegisteredOperatorStateBackendMetaInfo<>(restoredSnapshot);\n\n\t\t\t// check compatibility to determine if state migration is required\n\t\t\tTypeSerializer<S> newPartitionStateSerializer = partitionStateSerializer.duplicate();\n\n\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\tTypeSerializerSnapshot<S> stateSerializerSnapshot = Preconditions.checkNotNull(\n\t\t\t\t(TypeSerializerSnapshot<S>) restoredSnapshot.getTypeSerializerConfigSnapshot(StateMetaInfoSnapshot.CommonSerializerKeys.VALUE_SERIALIZER));\n\n\t\t\tTypeSerializerSchemaCompatibility<S> stateCompatibility =\n\t\t\t\tstateSerializerSnapshot.resolveSchemaCompatibility(newPartitionStateSerializer);\n\t\t\tif (stateCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"The new state serializer for operator state must not be incompatible.\");\n\t\t\t}\n\n\t\t\tpartitionableListState.setStateMetaInfo(\n\t\t\t\tnew RegisteredOperatorStateBackendMetaInfo<>(name, newPartitionStateSerializer, mode));\n\t\t}\n\n\t\taccessedStatesByName.put(name, partitionableListState);\n\t\treturn partitionableListState;\n\t}",
            " 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561 +\n 562 +\n 563  \n 564 +\n 565  \n 566  \n 567  \n 568 +\n 569  \n 570  \n 571  \n 572  \n 573 +\n 574  \n 575  \n 576  \n 577  \n 578  ",
            "\tprivate <S> ListState<S> getListState(\n\t\t\tListStateDescriptor<S> stateDescriptor,\n\t\t\tOperatorStateHandle.Mode mode) throws StateMigrationException {\n\n\t\tPreconditions.checkNotNull(stateDescriptor);\n\t\tString name = Preconditions.checkNotNull(stateDescriptor.getName());\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tPartitionableListState<S> previous = (PartitionableListState<S>) accessedStatesByName.get(name);\n\t\tif (previous != null) {\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tprevious.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tprevious.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tmode);\n\t\t\treturn previous;\n\t\t}\n\n\t\t// end up here if its the first time access after execution for the\n\t\t// provided state name; check compatibility of restored state, if any\n\t\t// TODO with eager registration in place, these checks should be moved to restore()\n\n\t\tstateDescriptor.initializeSerializerUnlessSet(getExecutionConfig());\n\t\tTypeSerializer<S> partitionStateSerializer = Preconditions.checkNotNull(stateDescriptor.getElementSerializer());\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tPartitionableListState<S> partitionableListState = (PartitionableListState<S>) registeredOperatorStates.get(name);\n\n\t\tif (null == partitionableListState) {\n\t\t\t// no restored state for the state name; simply create new state holder\n\n\t\t\tpartitionableListState = new PartitionableListState<>(\n\t\t\t\tnew RegisteredOperatorStateBackendMetaInfo<>(\n\t\t\t\t\tname,\n\t\t\t\t\tpartitionStateSerializer,\n\t\t\t\t\tmode));\n\n\t\t\tregisteredOperatorStates.put(name, partitionableListState);\n\t\t} else {\n\t\t\t// has restored state; check compatibility of new state access\n\n\t\t\tcheckStateNameAndMode(\n\t\t\t\t\tpartitionableListState.getStateMetaInfo().getName(),\n\t\t\t\t\tname,\n\t\t\t\t\tpartitionableListState.getStateMetaInfo().getAssignmentMode(),\n\t\t\t\t\tmode);\n\n\t\t\tRegisteredOperatorStateBackendMetaInfo<S> restoredPartitionableListStateMetaInfo =\n\t\t\t\tpartitionableListState.getStateMetaInfo();\n\n\t\t\t// check compatibility to determine if new serializers are incompatible\n\t\t\tTypeSerializer<S> newPartitionStateSerializer = partitionStateSerializer.duplicate();\n\n\t\t\tTypeSerializerSchemaCompatibility<S> stateCompatibility =\n\t\t\t\trestoredPartitionableListStateMetaInfo.updatePartitionStateSerializer(newPartitionStateSerializer);\n\t\t\tif (stateCompatibility.isIncompatible()) {\n\t\t\t\tthrow new StateMigrationException(\"The new state serializer for operator state must not be incompatible.\");\n\t\t\t}\n\n\t\t\tpartitionableListState.setStateMetaInfo(restoredPartitionableListStateMetaInfo);\n\t\t}\n\n\t\taccessedStatesByName.put(name, partitionableListState);\n\t\treturn partitionableListState;\n\t}"
        ],
        [
            "RocksDBKeyedStateBackend::dispose()",
            " 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427 -\n 428  \n 429  \n 430  \n 431  ",
            "\t/**\n\t * Should only be called by one thread, and only after all accesses to the DB happened.\n\t */\n\t@Override\n\tpublic void dispose() {\n\t\tsuper.dispose();\n\n\t\t// This call will block until all clients that still acquire access to the RocksDB instance have released it,\n\t\t// so that we cannot release the native resources while clients are still working with it in parallel.\n\t\trocksDBResourceGuard.close();\n\n\t\t// IMPORTANT: null reference to signal potential async checkpoint workers that the db was disposed, as\n\t\t// working on the disposed object results in SEGFAULTS.\n\t\tif (db != null) {\n\n\t\t\tIOUtils.closeQuietly(writeBatchWrapper);\n\n\t\t\t// Metric collection occurs on a background thread. When this method returns\n\t\t\t// it is guaranteed that thr RocksDB reference has been invalidated\n\t\t\t// and no more metric collection will be attempted against the database.\n\t\t\tif (nativeMetricMonitor != null) {\n\t\t\t\tnativeMetricMonitor.close();\n\t\t\t}\n\n\t\t\t// RocksDB's native memory management requires that *all* CFs (including default) are closed before the\n\t\t\t// DB is closed. See:\n\t\t\t// https://github.com/facebook/rocksdb/wiki/RocksJava-Basics#opening-a-database-with-column-families\n\t\t\t// Start with default CF ...\n\t\t\tIOUtils.closeQuietly(defaultColumnFamily);\n\n\t\t\t// ... continue with the ones created by Flink...\n\t\t\tfor (Tuple2<ColumnFamilyHandle, RegisteredStateMetaInfoBase> columnMetaData :\n\t\t\t\tkvStateInformation.values()) {\n\t\t\t\tIOUtils.closeQuietly(columnMetaData.f0);\n\t\t\t}\n\n\t\t\t// ... and finally close the DB instance ...\n\t\t\tIOUtils.closeQuietly(db);\n\n\t\t\t// invalidate the reference\n\t\t\tdb = null;\n\n\t\t\tIOUtils.closeQuietly(columnOptions);\n\t\t\tIOUtils.closeQuietly(dbOptions);\n\t\t\tIOUtils.closeQuietly(writeOptions);\n\t\t\tkvStateInformation.clear();\n\t\t\trestoredKvStateMetaInfos.clear();\n\n\t\t\tcleanInstanceBasePath();\n\t\t}\n\t}",
            " 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  ",
            "\t/**\n\t * Should only be called by one thread, and only after all accesses to the DB happened.\n\t */\n\t@Override\n\tpublic void dispose() {\n\t\tsuper.dispose();\n\n\t\t// This call will block until all clients that still acquire access to the RocksDB instance have released it,\n\t\t// so that we cannot release the native resources while clients are still working with it in parallel.\n\t\trocksDBResourceGuard.close();\n\n\t\t// IMPORTANT: null reference to signal potential async checkpoint workers that the db was disposed, as\n\t\t// working on the disposed object results in SEGFAULTS.\n\t\tif (db != null) {\n\n\t\t\tIOUtils.closeQuietly(writeBatchWrapper);\n\n\t\t\t// Metric collection occurs on a background thread. When this method returns\n\t\t\t// it is guaranteed that thr RocksDB reference has been invalidated\n\t\t\t// and no more metric collection will be attempted against the database.\n\t\t\tif (nativeMetricMonitor != null) {\n\t\t\t\tnativeMetricMonitor.close();\n\t\t\t}\n\n\t\t\t// RocksDB's native memory management requires that *all* CFs (including default) are closed before the\n\t\t\t// DB is closed. See:\n\t\t\t// https://github.com/facebook/rocksdb/wiki/RocksJava-Basics#opening-a-database-with-column-families\n\t\t\t// Start with default CF ...\n\t\t\tIOUtils.closeQuietly(defaultColumnFamily);\n\n\t\t\t// ... continue with the ones created by Flink...\n\t\t\tfor (Tuple2<ColumnFamilyHandle, RegisteredStateMetaInfoBase> columnMetaData :\n\t\t\t\tkvStateInformation.values()) {\n\t\t\t\tIOUtils.closeQuietly(columnMetaData.f0);\n\t\t\t}\n\n\t\t\t// ... and finally close the DB instance ...\n\t\t\tIOUtils.closeQuietly(db);\n\n\t\t\t// invalidate the reference\n\t\t\tdb = null;\n\n\t\t\tIOUtils.closeQuietly(columnOptions);\n\t\t\tIOUtils.closeQuietly(dbOptions);\n\t\t\tIOUtils.closeQuietly(writeOptions);\n\t\t\tkvStateInformation.clear();\n\n\t\t\tcleanInstanceBasePath();\n\t\t}\n\t}"
        ]
    ],
    "fa63c3356b3fa89e549c058cbb6c6ecc19e61d8a": [
        [
            "FlinkKafkaConsumerBase::run(SourceContext)",
            " 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718 -\n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  ",
            "\t@Override\n\tpublic void run(SourceContext<T> sourceContext) throws Exception {\n\t\tif (subscribedPartitionsToStartOffsets == null) {\n\t\t\tthrow new Exception(\"The partitions were not set for the consumer\");\n\t\t}\n\n\t\t// initialize commit metrics and default offset callback method\n\t\tthis.successfulCommits = this.getRuntimeContext().getMetricGroup().counter(COMMITS_SUCCEEDED_METRICS_COUNTER);\n\t\tthis.failedCommits =  this.getRuntimeContext().getMetricGroup().counter(COMMITS_FAILED_METRICS_COUNTER);\n\n\t\tthis.offsetCommitCallback = new KafkaCommitCallback() {\n\t\t\t@Override\n\t\t\tpublic void onSuccess() {\n\t\t\t\tsuccessfulCommits.inc();\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void onException(Throwable cause) {\n\t\t\t\tLOG.warn(\"Async Kafka commit failed.\", cause);\n\t\t\t\tfailedCommits.inc();\n\t\t\t}\n\t\t};\n\n\t\t// mark the subtask as temporarily idle if there are no initial seed partitions;\n\t\t// once this subtask discovers some partitions and starts collecting records, the subtask's\n\t\t// status will automatically be triggered back to be active.\n\t\tif (subscribedPartitionsToStartOffsets.isEmpty()) {\n\t\t\tsourceContext.markAsTemporarilyIdle();\n\t\t}\n\n\t\t// from this point forward:\n\t\t//   - 'snapshotState' will draw offsets from the fetcher,\n\t\t//     instead of being built from `subscribedPartitionsToStartOffsets`\n\t\t//   - 'notifyCheckpointComplete' will start to do work (i.e. commit offsets to\n\t\t//     Kafka through the fetcher, if configured to do so)\n\t\tthis.kafkaFetcher = createFetcher(\n\t\t\t\tsourceContext,\n\t\t\t\tsubscribedPartitionsToStartOffsets,\n\t\t\t\tperiodicWatermarkAssigner,\n\t\t\t\tpunctuatedWatermarkAssigner,\n\t\t\t\t(StreamingRuntimeContext) getRuntimeContext(),\n\t\t\t\toffsetCommitMode,\n\t\t\t\tgetRuntimeContext().getMetricGroup().addGroup(KAFKA_CONSUMER_METRICS_GROUP),\n\t\t\t\tuseMetrics);\n\n\t\tif (!running) {\n\t\t\treturn;\n\t\t}\n\n\t\t// depending on whether we were restored with the current state version (1.3),\n\t\t// remaining logic branches off into 2 paths:\n\t\t//  1) New state - partition discovery loop executed as separate thread, with this\n\t\t//                 thread running the main fetcher loop\n\t\t//  2) Old state - partition discovery is disabled and only the main fetcher loop is executed\n\n\t\tif (discoveryIntervalMillis != PARTITION_DISCOVERY_DISABLED) {\n\t\t\tfinal AtomicReference<Exception> discoveryLoopErrorRef = new AtomicReference<>();\n\t\t\tthis.discoveryLoopThread = new Thread(new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// --------------------- partition discovery loop ---------------------\n\n\t\t\t\t\t\tList<KafkaTopicPartition> discoveredPartitions;\n\n\t\t\t\t\t\t// throughout the loop, we always eagerly check if we are still running before\n\t\t\t\t\t\t// performing the next operation, so that we can escape the loop as soon as possible\n\n\t\t\t\t\t\twhile (running) {\n\t\t\t\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\t\t\t\tLOG.debug(\"Consumer subtask {} is trying to discover new partitions ...\", getRuntimeContext().getIndexOfThisSubtask());\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdiscoveredPartitions = partitionDiscoverer.discoverPartitions();\n\t\t\t\t\t\t\t} catch (AbstractPartitionDiscoverer.WakeupException | AbstractPartitionDiscoverer.ClosedException e) {\n\t\t\t\t\t\t\t\t// the partition discoverer may have been closed or woken up before or during the discovery;\n\t\t\t\t\t\t\t\t// this would only happen if the consumer was canceled; simply escape the loop\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// no need to add the discovered partitions if we were closed during the meantime\n\t\t\t\t\t\t\tif (running && !discoveredPartitions.isEmpty()) {\n\t\t\t\t\t\t\t\tkafkaFetcher.addDiscoveredPartitions(discoveredPartitions);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// do not waste any time sleeping if we're not running anymore\n\t\t\t\t\t\t\tif (running && discoveryIntervalMillis != 0) {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tThread.sleep(discoveryIntervalMillis);\n\t\t\t\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\t\t\t// may be interrupted if the consumer was canceled midway; simply escape the loop\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tdiscoveryLoopErrorRef.set(e);\n\t\t\t\t\t} finally {\n\t\t\t\t\t\t// calling cancel will also let the fetcher loop escape\n\t\t\t\t\t\t// (if not running, cancel() was already called)\n\t\t\t\t\t\tif (running) {\n\t\t\t\t\t\t\tcancel();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tdiscoveryLoopThread.start();\n\t\t\tkafkaFetcher.runFetchLoop();\n\n\t\t\t// --------------------------------------------------------------------\n\n\t\t\t// make sure that the partition discoverer is properly closed\n\t\t\tpartitionDiscoverer.close();\n\t\t\tdiscoveryLoopThread.join();\n\n\t\t\t// rethrow any fetcher errors\n\t\t\tfinal Exception discoveryLoopError = discoveryLoopErrorRef.get();\n\t\t\tif (discoveryLoopError != null) {\n\t\t\t\tthrow new RuntimeException(discoveryLoopError);\n\t\t\t}\n\t\t} else {\n\t\t\t// won't be using the discoverer\n\t\t\tpartitionDiscoverer.close();\n\n\t\t\tkafkaFetcher.runFetchLoop();\n\t\t}\n\t}",
            " 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718 +\n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  ",
            "\t@Override\n\tpublic void run(SourceContext<T> sourceContext) throws Exception {\n\t\tif (subscribedPartitionsToStartOffsets == null) {\n\t\t\tthrow new Exception(\"The partitions were not set for the consumer\");\n\t\t}\n\n\t\t// initialize commit metrics and default offset callback method\n\t\tthis.successfulCommits = this.getRuntimeContext().getMetricGroup().counter(COMMITS_SUCCEEDED_METRICS_COUNTER);\n\t\tthis.failedCommits =  this.getRuntimeContext().getMetricGroup().counter(COMMITS_FAILED_METRICS_COUNTER);\n\n\t\tthis.offsetCommitCallback = new KafkaCommitCallback() {\n\t\t\t@Override\n\t\t\tpublic void onSuccess() {\n\t\t\t\tsuccessfulCommits.inc();\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void onException(Throwable cause) {\n\t\t\t\tLOG.warn(\"Async Kafka commit failed.\", cause);\n\t\t\t\tfailedCommits.inc();\n\t\t\t}\n\t\t};\n\n\t\t// mark the subtask as temporarily idle if there are no initial seed partitions;\n\t\t// once this subtask discovers some partitions and starts collecting records, the subtask's\n\t\t// status will automatically be triggered back to be active.\n\t\tif (subscribedPartitionsToStartOffsets.isEmpty()) {\n\t\t\tsourceContext.markAsTemporarilyIdle();\n\t\t}\n\n\t\t// from this point forward:\n\t\t//   - 'snapshotState' will draw offsets from the fetcher,\n\t\t//     instead of being built from `subscribedPartitionsToStartOffsets`\n\t\t//   - 'notifyCheckpointComplete' will start to do work (i.e. commit offsets to\n\t\t//     Kafka through the fetcher, if configured to do so)\n\t\tthis.kafkaFetcher = createFetcher(\n\t\t\t\tsourceContext,\n\t\t\t\tsubscribedPartitionsToStartOffsets,\n\t\t\t\tperiodicWatermarkAssigner,\n\t\t\t\tpunctuatedWatermarkAssigner,\n\t\t\t\t(StreamingRuntimeContext) getRuntimeContext(),\n\t\t\t\toffsetCommitMode,\n\t\t\t\tgetRuntimeContext().getMetricGroup().addGroup(KAFKA_CONSUMER_METRICS_GROUP),\n\t\t\t\tuseMetrics);\n\n\t\tif (!running) {\n\t\t\treturn;\n\t\t}\n\n\t\t// depending on whether we were restored with the current state version (1.3),\n\t\t// remaining logic branches off into 2 paths:\n\t\t//  1) New state - partition discovery loop executed as separate thread, with this\n\t\t//                 thread running the main fetcher loop\n\t\t//  2) Old state - partition discovery is disabled and only the main fetcher loop is executed\n\n\t\tif (discoveryIntervalMillis != PARTITION_DISCOVERY_DISABLED) {\n\t\t\tfinal AtomicReference<Exception> discoveryLoopErrorRef = new AtomicReference<>();\n\t\t\tthis.discoveryLoopThread = new Thread(new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// --------------------- partition discovery loop ---------------------\n\n\t\t\t\t\t\tList<KafkaTopicPartition> discoveredPartitions;\n\n\t\t\t\t\t\t// throughout the loop, we always eagerly check if we are still running before\n\t\t\t\t\t\t// performing the next operation, so that we can escape the loop as soon as possible\n\n\t\t\t\t\t\twhile (running) {\n\t\t\t\t\t\t\tif (LOG.isDebugEnabled()) {\n\t\t\t\t\t\t\t\tLOG.debug(\"Consumer subtask {} is trying to discover new partitions ...\", getRuntimeContext().getIndexOfThisSubtask());\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tdiscoveredPartitions = partitionDiscoverer.discoverPartitions();\n\t\t\t\t\t\t\t} catch (AbstractPartitionDiscoverer.WakeupException | AbstractPartitionDiscoverer.ClosedException e) {\n\t\t\t\t\t\t\t\t// the partition discoverer may have been closed or woken up before or during the discovery;\n\t\t\t\t\t\t\t\t// this would only happen if the consumer was canceled; simply escape the loop\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// no need to add the discovered partitions if we were closed during the meantime\n\t\t\t\t\t\t\tif (running && !discoveredPartitions.isEmpty()) {\n\t\t\t\t\t\t\t\tkafkaFetcher.addDiscoveredPartitions(discoveredPartitions);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// do not waste any time sleeping if we're not running anymore\n\t\t\t\t\t\t\tif (running && discoveryIntervalMillis != 0) {\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tThread.sleep(discoveryIntervalMillis);\n\t\t\t\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\t\t\t// may be interrupted if the consumer was canceled midway; simply escape the loop\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tdiscoveryLoopErrorRef.set(e);\n\t\t\t\t\t} finally {\n\t\t\t\t\t\t// calling cancel will also let the fetcher loop escape\n\t\t\t\t\t\t// (if not running, cancel() was already called)\n\t\t\t\t\t\tif (running) {\n\t\t\t\t\t\t\tcancel();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}, \"Kafka Partition Discovery for \" + getRuntimeContext().getTaskNameWithSubtasks());\n\n\t\t\tdiscoveryLoopThread.start();\n\t\t\tkafkaFetcher.runFetchLoop();\n\n\t\t\t// --------------------------------------------------------------------\n\n\t\t\t// make sure that the partition discoverer is properly closed\n\t\t\tpartitionDiscoverer.close();\n\t\t\tdiscoveryLoopThread.join();\n\n\t\t\t// rethrow any fetcher errors\n\t\t\tfinal Exception discoveryLoopError = discoveryLoopErrorRef.get();\n\t\t\tif (discoveryLoopError != null) {\n\t\t\t\tthrow new RuntimeException(discoveryLoopError);\n\t\t\t}\n\t\t} else {\n\t\t\t// won't be using the discoverer\n\t\t\tpartitionDiscoverer.close();\n\n\t\t\tkafkaFetcher.runFetchLoop();\n\t\t}\n\t}"
        ]
    ],
    "4febcdc289bc0dce1090d831c7f99848a26f6465": [
        [
            "Elasticsearch5ApiCallBridge::createClient(Map)",
            "  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  ",
            "\t@Override\n\tpublic TransportClient createClient(Map<String, String> clientConfig) {\n\t\tSettings settings = Settings.builder().put(clientConfig)\n\t\t\t.put(NetworkModule.HTTP_TYPE_KEY, Netty3Plugin.NETTY_HTTP_TRANSPORT_NAME)\n\t\t\t.put(NetworkModule.TRANSPORT_TYPE_KEY, Netty3Plugin.NETTY_TRANSPORT_NAME)\n\t\t\t.build();\n\n\t\tTransportClient transportClient = new PreBuiltTransportClient(settings);\n\t\tfor (TransportAddress transport : ElasticsearchUtils.convertInetSocketAddresses(transportAddresses)) {\n\t\t\ttransportClient.addTransportAddress(transport);\n\t\t}\n\n\t\t// verify that we actually are connected to a cluster\n\t\tif (transportClient.connectedNodes().isEmpty()) {\n\t\t\tthrow new RuntimeException(\"Elasticsearch client is not connected to any Elasticsearch nodes!\");\n\t\t}\n\n\t\tif (LOG.isInfoEnabled()) {\n\t\t\tLOG.info(\"Created Elasticsearch TransportClient with connected nodes {}\", transportClient.connectedNodes());\n\t\t}\n\n\t\treturn transportClient;\n\t}",
            "  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82 +\n  83 +\n  84 +\n  85 +\n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  ",
            "\t@Override\n\tpublic TransportClient createClient(Map<String, String> clientConfig) {\n\t\tSettings settings = Settings.builder().put(clientConfig)\n\t\t\t.put(NetworkModule.HTTP_TYPE_KEY, Netty3Plugin.NETTY_HTTP_TRANSPORT_NAME)\n\t\t\t.put(NetworkModule.TRANSPORT_TYPE_KEY, Netty3Plugin.NETTY_TRANSPORT_NAME)\n\t\t\t.build();\n\n\t\tTransportClient transportClient = new PreBuiltTransportClient(settings);\n\t\tfor (TransportAddress transport : ElasticsearchUtils.convertInetSocketAddresses(transportAddresses)) {\n\t\t\ttransportClient.addTransportAddress(transport);\n\t\t}\n\n\t\t// verify that we actually are connected to a cluster\n\t\tif (transportClient.connectedNodes().isEmpty()) {\n\n\t\t\t// close the transportClient here\n\t\t\tIOUtils.closeQuietly(transportClient);\n\n\t\t\tthrow new RuntimeException(\"Elasticsearch client is not connected to any Elasticsearch nodes!\");\n\t\t}\n\n\t\tif (LOG.isInfoEnabled()) {\n\t\t\tLOG.info(\"Created Elasticsearch TransportClient with connected nodes {}\", transportClient.connectedNodes());\n\t\t}\n\n\t\treturn transportClient;\n\t}"
        ],
        [
            "Elasticsearch2ApiCallBridge::createClient(Map)",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  ",
            "\t@Override\n\tpublic TransportClient createClient(Map<String, String> clientConfig) {\n\t\tSettings settings = Settings.settingsBuilder().put(clientConfig).build();\n\n\t\tTransportClient transportClient = TransportClient.builder().settings(settings).build();\n\t\tfor (TransportAddress address : ElasticsearchUtils.convertInetSocketAddresses(transportAddresses)) {\n\t\t\ttransportClient.addTransportAddress(address);\n\t\t}\n\n\t\t// verify that we actually are connected to a cluster\n\t\tif (transportClient.connectedNodes().isEmpty()) {\n\t\t\tthrow new RuntimeException(\"Elasticsearch client is not connected to any Elasticsearch nodes!\");\n\t\t}\n\n\t\tif (LOG.isInfoEnabled()) {\n\t\t\tLOG.info(\"Created Elasticsearch TransportClient with connected nodes {}\", transportClient.connectedNodes());\n\t\t}\n\n\t\treturn transportClient;\n\t}",
            "  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76 +\n  77 +\n  78 +\n  79 +\n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  ",
            "\t@Override\n\tpublic TransportClient createClient(Map<String, String> clientConfig) {\n\t\tSettings settings = Settings.settingsBuilder().put(clientConfig).build();\n\n\t\tTransportClient transportClient = TransportClient.builder().settings(settings).build();\n\t\tfor (TransportAddress address : ElasticsearchUtils.convertInetSocketAddresses(transportAddresses)) {\n\t\t\ttransportClient.addTransportAddress(address);\n\t\t}\n\n\t\t// verify that we actually are connected to a cluster\n\t\tif (transportClient.connectedNodes().isEmpty()) {\n\n\t\t\t// close the transportClient here\n\t\t\tIOUtils.closeQuietly(transportClient);\n\n\t\t\tthrow new RuntimeException(\"Elasticsearch client is not connected to any Elasticsearch nodes!\");\n\t\t}\n\n\t\tif (LOG.isInfoEnabled()) {\n\t\t\tLOG.info(\"Created Elasticsearch TransportClient with connected nodes {}\", transportClient.connectedNodes());\n\t\t}\n\n\t\treturn transportClient;\n\t}"
        ]
    ],
    "1b71e447e097eae02e65d80eb297a01b21122715": [
        [
            "RocksDBMapState::clear()",
            " 218  \n 219  \n 220  \n 221  \n 222 -\n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230 -\n 231  \n 232  \n 233  \n 234  \n 235  \n 236 -\n 237 -\n 238  \n 239  \n 240  \n 241  \n 242  ",
            "\t@Override\n\tpublic void clear() {\n\t\ttry {\n\t\t\ttry (RocksIteratorWrapper iterator = RocksDBKeyedStateBackend.getRocksIterator(backend.db, columnFamily);\n\t\t\t\tWriteBatch writeBatch = new WriteBatch(128)) {\n\n\t\t\t\tfinal byte[] keyPrefixBytes = serializeCurrentKeyWithGroupAndNamespace();\n\t\t\t\titerator.seek(keyPrefixBytes);\n\n\t\t\t\twhile (iterator.isValid()) {\n\t\t\t\t\tbyte[] keyBytes = iterator.key();\n\t\t\t\t\tif (startWithKeyPrefix(keyPrefixBytes, keyBytes)) {\n\t\t\t\t\t\twriteBatch.remove(columnFamily, keyBytes);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\titerator.next();\n\t\t\t\t}\n\n\t\t\t\tbackend.db.write(writeOptions, writeBatch);\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Error while cleaning the state.\", e);\n\t\t}\n\t}",
            " 217  \n 218  \n 219  \n 220  \n 221 +\n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229 +\n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  ",
            "\t@Override\n\tpublic void clear() {\n\t\ttry {\n\t\t\ttry (RocksIteratorWrapper iterator = RocksDBKeyedStateBackend.getRocksIterator(backend.db, columnFamily);\n\t\t\t\tRocksDBWriteBatchWrapper rocksDBWriteBatchWrapper = new RocksDBWriteBatchWrapper(backend.db, backend.getWriteOptions())) {\n\n\t\t\t\tfinal byte[] keyPrefixBytes = serializeCurrentKeyWithGroupAndNamespace();\n\t\t\t\titerator.seek(keyPrefixBytes);\n\n\t\t\t\twhile (iterator.isValid()) {\n\t\t\t\t\tbyte[] keyBytes = iterator.key();\n\t\t\t\t\tif (startWithKeyPrefix(keyPrefixBytes, keyBytes)) {\n\t\t\t\t\t\trocksDBWriteBatchWrapper.remove(columnFamily, keyBytes);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\titerator.next();\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Error while cleaning the state.\", e);\n\t\t}\n\t}"
        ]
    ],
    "be419e2560ef89683b7795c75eb08ae2337fefee": [
        [
            "ExponentialWaitStrategy::sleepTime(long)",
            "  40  \n  41  \n  42 -\n  43  \n  44  \n  45  ",
            "\t@Override\n\tpublic long sleepTime(final long attempt) {\n\t\tcheckArgument(attempt >= 0, \"attempt must not be negative (%d)\", attempt);\n\t\tfinal long exponentialSleepTime = initialWait * Math.round(Math.pow(2, attempt));\n\t\treturn exponentialSleepTime >= 0 && exponentialSleepTime < maxWait ? exponentialSleepTime : maxWait;\n\t}",
            "  40  \n  41  \n  42 +\n  43  \n  44  \n  45  ",
            "\t@Override\n\tpublic long sleepTime(final long attempt) {\n\t\tcheckArgument(attempt >= 0, \"attempt must not be negative (%s)\", attempt);\n\t\tfinal long exponentialSleepTime = initialWait * Math.round(Math.pow(2, attempt));\n\t\treturn exponentialSleepTime >= 0 && exponentialSleepTime < maxWait ? exponentialSleepTime : maxWait;\n\t}"
        ],
        [
            "PythonStreamBinderTest::testProgram()",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69 -\n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  ",
            "\t@Test\n\tpublic void testProgram() throws Exception {\n\t\tPath testEntryPoint = new Path(getBaseTestPythonDir(), \"run_all_tests.py\");\n\t\tList<String> testFiles = findTestFiles();\n\n\t\tPreconditions.checkState(testFiles.size() > 0, \"No test files were found in {}.\", getBaseTestPythonDir());\n\n\t\tString[] arguments = new String[1 + 1 + testFiles.size()];\n\t\targuments[0] = testEntryPoint.getPath();\n\t\targuments[1] = findUtilsModule().getPath();\n\t\tint index = 2;\n\t\tfor (String testFile : testFiles) {\n\t\t\targuments[index] = testFile;\n\t\t\tindex++;\n\t\t}\n\t\ttry {\n\t\t\tnew PythonStreamBinder(new Configuration())\n\t\t\t\t.runPlan(arguments);\n\t\t} catch (PyException e) {\n\t\t\tif (e.getCause() instanceof JobExecutionException) {\n\t\t\t\t// JobExecutionExceptions are wrapped again by the jython interpreter resulting in horrible stacktraces\n\t\t\t\tthrow (JobExecutionException) e.getCause();\n\t\t\t} else {\n\t\t\t\t// probably caused by some issue in the main script itself\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69 +\n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  ",
            "\t@Test\n\tpublic void testProgram() throws Exception {\n\t\tPath testEntryPoint = new Path(getBaseTestPythonDir(), \"run_all_tests.py\");\n\t\tList<String> testFiles = findTestFiles();\n\n\t\tPreconditions.checkState(testFiles.size() > 0, \"No test files were found in %s.\", getBaseTestPythonDir());\n\n\t\tString[] arguments = new String[1 + 1 + testFiles.size()];\n\t\targuments[0] = testEntryPoint.getPath();\n\t\targuments[1] = findUtilsModule().getPath();\n\t\tint index = 2;\n\t\tfor (String testFile : testFiles) {\n\t\t\targuments[index] = testFile;\n\t\t\tindex++;\n\t\t}\n\t\ttry {\n\t\t\tnew PythonStreamBinder(new Configuration())\n\t\t\t\t.runPlan(arguments);\n\t\t} catch (PyException e) {\n\t\t\tif (e.getCause() instanceof JobExecutionException) {\n\t\t\t\t// JobExecutionExceptions are wrapped again by the jython interpreter resulting in horrible stacktraces\n\t\t\t\tthrow (JobExecutionException) e.getCause();\n\t\t\t} else {\n\t\t\t\t// probably caused by some issue in the main script itself\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}"
        ],
        [
            "NullableSerializer::NullableSerializerSnapshot::createOuterSerializerWithNestedSerializers(TypeSerializer)",
            " 329  \n 330  \n 331  \n 332 -\n 333  \n 334  \n 335  \n 336  \n 337  \n 338  ",
            "\t\t@Override\n\t\tprotected NullableSerializer<T> createOuterSerializerWithNestedSerializers(TypeSerializer<?>[] nestedSerializers) {\n\t\t\tcheckState(nullPaddingLength >= 0,\n\t\t\t\t\"Negative padding size after serializer construction: %d\",\n\t\t\t\tnullPaddingLength);\n\n\t\t\tfinal byte[] padding = (nullPaddingLength == 0) ? EMPTY_BYTE_ARRAY : new byte[nullPaddingLength];\n\t\t\tTypeSerializer<T> nestedSerializer = (TypeSerializer<T>) nestedSerializers[0];\n\t\t\treturn new NullableSerializer<>(nestedSerializer, padding);\n\t\t}",
            " 329  \n 330  \n 331  \n 332 +\n 333  \n 334  \n 335  \n 336  \n 337  \n 338  ",
            "\t\t@Override\n\t\tprotected NullableSerializer<T> createOuterSerializerWithNestedSerializers(TypeSerializer<?>[] nestedSerializers) {\n\t\t\tcheckState(nullPaddingLength >= 0,\n\t\t\t\t\"Negative padding size after serializer construction: %s\",\n\t\t\t\tnullPaddingLength);\n\n\t\t\tfinal byte[] padding = (nullPaddingLength == 0) ? EMPTY_BYTE_ARRAY : new byte[nullPaddingLength];\n\t\t\tTypeSerializer<T> nestedSerializer = (TypeSerializer<T>) nestedSerializers[0];\n\t\t\treturn new NullableSerializer<>(nestedSerializer, padding);\n\t\t}"
        ],
        [
            "JobDetails::JobDetails(JobID,String,long,long,long,JobStatus,long,int,int)",
            "  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97 -\n  98  \n  99  \n 100  ",
            "\tpublic JobDetails(\n\t\t\tJobID jobId,\n\t\t\tString jobName,\n\t\t\tlong startTime,\n\t\t\tlong endTime,\n\t\t\tlong duration,\n\t\t\tJobStatus status,\n\t\t\tlong lastUpdateTime,\n\t\t\tint[] tasksPerState,\n\t\t\tint numTasks) {\n\n\t\tthis.jobId = checkNotNull(jobId);\n\t\tthis.jobName = checkNotNull(jobName);\n\t\tthis.startTime = startTime;\n\t\tthis.endTime = endTime;\n\t\tthis.duration = duration;\n\t\tthis.status = checkNotNull(status);\n\t\tthis.lastUpdateTime = lastUpdateTime;\n\t\tPreconditions.checkArgument(tasksPerState.length == ExecutionState.values().length, \n\t\t\t\"tasksPerState argument must be of size {}.\", ExecutionState.values().length);\n\t\tthis.tasksPerState = checkNotNull(tasksPerState);\n\t\tthis.numTasks = numTasks;\n\t}",
            "  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97 +\n  98  \n  99  \n 100  ",
            "\tpublic JobDetails(\n\t\t\tJobID jobId,\n\t\t\tString jobName,\n\t\t\tlong startTime,\n\t\t\tlong endTime,\n\t\t\tlong duration,\n\t\t\tJobStatus status,\n\t\t\tlong lastUpdateTime,\n\t\t\tint[] tasksPerState,\n\t\t\tint numTasks) {\n\n\t\tthis.jobId = checkNotNull(jobId);\n\t\tthis.jobName = checkNotNull(jobName);\n\t\tthis.startTime = startTime;\n\t\tthis.endTime = endTime;\n\t\tthis.duration = duration;\n\t\tthis.status = checkNotNull(status);\n\t\tthis.lastUpdateTime = lastUpdateTime;\n\t\tPreconditions.checkArgument(tasksPerState.length == ExecutionState.values().length, \n\t\t\t\"tasksPerState argument must be of size %s.\", ExecutionState.values().length);\n\t\tthis.tasksPerState = checkNotNull(tasksPerState);\n\t\tthis.numTasks = numTasks;\n\t}"
        ],
        [
            "LinkedOptionalMapSerializer::readOptionalMap(DataInputView,BiFunctionWithException,BiFunctionWithException)",
            "  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84 -\n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  ",
            "\tpublic static <K, V> LinkedOptionalMap<K, V> readOptionalMap(\n\t\tDataInputView in,\n\t\tBiFunctionWithException<DataInputView, String, K, IOException> keyReader,\n\t\tBiFunctionWithException<DataInputView, String, V, IOException> valueReader) throws IOException {\n\n\t\tfinal long header = in.readLong();\n\t\tcheckState(header == HEADER, \"Corrupted stream received header %d\", header);\n\n\t\tlong mapSize = in.readInt();\n\t\tLinkedOptionalMap<K, V> map = new LinkedOptionalMap<>();\n\t\tfor (int i = 0; i < mapSize; i++) {\n\t\t\tString keyName = in.readUTF();\n\n\t\t\tfinal K key;\n\t\t\tif (in.readBoolean()) {\n\t\t\t\tkey = tryReadFrame(in, keyName, keyReader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tkey = null;\n\t\t\t}\n\n\t\t\tfinal V value;\n\t\t\tif (in.readBoolean()) {\n\t\t\t\tvalue = tryReadFrame(in, keyName, valueReader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tvalue = null;\n\t\t\t}\n\n\t\t\tmap.put(keyName, key, value);\n\t\t}\n\t\treturn map;\n\t}",
            "  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84 +\n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  ",
            "\tpublic static <K, V> LinkedOptionalMap<K, V> readOptionalMap(\n\t\tDataInputView in,\n\t\tBiFunctionWithException<DataInputView, String, K, IOException> keyReader,\n\t\tBiFunctionWithException<DataInputView, String, V, IOException> valueReader) throws IOException {\n\n\t\tfinal long header = in.readLong();\n\t\tcheckState(header == HEADER, \"Corrupted stream received header %s\", header);\n\n\t\tlong mapSize = in.readInt();\n\t\tLinkedOptionalMap<K, V> map = new LinkedOptionalMap<>();\n\t\tfor (int i = 0; i < mapSize; i++) {\n\t\t\tString keyName = in.readUTF();\n\n\t\t\tfinal K key;\n\t\t\tif (in.readBoolean()) {\n\t\t\t\tkey = tryReadFrame(in, keyName, keyReader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tkey = null;\n\t\t\t}\n\n\t\t\tfinal V value;\n\t\t\tif (in.readBoolean()) {\n\t\t\t\tvalue = tryReadFrame(in, keyName, valueReader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tvalue = null;\n\t\t\t}\n\n\t\t\tmap.put(keyName, key, value);\n\t\t}\n\t\treturn map;\n\t}"
        ],
        [
            "FlinkKafkaProducer::resumeTransaction(long,short)",
            " 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192 -\n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  ",
            "\t/**\n\t * Instead of obtaining producerId and epoch from the transaction coordinator, re-use previously obtained ones,\n\t * so that we can resume transaction after a restart. Implementation of this method is based on\n\t * {@link org.apache.kafka.clients.producer.KafkaProducer#initTransactions}.\n\t */\n\tpublic void resumeTransaction(long producerId, short epoch) {\n\t\tPreconditions.checkState(producerId >= 0 && epoch >= 0, \"Incorrect values for producerId {} and epoch {}\", producerId, epoch);\n\t\tLOG.info(\"Attempting to resume transaction {} with producerId {} and epoch {}\", transactionalId, producerId, epoch);\n\n\t\tObject transactionManager = getValue(kafkaProducer, \"transactionManager\");\n\t\tsynchronized (transactionManager) {\n\t\t\tObject sequenceNumbers = getValue(transactionManager, \"sequenceNumbers\");\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.INITIALIZING\"));\n\t\t\tinvoke(sequenceNumbers, \"clear\");\n\n\t\t\tObject producerIdAndEpoch = getValue(transactionManager, \"producerIdAndEpoch\");\n\t\t\tsetValue(producerIdAndEpoch, \"producerId\", producerId);\n\t\t\tsetValue(producerIdAndEpoch, \"epoch\", epoch);\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.READY\"));\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.IN_TRANSACTION\"));\n\t\t\tsetValue(transactionManager, \"transactionStarted\", true);\n\t\t}\n\t}",
            " 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192 +\n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  ",
            "\t/**\n\t * Instead of obtaining producerId and epoch from the transaction coordinator, re-use previously obtained ones,\n\t * so that we can resume transaction after a restart. Implementation of this method is based on\n\t * {@link org.apache.kafka.clients.producer.KafkaProducer#initTransactions}.\n\t */\n\tpublic void resumeTransaction(long producerId, short epoch) {\n\t\tPreconditions.checkState(producerId >= 0 && epoch >= 0, \"Incorrect values for producerId %s and epoch %s\", producerId, epoch);\n\t\tLOG.info(\"Attempting to resume transaction {} with producerId {} and epoch {}\", transactionalId, producerId, epoch);\n\n\t\tObject transactionManager = getValue(kafkaProducer, \"transactionManager\");\n\t\tsynchronized (transactionManager) {\n\t\t\tObject sequenceNumbers = getValue(transactionManager, \"sequenceNumbers\");\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.INITIALIZING\"));\n\t\t\tinvoke(sequenceNumbers, \"clear\");\n\n\t\t\tObject producerIdAndEpoch = getValue(transactionManager, \"producerIdAndEpoch\");\n\t\t\tsetValue(producerIdAndEpoch, \"producerId\", producerId);\n\t\t\tsetValue(producerIdAndEpoch, \"epoch\", epoch);\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.READY\"));\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.IN_TRANSACTION\"));\n\t\t\tsetValue(transactionManager, \"transactionStarted\", true);\n\t\t}\n\t}"
        ],
        [
            "NullableSerializer::NullableSerializerSnapshot::NullableSerializerSnapshot(int)",
            " 310  \n 311  \n 312  \n 313 -\n 314  \n 315  \n 316  \n 317  ",
            "\t\tprivate NullableSerializerSnapshot(int nullPaddingLength) {\n\t\t\tsuper(NullableSerializer.class);\n\t\t\tcheckArgument(nullPaddingLength >= 0,\n\t\t\t\t\"Computed NULL padding can not be negative. %d\",\n\t\t\t\tnullPaddingLength);\n\n\t\t\tthis.nullPaddingLength = nullPaddingLength;\n\t\t}",
            " 310  \n 311  \n 312  \n 313 +\n 314  \n 315  \n 316  \n 317  ",
            "\t\tprivate NullableSerializerSnapshot(int nullPaddingLength) {\n\t\t\tsuper(NullableSerializer.class);\n\t\t\tcheckArgument(nullPaddingLength >= 0,\n\t\t\t\t\"Computed NULL padding can not be negative. %s\",\n\t\t\t\tnullPaddingLength);\n\n\t\t\tthis.nullPaddingLength = nullPaddingLength;\n\t\t}"
        ],
        [
            "RestClientConfiguration::RestClientConfiguration(SSLHandlerFactory,long,long,int)",
            "  47  \n  48  \n  49  \n  50  \n  51  \n  52 -\n  53  \n  54  \n  55  \n  56  \n  57  ",
            "\tprivate RestClientConfiguration(\n\t\t\t@Nullable final SSLHandlerFactory sslHandlerFactory,\n\t\t\tfinal long connectionTimeout,\n\t\t\tfinal long idlenessTimeout,\n\t\t\tfinal int maxContentLength) {\n\t\tcheckArgument(maxContentLength > 0, \"maxContentLength must be positive, was: %d\", maxContentLength);\n\t\tthis.sslHandlerFactory = sslHandlerFactory;\n\t\tthis.connectionTimeout = connectionTimeout;\n\t\tthis.idlenessTimeout = idlenessTimeout;\n\t\tthis.maxContentLength = maxContentLength;\n\t}",
            "  47  \n  48  \n  49  \n  50  \n  51  \n  52 +\n  53  \n  54  \n  55  \n  56  \n  57  ",
            "\tprivate RestClientConfiguration(\n\t\t\t@Nullable final SSLHandlerFactory sslHandlerFactory,\n\t\t\tfinal long connectionTimeout,\n\t\t\tfinal long idlenessTimeout,\n\t\t\tfinal int maxContentLength) {\n\t\tcheckArgument(maxContentLength > 0, \"maxContentLength must be positive, was: %s\", maxContentLength);\n\t\tthis.sslHandlerFactory = sslHandlerFactory;\n\t\tthis.connectionTimeout = connectionTimeout;\n\t\tthis.idlenessTimeout = idlenessTimeout;\n\t\tthis.maxContentLength = maxContentLength;\n\t}"
        ],
        [
            "RestServerEndpointConfiguration::RestServerEndpointConfiguration(String,String,String,SSLHandlerFactory,Path,int,Map)",
            "  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71 -\n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  ",
            "\tprivate RestServerEndpointConfiguration(\n\t\t\tfinal String restAddress,\n\t\t\t@Nullable String restBindAddress,\n\t\t\tString restBindPortRange,\n\t\t\t@Nullable SSLHandlerFactory sslHandlerFactory,\n\t\t\tfinal Path uploadDir,\n\t\t\tfinal int maxContentLength,\n\t\t\tfinal Map<String, String> responseHeaders) {\n\n\t\tPreconditions.checkArgument(maxContentLength > 0, \"maxContentLength must be positive, was: %d\", maxContentLength);\n\n\t\tthis.restAddress = requireNonNull(restAddress);\n\t\tthis.restBindAddress = restBindAddress;\n\t\tthis.restBindPortRange = requireNonNull(restBindPortRange);\n\t\tthis.sslHandlerFactory = sslHandlerFactory;\n\t\tthis.uploadDir = requireNonNull(uploadDir);\n\t\tthis.maxContentLength = maxContentLength;\n\t\tthis.responseHeaders = Collections.unmodifiableMap(requireNonNull(responseHeaders));\n\t}",
            "  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71 +\n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  ",
            "\tprivate RestServerEndpointConfiguration(\n\t\t\tfinal String restAddress,\n\t\t\t@Nullable String restBindAddress,\n\t\t\tString restBindPortRange,\n\t\t\t@Nullable SSLHandlerFactory sslHandlerFactory,\n\t\t\tfinal Path uploadDir,\n\t\t\tfinal int maxContentLength,\n\t\t\tfinal Map<String, String> responseHeaders) {\n\n\t\tPreconditions.checkArgument(maxContentLength > 0, \"maxContentLength must be positive, was: %s\", maxContentLength);\n\n\t\tthis.restAddress = requireNonNull(restAddress);\n\t\tthis.restBindAddress = restBindAddress;\n\t\tthis.restBindPortRange = requireNonNull(restBindPortRange);\n\t\tthis.sslHandlerFactory = sslHandlerFactory;\n\t\tthis.uploadDir = requireNonNull(uploadDir);\n\t\tthis.maxContentLength = maxContentLength;\n\t\tthis.responseHeaders = Collections.unmodifiableMap(requireNonNull(responseHeaders));\n\t}"
        ],
        [
            "FlinkKafkaInternalProducer::resumeTransaction(long,short)",
            " 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151 -\n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  ",
            "\t/**\n\t * Instead of obtaining producerId and epoch from the transaction coordinator, re-use previously obtained ones,\n\t * so that we can resume transaction after a restart. Implementation of this method is based on\n\t * {@link KafkaProducer#initTransactions}.\n\t * https://github.com/apache/kafka/commit/5d2422258cb975a137a42a4e08f03573c49a387e#diff-f4ef1afd8792cd2a2e9069cd7ddea630\n\t */\n\tpublic void resumeTransaction(long producerId, short epoch) {\n\t\tPreconditions.checkState(producerId >= 0 && epoch >= 0, \"Incorrect values for producerId {} and epoch {}\", producerId, epoch);\n\t\tLOG.info(\"Attempting to resume transaction {} with producerId {} and epoch {}\", transactionalId, producerId, epoch);\n\n\t\tObject transactionManager = getValue(kafkaProducer, \"transactionManager\");\n\t\tsynchronized (transactionManager) {\n\t\t\tObject nextSequence = getValue(transactionManager, \"nextSequence\");\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.INITIALIZING\"));\n\t\t\tinvoke(nextSequence, \"clear\");\n\n\t\t\tObject producerIdAndEpoch = getValue(transactionManager, \"producerIdAndEpoch\");\n\t\t\tsetValue(producerIdAndEpoch, \"producerId\", producerId);\n\t\t\tsetValue(producerIdAndEpoch, \"epoch\", epoch);\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.READY\"));\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.IN_TRANSACTION\"));\n\t\t\tsetValue(transactionManager, \"transactionStarted\", true);\n\t\t}\n\t}",
            " 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151 +\n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  ",
            "\t/**\n\t * Instead of obtaining producerId and epoch from the transaction coordinator, re-use previously obtained ones,\n\t * so that we can resume transaction after a restart. Implementation of this method is based on\n\t * {@link KafkaProducer#initTransactions}.\n\t * https://github.com/apache/kafka/commit/5d2422258cb975a137a42a4e08f03573c49a387e#diff-f4ef1afd8792cd2a2e9069cd7ddea630\n\t */\n\tpublic void resumeTransaction(long producerId, short epoch) {\n\t\tPreconditions.checkState(producerId >= 0 && epoch >= 0, \"Incorrect values for producerId %s and epoch %s\", producerId, epoch);\n\t\tLOG.info(\"Attempting to resume transaction {} with producerId {} and epoch {}\", transactionalId, producerId, epoch);\n\n\t\tObject transactionManager = getValue(kafkaProducer, \"transactionManager\");\n\t\tsynchronized (transactionManager) {\n\t\t\tObject nextSequence = getValue(transactionManager, \"nextSequence\");\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.INITIALIZING\"));\n\t\t\tinvoke(nextSequence, \"clear\");\n\n\t\t\tObject producerIdAndEpoch = getValue(transactionManager, \"producerIdAndEpoch\");\n\t\t\tsetValue(producerIdAndEpoch, \"producerId\", producerId);\n\t\t\tsetValue(producerIdAndEpoch, \"epoch\", epoch);\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.READY\"));\n\n\t\t\tinvoke(transactionManager, \"transitionTo\", getEnum(\"org.apache.kafka.clients.producer.internals.TransactionManager$State.IN_TRANSACTION\"));\n\t\t\tsetValue(transactionManager, \"transactionStarted\", true);\n\t\t}\n\t}"
        ],
        [
            "PojoSerializerSnapshot::readSnapshot(int,DataInputView,ClassLoader)",
            " 122  \n 123  \n 124 -\n 125  \n 126  ",
            "\t@Override\n\tpublic void readSnapshot(int readVersion, DataInputView in, ClassLoader userCodeClassLoader) throws IOException {\n\t\tcheckArgument(readVersion == 2, \"unrecognized read version %d\", readVersion);\n\t\tsnapshotData = PojoSerializerSnapshotData.createFrom(in, userCodeClassLoader);\n\t}",
            " 122  \n 123  \n 124 +\n 125  \n 126  ",
            "\t@Override\n\tpublic void readSnapshot(int readVersion, DataInputView in, ClassLoader userCodeClassLoader) throws IOException {\n\t\tcheckArgument(readVersion == 2, \"unrecognized read version %s\", readVersion);\n\t\tsnapshotData = PojoSerializerSnapshotData.createFrom(in, userCodeClassLoader);\n\t}"
        ]
    ],
    "098979c744319fc7e92123eebfc391f204c7b96f": [
        [
            "HiveInspectors::toFlinkObject(ObjectInspector,Object)",
            " 275  \n 276  \n 277  \n 278  \n 279 -\n 280 -\n 281 -\n 282 -\n 283 -\n 284  \n 285  \n 286  \n 287  \n 288 -\n 289 -\n 290 -\n 291 -\n 292 -\n 293 -\n 294 -\n 295 -\n 296 -\n 297 -\n 298 -\n 299 -\n 300 -\n 301 -\n 302 -\n 303 -\n 304 -\n 305 -\n 306 -\n 307 -\n 308 -\n 309 -\n 310 -\n 311 -\n 312 -\n 313 -\n 314 -\n 315 -\n 316 -\n 317 -\n 318 -\n 319 -\n 320 -\n 321 -\n 322 -\n 323 -\n 324 -\n 325 -\n 326 -\n 327 -\n 328 -\n 329 -\n 330 -\n 331 -\n 332 -\n 333 -\n 334 -\n 335 -\n 336 -\n 337 -\n 338 -\n 339 -\n 340 -\n 341 -\n 342 -\n 343 -\n 344 -\n 345 -\n 346 -\n 347 -\n 348 -\n 349 -\n 350 -\n 351 -\n 352 -\n 353 -\n 354  \n 355  \n 356  \n 357 -\n 358 -\n 359 -\n 360  \n 361  \n 362  \n 363 -\n 364 -\n 365 -\n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  ",
            "\t/**\n\t * Converts a Hive object to Flink object with an ObjectInspector.\n\t */\n\tpublic static Object toFlinkObject(ObjectInspector inspector, Object data) {\n\t\tif (data == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tif (inspector instanceof VoidObjectInspector) {\n\t\t\treturn null;\n\t\t}\n\n\t\tif (inspector instanceof PrimitiveObjectInspector) {\n\t\t\tif (inspector instanceof BooleanObjectInspector) {\n\t\t\t\tBooleanObjectInspector oi = (BooleanObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof StringObjectInspector) {\n\t\t\t\tStringObjectInspector oi = (StringObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.getPrimitiveWritableObject(data).toString() :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof ByteObjectInspector) {\n\t\t\t\tByteObjectInspector oi = (ByteObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof ShortObjectInspector) {\n\t\t\t\tShortObjectInspector oi = (ShortObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof IntObjectInspector) {\n\t\t\t\tIntObjectInspector oi = (IntObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof LongObjectInspector) {\n\t\t\t\tLongObjectInspector oi = (LongObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof FloatObjectInspector) {\n\t\t\t\tFloatObjectInspector oi = (FloatObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof DoubleObjectInspector) {\n\t\t\t\tDoubleObjectInspector oi = (DoubleObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.get(data) :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof DateObjectInspector) {\n\t\t\t\tDateObjectInspector oi = (DateObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.getPrimitiveWritableObject(data).get() :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof TimestampObjectInspector) {\n\t\t\t\tTimestampObjectInspector oi = (TimestampObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.getPrimitiveWritableObject(data).getTimestamp() :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof BinaryObjectInspector) {\n\t\t\t\tBinaryObjectInspector oi = (BinaryObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.getPrimitiveWritableObject(data).getBytes() :\n\t\t\t\t\toi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof HiveCharObjectInspector) {\n\t\t\t\tHiveCharObjectInspector oi = (HiveCharObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.getPrimitiveWritableObject(data).getHiveChar().getValue() :\n\t\t\t\t\toi.getPrimitiveJavaObject(data).getValue();\n\t\t\t} else if (inspector instanceof HiveVarcharObjectInspector) {\n\t\t\t\tHiveVarcharObjectInspector oi = (HiveVarcharObjectInspector) inspector;\n\n\t\t\t\treturn oi.preferWritable() ?\n\t\t\t\t\toi.getPrimitiveWritableObject(data).getHiveVarchar().getValue() :\n\t\t\t\t\toi.getPrimitiveJavaObject(data).getValue();\n\t\t\t}\n\n\t\t\t// TODO: handle decimal type\n\t\t}\n\n\t\t// TODO: handle complex types like list and map\n\n\t\tif (inspector instanceof StandardStructObjectInspector) {\n\t\t\tStandardStructObjectInspector structInspector = (StandardStructObjectInspector) inspector;\n\n\t\t\tList<? extends StructField> fields = structInspector.getAllStructFieldRefs();\n\n\t\t\tRow row = new Row(fields.size());\n\t\t\tfor (int i = 0; i < row.getArity(); i++) {\n\t\t\t\trow.setField(\n\t\t\t\t\ti,\n\t\t\t\t\ttoFlinkObject(\n\t\t\t\t\t\tfields.get(i).getFieldObjectInspector(),\n\t\t\t\t\t\tstructInspector.getStructFieldData(data, fields.get(i)))\n\t\t\t\t);\n\t\t\t}\n\n\t\t\treturn row;\n\t\t}\n\n\t\tthrow new FlinkHiveUDFException(\n\t\t\tString.format(\"Unwrap does not support ObjectInspector '%s' yet\", inspector));\n\t}",
            " 198  \n 199  \n 200  \n 201  \n 202 +\n 203  \n 204  \n 205  \n 206  \n 207 +\n 208 +\n 209 +\n 210 +\n 211 +\n 212 +\n 213 +\n 214 +\n 215 +\n 216 +\n 217 +\n 218 +\n 219 +\n 220 +\n 221  \n 222  \n 223  \n 224 +\n 225  \n 226  \n 227  \n 228 +\n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  ",
            "\t/**\n\t * Converts a Hive object to Flink object with an ObjectInspector.\n\t */\n\tpublic static Object toFlinkObject(ObjectInspector inspector, Object data) {\n\t\tif (data == null || inspector instanceof VoidObjectInspector) {\n\t\t\treturn null;\n\t\t}\n\n\t\tif (inspector instanceof PrimitiveObjectInspector) {\n\t\t\tif (inspector instanceof BooleanObjectInspector ||\n\t\t\t\t\tinspector instanceof StringObjectInspector ||\n\t\t\t\t\tinspector instanceof ByteObjectInspector ||\n\t\t\t\t\tinspector instanceof ShortObjectInspector ||\n\t\t\t\t\tinspector instanceof IntObjectInspector ||\n\t\t\t\t\tinspector instanceof LongObjectInspector ||\n\t\t\t\t\tinspector instanceof FloatObjectInspector ||\n\t\t\t\t\tinspector instanceof DoubleObjectInspector ||\n\t\t\t\t\tinspector instanceof DateObjectInspector ||\n\t\t\t\t\tinspector instanceof TimestampObjectInspector ||\n\t\t\t\t\tinspector instanceof BinaryObjectInspector) {\n\n\t\t\t\tPrimitiveObjectInspector poi = (PrimitiveObjectInspector) inspector;\n\t\t\t\treturn poi.getPrimitiveJavaObject(data);\n\t\t\t} else if (inspector instanceof HiveCharObjectInspector) {\n\t\t\t\tHiveCharObjectInspector oi = (HiveCharObjectInspector) inspector;\n\n\t\t\t\treturn oi.getPrimitiveJavaObject(data).getValue();\n\t\t\t} else if (inspector instanceof HiveVarcharObjectInspector) {\n\t\t\t\tHiveVarcharObjectInspector oi = (HiveVarcharObjectInspector) inspector;\n\n\t\t\t\treturn oi.getPrimitiveJavaObject(data).getValue();\n\t\t\t}\n\n\t\t\t// TODO: handle decimal type\n\t\t}\n\n\t\t// TODO: handle complex types like list and map\n\n\t\tif (inspector instanceof StandardStructObjectInspector) {\n\t\t\tStandardStructObjectInspector structInspector = (StandardStructObjectInspector) inspector;\n\n\t\t\tList<? extends StructField> fields = structInspector.getAllStructFieldRefs();\n\n\t\t\tRow row = new Row(fields.size());\n\t\t\tfor (int i = 0; i < row.getArity(); i++) {\n\t\t\t\trow.setField(\n\t\t\t\t\ti,\n\t\t\t\t\ttoFlinkObject(\n\t\t\t\t\t\tfields.get(i).getFieldObjectInspector(),\n\t\t\t\t\t\tstructInspector.getStructFieldData(data, fields.get(i)))\n\t\t\t\t);\n\t\t\t}\n\n\t\t\treturn row;\n\t\t}\n\n\t\tthrow new FlinkHiveUDFException(\n\t\t\tString.format(\"Unwrap does not support ObjectInspector '%s' yet\", inspector));\n\t}"
        ],
        [
            "HiveInspectors::getObjectInspector(Class)",
            " 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431 -\n 432  \n 433  \n 434 -\n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  ",
            "\tpublic static ObjectInspector getObjectInspector(Class clazz) {\n\t\tTypeInfo typeInfo;\n\n\t\tif (clazz.equals(String.class) || clazz.equals(Text.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.stringTypeInfo;\n\t\t} else if (clazz.equals(Boolean.class) || clazz.equals(BooleanWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.booleanTypeInfo;\n\t\t} else if (clazz.equals(Byte.class) || clazz.equals(ByteWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.byteTypeInfo;\n\t\t} else if (clazz.equals(Short.class) || clazz.equals(ShortWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.shortTypeInfo;\n\t\t} else if (clazz.equals(Integer.class) || clazz.equals(IntWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.intTypeInfo;\n\t\t} else if (clazz.equals(Long.class) || clazz.equals(LongWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.longTypeInfo;\n\t\t} else if (clazz.equals(Float.class) || clazz.equals(FloatWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.floatTypeInfo;\n\t\t} else if (clazz.equals(Double.class) || clazz.equals(DoubleWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.doubleTypeInfo;\n\t\t} else if (clazz.equals(Date.class) || clazz.equals(DateWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.dateTypeInfo;\n\t\t} else if (clazz.equals(Timestamp.class) || clazz.equals(TimestampWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.timestampTypeInfo;\n\t\t} else if (clazz.equals(byte[].class) || clazz.equals(BytesWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.binaryTypeInfo;\n\t\t} else if (clazz.equals(HiveChar.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.charTypeInfo;\n\t\t} else if (clazz.equals(HiveVarchar.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.varcharTypeInfo;\n\t\t} else {\n\t\t\tthrow new FlinkHiveUDFException(\n\t\t\t\tString.format(\"Class %s is not supported yet\", clazz.getName()));\n\t\t}\n\n\t\treturn getObjectInspector(typeInfo);\n\t}",
            " 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294 +\n 295  \n 296  \n 297 +\n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  ",
            "\tpublic static ObjectInspector getObjectInspector(Class clazz) {\n\t\tTypeInfo typeInfo;\n\n\t\tif (clazz.equals(String.class) || clazz.equals(Text.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.stringTypeInfo;\n\t\t} else if (clazz.equals(Boolean.class) || clazz.equals(BooleanWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.booleanTypeInfo;\n\t\t} else if (clazz.equals(Byte.class) || clazz.equals(ByteWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.byteTypeInfo;\n\t\t} else if (clazz.equals(Short.class) || clazz.equals(ShortWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.shortTypeInfo;\n\t\t} else if (clazz.equals(Integer.class) || clazz.equals(IntWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.intTypeInfo;\n\t\t} else if (clazz.equals(Long.class) || clazz.equals(LongWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.longTypeInfo;\n\t\t} else if (clazz.equals(Float.class) || clazz.equals(FloatWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.floatTypeInfo;\n\t\t} else if (clazz.equals(Double.class) || clazz.equals(DoubleWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.doubleTypeInfo;\n\t\t} else if (clazz.equals(Date.class) || clazz.equals(DateWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.dateTypeInfo;\n\t\t} else if (clazz.equals(Timestamp.class) || clazz.equals(TimestampWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.timestampTypeInfo;\n\t\t} else if (clazz.equals(byte[].class) || clazz.equals(BytesWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.binaryTypeInfo;\n\t\t} else if (clazz.equals(HiveChar.class) || clazz.equals(HiveCharWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.charTypeInfo;\n\t\t} else if (clazz.equals(HiveVarchar.class) || clazz.equals(HiveVarcharWritable.class)) {\n\n\t\t\ttypeInfo = TypeInfoFactory.varcharTypeInfo;\n\t\t} else {\n\t\t\tthrow new FlinkHiveUDFException(\n\t\t\t\tString.format(\"Class %s is not supported yet\", clazz.getName()));\n\t\t}\n\n\t\treturn getObjectInspector(typeInfo);\n\t}"
        ],
        [
            "HiveInspectors::getConversion(ObjectInspector,DataType)",
            " 179  \n 180  \n 181  \n 182  \n 183  \n 184 -\n 185 -\n 186 -\n 187 -\n 188 -\n 189 -\n 190 -\n 191 -\n 192 -\n 193 -\n 194 -\n 195 -\n 196 -\n 197 -\n 198 -\n 199 -\n 200 -\n 201 -\n 202 -\n 203 -\n 204 -\n 205 -\n 206 -\n 207 -\n 208 -\n 209 -\n 210 -\n 211 -\n 212 -\n 213 -\n 214 -\n 215 -\n 216 -\n 217 -\n 218 -\n 219 -\n 220 -\n 221 -\n 222 -\n 223 -\n 224 -\n 225 -\n 226 -\n 227 -\n 228 -\n 229 -\n 230 -\n 231 -\n 232 -\n 233 -\n 234 -\n 235 -\n 236 -\n 237 -\n 238 -\n 239 -\n 240 -\n 241 -\n 242 -\n 243 -\n 244 -\n 245 -\n 246 -\n 247 -\n 248 -\n 249 -\n 250 -\n 251 -\n 252 -\n 253 -\n 254 -\n 255 -\n 256 -\n 257 -\n 258 -\n 259 -\n 260 -\n 261 -\n 262 -\n 263 -\n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  ",
            "\t/**\n\t * Get conversion for converting Flink object to Hive object from an ObjectInspector and the corresponding Flink DataType.\n\t */\n\tpublic static HiveObjectConversion getConversion(ObjectInspector inspector, DataType dataType) {\n\t\tif (inspector instanceof PrimitiveObjectInspector) {\n\t\t\tif (inspector instanceof JavaBooleanObjectInspector) {\n\t\t\t\tif (((JavaBooleanObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new BooleanWritable((Boolean) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaStringObjectInspector) {\n\t\t\t\tif (((StringObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new Text((String) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaByteObjectInspector) {\n\t\t\t\tif (((JavaByteObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new ByteWritable((Byte) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaShortObjectInspector) {\n\t\t\t\tif (((JavaShortObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new ShortWritable((Short) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaIntObjectInspector) {\n\t\t\t\tif (((JavaIntObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new IntWritable((Integer) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaLongObjectInspector) {\n\t\t\t\tif (((JavaLongObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new LongWritable((Long) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaFloatObjectInspector) {\n\t\t\t\tif (((JavaFloatObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new FloatWritable((Float) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaDoubleObjectInspector) {\n\t\t\t\tif (((JavaDoubleObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new DoubleWritable((Double) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaDateObjectInspector) {\n\t\t\t\tif (((JavaDateObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new DateWritable((Date) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaTimestampObjectInspector) {\n\t\t\t\tif (((JavaTimestampObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new TimestampWritable((Timestamp) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaBinaryObjectInspector) {\n\t\t\t\tif (((JavaBinaryObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new BytesWritable((byte[]) o);\n\t\t\t\t} else {\n\t\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaHiveCharObjectInspector) {\n\t\t\t\tif (((JavaHiveCharObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new HiveCharWritable(\n\t\t\t\t\t\tnew HiveChar((String) o, ((CharType) dataType.getLogicalType()).getLength()));\n\t\t\t\t} else {\n\t\t\t\t\treturn o -> new HiveChar((String) o, ((CharType) dataType.getLogicalType()).getLength());\n\t\t\t\t}\n\t\t\t} else if (inspector instanceof JavaHiveVarcharObjectInspector) {\n\t\t\t\tif (((JavaHiveVarcharObjectInspector) inspector).preferWritable()) {\n\t\t\t\t\treturn o -> new HiveVarcharWritable(\n\t\t\t\t\t\tnew HiveVarchar((String) o, ((VarCharType) dataType.getLogicalType()).getLength()));\n\t\t\t\t} else {\n\t\t\t\t\treturn o -> new HiveVarchar((String) o, ((VarCharType) dataType.getLogicalType()).getLength());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// TODO: handle decimal type\n\t\t}\n\n\t\t// TODO: handle complex types like struct, list, and map\n\n\t\tthrow new FlinkHiveUDFException(\n\t\t\tString.format(\"Flink doesn't support convert object conversion for %s yet\", inspector));\n\t}",
            " 166  \n 167  \n 168  \n 169  \n 170  \n 171 +\n 172 +\n 173 +\n 174 +\n 175 +\n 176 +\n 177 +\n 178 +\n 179 +\n 180 +\n 181 +\n 182 +\n 183 +\n 184 +\n 185 +\n 186 +\n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  ",
            "\t/**\n\t * Get conversion for converting Flink object to Hive object from an ObjectInspector and the corresponding Flink DataType.\n\t */\n\tpublic static HiveObjectConversion getConversion(ObjectInspector inspector, DataType dataType) {\n\t\tif (inspector instanceof PrimitiveObjectInspector) {\n\t\t\tif (inspector instanceof BooleanObjectInspector ||\n\t\t\t\t\tinspector instanceof StringObjectInspector ||\n\t\t\t\t\tinspector instanceof ByteObjectInspector ||\n\t\t\t\t\tinspector instanceof ShortObjectInspector ||\n\t\t\t\t\tinspector instanceof IntObjectInspector ||\n\t\t\t\t\tinspector instanceof LongObjectInspector ||\n\t\t\t\t\tinspector instanceof FloatObjectInspector ||\n\t\t\t\t\tinspector instanceof DoubleObjectInspector ||\n\t\t\t\t\tinspector instanceof DateObjectInspector ||\n\t\t\t\t\tinspector instanceof TimestampObjectInspector ||\n\t\t\t\t\tinspector instanceof BinaryObjectInspector) {\n\t\t\t\treturn IdentityConversion.INSTANCE;\n\t\t\t} else if (inspector instanceof HiveCharObjectInspector) {\n\t\t\t\treturn o -> new HiveChar((String) o, ((CharType) dataType.getLogicalType()).getLength());\n\t\t\t} else if (inspector instanceof HiveVarcharObjectInspector) {\n\t\t\t\treturn o -> new HiveVarchar((String) o, ((VarCharType) dataType.getLogicalType()).getLength());\n\t\t\t}\n\n\t\t\t// TODO: handle decimal type\n\t\t}\n\n\t\t// TODO: handle complex types like struct, list, and map\n\n\t\tthrow new FlinkHiveUDFException(\n\t\t\tString.format(\"Flink doesn't support convert object conversion for %s yet\", inspector));\n\t}"
        ]
    ]
}