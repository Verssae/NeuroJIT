{
    "f56244d21a331cec7da5b751a4de9effad49952b": [
        [
            "CollectionsTest::testMaps()",
            " 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  ",
            "    @Test\n    public void testMaps() throws Throwable\n    {\n        createTable(\"CREATE TABLE %s (k int PRIMARY KEY, m map<text, int>)\");\n\n        execute(\"INSERT INTO %s(k, m) VALUES (0, ?)\", map(\"v1\", 1, \"v2\", 2));\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v1\", 1, \"v2\", 2))\n        );\n\n        execute(\"UPDATE %s SET m[?] = ?, m[?] = ? WHERE k = 0\", \"v3\", 3, \"v4\", 4);\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v1\", 1, \"v2\", 2, \"v3\", 3, \"v4\", 4))\n        );\n\n        execute(\"DELETE m[?] FROM %s WHERE k = 0\", \"v1\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v2\", 2, \"v3\", 3, \"v4\", 4))\n        );\n\n        // Full overwrite\n        execute(\"UPDATE %s SET m = ? WHERE k = 0\", map(\"v6\", 6, \"v5\", 5));\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v5\", 5, \"v6\", 6))\n        );\n\n        execute(\"UPDATE %s SET m = m + ? WHERE k = 0\", map(\"v7\", 7));\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v5\", 5, \"v6\", 6, \"v7\", 7))\n        );\n\n        // The empty map is parsed as an empty set (because we don't have enough info at parsing\n        // time when we see a {}) and special cased later. This test checks this work properly\n        execute(\"UPDATE %s SET m = {} WHERE k = 0\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row((Object)null)",
            " 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158 +\n 159 +\n 160 +\n 161 +\n 162 +\n 163 +\n 164 +\n 165 +\n 166 +\n 167 +\n 168 +\n 169 +\n 170 +\n 171 +\n 172 +\n 173 +\n 174 +\n 175 +\n 176 +\n 177 +\n 178 +\n 179 +\n 180 +\n 181 +\n 182 +\n 183  \n 184  \n 185  \n 186  \n 187  \n 188  ",
            "    @Test\n    public void testMaps() throws Throwable\n    {\n        createTable(\"CREATE TABLE %s (k int PRIMARY KEY, m map<text, int>)\");\n\n        execute(\"INSERT INTO %s(k, m) VALUES (0, ?)\", map(\"v1\", 1, \"v2\", 2));\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v1\", 1, \"v2\", 2))\n        );\n\n        execute(\"UPDATE %s SET m[?] = ?, m[?] = ? WHERE k = 0\", \"v3\", 3, \"v4\", 4);\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v1\", 1, \"v2\", 2, \"v3\", 3, \"v4\", 4))\n        );\n\n        execute(\"DELETE m[?] FROM %s WHERE k = 0\", \"v1\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v2\", 2, \"v3\", 3, \"v4\", 4))\n        );\n\n        // Full overwrite\n        execute(\"UPDATE %s SET m = ? WHERE k = 0\", map(\"v6\", 6, \"v5\", 5));\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v5\", 5, \"v6\", 6))\n        );\n\n        execute(\"UPDATE %s SET m = m + ? WHERE k = 0\", map(\"v7\", 7));\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v5\", 5, \"v6\", 6, \"v7\", 7))\n        );\n\n        execute(\"DELETE m[?] FROM %s WHERE k = 0\", \"v7\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v5\", 5, \"v6\", 6))\n        );\n\n        execute(\"DELETE m[?] FROM %s WHERE k = 0\", \"v6\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row(map(\"v5\", 5))\n        );\n\n        execute(\"DELETE m[?] FROM %s WHERE k = 0\", \"v5\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row((Object)null)\n        );\n\n        // Deleting a non-existing key should succeed\n        execute(\"DELETE m[?] FROM %s WHERE k = 0\", \"v5\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row((Object) null)\n        );\n\n        // The empty map is parsed as an empty set (because we don't have enough info at parsing\n        // time when we see a {}) and special cased later. This test checks this work properly\n        execute(\"UPDATE %s SET m = {} WHERE k = 0\");\n\n        assertRows(execute(\"SELECT m FROM %s WHERE k = 0\"),\n            row((Object)null)"
        ],
        [
            "Lists::SetterByIndex::execute(ByteBuffer,ColumnFamily,Composite,UpdateParameters)",
            " 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345 -\n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  ",
            "        public void execute(ByteBuffer rowKey, ColumnFamily cf, Composite prefix, UpdateParameters params) throws InvalidRequestException\n        {\n            // we should not get here for frozen lists\n            assert column.type.isMultiCell() : \"Attempted to set an individual element on a frozen list\";\n\n            ByteBuffer index = idx.bindAndGet(params.options);\n            ByteBuffer value = t.bindAndGet(params.options);\n\n            if (index == null)\n                throw new InvalidRequestException(\"Invalid null value for list index\");\n\n            List<Cell> existingList = params.getPrefetchedList(rowKey, column.name);\n            int idx = ByteBufferUtil.toInt(index);\n            if (existingList == null)\n                throw new InvalidRequestException(\"Attempted to set an element on a list which is null\");\n            if (idx < 0 || idx >= existingList.size())\n                throw new InvalidRequestException(String.format(\"List index %d out of bound, list has size %d\", idx, existingList.size()));\n\n            CellName elementName = existingList.get(idx).name();\n            if (value == null)\n            {\n                cf.addColumn(params.makeTombstone(elementName));\n            }\n            else\n            {\n                // We don't support value > 64K because the serialization format encode the length as an unsigned short.\n                if (value.remaining() > FBUtilities.MAX_UNSIGNED_SHORT)\n                    throw new InvalidRequestException(String.format(\"List value is too long. List values are limited to %d bytes but %d bytes value provided\",\n                                                                    FBUtilities.MAX_UNSIGNED_SHORT,\n                                                                    value.remaining()));\n\n                cf.addColumn(params.makeColumn(elementName, value));\n            }\n        }",
            " 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345 +\n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  ",
            "        public void execute(ByteBuffer rowKey, ColumnFamily cf, Composite prefix, UpdateParameters params) throws InvalidRequestException\n        {\n            // we should not get here for frozen lists\n            assert column.type.isMultiCell() : \"Attempted to set an individual element on a frozen list\";\n\n            ByteBuffer index = idx.bindAndGet(params.options);\n            ByteBuffer value = t.bindAndGet(params.options);\n\n            if (index == null)\n                throw new InvalidRequestException(\"Invalid null value for list index\");\n\n            List<Cell> existingList = params.getPrefetchedList(rowKey, column.name);\n            int idx = ByteBufferUtil.toInt(index);\n            if (existingList == null || existingList.size() == 0)\n                throw new InvalidRequestException(\"Attempted to set an element on a list which is null\");\n            if (idx < 0 || idx >= existingList.size())\n                throw new InvalidRequestException(String.format(\"List index %d out of bound, list has size %d\", idx, existingList.size()));\n\n            CellName elementName = existingList.get(idx).name();\n            if (value == null)\n            {\n                cf.addColumn(params.makeTombstone(elementName));\n            }\n            else\n            {\n                // We don't support value > 64K because the serialization format encode the length as an unsigned short.\n                if (value.remaining() > FBUtilities.MAX_UNSIGNED_SHORT)\n                    throw new InvalidRequestException(String.format(\"List value is too long. List values are limited to %d bytes but %d bytes value provided\",\n                                                                    FBUtilities.MAX_UNSIGNED_SHORT,\n                                                                    value.remaining()));\n\n                cf.addColumn(params.makeColumn(elementName, value));\n            }\n        }"
        ],
        [
            "Lists::DiscarderByIndex::execute(ByteBuffer,ColumnFamily,Composite,UpdateParameters)",
            " 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503 -\n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  ",
            "        public void execute(ByteBuffer rowKey, ColumnFamily cf, Composite prefix, UpdateParameters params) throws InvalidRequestException\n        {\n            assert column.type.isMultiCell() : \"Attempted to delete an item by index from a frozen list\";\n            Term.Terminal index = t.bind(params.options);\n            if (index == null)\n                throw new InvalidRequestException(\"Invalid null value for list index\");\n\n            List<Cell> existingList = params.getPrefetchedList(rowKey, column.name);\n            int idx = ByteBufferUtil.toInt(index.get(params.options));\n            if (existingList == null)\n                throw new InvalidRequestException(\"Attempted to delete an element from a list which is null\");\n            if (idx < 0 || idx >= existingList.size())\n                throw new InvalidRequestException(String.format(\"List index %d out of bound, list has size %d\", idx, existingList.size()));\n\n            CellName elementName = existingList.get(idx).name();\n            cf.addColumn(params.makeTombstone(elementName));\n        }",
            " 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503 +\n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  ",
            "        public void execute(ByteBuffer rowKey, ColumnFamily cf, Composite prefix, UpdateParameters params) throws InvalidRequestException\n        {\n            assert column.type.isMultiCell() : \"Attempted to delete an item by index from a frozen list\";\n            Term.Terminal index = t.bind(params.options);\n            if (index == null)\n                throw new InvalidRequestException(\"Invalid null value for list index\");\n\n            List<Cell> existingList = params.getPrefetchedList(rowKey, column.name);\n            int idx = ByteBufferUtil.toInt(index.get(params.options));\n            if (existingList == null || existingList.size() == 0)\n                throw new InvalidRequestException(\"Attempted to delete an element from a list which is null\");\n            if (idx < 0 || idx >= existingList.size())\n                throw new InvalidRequestException(String.format(\"List index %d out of bound, list has size %d\", idx, existingList.size()));\n\n            CellName elementName = existingList.get(idx).name();\n            cf.addColumn(params.makeTombstone(elementName));\n        }"
        ],
        [
            "UpdateParameters::getPrefetchedList(ByteBuffer,ColumnIdentifier)",
            "  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100 -\n 101  ",
            "    public List<Cell> getPrefetchedList(ByteBuffer rowKey, ColumnIdentifier cql3ColumnName)\n    {\n        if (prefetchedLists == null)\n            return Collections.emptyList();\n\n        CQL3Row row = prefetchedLists.get(rowKey);\n        return row == null ? Collections.<Cell>emptyList() : row.getMultiCellColumn(cql3ColumnName);\n    }",
            "  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100 +\n 101 +\n 102 +\n 103 +\n 104 +\n 105  ",
            "    public List<Cell> getPrefetchedList(ByteBuffer rowKey, ColumnIdentifier cql3ColumnName)\n    {\n        if (prefetchedLists == null)\n            return Collections.emptyList();\n\n        CQL3Row row = prefetchedLists.get(rowKey);\n        if (row == null)\n            return Collections.<Cell>emptyList();\n\n        List<Cell> cql3List = row.getMultiCellColumn(cql3ColumnName);\n        return (cql3List == null) ? Collections.<Cell>emptyList() : cql3List;\n    }"
        ],
        [
            "CollectionsTest::testSets()",
            "  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  ",
            "    @Test\n    public void testSets() throws Throwable\n    {\n        createTable(\"CREATE TABLE %s (k int PRIMARY KEY, s set<text>)\");\n\n        execute(\"INSERT INTO %s(k, s) VALUES (0, ?)\", set(\"v1\", \"v2\", \"v3\", \"v4\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v1\", \"v2\", \"v3\", \"v4\"))\n        );\n\n        execute(\"DELETE s[?] FROM %s WHERE k = 0\", \"v1\");\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v2\", \"v3\", \"v4\"))\n        );\n\n        // Full overwrite\n        execute(\"UPDATE %s SET s = ? WHERE k = 0\", set(\"v6\", \"v5\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v5\", \"v6\"))\n        );\n\n        execute(\"UPDATE %s SET s = s + ? WHERE k = 0\", set(\"v7\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v5\", \"v6\", \"v7\"))\n        );\n\n        execute(\"UPDATE %s SET s = s - ? WHERE k = 0\", set(\"v6\", \"v5\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v7\"))\n        );\n\n        execute(\"DELETE s FROM %s WHERE k = 0\");\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row((Object)null)",
            "  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110 +\n 111 +\n 112 +\n 113 +\n 114 +\n 115  \n 116  \n 117  \n 118  ",
            "    @Test\n    public void testSets() throws Throwable\n    {\n        createTable(\"CREATE TABLE %s (k int PRIMARY KEY, s set<text>)\");\n\n        execute(\"INSERT INTO %s(k, s) VALUES (0, ?)\", set(\"v1\", \"v2\", \"v3\", \"v4\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v1\", \"v2\", \"v3\", \"v4\"))\n        );\n\n        execute(\"DELETE s[?] FROM %s WHERE k = 0\", \"v1\");\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v2\", \"v3\", \"v4\"))\n        );\n\n        // Full overwrite\n        execute(\"UPDATE %s SET s = ? WHERE k = 0\", set(\"v6\", \"v5\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v5\", \"v6\"))\n        );\n\n        execute(\"UPDATE %s SET s = s + ? WHERE k = 0\", set(\"v7\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v5\", \"v6\", \"v7\"))\n        );\n\n        execute(\"UPDATE %s SET s = s - ? WHERE k = 0\", set(\"v6\", \"v5\"));\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row(set(\"v7\"))\n        );\n\n        execute(\"DELETE s[?] FROM %s WHERE k = 0\", set(\"v7\"));\n\n        // Deleting an element that does not exist will succeed\n        execute(\"DELETE s[?] FROM %s WHERE k = 0\", set(\"v7\"));\n\n        execute(\"DELETE s FROM %s WHERE k = 0\");\n\n        assertRows(execute(\"SELECT s FROM %s WHERE k = 0\"),\n            row((Object)null)"
        ],
        [
            "CollectionsTest::testLists()",
            " 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206 -\n 207 -\n 208 -\n 209  \n 210  \n 211  ",
            "    @Test\n    public void testLists() throws Throwable\n    {\n        createTable(\"CREATE TABLE %s (k int PRIMARY KEY, l list<text>)\");\n\n        execute(\"INSERT INTO %s(k, l) VALUES (0, ?)\", list(\"v1\", \"v2\", \"v3\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v1\", \"v2\", \"v3\")));\n\n        execute(\"DELETE l[?] FROM %s WHERE k = 0\", 1);\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v1\", \"v3\")));\n\n        execute(\"UPDATE %s SET l[?] = ? WHERE k = 0\", 1, \"v4\");\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v1\", \"v4\")));\n\n        // Full overwrite\n        execute(\"UPDATE %s SET l = ? WHERE k = 0\", list(\"v6\", \"v5\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v6\", \"v5\")));\n\n        execute(\"UPDATE %s SET l = l + ? WHERE k = 0\", list(\"v7\", \"v8\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v6\", \"v5\", \"v7\", \"v8\")));\n\n        execute(\"UPDATE %s SET l = ? + l WHERE k = 0\", list(\"v9\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v9\", \"v6\", \"v5\", \"v7\", \"v8\")));\n\n        execute(\"UPDATE %s SET l = l - ? WHERE k = 0\", list(\"v5\", \"v8\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v9\", \"v6\", \"v7\")));\n\n        execute(\"DELETE l FROM %s WHERE k = 0\");\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row((Object) null));\n\n        assertInvalidMessage(\"Attempted to delete an element from a list which is null\",\n                             \"DELETE l[0] FROM %s WHERE k=0 \");\n\n        assertInvalidMessage(\"Attempted to set an element on a list which is null\",\n                             \"UPDATE %s SET l[0] = ? WHERE k=0\", list(\"v10\"));\n\n        assertInvalidMessage(\"Attempted to delete an element from a list which is null\",\n                             \"UPDATE %s SET l = l - ? WHERE k=0 \",\n                             list(\"v11\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row((Object) null));\n    }",
            " 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236 +\n 237  \n 238  \n 239  ",
            "    @Test\n    public void testLists() throws Throwable\n    {\n        createTable(\"CREATE TABLE %s (k int PRIMARY KEY, l list<text>)\");\n\n        execute(\"INSERT INTO %s(k, l) VALUES (0, ?)\", list(\"v1\", \"v2\", \"v3\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v1\", \"v2\", \"v3\")));\n\n        execute(\"DELETE l[?] FROM %s WHERE k = 0\", 1);\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v1\", \"v3\")));\n\n        execute(\"UPDATE %s SET l[?] = ? WHERE k = 0\", 1, \"v4\");\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v1\", \"v4\")));\n\n        // Full overwrite\n        execute(\"UPDATE %s SET l = ? WHERE k = 0\", list(\"v6\", \"v5\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v6\", \"v5\")));\n\n        execute(\"UPDATE %s SET l = l + ? WHERE k = 0\", list(\"v7\", \"v8\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v6\", \"v5\", \"v7\", \"v8\")));\n\n        execute(\"UPDATE %s SET l = ? + l WHERE k = 0\", list(\"v9\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v9\", \"v6\", \"v5\", \"v7\", \"v8\")));\n\n        execute(\"UPDATE %s SET l = l - ? WHERE k = 0\", list(\"v5\", \"v8\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row(list(\"v9\", \"v6\", \"v7\")));\n\n        execute(\"DELETE l FROM %s WHERE k = 0\");\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row((Object) null));\n\n        assertInvalidMessage(\"Attempted to delete an element from a list which is null\",\n                             \"DELETE l[0] FROM %s WHERE k=0 \");\n\n        assertInvalidMessage(\"Attempted to set an element on a list which is null\",\n                             \"UPDATE %s SET l[0] = ? WHERE k=0\", list(\"v10\"));\n\n        execute(\"UPDATE %s SET l = l - ? WHERE k=0 \", list(\"v11\"));\n\n        assertRows(execute(\"SELECT l FROM %s WHERE k = 0\"), row((Object) null));\n    }"
        ]
    ],
    "9b6f55bdec6d9b7c08d7cae267b2fefbf60d7afc": [
        [
            "SnapshotTask::run()",
            "  44  \n  45  \n  46 -\n  47  ",
            "    public void run()\n    {\n        MessagingService.instance().sendRRWithFailure(new SnapshotMessage(desc).createMessage(),\n                endpoint,",
            "  45  \n  46  \n  47 +\n  48  \n  49 +\n  50  ",
            "    public void run()\n    {\n        MessagingService.instance().sendRR(new SnapshotMessage(desc).createMessage(),\n                endpoint,\n                new SnapshotCallback(this), TimeUnit.HOURS.toMillis(1), true);\n    }"
        ],
        [
            "ActiveRepairService::prepareForRepair(Set,Collection,List)",
            " 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285 -\n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  ",
            "    public synchronized UUID prepareForRepair(Set<InetAddress> endpoints, Collection<Range<Token>> ranges, List<ColumnFamilyStore> columnFamilyStores)\n    {\n        UUID parentRepairSession = UUIDGen.getTimeUUID();\n        registerParentRepairSession(parentRepairSession, columnFamilyStores, ranges);\n        final CountDownLatch prepareLatch = new CountDownLatch(endpoints.size());\n        final AtomicBoolean status = new AtomicBoolean(true);\n        final Set<String> failedNodes = Collections.synchronizedSet(new HashSet<String>());\n        IAsyncCallbackWithFailure callback = new IAsyncCallbackWithFailure()\n        {\n            public void response(MessageIn msg)\n            {\n                prepareLatch.countDown();\n            }\n\n            public boolean isLatencyForSnitch()\n            {\n                return false;\n            }\n\n            public void onFailure(InetAddress from)\n            {\n                status.set(false);\n                failedNodes.add(from.getHostAddress());\n                prepareLatch.countDown();\n            }\n        };\n\n        List<UUID> cfIds = new ArrayList<>(columnFamilyStores.size());\n        for (ColumnFamilyStore cfs : columnFamilyStores)\n            cfIds.add(cfs.metadata.cfId);\n\n        for(InetAddress neighbour : endpoints)\n        {\n            PrepareMessage message = new PrepareMessage(parentRepairSession, cfIds, ranges);\n            MessageOut<RepairMessage> msg = message.createMessage();\n            MessagingService.instance().sendRRWithFailure(msg, neighbour, callback);\n        }\n        try\n        {\n            prepareLatch.await(1, TimeUnit.HOURS);\n        }\n        catch (InterruptedException e)\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString(), e);\n        }\n\n        if (!status.get())\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get positive replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString());\n        }\n\n        return parentRepairSession;\n    }",
            " 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285 +\n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  ",
            "    public synchronized UUID prepareForRepair(Set<InetAddress> endpoints, Collection<Range<Token>> ranges, List<ColumnFamilyStore> columnFamilyStores)\n    {\n        UUID parentRepairSession = UUIDGen.getTimeUUID();\n        registerParentRepairSession(parentRepairSession, columnFamilyStores, ranges);\n        final CountDownLatch prepareLatch = new CountDownLatch(endpoints.size());\n        final AtomicBoolean status = new AtomicBoolean(true);\n        final Set<String> failedNodes = Collections.synchronizedSet(new HashSet<String>());\n        IAsyncCallbackWithFailure callback = new IAsyncCallbackWithFailure()\n        {\n            public void response(MessageIn msg)\n            {\n                prepareLatch.countDown();\n            }\n\n            public boolean isLatencyForSnitch()\n            {\n                return false;\n            }\n\n            public void onFailure(InetAddress from)\n            {\n                status.set(false);\n                failedNodes.add(from.getHostAddress());\n                prepareLatch.countDown();\n            }\n        };\n\n        List<UUID> cfIds = new ArrayList<>(columnFamilyStores.size());\n        for (ColumnFamilyStore cfs : columnFamilyStores)\n            cfIds.add(cfs.metadata.cfId);\n\n        for(InetAddress neighbour : endpoints)\n        {\n            PrepareMessage message = new PrepareMessage(parentRepairSession, cfIds, ranges);\n            MessageOut<RepairMessage> msg = message.createMessage();\n            MessagingService.instance().sendRR(msg, neighbour, callback, TimeUnit.HOURS.toMillis(1), true);\n        }\n        try\n        {\n            prepareLatch.await(1, TimeUnit.HOURS);\n        }\n        catch (InterruptedException e)\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString(), e);\n        }\n\n        if (!status.get())\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get positive replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString());\n        }\n\n        return parentRepairSession;\n    }"
        ]
    ],
    "bd46463fbb7d6b0998c837450ce61df13eda041d": [
        [
            "CassandraDaemon::activate()",
            " 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536 -\n 537  \n 538 -\n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  ",
            "    /**\n     * A convenience method to initialize and start the daemon in one shot.\n     */\n    public void activate()\n    {\n        String pidFile = System.getProperty(\"cassandra-pidfile\");\n\n        if (FBUtilities.isWindows())\n        {\n            // We need to adjust the system timer on windows from the default 15ms down to the minimum of 1ms as this\n            // impacts timer intervals, thread scheduling, driver interrupts, etc.\n            WindowsTimer.startTimerPeriod(DatabaseDescriptor.getWindowsTimerInterval());\n        }\n\n        try\n        {\n            try\n            {\n                MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();\n                mbs.registerMBean(new StandardMBean(new NativeAccess(), NativeAccessMBean.class), new ObjectName(MBEAN_NAME));\n            }\n            catch (Exception e)\n            {\n                logger.error(\"error registering MBean {}\", MBEAN_NAME, e);\n                //Allow the server to start even if the bean can't be registered\n            }\n\n            try {\n                DatabaseDescriptor.forceStaticInitialization();\n            } catch (ExceptionInInitializerError e) {\n                throw e.getCause();\n            }\n\n            setup();\n\n            if (pidFile != null)\n            {\n                new File(pidFile).deleteOnExit();\n            }\n\n            if (System.getProperty(\"cassandra-foreground\") == null)\n            {\n                System.out.close();\n                System.err.close();\n            }\n\n            start();\n        }\n        catch (Throwable e)\n        {\n            boolean logStackTrace =\n                    e instanceof ConfigurationException ? ((ConfigurationException)e).logStackTrace : true;\n\n            System.out.println(\"Exception (\" + e.getClass().getName() + \") encountered during startup: \" + e.getMessage());\n\n            if (logStackTrace)\n            {\n                if (runManaged)\n                    logger.error(\"Exception encountered during startup\", e);\n                // try to warn user on stdout too, if we haven't already detached\n                e.printStackTrace();\n                exitOrFail(3, \"Exception encountered during startup\", e);\n            }\n            else\n            {\n                if (runManaged)\n                    logger.error(\"Exception encountered during startup: {}\", e.getMessage());\n                // try to warn user on stdout too, if we haven't already detached\n                System.err.println(e.getMessage());\n                exitOrFail(3, \"Exception encountered during startup: \" + e.getMessage());\n            }\n        }\n    }",
            " 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536 +\n 537 +\n 538  \n 539 +\n 540 +\n 541 +\n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  ",
            "    /**\n     * A convenience method to initialize and start the daemon in one shot.\n     */\n    public void activate()\n    {\n        String pidFile = System.getProperty(\"cassandra-pidfile\");\n\n        if (FBUtilities.isWindows())\n        {\n            // We need to adjust the system timer on windows from the default 15ms down to the minimum of 1ms as this\n            // impacts timer intervals, thread scheduling, driver interrupts, etc.\n            WindowsTimer.startTimerPeriod(DatabaseDescriptor.getWindowsTimerInterval());\n        }\n\n        try\n        {\n            try\n            {\n                MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();\n                mbs.registerMBean(new StandardMBean(new NativeAccess(), NativeAccessMBean.class), new ObjectName(MBEAN_NAME));\n            }\n            catch (Exception e)\n            {\n                logger.error(\"error registering MBean {}\", MBEAN_NAME, e);\n                //Allow the server to start even if the bean can't be registered\n            }\n\n            try\n            {\n                DatabaseDescriptor.forceStaticInitialization();\n            }\n            catch (ExceptionInInitializerError e)\n            {\n                throw e.getCause();\n            }\n\n            setup();\n\n            if (pidFile != null)\n            {\n                new File(pidFile).deleteOnExit();\n            }\n\n            if (System.getProperty(\"cassandra-foreground\") == null)\n            {\n                System.out.close();\n                System.err.close();\n            }\n\n            start();\n        }\n        catch (Throwable e)\n        {\n            boolean logStackTrace =\n                    e instanceof ConfigurationException ? ((ConfigurationException)e).logStackTrace : true;\n\n            System.out.println(\"Exception (\" + e.getClass().getName() + \") encountered during startup: \" + e.getMessage());\n\n            if (logStackTrace)\n            {\n                if (runManaged)\n                    logger.error(\"Exception encountered during startup\", e);\n                // try to warn user on stdout too, if we haven't already detached\n                e.printStackTrace();\n                exitOrFail(3, \"Exception encountered during startup\", e);\n            }\n            else\n            {\n                if (runManaged)\n                    logger.error(\"Exception encountered during startup: {}\", e.getMessage());\n                // try to warn user on stdout too, if we haven't already detached\n                System.err.println(e.getMessage());\n                exitOrFail(3, \"Exception encountered during startup: \" + e.getMessage());\n            }\n        }\n    }"
        ],
        [
            "CassandraDaemon::exitOrFail(int,String)",
            " 671 -\n 672  \n 673  ",
            "    private void exitOrFail(int code, String message) {\n        exitOrFail(code, message, null);\n    }",
            " 675 +\n 676 +\n 677  \n 678  ",
            "    private void exitOrFail(int code, String message)\n    {\n        exitOrFail(code, message, null);\n    }"
        ],
        [
            "CassandraDaemon::setup()",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324 -\n 325 -\n 326 -\n 327 -\n 328 -\n 329 -\n 330 -\n 331 -\n 332 -\n 333 -\n 334 -\n 335 -\n 336 -\n 337 -\n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  ",
            "    /**\n     * This is a hook for concrete daemons to initialize themselves suitably.\n     *\n     * Subclasses should override this to finish the job (listening on ports, etc.)\n     */\n    protected void setup()\n    {\n        // Delete any failed snapshot deletions on Windows - see CASSANDRA-9658\n        if (FBUtilities.isWindows())\n            WindowsFailedSnapshotTracker.deleteOldSnapshots();\n\n        ThreadAwareSecurityManager.install();\n\n        logSystemInfo();\n\n        CLibrary.tryMlockall();\n\n        try\n        {\n            startupChecks.verify();\n        }\n        catch (StartupException e)\n        {\n            exitOrFail(e.returnCode, e.getMessage(), e.getCause());\n        }\n\n        try\n        {\n            if (SystemKeyspace.snapshotOnVersionChange())\n            {\n                SystemKeyspace.migrateDataDirs();\n            }\n        }\n        catch (IOException e)\n        {\n            exitOrFail(3, e.getMessage(), e.getCause());\n        }\n\n        maybeInitJmx();\n\n        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler()\n        {\n            public void uncaughtException(Thread t, Throwable e)\n            {\n                StorageMetrics.exceptions.inc();\n                logger.error(\"Exception in thread {}\", t, e);\n                Tracing.trace(\"Exception in thread {}\", t, e);\n                for (Throwable e2 = e; e2 != null; e2 = e2.getCause())\n                {\n                    JVMStabilityInspector.inspectThrowable(e2);\n\n                    if (e2 instanceof FSError)\n                    {\n                        if (e2 != e) // make sure FSError gets logged exactly once.\n                            logger.error(\"Exception in thread {}\", t, e2);\n                        FileUtils.handleFSError((FSError) e2);\n                    }\n\n                    if (e2 instanceof CorruptSSTableException)\n                    {\n                        if (e2 != e)\n                            logger.error(\"Exception in thread \" + t, e2);\n                        FileUtils.handleCorruptSSTable((CorruptSSTableException) e2);\n                    }\n                }\n            }\n        });\n\n        /*\n         * Migrate pre-3.0 keyspaces, tables, types, functions, and aggregates, to their new 3.0 storage.\n         * We don't (and can't) wait for commit log replay here, but we don't need to - all schema changes force\n         * explicit memtable flushes.\n         */\n        LegacySchemaMigrator.migrate();\n\n        StorageService.instance.populateTokenMetadata();\n\n        // load schema from disk\n        Schema.instance.loadFromDisk();\n\n        // clean up debris in the rest of the keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            // Skip system as we've already cleaned it\n            if (keyspaceName.equals(SystemKeyspace.NAME))\n                continue;\n\n            for (CFMetaData cfm : Schema.instance.getTablesAndViews(keyspaceName))\n                ColumnFamilyStore.scrubDataDirectories(cfm);\n        }\n\n        Keyspace.setInitialized();\n        // initialize keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            if (logger.isDebugEnabled())\n                logger.debug(\"opening keyspace {}\", keyspaceName);\n            // disable auto compaction until commit log replay ends\n            for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())\n            {\n                for (ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    store.disableAutoCompaction();\n                }\n            }\n        }\n\n\n        try\n        {\n            loadRowAndKeyCacheAsync().get();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Error loading key or row cache\", t);\n        }\n\n        try\n        {\n            GCInspector.register();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Unable to start GCInspector (currently only supported on the Sun JVM)\");\n        }\n\n        // replay the log if necessary\n        try\n        {\n            CommitLog.instance.recover();\n        }\n        catch (IOException e)\n        {\n            throw new RuntimeException(e);\n        }\n\n        // migrate any legacy (pre-3.0) hints from system.hints table into the new store\n        new LegacyHintsMigrator(DatabaseDescriptor.getHintsDirectory(), DatabaseDescriptor.getMaxHintsFileSize()).migrate();\n\n        // migrate any legacy (pre-3.0) batch entries from system.batchlog to system.batches (new table format)\n        LegacyBatchlogMigrator.migrate();\n\n        // enable auto compaction\n        for (Keyspace keyspace : Keyspace.all())\n        {\n            for (ColumnFamilyStore cfs : keyspace.getColumnFamilyStores())\n            {\n                for (final ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    if (store.getCompactionStrategyManager().shouldBeEnabled())\n                        store.enableAutoCompaction();\n                }\n            }\n        }\n\n        Runnable viewRebuild = new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                for (Keyspace keyspace : Keyspace.all())\n                {\n                    keyspace.viewManager.buildAllViews();\n                }\n            }\n        };\n\n        ScheduledExecutors.optionalTasks.schedule(viewRebuild, StorageService.RING_DELAY, TimeUnit.MILLISECONDS);\n\n\n        SystemKeyspace.finishStartup();\n\n        // start server internals\n        StorageService.instance.registerDaemon(this);\n        try\n        {\n            StorageService.instance.initServer();\n        }\n        catch (ConfigurationException e)\n        {\n            System.err.println(e.getMessage() + \"\\nFatal configuration error; unable to start server.  See log for stacktrace.\");\n            exitOrFail(1, \"Fatal configuration error\", e);\n        }\n\n        Mx4jTool.maybeLoad();\n\n        // Metrics\n        String metricsReporterConfigFile = System.getProperty(\"cassandra.metricsReporterConfigFile\");\n        if (metricsReporterConfigFile != null)\n        {\n            logger.info(\"Trying to load metrics-reporter-config from file: {}\", metricsReporterConfigFile);\n            try\n            {\n                String reportFileLocation = CassandraDaemon.class.getClassLoader().getResource(metricsReporterConfigFile).getFile();\n                ReporterConfig.loadFromFile(reportFileLocation).enableAll(CassandraMetricsRegistry.Metrics);\n            }\n            catch (Exception e)\n            {\n                logger.warn(\"Failed to load metrics-reporter-config, metric sinks will not be activated\", e);\n            }\n        }\n\n        if (!FBUtilities.getBroadcastAddress().equals(InetAddress.getLoopbackAddress()))\n            waitForGossipToSettle();\n\n        // schedule periodic background compaction task submission. this is simply a backstop against compactions stalling\n        // due to scheduling errors or race conditions\n        ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(ColumnFamilyStore.getBackgroundCompactionTaskSubmitter(), 5, 1, TimeUnit.MINUTES);\n\n        // schedule periodic dumps of table size estimates into SystemKeyspace.SIZE_ESTIMATES_CF\n        // set cassandra.size_recorder_interval to 0 to disable\n        int sizeRecorderInterval = Integer.getInteger(\"cassandra.size_recorder_interval\", 5 * 60);\n        if (sizeRecorderInterval > 0)\n            ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(SizeEstimatesRecorder.instance, 30, sizeRecorderInterval, TimeUnit.SECONDS);\n\n        // Thrift\n        InetAddress rpcAddr = DatabaseDescriptor.getRpcAddress();\n        int rpcPort = DatabaseDescriptor.getRpcPort();\n        int listenBacklog = DatabaseDescriptor.getRpcListenBacklog();\n        thriftServer = new ThriftServer(rpcAddr, rpcPort, listenBacklog);\n\n        // Native transport\n        nativeTransportService = new NativeTransportService();\n\n        completeSetup();\n    }",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340 +\n 341 +\n 342 +\n 343 +\n 344 +\n 345 +\n 346 +\n 347 +\n 348 +\n 349 +\n 350 +\n 351 +\n 352 +\n 353 +\n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  ",
            "    /**\n     * This is a hook for concrete daemons to initialize themselves suitably.\n     *\n     * Subclasses should override this to finish the job (listening on ports, etc.)\n     */\n    protected void setup()\n    {\n        // Delete any failed snapshot deletions on Windows - see CASSANDRA-9658\n        if (FBUtilities.isWindows())\n            WindowsFailedSnapshotTracker.deleteOldSnapshots();\n\n        ThreadAwareSecurityManager.install();\n\n        logSystemInfo();\n\n        CLibrary.tryMlockall();\n\n        try\n        {\n            startupChecks.verify();\n        }\n        catch (StartupException e)\n        {\n            exitOrFail(e.returnCode, e.getMessage(), e.getCause());\n        }\n\n        try\n        {\n            if (SystemKeyspace.snapshotOnVersionChange())\n            {\n                SystemKeyspace.migrateDataDirs();\n            }\n        }\n        catch (IOException e)\n        {\n            exitOrFail(3, e.getMessage(), e.getCause());\n        }\n\n        maybeInitJmx();\n\n        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler()\n        {\n            public void uncaughtException(Thread t, Throwable e)\n            {\n                StorageMetrics.exceptions.inc();\n                logger.error(\"Exception in thread {}\", t, e);\n                Tracing.trace(\"Exception in thread {}\", t, e);\n                for (Throwable e2 = e; e2 != null; e2 = e2.getCause())\n                {\n                    JVMStabilityInspector.inspectThrowable(e2);\n\n                    if (e2 instanceof FSError)\n                    {\n                        if (e2 != e) // make sure FSError gets logged exactly once.\n                            logger.error(\"Exception in thread {}\", t, e2);\n                        FileUtils.handleFSError((FSError) e2);\n                    }\n\n                    if (e2 instanceof CorruptSSTableException)\n                    {\n                        if (e2 != e)\n                            logger.error(\"Exception in thread \" + t, e2);\n                        FileUtils.handleCorruptSSTable((CorruptSSTableException) e2);\n                    }\n                }\n            }\n        });\n\n        /*\n         * Migrate pre-3.0 keyspaces, tables, types, functions, and aggregates, to their new 3.0 storage.\n         * We don't (and can't) wait for commit log replay here, but we don't need to - all schema changes force\n         * explicit memtable flushes.\n         */\n        LegacySchemaMigrator.migrate();\n\n        StorageService.instance.populateTokenMetadata();\n\n        // load schema from disk\n        Schema.instance.loadFromDisk();\n\n        // clean up debris in the rest of the keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            // Skip system as we've already cleaned it\n            if (keyspaceName.equals(SystemKeyspace.NAME))\n                continue;\n\n            for (CFMetaData cfm : Schema.instance.getTablesAndViews(keyspaceName))\n                ColumnFamilyStore.scrubDataDirectories(cfm);\n        }\n\n        Keyspace.setInitialized();\n        // initialize keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            if (logger.isDebugEnabled())\n                logger.debug(\"opening keyspace {}\", keyspaceName);\n            // disable auto compaction until commit log replay ends\n            for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())\n            {\n                for (ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    store.disableAutoCompaction();\n                }\n            }\n        }\n\n\n        try\n        {\n            loadRowAndKeyCacheAsync().get();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Error loading key or row cache\", t);\n        }\n\n        try\n        {\n            GCInspector.register();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Unable to start GCInspector (currently only supported on the Sun JVM)\");\n        }\n\n        // replay the log if necessary\n        try\n        {\n            CommitLog.instance.recover();\n        }\n        catch (IOException e)\n        {\n            throw new RuntimeException(e);\n        }\n\n        // migrate any legacy (pre-3.0) hints from system.hints table into the new store\n        new LegacyHintsMigrator(DatabaseDescriptor.getHintsDirectory(), DatabaseDescriptor.getMaxHintsFileSize()).migrate();\n\n        // migrate any legacy (pre-3.0) batch entries from system.batchlog to system.batches (new table format)\n        LegacyBatchlogMigrator.migrate();\n\n        // enable auto compaction\n        for (Keyspace keyspace : Keyspace.all())\n        {\n            for (ColumnFamilyStore cfs : keyspace.getColumnFamilyStores())\n            {\n                for (final ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    if (store.getCompactionStrategyManager().shouldBeEnabled())\n                        store.enableAutoCompaction();\n                }\n            }\n        }\n\n        Runnable viewRebuild = new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                for (Keyspace keyspace : Keyspace.all())\n                {\n                    keyspace.viewManager.buildAllViews();\n                }\n            }\n        };\n\n        ScheduledExecutors.optionalTasks.schedule(viewRebuild, StorageService.RING_DELAY, TimeUnit.MILLISECONDS);\n\n\n        SystemKeyspace.finishStartup();\n\n        // Metrics\n        String metricsReporterConfigFile = System.getProperty(\"cassandra.metricsReporterConfigFile\");\n        if (metricsReporterConfigFile != null)\n        {\n            logger.info(\"Trying to load metrics-reporter-config from file: {}\", metricsReporterConfigFile);\n            try\n            {\n                String reportFileLocation = CassandraDaemon.class.getClassLoader().getResource(metricsReporterConfigFile).getFile();\n                ReporterConfig.loadFromFile(reportFileLocation).enableAll(CassandraMetricsRegistry.Metrics);\n            }\n            catch (Exception e)\n            {\n                logger.warn(\"Failed to load metrics-reporter-config, metric sinks will not be activated\", e);\n            }\n        }\n\n        // start server internals\n        StorageService.instance.registerDaemon(this);\n        try\n        {\n            StorageService.instance.initServer();\n        }\n        catch (ConfigurationException e)\n        {\n            System.err.println(e.getMessage() + \"\\nFatal configuration error; unable to start server.  See log for stacktrace.\");\n            exitOrFail(1, \"Fatal configuration error\", e);\n        }\n\n        Mx4jTool.maybeLoad();\n\n        if (!FBUtilities.getBroadcastAddress().equals(InetAddress.getLoopbackAddress()))\n            waitForGossipToSettle();\n\n        // schedule periodic background compaction task submission. this is simply a backstop against compactions stalling\n        // due to scheduling errors or race conditions\n        ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(ColumnFamilyStore.getBackgroundCompactionTaskSubmitter(), 5, 1, TimeUnit.MINUTES);\n\n        // schedule periodic dumps of table size estimates into SystemKeyspace.SIZE_ESTIMATES_CF\n        // set cassandra.size_recorder_interval to 0 to disable\n        int sizeRecorderInterval = Integer.getInteger(\"cassandra.size_recorder_interval\", 5 * 60);\n        if (sizeRecorderInterval > 0)\n            ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(SizeEstimatesRecorder.instance, 30, sizeRecorderInterval, TimeUnit.SECONDS);\n\n        // Thrift\n        InetAddress rpcAddr = DatabaseDescriptor.getRpcAddress();\n        int rpcPort = DatabaseDescriptor.getRpcPort();\n        int listenBacklog = DatabaseDescriptor.getRpcListenBacklog();\n        thriftServer = new ThriftServer(rpcAddr, rpcPort, listenBacklog);\n\n        // Native transport\n        nativeTransportService = new NativeTransportService();\n\n        completeSetup();\n    }"
        ],
        [
            "CassandraDaemon::deactivate()",
            " 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611 -\n 612  \n 613  \n 614  ",
            "    /**\n     * A convenience method to stop and destroy the daemon in one shot.\n     */\n    public void deactivate()\n    {\n        stop();\n        destroy();\n        // completely shut down cassandra\n        if(!runManaged) {\n            System.exit(0);\n        }\n    }",
            " 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614 +\n 615 +\n 616  \n 617  \n 618  ",
            "    /**\n     * A convenience method to stop and destroy the daemon in one shot.\n     */\n    public void deactivate()\n    {\n        stop();\n        destroy();\n        // completely shut down cassandra\n        if(!runManaged)\n        {\n            System.exit(0);\n        }\n    }"
        ],
        [
            "CassandraDaemon::exitOrFail(int,String,Throwable)",
            " 675 -\n 676 -\n 677 -\n 678 -\n 679 -\n 680 -\n 681 -\n 682 -\n 683 -\n 684 -\n 685  ",
            "    private void exitOrFail(int code, String message, Throwable cause) {\n            if(runManaged) {\n                RuntimeException t = cause!=null ? new RuntimeException(message, cause) : new RuntimeException(message);\n                throw t;\n            }\n            else {\n                logger.error(message, cause);\n                System.exit(code);\n            }\n\n        }",
            " 680 +\n 681 +\n 682 +\n 683 +\n 684 +\n 685 +\n 686  \n 687 +\n 688 +\n 689 +\n 690 +\n 691 +\n 692 +",
            "    private void exitOrFail(int code, String message, Throwable cause)\n    {\n        if (runManaged)\n        {\n            RuntimeException t = cause!=null ? new RuntimeException(message, cause) : new RuntimeException(message);\n            throw t;\n        }\n        else\n        {\n            logger.error(message, cause);\n            System.exit(code);\n        }\n    }"
        ]
    ],
    "d766f4fb20af4914b54420e22af0de909eb180ed": [
        [
            "CQLSSTableWriterTest::testForbidCounterUpdates()",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161 -\n 162  \n 163  ",
            "    @Test(expected = IllegalArgumentException.class)\n    public void testForbidCounterUpdates() throws Exception\n    {\n        String KS = \"cql_keyspace\";\n        String TABLE = \"counter1\";\n\n        File tempdir = Files.createTempDir();\n        File dataDir = new File(tempdir.getAbsolutePath() + File.separator + KS + File.separator + TABLE);\n        assert dataDir.mkdirs();\n\n        String schema = \"CREATE TABLE cql_keyspace.counter1 (\" +\n                        \"  my_id int, \" +\n                        \"  my_counter counter, \" +\n                        \"  PRIMARY KEY (my_id)\" +\n                        \")\";\n        String insert = String.format(\"UPDATE cql_keyspace.counter1 SET my_counter = my_counter - ? WHERE my_id = ?\");\n        CQLSSTableWriter.builder().inDirectory(dataDir)\n                        .forTable(schema)\n                        .withPartitioner(StorageService.instance.getPartitioner())\n                        .using(insert).build();\n    }",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161 +\n 162  \n 163  ",
            "    @Test(expected = IllegalArgumentException.class)\n    public void testForbidCounterUpdates() throws Exception\n    {\n        String KS = \"cql_keyspace\";\n        String TABLE = \"counter1\";\n\n        File tempdir = Files.createTempDir();\n        File dataDir = new File(tempdir.getAbsolutePath() + File.separator + KS + File.separator + TABLE);\n        assert dataDir.mkdirs();\n\n        String schema = \"CREATE TABLE cql_keyspace.counter1 (\" +\n                        \"  my_id int, \" +\n                        \"  my_counter counter, \" +\n                        \"  PRIMARY KEY (my_id)\" +\n                        \")\";\n        String insert = String.format(\"UPDATE cql_keyspace.counter1 SET my_counter = my_counter - ? WHERE my_id = ?\");\n        CQLSSTableWriter.builder().inDirectory(dataDir)\n                        .forTable(schema)\n                        .withPartitioner(Murmur3Partitioner.instance)\n                        .using(insert).build();\n    }"
        ]
    ],
    "ebd0aaefe54d8a1349a54d904831e1d9e5e812bf": [
        [
            "CompactionManager::performAnticompaction(ColumnFamilyStore,Collection,Refs,LifecycleTransaction,long,UUID,UUID)",
            " 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631 -\n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  ",
            "    /**\n     * Make sure the {validatedForRepair} are marked for compaction before calling this.\n     *\n     * Caller must reference the validatedForRepair sstables (via ParentRepairSession.getActiveRepairedSSTableRefs(..)).\n     *\n     * @param cfs\n     * @param ranges Ranges that the repair was carried out on\n     * @param validatedForRepair SSTables containing the repaired ranges. Should be referenced before passing them.\n     * @param parentRepairSession parent repair session ID\n     * @throws InterruptedException\n     * @throws IOException\n     */\n    public void performAnticompaction(ColumnFamilyStore cfs,\n                                      Collection<Range<Token>> ranges,\n                                      Refs<SSTableReader> validatedForRepair,\n                                      LifecycleTransaction txn,\n                                      long repairedAt,\n                                      UUID pendingRepair,\n                                      UUID parentRepairSession) throws InterruptedException, IOException\n    {\n        ActiveRepairService.ParentRepairSession prs = ActiveRepairService.instance.getParentRepairSession(parentRepairSession);\n        Preconditions.checkArgument(!prs.isPreview(), \"Cannot anticompact for previews\");\n\n        logger.info(\"{} Starting anticompaction for {}.{} on {}/{} sstables\", PreviewKind.NONE.logPrefix(parentRepairSession), cfs.keyspace.getName(), cfs.getTableName(), validatedForRepair.size(), cfs.getLiveSSTables());\n        logger.trace(\"{} Starting anticompaction for ranges {}\", PreviewKind.NONE.logPrefix(parentRepairSession), ranges);\n        Set<SSTableReader> sstables = new HashSet<>(validatedForRepair);\n        Set<SSTableReader> mutatedRepairStatuses = new HashSet<>();\n        // we should only notify that repair status changed if it actually did:\n        Set<SSTableReader> mutatedRepairStatusToNotify = new HashSet<>();\n        Map<SSTableReader, Boolean> wasRepairedBefore = new HashMap<>();\n        for (SSTableReader sstable : sstables)\n            wasRepairedBefore.put(sstable, sstable.isRepaired());\n\n        Set<SSTableReader> nonAnticompacting = new HashSet<>();\n\n        Iterator<SSTableReader> sstableIterator = sstables.iterator();\n        try\n        {\n            List<Range<Token>> normalizedRanges = Range.normalize(ranges);\n\n            while (sstableIterator.hasNext())\n            {\n                SSTableReader sstable = sstableIterator.next();\n\n                Range<Token> sstableRange = new Range<>(sstable.first.getToken(), sstable.last.getToken());\n\n                boolean shouldAnticompact = false;\n\n                for (Range<Token> r : normalizedRanges)\n                {\n                    if (r.contains(sstableRange))\n                    {\n                        logger.info(\"{} SSTable {} fully contained in range {}, mutating repairedAt instead of anticompacting\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, r);\n                        sstable.descriptor.getMetadataSerializer().mutateRepaired(sstable.descriptor, repairedAt, pendingRepair);\n                        sstable.reloadSSTableMetadata();\n                        mutatedRepairStatuses.add(sstable);\n                        if (!wasRepairedBefore.get(sstable))\n                            mutatedRepairStatusToNotify.add(sstable);\n                        sstableIterator.remove();\n                        shouldAnticompact = true;\n                        break;\n                    }\n                    else if (sstableRange.intersects(r))\n                    {\n                        logger.info(\"{} SSTable {} ({}) will be anticompacted on range {}\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, r);\n                        shouldAnticompact = true;\n                    }\n                }\n\n                if (!shouldAnticompact)\n                {\n                    logger.info(\"{} SSTable {} ({}) does not intersect repaired ranges {}, not touching repairedAt.\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, normalizedRanges);\n                    nonAnticompacting.add(sstable);\n                    sstableIterator.remove();\n                }\n            }\n            cfs.metric.bytesMutatedAnticompaction.inc(SSTableReader.getTotalBytes(mutatedRepairStatuses));\n            cfs.getTracker().notifySSTableRepairedStatusChanged(mutatedRepairStatusToNotify);\n            txn.cancel(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            validatedForRepair.release(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            assert txn.originals().equals(sstables);\n            if (!sstables.isEmpty())\n                doAntiCompaction(cfs, ranges, txn, repairedAt, pendingRepair);\n            txn.finish();\n        }\n        finally\n        {\n            validatedForRepair.release();\n            txn.close();\n        }\n\n        logger.info(\"{} Completed anticompaction successfully\", PreviewKind.NONE.logPrefix(parentRepairSession));\n    }",
            " 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631 +\n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  ",
            "    /**\n     * Make sure the {validatedForRepair} are marked for compaction before calling this.\n     *\n     * Caller must reference the validatedForRepair sstables (via ParentRepairSession.getActiveRepairedSSTableRefs(..)).\n     *\n     * @param cfs\n     * @param ranges Ranges that the repair was carried out on\n     * @param validatedForRepair SSTables containing the repaired ranges. Should be referenced before passing them.\n     * @param parentRepairSession parent repair session ID\n     * @throws InterruptedException\n     * @throws IOException\n     */\n    public void performAnticompaction(ColumnFamilyStore cfs,\n                                      Collection<Range<Token>> ranges,\n                                      Refs<SSTableReader> validatedForRepair,\n                                      LifecycleTransaction txn,\n                                      long repairedAt,\n                                      UUID pendingRepair,\n                                      UUID parentRepairSession) throws InterruptedException, IOException\n    {\n        ActiveRepairService.ParentRepairSession prs = ActiveRepairService.instance.getParentRepairSession(parentRepairSession);\n        Preconditions.checkArgument(!prs.isPreview(), \"Cannot anticompact for previews\");\n\n        logger.info(\"{} Starting anticompaction for {}.{} on {}/{} sstables\", PreviewKind.NONE.logPrefix(parentRepairSession), cfs.keyspace.getName(), cfs.getTableName(), validatedForRepair.size(), cfs.getLiveSSTables().size());\n        logger.trace(\"{} Starting anticompaction for ranges {}\", PreviewKind.NONE.logPrefix(parentRepairSession), ranges);\n        Set<SSTableReader> sstables = new HashSet<>(validatedForRepair);\n        Set<SSTableReader> mutatedRepairStatuses = new HashSet<>();\n        // we should only notify that repair status changed if it actually did:\n        Set<SSTableReader> mutatedRepairStatusToNotify = new HashSet<>();\n        Map<SSTableReader, Boolean> wasRepairedBefore = new HashMap<>();\n        for (SSTableReader sstable : sstables)\n            wasRepairedBefore.put(sstable, sstable.isRepaired());\n\n        Set<SSTableReader> nonAnticompacting = new HashSet<>();\n\n        Iterator<SSTableReader> sstableIterator = sstables.iterator();\n        try\n        {\n            List<Range<Token>> normalizedRanges = Range.normalize(ranges);\n\n            while (sstableIterator.hasNext())\n            {\n                SSTableReader sstable = sstableIterator.next();\n\n                Range<Token> sstableRange = new Range<>(sstable.first.getToken(), sstable.last.getToken());\n\n                boolean shouldAnticompact = false;\n\n                for (Range<Token> r : normalizedRanges)\n                {\n                    if (r.contains(sstableRange))\n                    {\n                        logger.info(\"{} SSTable {} fully contained in range {}, mutating repairedAt instead of anticompacting\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, r);\n                        sstable.descriptor.getMetadataSerializer().mutateRepaired(sstable.descriptor, repairedAt, pendingRepair);\n                        sstable.reloadSSTableMetadata();\n                        mutatedRepairStatuses.add(sstable);\n                        if (!wasRepairedBefore.get(sstable))\n                            mutatedRepairStatusToNotify.add(sstable);\n                        sstableIterator.remove();\n                        shouldAnticompact = true;\n                        break;\n                    }\n                    else if (sstableRange.intersects(r))\n                    {\n                        logger.info(\"{} SSTable {} ({}) will be anticompacted on range {}\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, r);\n                        shouldAnticompact = true;\n                    }\n                }\n\n                if (!shouldAnticompact)\n                {\n                    logger.info(\"{} SSTable {} ({}) does not intersect repaired ranges {}, not touching repairedAt.\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, normalizedRanges);\n                    nonAnticompacting.add(sstable);\n                    sstableIterator.remove();\n                }\n            }\n            cfs.metric.bytesMutatedAnticompaction.inc(SSTableReader.getTotalBytes(mutatedRepairStatuses));\n            cfs.getTracker().notifySSTableRepairedStatusChanged(mutatedRepairStatusToNotify);\n            txn.cancel(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            validatedForRepair.release(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            assert txn.originals().equals(sstables);\n            if (!sstables.isEmpty())\n                doAntiCompaction(cfs, ranges, txn, repairedAt, pendingRepair);\n            txn.finish();\n        }\n        finally\n        {\n            validatedForRepair.release();\n            txn.close();\n        }\n\n        logger.info(\"{} Completed anticompaction successfully\", PreviewKind.NONE.logPrefix(parentRepairSession));\n    }"
        ]
    ],
    "6a1b1f26b7174e8c9bf86a96514ab626ce2a4117": [
        [
            "StressAction::run()",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  ",
            "    public void run()\n    {\n        // creating keyspace and column families\n        settings.maybeCreateKeyspaces();\n\n        output.println(\"Sleeping 2s...\");\n        Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);\n\n        if (!settings.command.noWarmup)\n            warmup(settings.command.getFactory(settings));\n        if (settings.command.truncate == SettingsCommand.TruncateWhen.ONCE)\n            settings.command.truncateTables(settings);\n\n        // TODO : move this to a new queue wrapper that gates progress based on a poisson (or configurable) distribution\n        RateLimiter rateLimiter = null;\n        if (settings.rate.opRateTargetPerSecond > 0)\n            rateLimiter = RateLimiter.create(settings.rate.opRateTargetPerSecond);\n\n        boolean success;\n        if (settings.rate.minThreads > 0)\n            success = runMulti(settings.rate.auto, rateLimiter);\n        else\n            success = null != run(settings.command.getFactory(settings), settings.rate.threadCount, settings.command.count,\n                                  settings.command.duration, rateLimiter, settings.command.durationUnits, output, false);\n\n        if (success)\n            output.println(\"END\");\n        else\n            output.println(\"FAILURE\");\n\n        settings.disconnect();\n    }",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57 +\n  58 +\n  59 +\n  60 +\n  61 +\n  62 +\n  63 +\n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  ",
            "    public void run()\n    {\n        // creating keyspace and column families\n        settings.maybeCreateKeyspaces();\n\n        if (settings.command.count == 0)\n        {\n            output.println(\"N=0: SCHEMA CREATED, NOTHING ELSE DONE.\");\n            settings.disconnect();\n            return;\n        }\n\n        output.println(\"Sleeping 2s...\");\n        Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);\n\n        if (!settings.command.noWarmup)\n            warmup(settings.command.getFactory(settings));\n        if (settings.command.truncate == SettingsCommand.TruncateWhen.ONCE)\n            settings.command.truncateTables(settings);\n\n        // TODO : move this to a new queue wrapper that gates progress based on a poisson (or configurable) distribution\n        RateLimiter rateLimiter = null;\n        if (settings.rate.opRateTargetPerSecond > 0)\n            rateLimiter = RateLimiter.create(settings.rate.opRateTargetPerSecond);\n\n        boolean success;\n        if (settings.rate.minThreads > 0)\n            success = runMulti(settings.rate.auto, rateLimiter);\n        else\n            success = null != run(settings.command.getFactory(settings), settings.rate.threadCount, settings.command.count,\n                                  settings.command.duration, rateLimiter, settings.command.durationUnits, output, false);\n\n        if (success)\n            output.println(\"END\");\n        else\n            output.println(\"FAILURE\");\n\n        settings.disconnect();\n    }"
        ],
        [
            "StressAction::warmup(OpDistributionFactory)",
            "  86  \n  87  \n  88  \n  89  \n  90 -\n  91 -\n  92 -\n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  ",
            "    private void warmup(OpDistributionFactory operations)\n    {\n        PrintStream warmupOutput = new PrintStream(new OutputStream() { @Override public void write(int b) throws IOException { } } );\n        // do 25% of iterations as warmup but no more than 50k (by default hotspot compiles methods after 10k invocations)\n        int iterations = (settings.command.count > 0\n                         ? Math.min(50000, (int)(settings.command.count * 0.25))\n                         : 50000) * settings.node.nodes.size();\n        int threads = 100;\n\n        if (settings.rate.maxThreads > 0)\n            threads = Math.min(threads, settings.rate.maxThreads);\n        if (settings.rate.threadCount > 0)\n            threads = Math.min(threads, settings.rate.threadCount);\n\n        for (OpDistributionFactory single : operations.each())\n        {\n            // we need to warm up all the nodes in the cluster ideally, but we may not be the only stress instance;\n            // so warm up all the nodes we're speaking to only.\n            output.println(String.format(\"Warming up %s with %d iterations...\", single.desc(), iterations));\n            run(single, threads, iterations, 0, null, null, warmupOutput, true);\n        }\n    }",
            "  93  \n  94  \n  95  \n  96  \n  97 +\n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  ",
            "    private void warmup(OpDistributionFactory operations)\n    {\n        PrintStream warmupOutput = new PrintStream(new OutputStream() { @Override public void write(int b) throws IOException { } } );\n        // do 25% of iterations as warmup but no more than 50k (by default hotspot compiles methods after 10k invocations)\n        int iterations = Math.min(50000, (int) (settings.command.count * 0.25)) * settings.node.nodes.size();\n        int threads = 100;\n\n        if (settings.rate.maxThreads > 0)\n            threads = Math.min(threads, settings.rate.maxThreads);\n        if (settings.rate.threadCount > 0)\n            threads = Math.min(threads, settings.rate.threadCount);\n\n        for (OpDistributionFactory single : operations.each())\n        {\n            // we need to warm up all the nodes in the cluster ideally, but we may not be the only stress instance;\n            // so warm up all the nodes we're speaking to only.\n            output.println(String.format(\"Warming up %s with %d iterations...\", single.desc(), iterations));\n            run(single, threads, iterations, 0, null, null, warmupOutput, true);\n        }\n    }"
        ]
    ],
    "5d4335e8f8affc738cc72eacec2f01a8ea18a5b3": [
        [
            "InboundHandshakeHandler::handleStart(ChannelHandlerContext,ByteBuf)",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169 -\n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  ",
            "    /**\n     * Handles receiving the first message in the internode messaging handshake protocol. If the sender's protocol version\n     * is accepted, we respond with the second message of the handshake protocol.\n     */\n    @VisibleForTesting\n    State handleStart(ChannelHandlerContext ctx, ByteBuf in) throws IOException\n    {\n        FirstHandshakeMessage msg = FirstHandshakeMessage.maybeDecode(in);\n        if (msg == null)\n            return State.START;\n\n        logger.trace(\"received first handshake message from peer {}, message = {}\", ctx.channel().remoteAddress(), msg);\n        version = msg.messagingVersion;\n\n        if (msg.mode == NettyFactory.Mode.STREAMING)\n        {\n            // streaming connections are per-session and have a fixed version.  we can't do anything with a wrong-version stream connection, so drop it.\n            if (version != StreamMessage.CURRENT_VERSION)\n            {\n                logger.warn(\"Received stream using protocol version %d (my version %d). Terminating connection\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            setupStreamingPipeline(ctx, version);\n            return State.HANDSHAKE_COMPLETE;\n        }\n        else\n        {\n            if (version < MessagingService.VERSION_30)\n            {\n                logger.error(\"Unable to read obsolete message version {} from {}; The earliest version supported is 3.0.0\", version, ctx.channel().remoteAddress());\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            logger.trace(\"Connection version {} from {}\", version, ctx.channel().remoteAddress());\n            compressed = msg.compressionEnabled;\n\n            // if this version is < the MS version the other node is trying\n            // to connect with, the other node will disconnect\n            ctx.writeAndFlush(new SecondHandshakeMessage(MessagingService.current_version).encode(ctx.alloc()))\n               .addListener(ChannelFutureListener.CLOSE_ON_FAILURE);\n\n            // outbound side will reconnect to change the version\n            if (version > MessagingService.current_version)\n            {\n                logger.info(\"peer wants to use a messaging version higher ({}) than what this node supports ({})\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            long timeout = TimeUnit.MILLISECONDS.toNanos(DatabaseDescriptor.getRpcTimeout());\n            handshakeTimeout = ctx.executor().schedule(() -> failHandshake(ctx), timeout, TimeUnit.MILLISECONDS);\n            return State.AWAIT_MESSAGING_START_RESPONSE;\n        }\n    }",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169 +\n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  ",
            "    /**\n     * Handles receiving the first message in the internode messaging handshake protocol. If the sender's protocol version\n     * is accepted, we respond with the second message of the handshake protocol.\n     */\n    @VisibleForTesting\n    State handleStart(ChannelHandlerContext ctx, ByteBuf in) throws IOException\n    {\n        FirstHandshakeMessage msg = FirstHandshakeMessage.maybeDecode(in);\n        if (msg == null)\n            return State.START;\n\n        logger.trace(\"received first handshake message from peer {}, message = {}\", ctx.channel().remoteAddress(), msg);\n        version = msg.messagingVersion;\n\n        if (msg.mode == NettyFactory.Mode.STREAMING)\n        {\n            // streaming connections are per-session and have a fixed version.  we can't do anything with a wrong-version stream connection, so drop it.\n            if (version != StreamMessage.CURRENT_VERSION)\n            {\n                logger.warn(\"Received stream using protocol version {} (my version {}). Terminating connection\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            setupStreamingPipeline(ctx, version);\n            return State.HANDSHAKE_COMPLETE;\n        }\n        else\n        {\n            if (version < MessagingService.VERSION_30)\n            {\n                logger.error(\"Unable to read obsolete message version {} from {}; The earliest version supported is 3.0.0\", version, ctx.channel().remoteAddress());\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            logger.trace(\"Connection version {} from {}\", version, ctx.channel().remoteAddress());\n            compressed = msg.compressionEnabled;\n\n            // if this version is < the MS version the other node is trying\n            // to connect with, the other node will disconnect\n            ctx.writeAndFlush(new SecondHandshakeMessage(MessagingService.current_version).encode(ctx.alloc()))\n               .addListener(ChannelFutureListener.CLOSE_ON_FAILURE);\n\n            // outbound side will reconnect to change the version\n            if (version > MessagingService.current_version)\n            {\n                logger.info(\"peer wants to use a messaging version higher ({}) than what this node supports ({})\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            long timeout = TimeUnit.MILLISECONDS.toNanos(DatabaseDescriptor.getRpcTimeout());\n            handshakeTimeout = ctx.executor().schedule(() -> failHandshake(ctx), timeout, TimeUnit.MILLISECONDS);\n            return State.AWAIT_MESSAGING_START_RESPONSE;\n        }\n    }"
        ],
        [
            "DateTieredCompactionStrategyOptions::DateTieredCompactionStrategyOptions(Map)",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57 -\n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "    public DateTieredCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution.toString());\n        optionValue = options.get(MAX_SSTABLE_AGE_KEY);\n        double fractionalDays = optionValue == null ? DEFAULT_MAX_SSTABLE_AGE_DAYS : Double.parseDouble(optionValue);\n        maxSSTableAge = Math.round(fractionalDays * timestampResolution.convert(1, TimeUnit.DAYS));\n        optionValue = options.get(BASE_TIME_KEY);\n        baseTime = timestampResolution.convert(optionValue == null ? DEFAULT_BASE_TIME_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(MAX_WINDOW_SIZE_KEY);\n        maxWindowSize = timestampResolution.convert(optionValue == null ? DEFAULT_MAX_WINDOW_SIZE_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n    }",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57 +\n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "    public DateTieredCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution);\n        optionValue = options.get(MAX_SSTABLE_AGE_KEY);\n        double fractionalDays = optionValue == null ? DEFAULT_MAX_SSTABLE_AGE_DAYS : Double.parseDouble(optionValue);\n        maxSSTableAge = Math.round(fractionalDays * timestampResolution.convert(1, TimeUnit.DAYS));\n        optionValue = options.get(BASE_TIME_KEY);\n        baseTime = timestampResolution.convert(optionValue == null ? DEFAULT_BASE_TIME_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(MAX_WINDOW_SIZE_KEY);\n        maxWindowSize = timestampResolution.convert(optionValue == null ? DEFAULT_MAX_WINDOW_SIZE_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n    }"
        ],
        [
            "DynamicCompositeType::validateComparator(int,ByteBuffer)",
            " 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202 -\n 203  \n 204 -\n 205  \n 206 -\n 207 -\n 208  \n 209  \n 210  \n 211 -\n 212  \n 213 -\n 214 -\n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  ",
            "    protected AbstractType<?> validateComparator(int i, ByteBuffer bb) throws MarshalException\n    {\n        AbstractType<?> comparator = null;\n        if (bb.remaining() < 2)\n            throw new MarshalException(\"Not enough bytes to header of the comparator part of component \" + i);\n        int header = ByteBufferUtil.readShortLength(bb);\n        if ((header & 0x8000) == 0)\n        {\n            if (bb.remaining() < header)\n                throw new MarshalException(\"Not enough bytes to read comparator name of component \" + i);\n\n            ByteBuffer value = ByteBufferUtil.readBytes(bb, header);\n            String valueStr = null;\n            try\n            {\n                valueStr = ByteBufferUtil.string(value);\n                comparator = TypeParser.parse(valueStr);\n            }\n            catch (CharacterCodingException ce) \n            {\n                // ByteBufferUtil.string failed. \n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed with [{}] when decoding the byte buffer in ByteBufferUtil.string()\", \n                   ce.toString());\n            }\n            catch (Exception e)\n            {\n                // parse failed. \n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed to parse value string \\\"{}\\\" with exception: [{}]\", \n                   valueStr, e.toString());\n            }\n        }\n        else\n        {\n            comparator = aliases.get((byte)(header & 0xFF));\n        }\n\n        if (comparator == null)\n            throw new MarshalException(\"Cannot find comparator for component \" + i);\n        else\n            return comparator;\n    }",
            " 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202 +\n 203  \n 204 +\n 205  \n 206 +\n 207 +\n 208  \n 209  \n 210  \n 211 +\n 212  \n 213 +\n 214 +\n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  ",
            "    protected AbstractType<?> validateComparator(int i, ByteBuffer bb) throws MarshalException\n    {\n        AbstractType<?> comparator = null;\n        if (bb.remaining() < 2)\n            throw new MarshalException(\"Not enough bytes to header of the comparator part of component \" + i);\n        int header = ByteBufferUtil.readShortLength(bb);\n        if ((header & 0x8000) == 0)\n        {\n            if (bb.remaining() < header)\n                throw new MarshalException(\"Not enough bytes to read comparator name of component \" + i);\n\n            ByteBuffer value = ByteBufferUtil.readBytes(bb, header);\n            String valueStr = null;\n            try\n            {\n                valueStr = ByteBufferUtil.string(value);\n                comparator = TypeParser.parse(valueStr);\n            }\n            catch (CharacterCodingException ce)\n            {\n                // ByteBufferUtil.string failed.\n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed with [{}] when decoding the byte buffer in ByteBufferUtil.string()\",\n                   ce);\n            }\n            catch (Exception e)\n            {\n                // parse failed.\n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed to parse value string \\\"{}\\\" with exception: [{}]\",\n                   valueStr, e);\n            }\n        }\n        else\n        {\n            comparator = aliases.get((byte)(header & 0xFF));\n        }\n\n        if (comparator == null)\n            throw new MarshalException(\"Cannot find comparator for component \" + i);\n        else\n            return comparator;\n    }"
        ],
        [
            "InboundHandshakeHandler::decode(ChannelHandlerContext,ByteBuf,List)",
            "  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94 -\n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  ",
            "    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)\n    {\n        try\n        {\n            if (!hasAuthenticated)\n            {\n                logSecureSocketDetails(ctx);\n                if (!handleAuthenticate(ctx.channel().remoteAddress(), ctx))\n                    return;\n            }\n\n            switch (state)\n            {\n                case START:\n                    state = handleStart(ctx, in);\n                    break;\n                case AWAIT_MESSAGING_START_RESPONSE:\n                    state = handleMessagingStartResponse(ctx, in);\n                    break;\n                case HANDSHAKE_FAIL:\n                    throw new IllegalStateException(\"channel should be closed after determining the handshake failed with peer: \" + ctx.channel().remoteAddress());\n                default:\n                    logger.error(\"unhandled state: \" + state);\n                    state = State.HANDSHAKE_FAIL;\n                    ctx.close();\n            }\n        }\n        catch (Exception e)\n        {\n            logger.error(\"unexpected error while negotiating internode messaging handshake\", e);\n            state = State.HANDSHAKE_FAIL;\n            ctx.close();\n        }\n    }",
            "  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94 +\n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  ",
            "    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)\n    {\n        try\n        {\n            if (!hasAuthenticated)\n            {\n                logSecureSocketDetails(ctx);\n                if (!handleAuthenticate(ctx.channel().remoteAddress(), ctx))\n                    return;\n            }\n\n            switch (state)\n            {\n                case START:\n                    state = handleStart(ctx, in);\n                    break;\n                case AWAIT_MESSAGING_START_RESPONSE:\n                    state = handleMessagingStartResponse(ctx, in);\n                    break;\n                case HANDSHAKE_FAIL:\n                    throw new IllegalStateException(\"channel should be closed after determining the handshake failed with peer: \" + ctx.channel().remoteAddress());\n                default:\n                    logger.error(\"unhandled state: {}\", state);\n                    state = State.HANDSHAKE_FAIL;\n                    ctx.close();\n            }\n        }\n        catch (Exception e)\n        {\n            logger.error(\"unexpected error while negotiating internode messaging handshake\", e);\n            state = State.HANDSHAKE_FAIL;\n            ctx.close();\n        }\n    }"
        ],
        [
            "LogTransaction::delete(File)",
            " 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215 -\n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  ",
            "    static void delete(File file)\n    {\n        try\n        {\n            if (logger.isTraceEnabled())\n                logger.trace(\"Deleting {}\", file);\n\n            Files.delete(file.toPath());\n        }\n        catch (NoSuchFileException e)\n        {\n            logger.error(\"Unable to delete {} as it does not exist, see debug log file for stack trace\", file);\n            if (logger.isDebugEnabled())\n            {\n                ByteArrayOutputStream baos = new ByteArrayOutputStream();\n                try (PrintStream ps = new PrintStream(baos))\n                {\n                    e.printStackTrace(ps);\n                }\n                logger.debug(\"Unable to delete {} as it does not exist, stack trace:\\n {}\", file, baos.toString());\n            }\n        }\n        catch (IOException e)\n        {\n            logger.error(\"Unable to delete {}\", file, e);\n            throw new RuntimeException(e);\n        }\n    }",
            " 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215 +\n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  ",
            "    static void delete(File file)\n    {\n        try\n        {\n            if (logger.isTraceEnabled())\n                logger.trace(\"Deleting {}\", file);\n\n            Files.delete(file.toPath());\n        }\n        catch (NoSuchFileException e)\n        {\n            logger.error(\"Unable to delete {} as it does not exist, see debug log file for stack trace\", file);\n            if (logger.isDebugEnabled())\n            {\n                ByteArrayOutputStream baos = new ByteArrayOutputStream();\n                try (PrintStream ps = new PrintStream(baos))\n                {\n                    e.printStackTrace(ps);\n                }\n                logger.debug(\"Unable to delete {} as it does not exist, stack trace:\\n {}\", file, baos);\n            }\n        }\n        catch (IOException e)\n        {\n            logger.error(\"Unable to delete {}\", file, e);\n            throw new RuntimeException(e);\n        }\n    }"
        ],
        [
            "TimeWindowCompactionStrategyOptions::TimeWindowCompactionStrategyOptions(Map)",
            "  61  \n  62  \n  63  \n  64  \n  65  \n  66 -\n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  ",
            "    public TimeWindowCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution.toString());\n\n        optionValue = options.get(COMPACTION_WINDOW_UNIT_KEY);\n        sstableWindowUnit = optionValue == null ? DEFAULT_COMPACTION_WINDOW_UNIT : TimeUnit.valueOf(optionValue);\n\n        optionValue = options.get(COMPACTION_WINDOW_SIZE_KEY);\n        sstableWindowSize = optionValue == null ? DEFAULT_COMPACTION_WINDOW_SIZE : Integer.parseInt(optionValue);\n\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n\n        optionValue = options.get(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_KEY);\n        ignoreOverlaps = optionValue == null ? DEFAULT_UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION : (Boolean.getBoolean(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_PROPERTY) && Boolean.parseBoolean(optionValue));\n\n        stcsOptions = new SizeTieredCompactionStrategyOptions(options);\n    }",
            "  61  \n  62  \n  63  \n  64  \n  65  \n  66 +\n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  ",
            "    public TimeWindowCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution);\n\n        optionValue = options.get(COMPACTION_WINDOW_UNIT_KEY);\n        sstableWindowUnit = optionValue == null ? DEFAULT_COMPACTION_WINDOW_UNIT : TimeUnit.valueOf(optionValue);\n\n        optionValue = options.get(COMPACTION_WINDOW_SIZE_KEY);\n        sstableWindowSize = optionValue == null ? DEFAULT_COMPACTION_WINDOW_SIZE : Integer.parseInt(optionValue);\n\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n\n        optionValue = options.get(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_KEY);\n        ignoreOverlaps = optionValue == null ? DEFAULT_UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION : (Boolean.getBoolean(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_PROPERTY) && Boolean.parseBoolean(optionValue));\n\n        stcsOptions = new SizeTieredCompactionStrategyOptions(options);\n    }"
        ]
    ],
    "59b8e171e91e4d714acac5ec195f40158e2e2971": [
        [
            "ConnectionHandler::MessageHandler::signalCloseDone()",
            " 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  ",
            "        protected void signalCloseDone()\n        {\n            closeFuture.get().set(null);\n\n            // We can now close the socket\n            try\n            {\n                socket.close();\n            }",
            " 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218 +\n 219 +\n 220 +\n 221 +\n 222 +\n 223 +\n 224  ",
            "        protected void signalCloseDone()\n        {\n            closeFuture.get().set(null);\n\n            // We can now close the socket\n            try\n            {\n                socket.close();\n            }\n            catch (IOException e)\n            {\n                // Erroring out while closing shouldn't happen but is not really a big deal, so just log\n                // it at DEBUG and ignore otherwise.\n                logger.debug(\"Unexpected error while closing streaming connection\", e);\n            }\n        }"
        ]
    ],
    "8206839328e665108e33de8b48926942d46cf12e": [
        [
            "DatabaseDescriptor::clientInitialization(boolean)",
            " 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  ",
            "    /**\n     * Initializes this class as a client, which means that just an empty configuration will\n     * be used.\n     *\n     * @param failIfDaemonOrTool if {@code true} and a call to {@link #daemonInitialization()} or\n     *                           {@link #toolInitialization()} has been performed before, an\n     *                           {@link AssertionError} will be thrown.\n     */\n    public static void clientInitialization(boolean failIfDaemonOrTool)\n    {\n        if (!failIfDaemonOrTool && (daemonInitialized || toolInitialized))\n        {\n            return;\n        }\n        else\n        {\n            if (daemonInitialized)\n                throw new AssertionError(\"daemonInitialization() already called\");\n            if (toolInitialized)\n                throw new AssertionError(\"toolInitialization() already called\");\n        }\n\n        if (clientInitialized)\n            return;\n        clientInitialized = true;\n\n        Config.setClientMode(true);\n        conf = new Config();\n    }",
            " 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222 +\n 223 +\n 224  ",
            "    /**\n     * Initializes this class as a client, which means that just an empty configuration will\n     * be used.\n     *\n     * @param failIfDaemonOrTool if {@code true} and a call to {@link #daemonInitialization()} or\n     *                           {@link #toolInitialization()} has been performed before, an\n     *                           {@link AssertionError} will be thrown.\n     */\n    public static void clientInitialization(boolean failIfDaemonOrTool)\n    {\n        if (!failIfDaemonOrTool && (daemonInitialized || toolInitialized))\n        {\n            return;\n        }\n        else\n        {\n            if (daemonInitialized)\n                throw new AssertionError(\"daemonInitialization() already called\");\n            if (toolInitialized)\n                throw new AssertionError(\"toolInitialization() already called\");\n        }\n\n        if (clientInitialized)\n            return;\n        clientInitialized = true;\n\n        Config.setClientMode(true);\n        conf = new Config();\n        diskOptimizationStrategy = new SpinningDiskOptimizationStrategy();\n        partitioner = Murmur3Partitioner.instance;\n    }"
        ]
    ],
    "bb9aa098813b7f047f450086e18a78b149bb5349": [
        [
            "SSLFactory::buildTrustManagerFactory(EncryptionOptions)",
            " 170  \n 171  \n 172  \n 173  \n 174 -\n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  ",
            "    static TrustManagerFactory buildTrustManagerFactory(EncryptionOptions options) throws IOException\n    {\n        try (InputStream tsf = Files.newInputStream(Paths.get(options.truststore)))\n        {\n            TrustManagerFactory tmf = TrustManagerFactory.getInstance(options.algorithm);\n            KeyStore ts = KeyStore.getInstance(options.store_type);\n            ts.load(tsf, options.truststore_password.toCharArray());\n            tmf.init(ts);\n            return tmf;\n        }\n        catch (Exception e)\n        {\n            throw new IOException(\"failed to build trust manager store for secure connections\", e);\n        }\n    }",
            " 170  \n 171  \n 172  \n 173  \n 174 +\n 175 +\n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  ",
            "    static TrustManagerFactory buildTrustManagerFactory(EncryptionOptions options) throws IOException\n    {\n        try (InputStream tsf = Files.newInputStream(Paths.get(options.truststore)))\n        {\n            TrustManagerFactory tmf = TrustManagerFactory.getInstance(\n                options.algorithm == null ? TrustManagerFactory.getDefaultAlgorithm() : options.algorithm);\n            KeyStore ts = KeyStore.getInstance(options.store_type);\n            ts.load(tsf, options.truststore_password.toCharArray());\n            tmf.init(ts);\n            return tmf;\n        }\n        catch (Exception e)\n        {\n            throw new IOException(\"failed to build trust manager store for secure connections\", e);\n        }\n    }"
        ],
        [
            "LoaderOptions::getCmdLineOptions()",
            " 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613 -\n 614  \n 615  \n 616  \n 617  \n 618  \n 619  ",
            "    private static CmdLineOptions getCmdLineOptions()\n    {\n        CmdLineOptions options = new CmdLineOptions();\n        options.addOption(\"v\", VERBOSE_OPTION, \"verbose output\");\n        options.addOption(\"h\", HELP_OPTION, \"display this help message\");\n        options.addOption(null, NOPROGRESS_OPTION, \"don't display progress\");\n        options.addOption(\"i\", IGNORE_NODES_OPTION, \"NODES\", \"don't stream to this (comma separated) list of nodes\");\n        options.addOption(\"d\", INITIAL_HOST_ADDRESS_OPTION, \"initial hosts\", \"Required. try to connect to these hosts (comma separated) initially for ring information\");\n        options.addOption(\"p\",  NATIVE_PORT_OPTION, \"native transport port\", \"port used for native connection (default 9042)\");\n        options.addOption(\"sp\",  STORAGE_PORT_OPTION, \"storage port\", \"port used for internode communication (default 7000)\");\n        options.addOption(\"ssp\",  SSL_STORAGE_PORT_OPTION, \"ssl storage port\", \"port used for TLS internode communication (default 7001)\");\n        options.addOption(\"t\", THROTTLE_MBITS, \"throttle\", \"throttle speed in Mbits (default unlimited)\");\n        options.addOption(\"idct\", INTER_DC_THROTTLE_MBITS, \"inter-dc-throttle\", \"inter-datacenter throttle speed in Mbits (default unlimited)\");\n        options.addOption(\"u\", USER_OPTION, \"username\", \"username for cassandra authentication\");\n        options.addOption(\"pw\", PASSWD_OPTION, \"password\", \"password for cassandra authentication\");\n        options.addOption(\"ap\", AUTH_PROVIDER_OPTION, \"auth provider\", \"custom AuthProvider class name for cassandra authentication\");\n        options.addOption(\"cph\", CONNECTIONS_PER_HOST, \"connectionsPerHost\", \"number of concurrent connections-per-host.\");\n        // ssl connection-related options\n        options.addOption(\"ts\", SSL_TRUSTSTORE, \"TRUSTSTORE\", \"Client SSL: full path to truststore\");\n        options.addOption(\"tspw\", SSL_TRUSTSTORE_PW, \"TRUSTSTORE-PASSWORD\", \"Client SSL: password of the truststore\");\n        options.addOption(\"ks\", SSL_KEYSTORE, \"KEYSTORE\", \"Client SSL: full path to keystore\");\n        options.addOption(\"kspw\", SSL_KEYSTORE_PW, \"KEYSTORE-PASSWORD\", \"Client SSL: password of the keystore\");\n        options.addOption(\"prtcl\", SSL_PROTOCOL, \"PROTOCOL\", \"Client SSL: connections protocol to use (default: TLS)\");\n        options.addOption(\"alg\", SSL_ALGORITHM, \"ALGORITHM\", \"Client SSL: algorithm (default: SunX509)\");\n        options.addOption(\"st\", SSL_STORE_TYPE, \"STORE-TYPE\", \"Client SSL: type of store\");\n        options.addOption(\"ciphers\", SSL_CIPHER_SUITES, \"CIPHER-SUITES\", \"Client SSL: comma-separated list of encryption suites to use\");\n        options.addOption(\"f\", CONFIG_PATH, \"path to config file\", \"cassandra.yaml file path for streaming throughput and client/server SSL.\");\n        options.addOption(\"spd\", ALLOW_SERVER_PORT_DISCOVERY_OPTION, \"allow server port discovery\", \"Use ports published by server to decide how to connect. With SSL requires StartTLS to be used.\");\n        return options;\n    }",
            " 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613 +\n 614  \n 615  \n 616  \n 617  \n 618  \n 619  ",
            "    private static CmdLineOptions getCmdLineOptions()\n    {\n        CmdLineOptions options = new CmdLineOptions();\n        options.addOption(\"v\", VERBOSE_OPTION, \"verbose output\");\n        options.addOption(\"h\", HELP_OPTION, \"display this help message\");\n        options.addOption(null, NOPROGRESS_OPTION, \"don't display progress\");\n        options.addOption(\"i\", IGNORE_NODES_OPTION, \"NODES\", \"don't stream to this (comma separated) list of nodes\");\n        options.addOption(\"d\", INITIAL_HOST_ADDRESS_OPTION, \"initial hosts\", \"Required. try to connect to these hosts (comma separated) initially for ring information\");\n        options.addOption(\"p\",  NATIVE_PORT_OPTION, \"native transport port\", \"port used for native connection (default 9042)\");\n        options.addOption(\"sp\",  STORAGE_PORT_OPTION, \"storage port\", \"port used for internode communication (default 7000)\");\n        options.addOption(\"ssp\",  SSL_STORAGE_PORT_OPTION, \"ssl storage port\", \"port used for TLS internode communication (default 7001)\");\n        options.addOption(\"t\", THROTTLE_MBITS, \"throttle\", \"throttle speed in Mbits (default unlimited)\");\n        options.addOption(\"idct\", INTER_DC_THROTTLE_MBITS, \"inter-dc-throttle\", \"inter-datacenter throttle speed in Mbits (default unlimited)\");\n        options.addOption(\"u\", USER_OPTION, \"username\", \"username for cassandra authentication\");\n        options.addOption(\"pw\", PASSWD_OPTION, \"password\", \"password for cassandra authentication\");\n        options.addOption(\"ap\", AUTH_PROVIDER_OPTION, \"auth provider\", \"custom AuthProvider class name for cassandra authentication\");\n        options.addOption(\"cph\", CONNECTIONS_PER_HOST, \"connectionsPerHost\", \"number of concurrent connections-per-host.\");\n        // ssl connection-related options\n        options.addOption(\"ts\", SSL_TRUSTSTORE, \"TRUSTSTORE\", \"Client SSL: full path to truststore\");\n        options.addOption(\"tspw\", SSL_TRUSTSTORE_PW, \"TRUSTSTORE-PASSWORD\", \"Client SSL: password of the truststore\");\n        options.addOption(\"ks\", SSL_KEYSTORE, \"KEYSTORE\", \"Client SSL: full path to keystore\");\n        options.addOption(\"kspw\", SSL_KEYSTORE_PW, \"KEYSTORE-PASSWORD\", \"Client SSL: password of the keystore\");\n        options.addOption(\"prtcl\", SSL_PROTOCOL, \"PROTOCOL\", \"Client SSL: connections protocol to use (default: TLS)\");\n        options.addOption(\"alg\", SSL_ALGORITHM, \"ALGORITHM\", \"Client SSL: algorithm\");\n        options.addOption(\"st\", SSL_STORE_TYPE, \"STORE-TYPE\", \"Client SSL: type of store\");\n        options.addOption(\"ciphers\", SSL_CIPHER_SUITES, \"CIPHER-SUITES\", \"Client SSL: comma-separated list of encryption suites to use\");\n        options.addOption(\"f\", CONFIG_PATH, \"path to config file\", \"cassandra.yaml file path for streaming throughput and client/server SSL.\");\n        options.addOption(\"spd\", ALLOW_SERVER_PORT_DISCOVERY_OPTION, \"allow server port discovery\", \"Use ports published by server to decide how to connect. With SSL requires StartTLS to be used.\");\n        return options;\n    }"
        ],
        [
            "SSLFactory::buildKeyManagerFactory(EncryptionOptions)",
            " 186  \n 187  \n 188  \n 189  \n 190 -\n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  ",
            "    static KeyManagerFactory buildKeyManagerFactory(EncryptionOptions options) throws IOException\n    {\n        try (InputStream ksf = Files.newInputStream(Paths.get(options.keystore)))\n        {\n            KeyManagerFactory kmf = KeyManagerFactory.getInstance(options.algorithm);\n            KeyStore ks = KeyStore.getInstance(options.store_type);\n            ks.load(ksf, options.keystore_password.toCharArray());\n            if (!checkedExpiry)\n            {\n                for (Enumeration<String> aliases = ks.aliases(); aliases.hasMoreElements(); )\n                {\n                    String alias = aliases.nextElement();\n                    if (ks.getCertificate(alias).getType().equals(\"X.509\"))\n                    {\n                        Date expires = ((X509Certificate) ks.getCertificate(alias)).getNotAfter();\n                        if (expires.before(new Date()))\n                            logger.warn(\"Certificate for {} expired on {}\", alias, expires);\n                    }\n                }\n                checkedExpiry = true;\n            }\n            kmf.init(ks, options.keystore_password.toCharArray());\n            return kmf;\n        }\n        catch (Exception e)\n        {\n            throw new IOException(\"failed to build trust manager store for secure connections\", e);\n        }\n    }",
            " 187  \n 188  \n 189  \n 190  \n 191 +\n 192 +\n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  ",
            "    static KeyManagerFactory buildKeyManagerFactory(EncryptionOptions options) throws IOException\n    {\n        try (InputStream ksf = Files.newInputStream(Paths.get(options.keystore)))\n        {\n            KeyManagerFactory kmf = KeyManagerFactory.getInstance(\n                options.algorithm == null ? KeyManagerFactory.getDefaultAlgorithm() : options.algorithm);\n            KeyStore ks = KeyStore.getInstance(options.store_type);\n            ks.load(ksf, options.keystore_password.toCharArray());\n            if (!checkedExpiry)\n            {\n                for (Enumeration<String> aliases = ks.aliases(); aliases.hasMoreElements(); )\n                {\n                    String alias = aliases.nextElement();\n                    if (ks.getCertificate(alias).getType().equals(\"X.509\"))\n                    {\n                        Date expires = ((X509Certificate) ks.getCertificate(alias)).getNotAfter();\n                        if (expires.before(new Date()))\n                            logger.warn(\"Certificate for {} expired on {}\", alias, expires);\n                    }\n                }\n                checkedExpiry = true;\n            }\n            kmf.init(ks, options.keystore_password.toCharArray());\n            return kmf;\n        }\n        catch (Exception e)\n        {\n            throw new IOException(\"failed to build trust manager store for secure connections\", e);\n        }\n    }"
        ]
    ],
    "cba5ef609d6d25380afcb0dff06fe325101c727c": [
        [
            "LegacyLayout::LegacyBoundComparator::compare(LegacyBound,LegacyBound)",
            "1699  \n1700  \n1701  \n1702  \n1703  \n1704  \n1705  \n1706  ",
            "        public int compare(LegacyBound a, LegacyBound b)\n        {\n            int result = this.clusteringComparator.compare(a.bound, b.bound);\n            if (result != 0)\n                return result;\n\n            return UTF8Type.instance.compare(a.collectionName.name.bytes, b.collectionName.name.bytes);\n        }",
            "1699  \n1700  \n1701 +\n1702 +\n1703 +\n1704 +\n1705 +\n1706 +\n1707 +\n1708 +\n1709 +\n1710 +\n1711  \n1712  \n1713  \n1714  \n1715 +\n1716 +\n1717 +\n1718 +\n1719 +\n1720 +\n1721  \n1722  ",
            "        public int compare(LegacyBound a, LegacyBound b)\n        {\n            // In the legacy sorting, BOTTOM comes before anything else\n            if (a == LegacyBound.BOTTOM)\n                return b == LegacyBound.BOTTOM ? 0 : -1;\n            if (b == LegacyBound.BOTTOM)\n                return 1;\n\n            // Excluding BOTTOM, statics are always before anything else.\n            if (a.isStatic != b.isStatic)\n                return a.isStatic ? -1 : 1;\n\n            int result = this.clusteringComparator.compare(a.bound, b.bound);\n            if (result != 0)\n                return result;\n\n            // If both have equal \"bound\" but one is a collection tombstone and not the other, then the other comes before as it points to the beginning of the row.\n            if (a.collectionName == null)\n                return b.collectionName == null ? 0 : 1;\n            if (b.collectionName == null)\n                return -1;\n\n            return UTF8Type.instance.compare(a.collectionName.name.bytes, b.collectionName.name.bytes);\n        }"
        ]
    ],
    "c7557bdecda6ffe76bb5ee62be4c2d6c53804681": [
        [
            "MaterializedViewUtils::getViewNaturalEndpoint(String,Token,Token)",
            "  37  \n  38  \n  39  \n  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  ",
            "    /**\n     * Calculate the natural endpoint for the view.\n     *\n     * The view natural endpoint is the endpint which has the same cardinality as this node in the replication factor.\n     * The cardinality is the number at which this node would store a piece of data, given the change in replication\n     * factor.\n     *\n     * For example, if we have the following ring:\n     *   A, T1 -> B, T2 -> C, T3 -> A\n     *\n     * For the token T1, at RF=1, A would be included, so A's cardinality for T1 is 1. For the token T1, at RF=2, B would\n     * be included, so B's cardinality for token T1 is 2. For token T3, at RF = 2, A would be included, so A's cardinality\n     * for T3 is 2.\n     *\n     * For a view whose base token is T1 and whose view token is T3, the pairings between the nodes would be:\n     *  A writes to C (A's cardinality is 1 for T1, and C's cardinality is 1 for T3)\n     *  B writes to A (B's cardinality is 2 for T1, and A's cardinality is 2 for T3)\n     *  C writes to B (C's cardinality is 3 for T1, and B's cardinality is 3 for T3)\n     *\n     * @throws RuntimeException if this method is called using a base token which does not belong to this replica\n     */\n    public static InetAddress getViewNaturalEndpoint(String keyspaceName, Token baseToken, Token viewToken)\n    {\n        AbstractReplicationStrategy replicationStrategy = Keyspace.open(keyspaceName).getReplicationStrategy();\n\n        String localDataCenter = DatabaseDescriptor.getEndpointSnitch().getDatacenter(FBUtilities.getBroadcastAddress());\n        List<InetAddress> localBaseEndpoints = new ArrayList<>();\n        List<InetAddress> localViewEndpoints = new ArrayList<>();\n        for (InetAddress baseEndpoint : replicationStrategy.getNaturalEndpoints(baseToken))\n        {\n            if (DatabaseDescriptor.getEndpointSnitch().getDatacenter(baseEndpoint).equals(localDataCenter))\n                localBaseEndpoints.add(baseEndpoint);\n        }\n\n        for (InetAddress viewEndpoint : replicationStrategy.getNaturalEndpoints(viewToken))\n        {\n            // If we are a base endpoint which is also a view replica, we use ourselves as our view replica\n            if (viewEndpoint.equals(FBUtilities.getBroadcastAddress()))\n                return viewEndpoint;\n\n            // We have to remove any endpoint which is shared between the base and the view, as it will select itself\n            // and throw off the counts otherwise.\n            if (localBaseEndpoints.contains(viewEndpoint))\n                localBaseEndpoints.remove(viewEndpoint);\n            else if (DatabaseDescriptor.getEndpointSnitch().getDatacenter(viewEndpoint).equals(localDataCenter))\n                localViewEndpoints.add(viewEndpoint);\n        }\n\n        // The replication strategy will be the same for the base and the view, as they must belong to the same keyspace.\n        // Since the same replication strategy is used, the same placement should be used and we should get the same\n        // number of replicas for all of the tokens in the ring.\n        assert localBaseEndpoints.size() == localViewEndpoints.size() : \"Replication strategy should have the same number of endpoints for the base and the view\";\n        int baseIdx = localBaseEndpoints.indexOf(FBUtilities.getBroadcastAddress());\n        if (baseIdx < 0)\n            throw new RuntimeException(\"Trying to get the view natural endpoint on a non-data replica\");\n\n        return localViewEndpoints.get(baseIdx);\n    }",
            "  38  \n  39  \n  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91 +\n  92  \n  93 +\n  94 +\n  95 +\n  96 +\n  97 +\n  98 +\n  99 +\n 100 +\n 101 +\n 102 +\n 103  \n 104 +\n 105 +\n 106  \n 107  \n 108  ",
            "    /**\n     * Calculate the natural endpoint for the view.\n     *\n     * The view natural endpoint is the endpint which has the same cardinality as this node in the replication factor.\n     * The cardinality is the number at which this node would store a piece of data, given the change in replication\n     * factor.\n     *\n     * For example, if we have the following ring:\n     *   A, T1 -> B, T2 -> C, T3 -> A\n     *\n     * For the token T1, at RF=1, A would be included, so A's cardinality for T1 is 1. For the token T1, at RF=2, B would\n     * be included, so B's cardinality for token T1 is 2. For token T3, at RF = 2, A would be included, so A's cardinality\n     * for T3 is 2.\n     *\n     * For a view whose base token is T1 and whose view token is T3, the pairings between the nodes would be:\n     *  A writes to C (A's cardinality is 1 for T1, and C's cardinality is 1 for T3)\n     *  B writes to A (B's cardinality is 2 for T1, and A's cardinality is 2 for T3)\n     *  C writes to B (C's cardinality is 3 for T1, and B's cardinality is 3 for T3)\n     *\n     * @throws RuntimeException if this method is called using a base token which does not belong to this replica\n     */\n    public static InetAddress getViewNaturalEndpoint(String keyspaceName, Token baseToken, Token viewToken)\n    {\n        AbstractReplicationStrategy replicationStrategy = Keyspace.open(keyspaceName).getReplicationStrategy();\n\n        String localDataCenter = DatabaseDescriptor.getEndpointSnitch().getDatacenter(FBUtilities.getBroadcastAddress());\n        List<InetAddress> localBaseEndpoints = new ArrayList<>();\n        List<InetAddress> localViewEndpoints = new ArrayList<>();\n        for (InetAddress baseEndpoint : replicationStrategy.getNaturalEndpoints(baseToken))\n        {\n            if (DatabaseDescriptor.getEndpointSnitch().getDatacenter(baseEndpoint).equals(localDataCenter))\n                localBaseEndpoints.add(baseEndpoint);\n        }\n\n        for (InetAddress viewEndpoint : replicationStrategy.getNaturalEndpoints(viewToken))\n        {\n            // If we are a base endpoint which is also a view replica, we use ourselves as our view replica\n            if (viewEndpoint.equals(FBUtilities.getBroadcastAddress()))\n                return viewEndpoint;\n\n            // We have to remove any endpoint which is shared between the base and the view, as it will select itself\n            // and throw off the counts otherwise.\n            if (localBaseEndpoints.contains(viewEndpoint))\n                localBaseEndpoints.remove(viewEndpoint);\n            else if (DatabaseDescriptor.getEndpointSnitch().getDatacenter(viewEndpoint).equals(localDataCenter))\n                localViewEndpoints.add(viewEndpoint);\n        }\n\n        // The replication strategy will be the same for the base and the view, as they must belong to the same keyspace.\n        // Since the same replication strategy is used, the same placement should be used and we should get the same\n        // number of replicas for all of the tokens in the ring.\n        assert localBaseEndpoints.size() == localViewEndpoints.size() : \"Replication strategy should have the same number of endpoints for the base and the view\";\n        int baseIdx = localBaseEndpoints.indexOf(FBUtilities.getBroadcastAddress());\n\n        if (baseIdx < 0)\n        {\n\n            if (StorageService.instance.getTokenMetadata().pendingEndpointsFor(viewToken, keyspaceName).size() > 0)\n            {\n                //Since there are pending endpoints we are going to store hints this in the batchlog regardless.\n                //So we can pretend we are the views endpoint.\n\n                return FBUtilities.getBroadcastAddress();\n            }\n\n            throw new RuntimeException(\"Trying to get the view natural endpoint on a non-data replica\");\n        }\n\n\n        return localViewEndpoints.get(baseIdx);\n    }"
        ]
    ]
}