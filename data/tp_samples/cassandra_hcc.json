{
    "9b6f55bdec6d9b7c08d7cae267b2fefbf60d7afc": [
        [
            "SnapshotTask::run()",
            "  44  \n  45  \n  46 -\n  47  ",
            "    public void run()\n    {\n        MessagingService.instance().sendRRWithFailure(new SnapshotMessage(desc).createMessage(),\n                endpoint,",
            "  45  \n  46  \n  47 +\n  48  \n  49 +\n  50  ",
            "    public void run()\n    {\n        MessagingService.instance().sendRR(new SnapshotMessage(desc).createMessage(),\n                endpoint,\n                new SnapshotCallback(this), TimeUnit.HOURS.toMillis(1), true);\n    }"
        ],
        [
            "ActiveRepairService::prepareForRepair(Set,Collection,List)",
            " 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285 -\n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  ",
            "    public synchronized UUID prepareForRepair(Set<InetAddress> endpoints, Collection<Range<Token>> ranges, List<ColumnFamilyStore> columnFamilyStores)\n    {\n        UUID parentRepairSession = UUIDGen.getTimeUUID();\n        registerParentRepairSession(parentRepairSession, columnFamilyStores, ranges);\n        final CountDownLatch prepareLatch = new CountDownLatch(endpoints.size());\n        final AtomicBoolean status = new AtomicBoolean(true);\n        final Set<String> failedNodes = Collections.synchronizedSet(new HashSet<String>());\n        IAsyncCallbackWithFailure callback = new IAsyncCallbackWithFailure()\n        {\n            public void response(MessageIn msg)\n            {\n                prepareLatch.countDown();\n            }\n\n            public boolean isLatencyForSnitch()\n            {\n                return false;\n            }\n\n            public void onFailure(InetAddress from)\n            {\n                status.set(false);\n                failedNodes.add(from.getHostAddress());\n                prepareLatch.countDown();\n            }\n        };\n\n        List<UUID> cfIds = new ArrayList<>(columnFamilyStores.size());\n        for (ColumnFamilyStore cfs : columnFamilyStores)\n            cfIds.add(cfs.metadata.cfId);\n\n        for(InetAddress neighbour : endpoints)\n        {\n            PrepareMessage message = new PrepareMessage(parentRepairSession, cfIds, ranges);\n            MessageOut<RepairMessage> msg = message.createMessage();\n            MessagingService.instance().sendRRWithFailure(msg, neighbour, callback);\n        }\n        try\n        {\n            prepareLatch.await(1, TimeUnit.HOURS);\n        }\n        catch (InterruptedException e)\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString(), e);\n        }\n\n        if (!status.get())\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get positive replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString());\n        }\n\n        return parentRepairSession;\n    }",
            " 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285 +\n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  ",
            "    public synchronized UUID prepareForRepair(Set<InetAddress> endpoints, Collection<Range<Token>> ranges, List<ColumnFamilyStore> columnFamilyStores)\n    {\n        UUID parentRepairSession = UUIDGen.getTimeUUID();\n        registerParentRepairSession(parentRepairSession, columnFamilyStores, ranges);\n        final CountDownLatch prepareLatch = new CountDownLatch(endpoints.size());\n        final AtomicBoolean status = new AtomicBoolean(true);\n        final Set<String> failedNodes = Collections.synchronizedSet(new HashSet<String>());\n        IAsyncCallbackWithFailure callback = new IAsyncCallbackWithFailure()\n        {\n            public void response(MessageIn msg)\n            {\n                prepareLatch.countDown();\n            }\n\n            public boolean isLatencyForSnitch()\n            {\n                return false;\n            }\n\n            public void onFailure(InetAddress from)\n            {\n                status.set(false);\n                failedNodes.add(from.getHostAddress());\n                prepareLatch.countDown();\n            }\n        };\n\n        List<UUID> cfIds = new ArrayList<>(columnFamilyStores.size());\n        for (ColumnFamilyStore cfs : columnFamilyStores)\n            cfIds.add(cfs.metadata.cfId);\n\n        for(InetAddress neighbour : endpoints)\n        {\n            PrepareMessage message = new PrepareMessage(parentRepairSession, cfIds, ranges);\n            MessageOut<RepairMessage> msg = message.createMessage();\n            MessagingService.instance().sendRR(msg, neighbour, callback, TimeUnit.HOURS.toMillis(1), true);\n        }\n        try\n        {\n            prepareLatch.await(1, TimeUnit.HOURS);\n        }\n        catch (InterruptedException e)\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString(), e);\n        }\n\n        if (!status.get())\n        {\n            parentRepairSessions.remove(parentRepairSession);\n            throw new RuntimeException(\"Did not get positive replies from all endpoints. List of failed endpoint(s): \" + failedNodes.toString());\n        }\n\n        return parentRepairSession;\n    }"
        ]
    ],
    "59b8e171e91e4d714acac5ec195f40158e2e2971": [
        [
            "ConnectionHandler::MessageHandler::signalCloseDone()",
            " 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  ",
            "        protected void signalCloseDone()\n        {\n            closeFuture.get().set(null);\n\n            // We can now close the socket\n            try\n            {\n                socket.close();\n            }",
            " 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218 +\n 219 +\n 220 +\n 221 +\n 222 +\n 223 +\n 224  ",
            "        protected void signalCloseDone()\n        {\n            closeFuture.get().set(null);\n\n            // We can now close the socket\n            try\n            {\n                socket.close();\n            }\n            catch (IOException e)\n            {\n                // Erroring out while closing shouldn't happen but is not really a big deal, so just log\n                // it at DEBUG and ignore otherwise.\n                logger.debug(\"Unexpected error while closing streaming connection\", e);\n            }\n        }"
        ]
    ],
    "89afc956d8b6281ca29de8df3f7949574c6b34f5": [
        [
            "BufferPool::Chunk::free(ByteBuffer,boolean)",
            " 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833 -\n 834  \n 835  \n 836  \n 837  \n 838  ",
            "        /**\n         * Release a buffer. Return:\n         *    0L if the buffer must be recycled after the call;\n         *   -1L if it is free (and so we should tryRecycle if owner is now null)\n         *    some other value otherwise\n         **/\n        long free(ByteBuffer buffer, boolean tryRelease)\n        {\n            if (!releaseAttachment(buffer))\n                return 1L;\n\n            long address = MemoryUtil.getAddress(buffer);\n            assert (address >= baseAddress) & (address <= baseAddress + capacity());\n\n            int position = (int)(address - baseAddress);\n            int size = roundUp(buffer.capacity());\n\n            position >>= shift;\n            int slotCount = size >> shift;\n\n            long slotBits = (1L << slotCount) - 1;\n            long shiftedSlotBits = (slotBits << position);\n\n            if (slotCount == 64)\n            {\n                assert size == capacity();\n                assert position == 0;\n                shiftedSlotBits = -1L;\n            }\n\n            long next;\n            while (true)\n            {\n                long cur = freeSlots;\n                next = cur | shiftedSlotBits;\n                assert next == (cur ^ shiftedSlotBits); // ensure no double free\n                if (tryRelease & (next == -1L))\n                    next = 0L;\n                if (freeSlotsUpdater.compareAndSet(this, cur, next))\n                    return next;\n            }\n        }",
            " 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833 +\n 834  \n 835  \n 836  \n 837  \n 838  ",
            "        /**\n         * Release a buffer. Return:\n         *    0L if the buffer must be recycled after the call;\n         *   -1L if it is free (and so we should tryRecycle if owner is now null)\n         *    some other value otherwise\n         **/\n        long free(ByteBuffer buffer, boolean tryRelease)\n        {\n            if (!releaseAttachment(buffer))\n                return 1L;\n\n            long address = MemoryUtil.getAddress(buffer);\n            assert (address >= baseAddress) & (address <= baseAddress + capacity());\n\n            int position = (int)(address - baseAddress);\n            int size = roundUp(buffer.capacity());\n\n            position >>= shift;\n            int slotCount = size >> shift;\n\n            long slotBits = (1L << slotCount) - 1;\n            long shiftedSlotBits = (slotBits << position);\n\n            if (slotCount == 64)\n            {\n                assert size == capacity();\n                assert position == 0;\n                shiftedSlotBits = -1L;\n            }\n\n            long next;\n            while (true)\n            {\n                long cur = freeSlots;\n                next = cur | shiftedSlotBits;\n                assert next == (cur ^ shiftedSlotBits); // ensure no double free\n                if (tryRelease && (next == -1L))\n                    next = 0L;\n                if (freeSlotsUpdater.compareAndSet(this, cur, next))\n                    return next;\n            }\n        }"
        ],
        [
            "BufferPool::get(int,BufferType)",
            "  86  \n  87  \n  88  \n  89 -\n  90  \n  91  \n  92  \n  93  ",
            "    public static ByteBuffer get(int size, BufferType bufferType)\n    {\n        boolean direct = bufferType == BufferType.OFF_HEAP;\n        if (DISABLED | !direct)\n            return allocate(size, !direct);\n        else\n            return takeFromPool(size, !direct);\n    }",
            "  86  \n  87  \n  88  \n  89 +\n  90  \n  91  \n  92  \n  93  ",
            "    public static ByteBuffer get(int size, BufferType bufferType)\n    {\n        boolean direct = bufferType == BufferType.OFF_HEAP;\n        if (DISABLED || !direct)\n            return allocate(size, !direct);\n        else\n            return takeFromPool(size, !direct);\n    }"
        ],
        [
            "BufferPool::LocalPool::put(ByteBuffer)",
            " 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411 -\n 412  \n 413  \n 414  \n 415  \n 416  \n 417  ",
            "        public void put(ByteBuffer buffer)\n        {\n            Chunk chunk = Chunk.getParentChunk(buffer);\n            if (chunk == null)\n            {\n                FileUtils.clean(buffer);\n                return;\n            }\n\n            LocalPool owner = chunk.owner;\n            // ask the free method to take exclusive ownership of the act of recycling\n            // if we are either: already not owned by anyone, or owned by ourselves\n            long free = chunk.free(buffer, owner == null | owner == this);\n            if (free == 0L)\n            {\n                // 0L => we own recycling responsibility, so must recycle;\n                chunk.recycle();\n                // if we are also the owner, we must remove the Chunk from our local queue\n                if (owner == this)\n                    removeFromLocalQueue(chunk);\n            }\n            else if (((free == -1L) & owner != this) && chunk.owner == null)\n            {\n                // although we try to take recycle ownership cheaply, it is not always possible to do so if the owner is racing to unset.\n                // we must also check after completely freeing if the owner has since been unset, and try to recycle\n                chunk.tryRecycle();\n            }\n        }",
            " 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411 +\n 412  \n 413  \n 414  \n 415  \n 416  \n 417  ",
            "        public void put(ByteBuffer buffer)\n        {\n            Chunk chunk = Chunk.getParentChunk(buffer);\n            if (chunk == null)\n            {\n                FileUtils.clean(buffer);\n                return;\n            }\n\n            LocalPool owner = chunk.owner;\n            // ask the free method to take exclusive ownership of the act of recycling\n            // if we are either: already not owned by anyone, or owned by ourselves\n            long free = chunk.free(buffer, owner == null | owner == this);\n            if (free == 0L)\n            {\n                // 0L => we own recycling responsibility, so must recycle;\n                chunk.recycle();\n                // if we are also the owner, we must remove the Chunk from our local queue\n                if (owner == this)\n                    removeFromLocalQueue(chunk);\n            }\n            else if (((free == -1L) && owner != this) && chunk.owner == null)\n            {\n                // although we try to take recycle ownership cheaply, it is not always possible to do so if the owner is racing to unset.\n                // we must also check after completely freeing if the owner has since been unset, and try to recycle\n                chunk.tryRecycle();\n            }\n        }"
        ],
        [
            "BufferPool::put(ByteBuffer)",
            " 142  \n 143  \n 144 -\n 145  \n 146  ",
            "    public static void put(ByteBuffer buffer)\n    {\n        if (!(DISABLED | buffer.hasArray()))\n            localPool.get().put(buffer);\n    }",
            " 142  \n 143  \n 144 +\n 145  \n 146  ",
            "    public static void put(ByteBuffer buffer)\n    {\n        if (!(DISABLED || buffer.hasArray()))\n            localPool.get().put(buffer);\n    }"
        ]
    ],
    "26bd5124efbc08a657e703b3f9776d9fd6ba6c22": [
        [
            "JavaDriverClient::connect(ProtocolOptions)",
            "  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  ",
            "    public void connect(ProtocolOptions.Compression compression) throws Exception\n    {\n        Cluster.Builder clusterBuilder = Cluster.builder()\n                                                .addContactPoint(host)\n                                                .withPort(port)\n                                                .withoutMetrics(); // The driver uses metrics 3 with conflict with our version\n        if (whitelist != null)\n            clusterBuilder.withLoadBalancingPolicy(whitelist);\n        clusterBuilder.withCompression(compression);\n        if (encryptionOptions.enabled)\n        {\n            SSLContext sslContext;\n            sslContext = SSLFactory.createSSLContext(encryptionOptions, true);\n            SSLOptions sslOptions = new SSLOptions(sslContext, encryptionOptions.cipher_suites);\n            clusterBuilder.withSSL(sslOptions);\n        }\n\n        if (authProvider != null)\n        {\n            clusterBuilder.withAuthProvider(authProvider);\n        }\n        else if (username != null)\n        {\n            clusterBuilder.withCredentials(username, password);\n        }\n\n        cluster = clusterBuilder.build();\n        Metadata metadata = cluster.getMetadata();\n        System.out.printf(\"Connected to cluster: %s%n\",\n                metadata.getClusterName());\n        for (Host host : metadata.getAllHosts())\n        {\n            System.out.printf(\"Datatacenter: %s; Host: %s; Rack: %s%n\",\n                    host.getDatacenter(), host.getAddress(), host.getRack());\n        }\n\n        session = cluster.connect();\n    }",
            "  90  \n  91  \n  92 +\n  93 +\n  94  \n  95  \n  96  \n  97 +\n  98 +\n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  ",
            "    public void connect(ProtocolOptions.Compression compression) throws Exception\n    {\n        PoolingOptions poolingOpts = new PoolingOptions();\n        poolingOpts.setCoreConnectionsPerHost(HostDistance.LOCAL, 8);\n        Cluster.Builder clusterBuilder = Cluster.builder()\n                                                .addContactPoint(host)\n                                                .withPort(port)\n                                                .withPoolingOptions(poolingOpts)\n                                                .withProtocolVersion(ProtocolVersion.V2)\n                                                .withoutMetrics(); // The driver uses metrics 3 with conflict with our version\n        if (whitelist != null)\n            clusterBuilder.withLoadBalancingPolicy(whitelist);\n        clusterBuilder.withCompression(compression);\n        if (encryptionOptions.enabled)\n        {\n            SSLContext sslContext;\n            sslContext = SSLFactory.createSSLContext(encryptionOptions, true);\n            SSLOptions sslOptions = new SSLOptions(sslContext, encryptionOptions.cipher_suites);\n            clusterBuilder.withSSL(sslOptions);\n        }\n\n        if (authProvider != null)\n        {\n            clusterBuilder.withAuthProvider(authProvider);\n        }\n        else if (username != null)\n        {\n            clusterBuilder.withCredentials(username, password);\n        }\n\n        cluster = clusterBuilder.build();\n        Metadata metadata = cluster.getMetadata();\n        System.out.printf(\"Connected to cluster: %s%n\",\n                metadata.getClusterName());\n        for (Host host : metadata.getAllHosts())\n        {\n            System.out.printf(\"Datatacenter: %s; Host: %s; Rack: %s%n\",\n                    host.getDatacenter(), host.getAddress(), host.getRack());\n        }\n\n        session = cluster.connect();\n    }"
        ]
    ],
    "bd46463fbb7d6b0998c837450ce61df13eda041d": [
        [
            "CassandraDaemon::setup()",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324 -\n 325 -\n 326 -\n 327 -\n 328 -\n 329 -\n 330 -\n 331 -\n 332 -\n 333 -\n 334 -\n 335 -\n 336 -\n 337 -\n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  ",
            "    /**\n     * This is a hook for concrete daemons to initialize themselves suitably.\n     *\n     * Subclasses should override this to finish the job (listening on ports, etc.)\n     */\n    protected void setup()\n    {\n        // Delete any failed snapshot deletions on Windows - see CASSANDRA-9658\n        if (FBUtilities.isWindows())\n            WindowsFailedSnapshotTracker.deleteOldSnapshots();\n\n        ThreadAwareSecurityManager.install();\n\n        logSystemInfo();\n\n        CLibrary.tryMlockall();\n\n        try\n        {\n            startupChecks.verify();\n        }\n        catch (StartupException e)\n        {\n            exitOrFail(e.returnCode, e.getMessage(), e.getCause());\n        }\n\n        try\n        {\n            if (SystemKeyspace.snapshotOnVersionChange())\n            {\n                SystemKeyspace.migrateDataDirs();\n            }\n        }\n        catch (IOException e)\n        {\n            exitOrFail(3, e.getMessage(), e.getCause());\n        }\n\n        maybeInitJmx();\n\n        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler()\n        {\n            public void uncaughtException(Thread t, Throwable e)\n            {\n                StorageMetrics.exceptions.inc();\n                logger.error(\"Exception in thread {}\", t, e);\n                Tracing.trace(\"Exception in thread {}\", t, e);\n                for (Throwable e2 = e; e2 != null; e2 = e2.getCause())\n                {\n                    JVMStabilityInspector.inspectThrowable(e2);\n\n                    if (e2 instanceof FSError)\n                    {\n                        if (e2 != e) // make sure FSError gets logged exactly once.\n                            logger.error(\"Exception in thread {}\", t, e2);\n                        FileUtils.handleFSError((FSError) e2);\n                    }\n\n                    if (e2 instanceof CorruptSSTableException)\n                    {\n                        if (e2 != e)\n                            logger.error(\"Exception in thread \" + t, e2);\n                        FileUtils.handleCorruptSSTable((CorruptSSTableException) e2);\n                    }\n                }\n            }\n        });\n\n        /*\n         * Migrate pre-3.0 keyspaces, tables, types, functions, and aggregates, to their new 3.0 storage.\n         * We don't (and can't) wait for commit log replay here, but we don't need to - all schema changes force\n         * explicit memtable flushes.\n         */\n        LegacySchemaMigrator.migrate();\n\n        StorageService.instance.populateTokenMetadata();\n\n        // load schema from disk\n        Schema.instance.loadFromDisk();\n\n        // clean up debris in the rest of the keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            // Skip system as we've already cleaned it\n            if (keyspaceName.equals(SystemKeyspace.NAME))\n                continue;\n\n            for (CFMetaData cfm : Schema.instance.getTablesAndViews(keyspaceName))\n                ColumnFamilyStore.scrubDataDirectories(cfm);\n        }\n\n        Keyspace.setInitialized();\n        // initialize keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            if (logger.isDebugEnabled())\n                logger.debug(\"opening keyspace {}\", keyspaceName);\n            // disable auto compaction until commit log replay ends\n            for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())\n            {\n                for (ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    store.disableAutoCompaction();\n                }\n            }\n        }\n\n\n        try\n        {\n            loadRowAndKeyCacheAsync().get();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Error loading key or row cache\", t);\n        }\n\n        try\n        {\n            GCInspector.register();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Unable to start GCInspector (currently only supported on the Sun JVM)\");\n        }\n\n        // replay the log if necessary\n        try\n        {\n            CommitLog.instance.recover();\n        }\n        catch (IOException e)\n        {\n            throw new RuntimeException(e);\n        }\n\n        // migrate any legacy (pre-3.0) hints from system.hints table into the new store\n        new LegacyHintsMigrator(DatabaseDescriptor.getHintsDirectory(), DatabaseDescriptor.getMaxHintsFileSize()).migrate();\n\n        // migrate any legacy (pre-3.0) batch entries from system.batchlog to system.batches (new table format)\n        LegacyBatchlogMigrator.migrate();\n\n        // enable auto compaction\n        for (Keyspace keyspace : Keyspace.all())\n        {\n            for (ColumnFamilyStore cfs : keyspace.getColumnFamilyStores())\n            {\n                for (final ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    if (store.getCompactionStrategyManager().shouldBeEnabled())\n                        store.enableAutoCompaction();\n                }\n            }\n        }\n\n        Runnable viewRebuild = new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                for (Keyspace keyspace : Keyspace.all())\n                {\n                    keyspace.viewManager.buildAllViews();\n                }\n            }\n        };\n\n        ScheduledExecutors.optionalTasks.schedule(viewRebuild, StorageService.RING_DELAY, TimeUnit.MILLISECONDS);\n\n\n        SystemKeyspace.finishStartup();\n\n        // start server internals\n        StorageService.instance.registerDaemon(this);\n        try\n        {\n            StorageService.instance.initServer();\n        }\n        catch (ConfigurationException e)\n        {\n            System.err.println(e.getMessage() + \"\\nFatal configuration error; unable to start server.  See log for stacktrace.\");\n            exitOrFail(1, \"Fatal configuration error\", e);\n        }\n\n        Mx4jTool.maybeLoad();\n\n        // Metrics\n        String metricsReporterConfigFile = System.getProperty(\"cassandra.metricsReporterConfigFile\");\n        if (metricsReporterConfigFile != null)\n        {\n            logger.info(\"Trying to load metrics-reporter-config from file: {}\", metricsReporterConfigFile);\n            try\n            {\n                String reportFileLocation = CassandraDaemon.class.getClassLoader().getResource(metricsReporterConfigFile).getFile();\n                ReporterConfig.loadFromFile(reportFileLocation).enableAll(CassandraMetricsRegistry.Metrics);\n            }\n            catch (Exception e)\n            {\n                logger.warn(\"Failed to load metrics-reporter-config, metric sinks will not be activated\", e);\n            }\n        }\n\n        if (!FBUtilities.getBroadcastAddress().equals(InetAddress.getLoopbackAddress()))\n            waitForGossipToSettle();\n\n        // schedule periodic background compaction task submission. this is simply a backstop against compactions stalling\n        // due to scheduling errors or race conditions\n        ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(ColumnFamilyStore.getBackgroundCompactionTaskSubmitter(), 5, 1, TimeUnit.MINUTES);\n\n        // schedule periodic dumps of table size estimates into SystemKeyspace.SIZE_ESTIMATES_CF\n        // set cassandra.size_recorder_interval to 0 to disable\n        int sizeRecorderInterval = Integer.getInteger(\"cassandra.size_recorder_interval\", 5 * 60);\n        if (sizeRecorderInterval > 0)\n            ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(SizeEstimatesRecorder.instance, 30, sizeRecorderInterval, TimeUnit.SECONDS);\n\n        // Thrift\n        InetAddress rpcAddr = DatabaseDescriptor.getRpcAddress();\n        int rpcPort = DatabaseDescriptor.getRpcPort();\n        int listenBacklog = DatabaseDescriptor.getRpcListenBacklog();\n        thriftServer = new ThriftServer(rpcAddr, rpcPort, listenBacklog);\n\n        // Native transport\n        nativeTransportService = new NativeTransportService();\n\n        completeSetup();\n    }",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340 +\n 341 +\n 342 +\n 343 +\n 344 +\n 345 +\n 346 +\n 347 +\n 348 +\n 349 +\n 350 +\n 351 +\n 352 +\n 353 +\n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  ",
            "    /**\n     * This is a hook for concrete daemons to initialize themselves suitably.\n     *\n     * Subclasses should override this to finish the job (listening on ports, etc.)\n     */\n    protected void setup()\n    {\n        // Delete any failed snapshot deletions on Windows - see CASSANDRA-9658\n        if (FBUtilities.isWindows())\n            WindowsFailedSnapshotTracker.deleteOldSnapshots();\n\n        ThreadAwareSecurityManager.install();\n\n        logSystemInfo();\n\n        CLibrary.tryMlockall();\n\n        try\n        {\n            startupChecks.verify();\n        }\n        catch (StartupException e)\n        {\n            exitOrFail(e.returnCode, e.getMessage(), e.getCause());\n        }\n\n        try\n        {\n            if (SystemKeyspace.snapshotOnVersionChange())\n            {\n                SystemKeyspace.migrateDataDirs();\n            }\n        }\n        catch (IOException e)\n        {\n            exitOrFail(3, e.getMessage(), e.getCause());\n        }\n\n        maybeInitJmx();\n\n        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler()\n        {\n            public void uncaughtException(Thread t, Throwable e)\n            {\n                StorageMetrics.exceptions.inc();\n                logger.error(\"Exception in thread {}\", t, e);\n                Tracing.trace(\"Exception in thread {}\", t, e);\n                for (Throwable e2 = e; e2 != null; e2 = e2.getCause())\n                {\n                    JVMStabilityInspector.inspectThrowable(e2);\n\n                    if (e2 instanceof FSError)\n                    {\n                        if (e2 != e) // make sure FSError gets logged exactly once.\n                            logger.error(\"Exception in thread {}\", t, e2);\n                        FileUtils.handleFSError((FSError) e2);\n                    }\n\n                    if (e2 instanceof CorruptSSTableException)\n                    {\n                        if (e2 != e)\n                            logger.error(\"Exception in thread \" + t, e2);\n                        FileUtils.handleCorruptSSTable((CorruptSSTableException) e2);\n                    }\n                }\n            }\n        });\n\n        /*\n         * Migrate pre-3.0 keyspaces, tables, types, functions, and aggregates, to their new 3.0 storage.\n         * We don't (and can't) wait for commit log replay here, but we don't need to - all schema changes force\n         * explicit memtable flushes.\n         */\n        LegacySchemaMigrator.migrate();\n\n        StorageService.instance.populateTokenMetadata();\n\n        // load schema from disk\n        Schema.instance.loadFromDisk();\n\n        // clean up debris in the rest of the keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            // Skip system as we've already cleaned it\n            if (keyspaceName.equals(SystemKeyspace.NAME))\n                continue;\n\n            for (CFMetaData cfm : Schema.instance.getTablesAndViews(keyspaceName))\n                ColumnFamilyStore.scrubDataDirectories(cfm);\n        }\n\n        Keyspace.setInitialized();\n        // initialize keyspaces\n        for (String keyspaceName : Schema.instance.getKeyspaces())\n        {\n            if (logger.isDebugEnabled())\n                logger.debug(\"opening keyspace {}\", keyspaceName);\n            // disable auto compaction until commit log replay ends\n            for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())\n            {\n                for (ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    store.disableAutoCompaction();\n                }\n            }\n        }\n\n\n        try\n        {\n            loadRowAndKeyCacheAsync().get();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Error loading key or row cache\", t);\n        }\n\n        try\n        {\n            GCInspector.register();\n        }\n        catch (Throwable t)\n        {\n            JVMStabilityInspector.inspectThrowable(t);\n            logger.warn(\"Unable to start GCInspector (currently only supported on the Sun JVM)\");\n        }\n\n        // replay the log if necessary\n        try\n        {\n            CommitLog.instance.recover();\n        }\n        catch (IOException e)\n        {\n            throw new RuntimeException(e);\n        }\n\n        // migrate any legacy (pre-3.0) hints from system.hints table into the new store\n        new LegacyHintsMigrator(DatabaseDescriptor.getHintsDirectory(), DatabaseDescriptor.getMaxHintsFileSize()).migrate();\n\n        // migrate any legacy (pre-3.0) batch entries from system.batchlog to system.batches (new table format)\n        LegacyBatchlogMigrator.migrate();\n\n        // enable auto compaction\n        for (Keyspace keyspace : Keyspace.all())\n        {\n            for (ColumnFamilyStore cfs : keyspace.getColumnFamilyStores())\n            {\n                for (final ColumnFamilyStore store : cfs.concatWithIndexes())\n                {\n                    if (store.getCompactionStrategyManager().shouldBeEnabled())\n                        store.enableAutoCompaction();\n                }\n            }\n        }\n\n        Runnable viewRebuild = new Runnable()\n        {\n            @Override\n            public void run()\n            {\n                for (Keyspace keyspace : Keyspace.all())\n                {\n                    keyspace.viewManager.buildAllViews();\n                }\n            }\n        };\n\n        ScheduledExecutors.optionalTasks.schedule(viewRebuild, StorageService.RING_DELAY, TimeUnit.MILLISECONDS);\n\n\n        SystemKeyspace.finishStartup();\n\n        // Metrics\n        String metricsReporterConfigFile = System.getProperty(\"cassandra.metricsReporterConfigFile\");\n        if (metricsReporterConfigFile != null)\n        {\n            logger.info(\"Trying to load metrics-reporter-config from file: {}\", metricsReporterConfigFile);\n            try\n            {\n                String reportFileLocation = CassandraDaemon.class.getClassLoader().getResource(metricsReporterConfigFile).getFile();\n                ReporterConfig.loadFromFile(reportFileLocation).enableAll(CassandraMetricsRegistry.Metrics);\n            }\n            catch (Exception e)\n            {\n                logger.warn(\"Failed to load metrics-reporter-config, metric sinks will not be activated\", e);\n            }\n        }\n\n        // start server internals\n        StorageService.instance.registerDaemon(this);\n        try\n        {\n            StorageService.instance.initServer();\n        }\n        catch (ConfigurationException e)\n        {\n            System.err.println(e.getMessage() + \"\\nFatal configuration error; unable to start server.  See log for stacktrace.\");\n            exitOrFail(1, \"Fatal configuration error\", e);\n        }\n\n        Mx4jTool.maybeLoad();\n\n        if (!FBUtilities.getBroadcastAddress().equals(InetAddress.getLoopbackAddress()))\n            waitForGossipToSettle();\n\n        // schedule periodic background compaction task submission. this is simply a backstop against compactions stalling\n        // due to scheduling errors or race conditions\n        ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(ColumnFamilyStore.getBackgroundCompactionTaskSubmitter(), 5, 1, TimeUnit.MINUTES);\n\n        // schedule periodic dumps of table size estimates into SystemKeyspace.SIZE_ESTIMATES_CF\n        // set cassandra.size_recorder_interval to 0 to disable\n        int sizeRecorderInterval = Integer.getInteger(\"cassandra.size_recorder_interval\", 5 * 60);\n        if (sizeRecorderInterval > 0)\n            ScheduledExecutors.optionalTasks.scheduleWithFixedDelay(SizeEstimatesRecorder.instance, 30, sizeRecorderInterval, TimeUnit.SECONDS);\n\n        // Thrift\n        InetAddress rpcAddr = DatabaseDescriptor.getRpcAddress();\n        int rpcPort = DatabaseDescriptor.getRpcPort();\n        int listenBacklog = DatabaseDescriptor.getRpcListenBacklog();\n        thriftServer = new ThriftServer(rpcAddr, rpcPort, listenBacklog);\n\n        // Native transport\n        nativeTransportService = new NativeTransportService();\n\n        completeSetup();\n    }"
        ]
    ],
    "a0076e70eed5501ac9d8c3ff41ce8018710a1585": [
        [
            "JavaDriverClient::JavaDriverClient(StressSettings,String,int,EncryptionOptions)",
            "  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  ",
            "    public JavaDriverClient(StressSettings settings, String host, int port, EncryptionOptions.ClientEncryptionOptions encryptionOptions)\n    {\n        this.host = host;\n        this.port = port;\n        this.username = settings.mode.username;\n        this.password = settings.mode.password;\n        this.authProvider = settings.mode.authProvider;\n        this.encryptionOptions = encryptionOptions;\n        if (settings.node.isWhiteList)\n            whitelist = new WhiteListPolicy(new DCAwareRoundRobinPolicy(), settings.node.resolveAll(settings.port.nativePort));\n        else\n            whitelist = null;\n    }",
            "  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74 +\n  75 +\n  76 +\n  77 +\n  78 +\n  79 +\n  80 +\n  81 +\n  82 +\n  83 +\n  84 +\n  85 +\n  86 +\n  87  ",
            "    public JavaDriverClient(StressSettings settings, String host, int port, EncryptionOptions.ClientEncryptionOptions encryptionOptions)\n    {\n        this.host = host;\n        this.port = port;\n        this.username = settings.mode.username;\n        this.password = settings.mode.password;\n        this.authProvider = settings.mode.authProvider;\n        this.encryptionOptions = encryptionOptions;\n        if (settings.node.isWhiteList)\n            whitelist = new WhiteListPolicy(new DCAwareRoundRobinPolicy(), settings.node.resolveAll(settings.port.nativePort));\n        else\n            whitelist = null;\n        connectionsPerHost = settings.mode.connectionsPerHost == null ? 8 : settings.mode.connectionsPerHost;\n\n        int maxThreadCount = 0;\n        if (settings.rate.auto)\n            maxThreadCount = settings.rate.maxThreads;\n        else\n            maxThreadCount = settings.rate.threadCount;\n\n        //Always allow enough pending requests so every thread can have a request pending\n        //See https://issues.apache.org/jira/browse/CASSANDRA-7217\n        int requestsPerConnection = (maxThreadCount / connectionsPerHost) + connectionsPerHost;\n\n        maxPendingPerConnection = settings.mode.maxPendingPerConnection == null ? Math.max(128, requestsPerConnection ) : settings.mode.maxPendingPerConnection;\n    }"
        ],
        [
            "SettingsMode::Cql3Options::options()",
            " 150  \n 151  \n 152  \n 153 -\n 154  ",
            "        @Override\n        public List<? extends Option> options()\n        {\n            return Arrays.asList(mode(), useUnPrepared, api, useCompression, port, user, password, authProvider);\n        }",
            " 161  \n 162  \n 163  \n 164 +\n 165 +\n 166  ",
            "        @Override\n        public List<? extends Option> options()\n        {\n            return Arrays.asList(mode(), useUnPrepared, api, useCompression, port, user, password, authProvider,\n                                 maxPendingPerConnection, connectionsPerHost);\n        }"
        ],
        [
            "SettingsMode::SettingsMode(GroupedOptions)",
            "  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  ",
            "    public SettingsMode(GroupedOptions options)\n    {\n        if (options instanceof Cql3Options)\n        {\n            cqlVersion = CqlVersion.CQL3;\n            Cql3Options opts = (Cql3Options) options;\n            api = opts.mode().displayPrefix.equals(\"native\") ? ConnectionAPI.JAVA_DRIVER_NATIVE : ConnectionAPI.THRIFT;\n            style = opts.useUnPrepared.setByUser() ? ConnectionStyle.CQL :  ConnectionStyle.CQL_PREPARED;\n            compression = ProtocolOptions.Compression.valueOf(opts.useCompression.value().toUpperCase()).name();\n            username = opts.user.value();\n            password = opts.password.value();\n            authProviderClassname = opts.authProvider.value();\n            if (authProviderClassname != null)\n            {\n                try\n                {\n                    Class<?> clazz = Class.forName(authProviderClassname);\n                    if (!AuthProvider.class.isAssignableFrom(clazz))\n                        throw new IllegalArgumentException(clazz + \" is not a valid auth provider\");\n                    // check we can instantiate it\n                    if (PlainTextAuthProvider.class.equals(clazz))\n                    {\n                        authProvider = (AuthProvider) clazz.getConstructor(String.class, String.class)\n                            .newInstance(username, password);\n                    } else\n                    {\n                        authProvider = (AuthProvider) clazz.newInstance();\n                    }\n                }\n                catch (Exception e)\n                {\n                    throw new IllegalArgumentException(\"Invalid auth provider class: \" + opts.authProvider.value(), e);\n                }\n            }\n            else\n            {\n                authProvider = null;\n            }\n        }\n        else if (options instanceof Cql3SimpleNativeOptions)\n        {\n            cqlVersion = CqlVersion.CQL3;\n            Cql3SimpleNativeOptions opts = (Cql3SimpleNativeOptions) options;\n            api = ConnectionAPI.SIMPLE_NATIVE;\n            style = opts.usePrepared.setByUser() ? ConnectionStyle.CQL_PREPARED : ConnectionStyle.CQL;\n            compression = ProtocolOptions.Compression.NONE.name();\n            username = null;\n            password = null;\n            authProvider = null;\n            authProviderClassname = null;\n        }\n        else if (options instanceof ThriftOptions)\n        {\n            ThriftOptions opts = (ThriftOptions) options;\n            cqlVersion = CqlVersion.NOCQL;\n            api = opts.smart.setByUser() ? ConnectionAPI.THRIFT_SMART : ConnectionAPI.THRIFT;\n            style = ConnectionStyle.THRIFT;\n            compression = ProtocolOptions.Compression.NONE.name();\n            username = opts.user.value();\n            password = opts.password.value();\n            authProviderClassname = null;\n            authProvider = null;\n        }\n        else\n            throw new IllegalStateException();\n    }",
            "  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61 +\n  62 +\n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102 +\n 103 +\n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116 +\n 117 +\n 118  \n 119  \n 120  \n 121  ",
            "    public SettingsMode(GroupedOptions options)\n    {\n        if (options instanceof Cql3Options)\n        {\n            cqlVersion = CqlVersion.CQL3;\n            Cql3Options opts = (Cql3Options) options;\n            api = opts.mode().displayPrefix.equals(\"native\") ? ConnectionAPI.JAVA_DRIVER_NATIVE : ConnectionAPI.THRIFT;\n            style = opts.useUnPrepared.setByUser() ? ConnectionStyle.CQL :  ConnectionStyle.CQL_PREPARED;\n            compression = ProtocolOptions.Compression.valueOf(opts.useCompression.value().toUpperCase()).name();\n            username = opts.user.value();\n            password = opts.password.value();\n            maxPendingPerConnection = opts.maxPendingPerConnection.value().isEmpty() ? null : Integer.valueOf(opts.maxPendingPerConnection.value());\n            connectionsPerHost = opts.connectionsPerHost.value().isEmpty() ? null : Integer.valueOf(opts.connectionsPerHost.value());\n            authProviderClassname = opts.authProvider.value();\n            if (authProviderClassname != null)\n            {\n                try\n                {\n                    Class<?> clazz = Class.forName(authProviderClassname);\n                    if (!AuthProvider.class.isAssignableFrom(clazz))\n                        throw new IllegalArgumentException(clazz + \" is not a valid auth provider\");\n                    // check we can instantiate it\n                    if (PlainTextAuthProvider.class.equals(clazz))\n                    {\n                        authProvider = (AuthProvider) clazz.getConstructor(String.class, String.class)\n                            .newInstance(username, password);\n                    } else\n                    {\n                        authProvider = (AuthProvider) clazz.newInstance();\n                    }\n                }\n                catch (Exception e)\n                {\n                    throw new IllegalArgumentException(\"Invalid auth provider class: \" + opts.authProvider.value(), e);\n                }\n            }\n            else\n            {\n                authProvider = null;\n            }\n        }\n        else if (options instanceof Cql3SimpleNativeOptions)\n        {\n            cqlVersion = CqlVersion.CQL3;\n            Cql3SimpleNativeOptions opts = (Cql3SimpleNativeOptions) options;\n            api = ConnectionAPI.SIMPLE_NATIVE;\n            style = opts.usePrepared.setByUser() ? ConnectionStyle.CQL_PREPARED : ConnectionStyle.CQL;\n            compression = ProtocolOptions.Compression.NONE.name();\n            username = null;\n            password = null;\n            authProvider = null;\n            authProviderClassname = null;\n            maxPendingPerConnection = null;\n            connectionsPerHost = null;\n        }\n        else if (options instanceof ThriftOptions)\n        {\n            ThriftOptions opts = (ThriftOptions) options;\n            cqlVersion = CqlVersion.NOCQL;\n            api = opts.smart.setByUser() ? ConnectionAPI.THRIFT_SMART : ConnectionAPI.THRIFT;\n            style = ConnectionStyle.THRIFT;\n            compression = ProtocolOptions.Compression.NONE.name();\n            username = opts.user.value();\n            password = opts.password.value();\n            authProviderClassname = null;\n            authProvider = null;\n            maxPendingPerConnection = null;\n            connectionsPerHost = null;\n        }\n        else\n            throw new IllegalStateException();\n    }"
        ],
        [
            "JavaDriverClient::connect(ProtocolOptions)",
            "  90  \n  91  \n  92  \n  93  \n  94 -\n  95 -\n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126 -\n 127 -\n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  ",
            "    public void connect(ProtocolOptions.Compression compression) throws Exception\n    {\n\n        PoolingOptions poolingOpts = new PoolingOptions()\n                                     .setConnectionsPerHost(HostDistance.LOCAL, 8, 8)\n                                     .setMaxRequestsPerConnection(HostDistance.LOCAL, 128)\n                                     .setNewConnectionThreshold(HostDistance.LOCAL, 100);\n\n        Cluster.Builder clusterBuilder = Cluster.builder()\n                                                .addContactPoint(host)\n                                                .withPort(port)\n                                                .withPoolingOptions(poolingOpts)\n                                                .withoutJMXReporting()\n                                                .withoutMetrics(); // The driver uses metrics 3 with conflict with our version\n        if (whitelist != null)\n            clusterBuilder.withLoadBalancingPolicy(whitelist);\n        clusterBuilder.withCompression(compression);\n        if (encryptionOptions.enabled)\n        {\n            SSLContext sslContext;\n            sslContext = SSLFactory.createSSLContext(encryptionOptions, true);\n            SSLOptions sslOptions = new SSLOptions(sslContext, encryptionOptions.cipher_suites);\n            clusterBuilder.withSSL(sslOptions);\n        }\n\n        if (authProvider != null)\n        {\n            clusterBuilder.withAuthProvider(authProvider);\n        }\n        else if (username != null)\n        {\n            clusterBuilder.withCredentials(username, password);\n        }\n\n        cluster = clusterBuilder.build();\n        Metadata metadata = cluster.getMetadata();\n        System.out.printf(\"Connected to cluster: %s%n\",\n                metadata.getClusterName());\n        for (Host host : metadata.getAllHosts())\n        {\n            System.out.printf(\"Datatacenter: %s; Host: %s; Rack: %s%n\",\n                    host.getDatacenter(), host.getAddress(), host.getRack());\n        }\n\n        session = cluster.connect();\n    }",
            " 105  \n 106  \n 107  \n 108  \n 109 +\n 110 +\n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141 +\n 142 +\n 143 +\n 144 +\n 145 +\n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  ",
            "    public void connect(ProtocolOptions.Compression compression) throws Exception\n    {\n\n        PoolingOptions poolingOpts = new PoolingOptions()\n                                     .setConnectionsPerHost(HostDistance.LOCAL, connectionsPerHost, connectionsPerHost)\n                                     .setMaxRequestsPerConnection(HostDistance.LOCAL, maxPendingPerConnection)\n                                     .setNewConnectionThreshold(HostDistance.LOCAL, 100);\n\n        Cluster.Builder clusterBuilder = Cluster.builder()\n                                                .addContactPoint(host)\n                                                .withPort(port)\n                                                .withPoolingOptions(poolingOpts)\n                                                .withoutJMXReporting()\n                                                .withoutMetrics(); // The driver uses metrics 3 with conflict with our version\n        if (whitelist != null)\n            clusterBuilder.withLoadBalancingPolicy(whitelist);\n        clusterBuilder.withCompression(compression);\n        if (encryptionOptions.enabled)\n        {\n            SSLContext sslContext;\n            sslContext = SSLFactory.createSSLContext(encryptionOptions, true);\n            SSLOptions sslOptions = new SSLOptions(sslContext, encryptionOptions.cipher_suites);\n            clusterBuilder.withSSL(sslOptions);\n        }\n\n        if (authProvider != null)\n        {\n            clusterBuilder.withAuthProvider(authProvider);\n        }\n        else if (username != null)\n        {\n            clusterBuilder.withCredentials(username, password);\n        }\n\n        cluster = clusterBuilder.build();\n        Metadata metadata = cluster.getMetadata();\n        System.out.printf(\n                \"Connected to cluster: %s, max pending requests per connection %d, max connections per host %d%n\",\n                metadata.getClusterName(),\n                maxPendingPerConnection,\n                connectionsPerHost);\n        for (Host host : metadata.getAllHosts())\n        {\n            System.out.printf(\"Datatacenter: %s; Host: %s; Rack: %s%n\",\n                    host.getDatacenter(), host.getAddress(), host.getRack());\n        }\n\n        session = cluster.connect();\n    }"
        ]
    ],
    "6a1b1f26b7174e8c9bf86a96514ab626ce2a4117": [
        [
            "StressAction::run()",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  ",
            "    public void run()\n    {\n        // creating keyspace and column families\n        settings.maybeCreateKeyspaces();\n\n        output.println(\"Sleeping 2s...\");\n        Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);\n\n        if (!settings.command.noWarmup)\n            warmup(settings.command.getFactory(settings));\n        if (settings.command.truncate == SettingsCommand.TruncateWhen.ONCE)\n            settings.command.truncateTables(settings);\n\n        // TODO : move this to a new queue wrapper that gates progress based on a poisson (or configurable) distribution\n        RateLimiter rateLimiter = null;\n        if (settings.rate.opRateTargetPerSecond > 0)\n            rateLimiter = RateLimiter.create(settings.rate.opRateTargetPerSecond);\n\n        boolean success;\n        if (settings.rate.minThreads > 0)\n            success = runMulti(settings.rate.auto, rateLimiter);\n        else\n            success = null != run(settings.command.getFactory(settings), settings.rate.threadCount, settings.command.count,\n                                  settings.command.duration, rateLimiter, settings.command.durationUnits, output, false);\n\n        if (success)\n            output.println(\"END\");\n        else\n            output.println(\"FAILURE\");\n\n        settings.disconnect();\n    }",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57 +\n  58 +\n  59 +\n  60 +\n  61 +\n  62 +\n  63 +\n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  ",
            "    public void run()\n    {\n        // creating keyspace and column families\n        settings.maybeCreateKeyspaces();\n\n        if (settings.command.count == 0)\n        {\n            output.println(\"N=0: SCHEMA CREATED, NOTHING ELSE DONE.\");\n            settings.disconnect();\n            return;\n        }\n\n        output.println(\"Sleeping 2s...\");\n        Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);\n\n        if (!settings.command.noWarmup)\n            warmup(settings.command.getFactory(settings));\n        if (settings.command.truncate == SettingsCommand.TruncateWhen.ONCE)\n            settings.command.truncateTables(settings);\n\n        // TODO : move this to a new queue wrapper that gates progress based on a poisson (or configurable) distribution\n        RateLimiter rateLimiter = null;\n        if (settings.rate.opRateTargetPerSecond > 0)\n            rateLimiter = RateLimiter.create(settings.rate.opRateTargetPerSecond);\n\n        boolean success;\n        if (settings.rate.minThreads > 0)\n            success = runMulti(settings.rate.auto, rateLimiter);\n        else\n            success = null != run(settings.command.getFactory(settings), settings.rate.threadCount, settings.command.count,\n                                  settings.command.duration, rateLimiter, settings.command.durationUnits, output, false);\n\n        if (success)\n            output.println(\"END\");\n        else\n            output.println(\"FAILURE\");\n\n        settings.disconnect();\n    }"
        ],
        [
            "StressAction::warmup(OpDistributionFactory)",
            "  86  \n  87  \n  88  \n  89  \n  90 -\n  91 -\n  92 -\n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  ",
            "    private void warmup(OpDistributionFactory operations)\n    {\n        PrintStream warmupOutput = new PrintStream(new OutputStream() { @Override public void write(int b) throws IOException { } } );\n        // do 25% of iterations as warmup but no more than 50k (by default hotspot compiles methods after 10k invocations)\n        int iterations = (settings.command.count > 0\n                         ? Math.min(50000, (int)(settings.command.count * 0.25))\n                         : 50000) * settings.node.nodes.size();\n        int threads = 100;\n\n        if (settings.rate.maxThreads > 0)\n            threads = Math.min(threads, settings.rate.maxThreads);\n        if (settings.rate.threadCount > 0)\n            threads = Math.min(threads, settings.rate.threadCount);\n\n        for (OpDistributionFactory single : operations.each())\n        {\n            // we need to warm up all the nodes in the cluster ideally, but we may not be the only stress instance;\n            // so warm up all the nodes we're speaking to only.\n            output.println(String.format(\"Warming up %s with %d iterations...\", single.desc(), iterations));\n            run(single, threads, iterations, 0, null, null, warmupOutput, true);\n        }\n    }",
            "  93  \n  94  \n  95  \n  96  \n  97 +\n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  ",
            "    private void warmup(OpDistributionFactory operations)\n    {\n        PrintStream warmupOutput = new PrintStream(new OutputStream() { @Override public void write(int b) throws IOException { } } );\n        // do 25% of iterations as warmup but no more than 50k (by default hotspot compiles methods after 10k invocations)\n        int iterations = Math.min(50000, (int) (settings.command.count * 0.25)) * settings.node.nodes.size();\n        int threads = 100;\n\n        if (settings.rate.maxThreads > 0)\n            threads = Math.min(threads, settings.rate.maxThreads);\n        if (settings.rate.threadCount > 0)\n            threads = Math.min(threads, settings.rate.threadCount);\n\n        for (OpDistributionFactory single : operations.each())\n        {\n            // we need to warm up all the nodes in the cluster ideally, but we may not be the only stress instance;\n            // so warm up all the nodes we're speaking to only.\n            output.println(String.format(\"Warming up %s with %d iterations...\", single.desc(), iterations));\n            run(single, threads, iterations, 0, null, null, warmupOutput, true);\n        }\n    }"
        ]
    ],
    "5d4335e8f8affc738cc72eacec2f01a8ea18a5b3": [
        [
            "LogTransaction::delete(File)",
            " 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215 -\n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  ",
            "    static void delete(File file)\n    {\n        try\n        {\n            if (logger.isTraceEnabled())\n                logger.trace(\"Deleting {}\", file);\n\n            Files.delete(file.toPath());\n        }\n        catch (NoSuchFileException e)\n        {\n            logger.error(\"Unable to delete {} as it does not exist, see debug log file for stack trace\", file);\n            if (logger.isDebugEnabled())\n            {\n                ByteArrayOutputStream baos = new ByteArrayOutputStream();\n                try (PrintStream ps = new PrintStream(baos))\n                {\n                    e.printStackTrace(ps);\n                }\n                logger.debug(\"Unable to delete {} as it does not exist, stack trace:\\n {}\", file, baos.toString());\n            }\n        }\n        catch (IOException e)\n        {\n            logger.error(\"Unable to delete {}\", file, e);\n            throw new RuntimeException(e);\n        }\n    }",
            " 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215 +\n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  ",
            "    static void delete(File file)\n    {\n        try\n        {\n            if (logger.isTraceEnabled())\n                logger.trace(\"Deleting {}\", file);\n\n            Files.delete(file.toPath());\n        }\n        catch (NoSuchFileException e)\n        {\n            logger.error(\"Unable to delete {} as it does not exist, see debug log file for stack trace\", file);\n            if (logger.isDebugEnabled())\n            {\n                ByteArrayOutputStream baos = new ByteArrayOutputStream();\n                try (PrintStream ps = new PrintStream(baos))\n                {\n                    e.printStackTrace(ps);\n                }\n                logger.debug(\"Unable to delete {} as it does not exist, stack trace:\\n {}\", file, baos);\n            }\n        }\n        catch (IOException e)\n        {\n            logger.error(\"Unable to delete {}\", file, e);\n            throw new RuntimeException(e);\n        }\n    }"
        ],
        [
            "TimeWindowCompactionStrategyOptions::TimeWindowCompactionStrategyOptions(Map)",
            "  61  \n  62  \n  63  \n  64  \n  65  \n  66 -\n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  ",
            "    public TimeWindowCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution.toString());\n\n        optionValue = options.get(COMPACTION_WINDOW_UNIT_KEY);\n        sstableWindowUnit = optionValue == null ? DEFAULT_COMPACTION_WINDOW_UNIT : TimeUnit.valueOf(optionValue);\n\n        optionValue = options.get(COMPACTION_WINDOW_SIZE_KEY);\n        sstableWindowSize = optionValue == null ? DEFAULT_COMPACTION_WINDOW_SIZE : Integer.parseInt(optionValue);\n\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n\n        optionValue = options.get(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_KEY);\n        ignoreOverlaps = optionValue == null ? DEFAULT_UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION : (Boolean.getBoolean(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_PROPERTY) && Boolean.parseBoolean(optionValue));\n\n        stcsOptions = new SizeTieredCompactionStrategyOptions(options);\n    }",
            "  61  \n  62  \n  63  \n  64  \n  65  \n  66 +\n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  ",
            "    public TimeWindowCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution);\n\n        optionValue = options.get(COMPACTION_WINDOW_UNIT_KEY);\n        sstableWindowUnit = optionValue == null ? DEFAULT_COMPACTION_WINDOW_UNIT : TimeUnit.valueOf(optionValue);\n\n        optionValue = options.get(COMPACTION_WINDOW_SIZE_KEY);\n        sstableWindowSize = optionValue == null ? DEFAULT_COMPACTION_WINDOW_SIZE : Integer.parseInt(optionValue);\n\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n\n        optionValue = options.get(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_KEY);\n        ignoreOverlaps = optionValue == null ? DEFAULT_UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION : (Boolean.getBoolean(UNSAFE_AGGRESSIVE_SSTABLE_EXPIRATION_PROPERTY) && Boolean.parseBoolean(optionValue));\n\n        stcsOptions = new SizeTieredCompactionStrategyOptions(options);\n    }"
        ],
        [
            "DateTieredCompactionStrategyOptions::DateTieredCompactionStrategyOptions(Map)",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57 -\n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "    public DateTieredCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution.toString());\n        optionValue = options.get(MAX_SSTABLE_AGE_KEY);\n        double fractionalDays = optionValue == null ? DEFAULT_MAX_SSTABLE_AGE_DAYS : Double.parseDouble(optionValue);\n        maxSSTableAge = Math.round(fractionalDays * timestampResolution.convert(1, TimeUnit.DAYS));\n        optionValue = options.get(BASE_TIME_KEY);\n        baseTime = timestampResolution.convert(optionValue == null ? DEFAULT_BASE_TIME_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(MAX_WINDOW_SIZE_KEY);\n        maxWindowSize = timestampResolution.convert(optionValue == null ? DEFAULT_MAX_WINDOW_SIZE_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n    }",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57 +\n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "    public DateTieredCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        if (timestampResolution != DEFAULT_TIMESTAMP_RESOLUTION)\n            logger.warn(\"Using a non-default timestamp_resolution {} - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?\", timestampResolution);\n        optionValue = options.get(MAX_SSTABLE_AGE_KEY);\n        double fractionalDays = optionValue == null ? DEFAULT_MAX_SSTABLE_AGE_DAYS : Double.parseDouble(optionValue);\n        maxSSTableAge = Math.round(fractionalDays * timestampResolution.convert(1, TimeUnit.DAYS));\n        optionValue = options.get(BASE_TIME_KEY);\n        baseTime = timestampResolution.convert(optionValue == null ? DEFAULT_BASE_TIME_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY);\n        expiredSSTableCheckFrequency = TimeUnit.MILLISECONDS.convert(optionValue == null ? DEFAULT_EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n        optionValue = options.get(MAX_WINDOW_SIZE_KEY);\n        maxWindowSize = timestampResolution.convert(optionValue == null ? DEFAULT_MAX_WINDOW_SIZE_SECONDS : Long.parseLong(optionValue), TimeUnit.SECONDS);\n    }"
        ],
        [
            "InboundHandshakeHandler::handleStart(ChannelHandlerContext,ByteBuf)",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169 -\n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  ",
            "    /**\n     * Handles receiving the first message in the internode messaging handshake protocol. If the sender's protocol version\n     * is accepted, we respond with the second message of the handshake protocol.\n     */\n    @VisibleForTesting\n    State handleStart(ChannelHandlerContext ctx, ByteBuf in) throws IOException\n    {\n        FirstHandshakeMessage msg = FirstHandshakeMessage.maybeDecode(in);\n        if (msg == null)\n            return State.START;\n\n        logger.trace(\"received first handshake message from peer {}, message = {}\", ctx.channel().remoteAddress(), msg);\n        version = msg.messagingVersion;\n\n        if (msg.mode == NettyFactory.Mode.STREAMING)\n        {\n            // streaming connections are per-session and have a fixed version.  we can't do anything with a wrong-version stream connection, so drop it.\n            if (version != StreamMessage.CURRENT_VERSION)\n            {\n                logger.warn(\"Received stream using protocol version %d (my version %d). Terminating connection\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            setupStreamingPipeline(ctx, version);\n            return State.HANDSHAKE_COMPLETE;\n        }\n        else\n        {\n            if (version < MessagingService.VERSION_30)\n            {\n                logger.error(\"Unable to read obsolete message version {} from {}; The earliest version supported is 3.0.0\", version, ctx.channel().remoteAddress());\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            logger.trace(\"Connection version {} from {}\", version, ctx.channel().remoteAddress());\n            compressed = msg.compressionEnabled;\n\n            // if this version is < the MS version the other node is trying\n            // to connect with, the other node will disconnect\n            ctx.writeAndFlush(new SecondHandshakeMessage(MessagingService.current_version).encode(ctx.alloc()))\n               .addListener(ChannelFutureListener.CLOSE_ON_FAILURE);\n\n            // outbound side will reconnect to change the version\n            if (version > MessagingService.current_version)\n            {\n                logger.info(\"peer wants to use a messaging version higher ({}) than what this node supports ({})\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            long timeout = TimeUnit.MILLISECONDS.toNanos(DatabaseDescriptor.getRpcTimeout());\n            handshakeTimeout = ctx.executor().schedule(() -> failHandshake(ctx), timeout, TimeUnit.MILLISECONDS);\n            return State.AWAIT_MESSAGING_START_RESPONSE;\n        }\n    }",
            " 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169 +\n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  ",
            "    /**\n     * Handles receiving the first message in the internode messaging handshake protocol. If the sender's protocol version\n     * is accepted, we respond with the second message of the handshake protocol.\n     */\n    @VisibleForTesting\n    State handleStart(ChannelHandlerContext ctx, ByteBuf in) throws IOException\n    {\n        FirstHandshakeMessage msg = FirstHandshakeMessage.maybeDecode(in);\n        if (msg == null)\n            return State.START;\n\n        logger.trace(\"received first handshake message from peer {}, message = {}\", ctx.channel().remoteAddress(), msg);\n        version = msg.messagingVersion;\n\n        if (msg.mode == NettyFactory.Mode.STREAMING)\n        {\n            // streaming connections are per-session and have a fixed version.  we can't do anything with a wrong-version stream connection, so drop it.\n            if (version != StreamMessage.CURRENT_VERSION)\n            {\n                logger.warn(\"Received stream using protocol version {} (my version {}). Terminating connection\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            setupStreamingPipeline(ctx, version);\n            return State.HANDSHAKE_COMPLETE;\n        }\n        else\n        {\n            if (version < MessagingService.VERSION_30)\n            {\n                logger.error(\"Unable to read obsolete message version {} from {}; The earliest version supported is 3.0.0\", version, ctx.channel().remoteAddress());\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            logger.trace(\"Connection version {} from {}\", version, ctx.channel().remoteAddress());\n            compressed = msg.compressionEnabled;\n\n            // if this version is < the MS version the other node is trying\n            // to connect with, the other node will disconnect\n            ctx.writeAndFlush(new SecondHandshakeMessage(MessagingService.current_version).encode(ctx.alloc()))\n               .addListener(ChannelFutureListener.CLOSE_ON_FAILURE);\n\n            // outbound side will reconnect to change the version\n            if (version > MessagingService.current_version)\n            {\n                logger.info(\"peer wants to use a messaging version higher ({}) than what this node supports ({})\", version, MessagingService.current_version);\n                ctx.close();\n                return State.HANDSHAKE_FAIL;\n            }\n\n            long timeout = TimeUnit.MILLISECONDS.toNanos(DatabaseDescriptor.getRpcTimeout());\n            handshakeTimeout = ctx.executor().schedule(() -> failHandshake(ctx), timeout, TimeUnit.MILLISECONDS);\n            return State.AWAIT_MESSAGING_START_RESPONSE;\n        }\n    }"
        ],
        [
            "DynamicCompositeType::validateComparator(int,ByteBuffer)",
            " 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202 -\n 203  \n 204 -\n 205  \n 206 -\n 207 -\n 208  \n 209  \n 210  \n 211 -\n 212  \n 213 -\n 214 -\n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  ",
            "    protected AbstractType<?> validateComparator(int i, ByteBuffer bb) throws MarshalException\n    {\n        AbstractType<?> comparator = null;\n        if (bb.remaining() < 2)\n            throw new MarshalException(\"Not enough bytes to header of the comparator part of component \" + i);\n        int header = ByteBufferUtil.readShortLength(bb);\n        if ((header & 0x8000) == 0)\n        {\n            if (bb.remaining() < header)\n                throw new MarshalException(\"Not enough bytes to read comparator name of component \" + i);\n\n            ByteBuffer value = ByteBufferUtil.readBytes(bb, header);\n            String valueStr = null;\n            try\n            {\n                valueStr = ByteBufferUtil.string(value);\n                comparator = TypeParser.parse(valueStr);\n            }\n            catch (CharacterCodingException ce) \n            {\n                // ByteBufferUtil.string failed. \n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed with [{}] when decoding the byte buffer in ByteBufferUtil.string()\", \n                   ce.toString());\n            }\n            catch (Exception e)\n            {\n                // parse failed. \n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed to parse value string \\\"{}\\\" with exception: [{}]\", \n                   valueStr, e.toString());\n            }\n        }\n        else\n        {\n            comparator = aliases.get((byte)(header & 0xFF));\n        }\n\n        if (comparator == null)\n            throw new MarshalException(\"Cannot find comparator for component \" + i);\n        else\n            return comparator;\n    }",
            " 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202 +\n 203  \n 204 +\n 205  \n 206 +\n 207 +\n 208  \n 209  \n 210  \n 211 +\n 212  \n 213 +\n 214 +\n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  ",
            "    protected AbstractType<?> validateComparator(int i, ByteBuffer bb) throws MarshalException\n    {\n        AbstractType<?> comparator = null;\n        if (bb.remaining() < 2)\n            throw new MarshalException(\"Not enough bytes to header of the comparator part of component \" + i);\n        int header = ByteBufferUtil.readShortLength(bb);\n        if ((header & 0x8000) == 0)\n        {\n            if (bb.remaining() < header)\n                throw new MarshalException(\"Not enough bytes to read comparator name of component \" + i);\n\n            ByteBuffer value = ByteBufferUtil.readBytes(bb, header);\n            String valueStr = null;\n            try\n            {\n                valueStr = ByteBufferUtil.string(value);\n                comparator = TypeParser.parse(valueStr);\n            }\n            catch (CharacterCodingException ce)\n            {\n                // ByteBufferUtil.string failed.\n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed with [{}] when decoding the byte buffer in ByteBufferUtil.string()\",\n                   ce);\n            }\n            catch (Exception e)\n            {\n                // parse failed.\n                // Log it here and we'll further throw an exception below since comparator == null\n                logger.error(\"Failed to parse value string \\\"{}\\\" with exception: [{}]\",\n                   valueStr, e);\n            }\n        }\n        else\n        {\n            comparator = aliases.get((byte)(header & 0xFF));\n        }\n\n        if (comparator == null)\n            throw new MarshalException(\"Cannot find comparator for component \" + i);\n        else\n            return comparator;\n    }"
        ],
        [
            "InboundHandshakeHandler::decode(ChannelHandlerContext,ByteBuf,List)",
            "  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94 -\n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  ",
            "    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)\n    {\n        try\n        {\n            if (!hasAuthenticated)\n            {\n                logSecureSocketDetails(ctx);\n                if (!handleAuthenticate(ctx.channel().remoteAddress(), ctx))\n                    return;\n            }\n\n            switch (state)\n            {\n                case START:\n                    state = handleStart(ctx, in);\n                    break;\n                case AWAIT_MESSAGING_START_RESPONSE:\n                    state = handleMessagingStartResponse(ctx, in);\n                    break;\n                case HANDSHAKE_FAIL:\n                    throw new IllegalStateException(\"channel should be closed after determining the handshake failed with peer: \" + ctx.channel().remoteAddress());\n                default:\n                    logger.error(\"unhandled state: \" + state);\n                    state = State.HANDSHAKE_FAIL;\n                    ctx.close();\n            }\n        }\n        catch (Exception e)\n        {\n            logger.error(\"unexpected error while negotiating internode messaging handshake\", e);\n            state = State.HANDSHAKE_FAIL;\n            ctx.close();\n        }\n    }",
            "  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94 +\n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  ",
            "    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out)\n    {\n        try\n        {\n            if (!hasAuthenticated)\n            {\n                logSecureSocketDetails(ctx);\n                if (!handleAuthenticate(ctx.channel().remoteAddress(), ctx))\n                    return;\n            }\n\n            switch (state)\n            {\n                case START:\n                    state = handleStart(ctx, in);\n                    break;\n                case AWAIT_MESSAGING_START_RESPONSE:\n                    state = handleMessagingStartResponse(ctx, in);\n                    break;\n                case HANDSHAKE_FAIL:\n                    throw new IllegalStateException(\"channel should be closed after determining the handshake failed with peer: \" + ctx.channel().remoteAddress());\n                default:\n                    logger.error(\"unhandled state: {}\", state);\n                    state = State.HANDSHAKE_FAIL;\n                    ctx.close();\n            }\n        }\n        catch (Exception e)\n        {\n            logger.error(\"unexpected error while negotiating internode messaging handshake\", e);\n            state = State.HANDSHAKE_FAIL;\n            ctx.close();\n        }\n    }"
        ]
    ],
    "f970de55746dd074843d8cfd5385b12acda56ee9": [
        [
            "CqlRecordWriter::RangeClient::run()",
            " 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324 -\n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  ",
            "        /**\n         * Loops collecting cql binded variable values from the queue and sending to Cassandra\n         */\n        public void run()\n        {\n            outer:\n            while (run || !queue.isEmpty())\n            {\n                List<ByteBuffer> bindVariables;\n                try\n                {\n                    bindVariables = queue.take();\n                }\n                catch (InterruptedException e)\n                {\n                    // re-check loop condition after interrupt\n                    continue;\n                }\n\n                ListIterator<InetAddress> iter = endpoints.listIterator();\n                while (true)\n                {\n                    // send the mutation to the last-used endpoint.  first time through, this will NPE harmlessly.\n\n                    // attempt to connect to a different endpoint\n                    try\n                    {\n                        InetAddress address = iter.next();\n                        String host = address.getHostName();\n                        client = CqlConfigHelper.getOutputCluster(host, conf).connect();\n                    }\n                    catch (Exception e)\n                    {\n                        //If connection died due to Interrupt, just try connecting to the endpoint again.\n                        if (Thread.interrupted()) {\n                            lastException = new IOException(e);\n                            iter.previous();\n                        }\n                        closeInternal();\n\n                        // Most exceptions mean something unexpected went wrong to that endpoint, so\n                        // we should try again to another.  Other exceptions (auth or invalid request) are fatal.\n                        if ((e instanceof AuthenticationException || e instanceof InvalidQueryException) || !iter.hasNext())\n                        {\n                            lastException = new IOException(e);\n                            break outer;\n                        }\n                    }\n\n                    try\n                    {\n                        int i = 0;\n                        PreparedStatement statement = preparedStatement(client);\n                        while (bindVariables != null)\n                        {\n                            BoundStatement boundStatement = new BoundStatement(statement);\n                            for (int columnPosition = 0; columnPosition < bindVariables.size(); columnPosition++)\n                            {\n                                boundStatement.setBytesUnsafe(columnPosition, bindVariables.get(columnPosition));\n                            }\n                            client.execute(boundStatement);\n                            i++;\n                            \n                            if (i >= batchThreshold)\n                                break;\n                            bindVariables = queue.poll();\n                        }\n                        break;\n                    }\n                    catch (Exception e)\n                    {\n                        closeInternal();\n                        if (!iter.hasNext())\n                        {\n                            lastException = new IOException(e);\n                            break outer;\n                        }\n                    }\n\n                }\n            }\n            // close all our connections once we are done.\n            closeInternal();\n        }",
            " 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325 +\n 326 +\n 327 +\n 328 +\n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341 +\n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  ",
            "        /**\n         * Loops collecting cql binded variable values from the queue and sending to Cassandra\n         */\n        public void run()\n        {\n            outer:\n            while (run || !queue.isEmpty())\n            {\n                List<ByteBuffer> bindVariables;\n                try\n                {\n                    bindVariables = queue.take();\n                }\n                catch (InterruptedException e)\n                {\n                    // re-check loop condition after interrupt\n                    continue;\n                }\n\n                ListIterator<InetAddress> iter = endpoints.listIterator();\n                while (true)\n                {\n                    // send the mutation to the last-used endpoint.  first time through, this will NPE harmlessly.\n\n                    // attempt to connect to a different endpoint\n                    try\n                    {\n                        InetAddress address = iter.next();\n                        String host = address.getHostName();\n                        client = CqlConfigHelper.getOutputCluster(host, conf).connect();\n                    }\n                    catch (Exception e)\n                    {\n                        //If connection died due to Interrupt, just try connecting to the endpoint again.\n                        //There are too many ways for the Thread.interrupted() state to be cleared, so\n                        //we can't rely on that here. Until the java driver gives us a better way of knowing\n                        //that this exception came from an InterruptedException, this is the best solution.\n                        if (e instanceof DriverException && e.getMessage().contains(\"Connection thread interrupted\")) {\n                            lastException = new IOException(e);\n                            iter.previous();\n                        }\n                        closeInternal();\n\n                        // Most exceptions mean something unexpected went wrong to that endpoint, so\n                        // we should try again to another.  Other exceptions (auth or invalid request) are fatal.\n                        if ((e instanceof AuthenticationException || e instanceof InvalidQueryException) || !iter.hasNext())\n                        {\n                            lastException = new IOException(e);\n                            break outer;\n                        }\n                        continue;\n                    }\n\n                    try\n                    {\n                        int i = 0;\n                        PreparedStatement statement = preparedStatement(client);\n                        while (bindVariables != null)\n                        {\n                            BoundStatement boundStatement = new BoundStatement(statement);\n                            for (int columnPosition = 0; columnPosition < bindVariables.size(); columnPosition++)\n                            {\n                                boundStatement.setBytesUnsafe(columnPosition, bindVariables.get(columnPosition));\n                            }\n                            client.execute(boundStatement);\n                            i++;\n                            \n                            if (i >= batchThreshold)\n                                break;\n                            bindVariables = queue.poll();\n                        }\n                        break;\n                    }\n                    catch (Exception e)\n                    {\n                        closeInternal();\n                        if (!iter.hasNext())\n                        {\n                            lastException = new IOException(e);\n                            break outer;\n                        }\n                    }\n\n                }\n            }\n            // close all our connections once we are done.\n            closeInternal();\n        }"
        ]
    ],
    "d766f4fb20af4914b54420e22af0de909eb180ed": [
        [
            "CQLSSTableWriterTest::testForbidCounterUpdates()",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161 -\n 162  \n 163  ",
            "    @Test(expected = IllegalArgumentException.class)\n    public void testForbidCounterUpdates() throws Exception\n    {\n        String KS = \"cql_keyspace\";\n        String TABLE = \"counter1\";\n\n        File tempdir = Files.createTempDir();\n        File dataDir = new File(tempdir.getAbsolutePath() + File.separator + KS + File.separator + TABLE);\n        assert dataDir.mkdirs();\n\n        String schema = \"CREATE TABLE cql_keyspace.counter1 (\" +\n                        \"  my_id int, \" +\n                        \"  my_counter counter, \" +\n                        \"  PRIMARY KEY (my_id)\" +\n                        \")\";\n        String insert = String.format(\"UPDATE cql_keyspace.counter1 SET my_counter = my_counter - ? WHERE my_id = ?\");\n        CQLSSTableWriter.builder().inDirectory(dataDir)\n                        .forTable(schema)\n                        .withPartitioner(StorageService.instance.getPartitioner())\n                        .using(insert).build();\n    }",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161 +\n 162  \n 163  ",
            "    @Test(expected = IllegalArgumentException.class)\n    public void testForbidCounterUpdates() throws Exception\n    {\n        String KS = \"cql_keyspace\";\n        String TABLE = \"counter1\";\n\n        File tempdir = Files.createTempDir();\n        File dataDir = new File(tempdir.getAbsolutePath() + File.separator + KS + File.separator + TABLE);\n        assert dataDir.mkdirs();\n\n        String schema = \"CREATE TABLE cql_keyspace.counter1 (\" +\n                        \"  my_id int, \" +\n                        \"  my_counter counter, \" +\n                        \"  PRIMARY KEY (my_id)\" +\n                        \")\";\n        String insert = String.format(\"UPDATE cql_keyspace.counter1 SET my_counter = my_counter - ? WHERE my_id = ?\");\n        CQLSSTableWriter.builder().inDirectory(dataDir)\n                        .forTable(schema)\n                        .withPartitioner(Murmur3Partitioner.instance)\n                        .using(insert).build();\n    }"
        ]
    ],
    "ebd0aaefe54d8a1349a54d904831e1d9e5e812bf": [
        [
            "CompactionManager::performAnticompaction(ColumnFamilyStore,Collection,Refs,LifecycleTransaction,long,UUID,UUID)",
            " 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631 -\n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  ",
            "    /**\n     * Make sure the {validatedForRepair} are marked for compaction before calling this.\n     *\n     * Caller must reference the validatedForRepair sstables (via ParentRepairSession.getActiveRepairedSSTableRefs(..)).\n     *\n     * @param cfs\n     * @param ranges Ranges that the repair was carried out on\n     * @param validatedForRepair SSTables containing the repaired ranges. Should be referenced before passing them.\n     * @param parentRepairSession parent repair session ID\n     * @throws InterruptedException\n     * @throws IOException\n     */\n    public void performAnticompaction(ColumnFamilyStore cfs,\n                                      Collection<Range<Token>> ranges,\n                                      Refs<SSTableReader> validatedForRepair,\n                                      LifecycleTransaction txn,\n                                      long repairedAt,\n                                      UUID pendingRepair,\n                                      UUID parentRepairSession) throws InterruptedException, IOException\n    {\n        ActiveRepairService.ParentRepairSession prs = ActiveRepairService.instance.getParentRepairSession(parentRepairSession);\n        Preconditions.checkArgument(!prs.isPreview(), \"Cannot anticompact for previews\");\n\n        logger.info(\"{} Starting anticompaction for {}.{} on {}/{} sstables\", PreviewKind.NONE.logPrefix(parentRepairSession), cfs.keyspace.getName(), cfs.getTableName(), validatedForRepair.size(), cfs.getLiveSSTables());\n        logger.trace(\"{} Starting anticompaction for ranges {}\", PreviewKind.NONE.logPrefix(parentRepairSession), ranges);\n        Set<SSTableReader> sstables = new HashSet<>(validatedForRepair);\n        Set<SSTableReader> mutatedRepairStatuses = new HashSet<>();\n        // we should only notify that repair status changed if it actually did:\n        Set<SSTableReader> mutatedRepairStatusToNotify = new HashSet<>();\n        Map<SSTableReader, Boolean> wasRepairedBefore = new HashMap<>();\n        for (SSTableReader sstable : sstables)\n            wasRepairedBefore.put(sstable, sstable.isRepaired());\n\n        Set<SSTableReader> nonAnticompacting = new HashSet<>();\n\n        Iterator<SSTableReader> sstableIterator = sstables.iterator();\n        try\n        {\n            List<Range<Token>> normalizedRanges = Range.normalize(ranges);\n\n            while (sstableIterator.hasNext())\n            {\n                SSTableReader sstable = sstableIterator.next();\n\n                Range<Token> sstableRange = new Range<>(sstable.first.getToken(), sstable.last.getToken());\n\n                boolean shouldAnticompact = false;\n\n                for (Range<Token> r : normalizedRanges)\n                {\n                    if (r.contains(sstableRange))\n                    {\n                        logger.info(\"{} SSTable {} fully contained in range {}, mutating repairedAt instead of anticompacting\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, r);\n                        sstable.descriptor.getMetadataSerializer().mutateRepaired(sstable.descriptor, repairedAt, pendingRepair);\n                        sstable.reloadSSTableMetadata();\n                        mutatedRepairStatuses.add(sstable);\n                        if (!wasRepairedBefore.get(sstable))\n                            mutatedRepairStatusToNotify.add(sstable);\n                        sstableIterator.remove();\n                        shouldAnticompact = true;\n                        break;\n                    }\n                    else if (sstableRange.intersects(r))\n                    {\n                        logger.info(\"{} SSTable {} ({}) will be anticompacted on range {}\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, r);\n                        shouldAnticompact = true;\n                    }\n                }\n\n                if (!shouldAnticompact)\n                {\n                    logger.info(\"{} SSTable {} ({}) does not intersect repaired ranges {}, not touching repairedAt.\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, normalizedRanges);\n                    nonAnticompacting.add(sstable);\n                    sstableIterator.remove();\n                }\n            }\n            cfs.metric.bytesMutatedAnticompaction.inc(SSTableReader.getTotalBytes(mutatedRepairStatuses));\n            cfs.getTracker().notifySSTableRepairedStatusChanged(mutatedRepairStatusToNotify);\n            txn.cancel(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            validatedForRepair.release(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            assert txn.originals().equals(sstables);\n            if (!sstables.isEmpty())\n                doAntiCompaction(cfs, ranges, txn, repairedAt, pendingRepair);\n            txn.finish();\n        }\n        finally\n        {\n            validatedForRepair.release();\n            txn.close();\n        }\n\n        logger.info(\"{} Completed anticompaction successfully\", PreviewKind.NONE.logPrefix(parentRepairSession));\n    }",
            " 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631 +\n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  ",
            "    /**\n     * Make sure the {validatedForRepair} are marked for compaction before calling this.\n     *\n     * Caller must reference the validatedForRepair sstables (via ParentRepairSession.getActiveRepairedSSTableRefs(..)).\n     *\n     * @param cfs\n     * @param ranges Ranges that the repair was carried out on\n     * @param validatedForRepair SSTables containing the repaired ranges. Should be referenced before passing them.\n     * @param parentRepairSession parent repair session ID\n     * @throws InterruptedException\n     * @throws IOException\n     */\n    public void performAnticompaction(ColumnFamilyStore cfs,\n                                      Collection<Range<Token>> ranges,\n                                      Refs<SSTableReader> validatedForRepair,\n                                      LifecycleTransaction txn,\n                                      long repairedAt,\n                                      UUID pendingRepair,\n                                      UUID parentRepairSession) throws InterruptedException, IOException\n    {\n        ActiveRepairService.ParentRepairSession prs = ActiveRepairService.instance.getParentRepairSession(parentRepairSession);\n        Preconditions.checkArgument(!prs.isPreview(), \"Cannot anticompact for previews\");\n\n        logger.info(\"{} Starting anticompaction for {}.{} on {}/{} sstables\", PreviewKind.NONE.logPrefix(parentRepairSession), cfs.keyspace.getName(), cfs.getTableName(), validatedForRepair.size(), cfs.getLiveSSTables().size());\n        logger.trace(\"{} Starting anticompaction for ranges {}\", PreviewKind.NONE.logPrefix(parentRepairSession), ranges);\n        Set<SSTableReader> sstables = new HashSet<>(validatedForRepair);\n        Set<SSTableReader> mutatedRepairStatuses = new HashSet<>();\n        // we should only notify that repair status changed if it actually did:\n        Set<SSTableReader> mutatedRepairStatusToNotify = new HashSet<>();\n        Map<SSTableReader, Boolean> wasRepairedBefore = new HashMap<>();\n        for (SSTableReader sstable : sstables)\n            wasRepairedBefore.put(sstable, sstable.isRepaired());\n\n        Set<SSTableReader> nonAnticompacting = new HashSet<>();\n\n        Iterator<SSTableReader> sstableIterator = sstables.iterator();\n        try\n        {\n            List<Range<Token>> normalizedRanges = Range.normalize(ranges);\n\n            while (sstableIterator.hasNext())\n            {\n                SSTableReader sstable = sstableIterator.next();\n\n                Range<Token> sstableRange = new Range<>(sstable.first.getToken(), sstable.last.getToken());\n\n                boolean shouldAnticompact = false;\n\n                for (Range<Token> r : normalizedRanges)\n                {\n                    if (r.contains(sstableRange))\n                    {\n                        logger.info(\"{} SSTable {} fully contained in range {}, mutating repairedAt instead of anticompacting\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, r);\n                        sstable.descriptor.getMetadataSerializer().mutateRepaired(sstable.descriptor, repairedAt, pendingRepair);\n                        sstable.reloadSSTableMetadata();\n                        mutatedRepairStatuses.add(sstable);\n                        if (!wasRepairedBefore.get(sstable))\n                            mutatedRepairStatusToNotify.add(sstable);\n                        sstableIterator.remove();\n                        shouldAnticompact = true;\n                        break;\n                    }\n                    else if (sstableRange.intersects(r))\n                    {\n                        logger.info(\"{} SSTable {} ({}) will be anticompacted on range {}\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, r);\n                        shouldAnticompact = true;\n                    }\n                }\n\n                if (!shouldAnticompact)\n                {\n                    logger.info(\"{} SSTable {} ({}) does not intersect repaired ranges {}, not touching repairedAt.\", PreviewKind.NONE.logPrefix(parentRepairSession), sstable, sstableRange, normalizedRanges);\n                    nonAnticompacting.add(sstable);\n                    sstableIterator.remove();\n                }\n            }\n            cfs.metric.bytesMutatedAnticompaction.inc(SSTableReader.getTotalBytes(mutatedRepairStatuses));\n            cfs.getTracker().notifySSTableRepairedStatusChanged(mutatedRepairStatusToNotify);\n            txn.cancel(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            validatedForRepair.release(Sets.union(nonAnticompacting, mutatedRepairStatuses));\n            assert txn.originals().equals(sstables);\n            if (!sstables.isEmpty())\n                doAntiCompaction(cfs, ranges, txn, repairedAt, pendingRepair);\n            txn.finish();\n        }\n        finally\n        {\n            validatedForRepair.release();\n            txn.close();\n        }\n\n        logger.info(\"{} Completed anticompaction successfully\", PreviewKind.NONE.logPrefix(parentRepairSession));\n    }"
        ]
    ],
    "ba926ff6d8c09834d5c45f4eae8d75d9051b1058": [
        [
            "SettingsNode::SettingsNode(Options)",
            "  37  \n  38  \n  39  \n  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  ",
            "    public SettingsNode(Options options)\n    {\n        if (options.file.setByUser())\n        {\n            try\n            {\n                String node;\n                List<String> tmpNodes = new ArrayList<String>();\n                BufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream(options.file.value())));\n                try\n                {\n                    while ((node = in.readLine()) != null)\n                    {\n                        if (node.length() > 0)\n                            tmpNodes.add(node);\n                    }\n                    nodes = Arrays.asList(tmpNodes.toArray(new String[tmpNodes.size()]));\n                }\n                finally\n                {\n                    in.close();\n                }\n            }\n            catch(IOException ioe)\n            {\n                throw new RuntimeException(ioe);\n            }\n\n        }\n        else\n            nodes = Arrays.asList(options.list.value().split(\",\"));\n        isWhiteList = options.whitelist.setByUser();\n    }",
            "  38  \n  39  \n  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68 +\n  69  \n  70 +\n  71 +\n  72  \n  73 +\n  74  ",
            "    public SettingsNode(Options options)\n    {\n        if (options.file.setByUser())\n        {\n            try\n            {\n                String node;\n                List<String> tmpNodes = new ArrayList<String>();\n                BufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream(options.file.value())));\n                try\n                {\n                    while ((node = in.readLine()) != null)\n                    {\n                        if (node.length() > 0)\n                            tmpNodes.add(node);\n                    }\n                    nodes = Arrays.asList(tmpNodes.toArray(new String[tmpNodes.size()]));\n                }\n                finally\n                {\n                    in.close();\n                }\n            }\n            catch(IOException ioe)\n            {\n                throw new RuntimeException(ioe);\n            }\n\n        }\n        else\n        {\n            nodes = Arrays.asList(options.list.value().split(\",\"));\n        }\n\n        isWhiteList = options.whitelist.setByUser();\n        datacenter = options.datacenter.value();\n    }"
        ],
        [
            "SettingsNode::Options::options()",
            " 142  \n 143  \n 144  \n 145 -\n 146  ",
            "        @Override\n        public List<? extends Option> options()\n        {\n            return Arrays.asList(whitelist, file, list);\n        }",
            " 148  \n 149  \n 150  \n 151 +\n 152  ",
            "        @Override\n        public List<? extends Option> options()\n        {\n            return Arrays.asList(datacenter, whitelist, file, list);\n        }"
        ],
        [
            "JavaDriverClient::JavaDriverClient(StressSettings,String,int,EncryptionOptions)",
            "  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73 -\n  74  \n  75 -\n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  ",
            "    public JavaDriverClient(StressSettings settings, String host, int port, EncryptionOptions.ClientEncryptionOptions encryptionOptions)\n    {\n        this.protocolVersion = settings.mode.protocolVersion;\n        this.host = host;\n        this.port = port;\n        this.username = settings.mode.username;\n        this.password = settings.mode.password;\n        this.authProvider = settings.mode.authProvider;\n        this.encryptionOptions = encryptionOptions;\n        if (settings.node.isWhiteList)\n            whitelist = new WhiteListPolicy(DCAwareRoundRobinPolicy.builder().build(), settings.node.resolveAll(settings.port.nativePort));\n        else\n            whitelist = null;\n        connectionsPerHost = settings.mode.connectionsPerHost == null ? 8 : settings.mode.connectionsPerHost;\n\n        int maxThreadCount = 0;\n        if (settings.rate.auto)\n            maxThreadCount = settings.rate.maxThreads;\n        else\n            maxThreadCount = settings.rate.threadCount;\n\n        //Always allow enough pending requests so every thread can have a request pending\n        //See https://issues.apache.org/jira/browse/CASSANDRA-7217\n        int requestsPerConnection = (maxThreadCount / connectionsPerHost) + connectionsPerHost;\n\n        maxPendingPerConnection = settings.mode.maxPendingPerConnection == null ? Math.max(128, requestsPerConnection ) : settings.mode.maxPendingPerConnection;\n    }",
            "  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73 +\n  74 +\n  75 +\n  76 +\n  77 +\n  78  \n  79 +\n  80 +\n  81 +\n  82  \n  83 +\n  84 +\n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  ",
            "    public JavaDriverClient(StressSettings settings, String host, int port, EncryptionOptions.ClientEncryptionOptions encryptionOptions)\n    {\n        this.protocolVersion = settings.mode.protocolVersion;\n        this.host = host;\n        this.port = port;\n        this.username = settings.mode.username;\n        this.password = settings.mode.password;\n        this.authProvider = settings.mode.authProvider;\n        this.encryptionOptions = encryptionOptions;\n\n        DCAwareRoundRobinPolicy.Builder policyBuilder = DCAwareRoundRobinPolicy.builder();\n        if (settings.node.datacenter != null)\n            policyBuilder.withLocalDc(settings.node.datacenter);\n\n        if (settings.node.isWhiteList)\n            loadBalancingPolicy = new WhiteListPolicy(policyBuilder.build(), settings.node.resolveAll(settings.port.nativePort));\n        else if (settings.node.datacenter != null)\n            loadBalancingPolicy = policyBuilder.build();\n        else\n            loadBalancingPolicy = null;\n\n        connectionsPerHost = settings.mode.connectionsPerHost == null ? 8 : settings.mode.connectionsPerHost;\n\n        int maxThreadCount = 0;\n        if (settings.rate.auto)\n            maxThreadCount = settings.rate.maxThreads;\n        else\n            maxThreadCount = settings.rate.threadCount;\n\n        //Always allow enough pending requests so every thread can have a request pending\n        //See https://issues.apache.org/jira/browse/CASSANDRA-7217\n        int requestsPerConnection = (maxThreadCount / connectionsPerHost) + connectionsPerHost;\n\n        maxPendingPerConnection = settings.mode.maxPendingPerConnection == null ? Math.max(128, requestsPerConnection ) : settings.mode.maxPendingPerConnection;\n    }"
        ],
        [
            "JavaDriverClient::connect(ProtocolOptions)",
            " 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122 -\n 123 -\n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  ",
            "    public void connect(ProtocolOptions.Compression compression) throws Exception\n    {\n\n        PoolingOptions poolingOpts = new PoolingOptions()\n                                     .setConnectionsPerHost(HostDistance.LOCAL, connectionsPerHost, connectionsPerHost)\n                                     .setMaxRequestsPerConnection(HostDistance.LOCAL, maxPendingPerConnection)\n                                     .setNewConnectionThreshold(HostDistance.LOCAL, 100);\n\n        Cluster.Builder clusterBuilder = Cluster.builder()\n                                                .addContactPoint(host)\n                                                .withPort(port)\n                                                .withPoolingOptions(poolingOpts)\n                                                .withoutJMXReporting()\n                                                .withProtocolVersion(protocolVersion)\n                                                .withoutMetrics(); // The driver uses metrics 3 with conflict with our version\n        if (whitelist != null)\n            clusterBuilder.withLoadBalancingPolicy(whitelist);\n        clusterBuilder.withCompression(compression);\n        if (encryptionOptions.enabled)\n        {\n            SSLContext sslContext;\n            sslContext = SSLFactory.createSSLContext(encryptionOptions, true);\n            SSLOptions sslOptions = JdkSSLOptions.builder()\n                                                 .withSSLContext(sslContext)\n                                                 .withCipherSuites(encryptionOptions.cipher_suites).build();\n            clusterBuilder.withSSL(sslOptions);\n        }\n\n        if (authProvider != null)\n        {\n            clusterBuilder.withAuthProvider(authProvider);\n        }\n        else if (username != null)\n        {\n            clusterBuilder.withCredentials(username, password);\n        }\n\n        cluster = clusterBuilder.build();\n        Metadata metadata = cluster.getMetadata();\n        System.out.printf(\n                \"Connected to cluster: %s, max pending requests per connection %d, max connections per host %d%n\",\n                metadata.getClusterName(),\n                maxPendingPerConnection,\n                connectionsPerHost);\n        for (Host host : metadata.getAllHosts())\n        {\n            System.out.printf(\"Datatacenter: %s; Host: %s; Rack: %s%n\",\n                    host.getDatacenter(), host.getAddress(), host.getRack());\n        }\n\n        session = cluster.connect();\n    }",
            " 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131 +\n 132 +\n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  ",
            "    public void connect(ProtocolOptions.Compression compression) throws Exception\n    {\n\n        PoolingOptions poolingOpts = new PoolingOptions()\n                                     .setConnectionsPerHost(HostDistance.LOCAL, connectionsPerHost, connectionsPerHost)\n                                     .setMaxRequestsPerConnection(HostDistance.LOCAL, maxPendingPerConnection)\n                                     .setNewConnectionThreshold(HostDistance.LOCAL, 100);\n\n        Cluster.Builder clusterBuilder = Cluster.builder()\n                                                .addContactPoint(host)\n                                                .withPort(port)\n                                                .withPoolingOptions(poolingOpts)\n                                                .withoutJMXReporting()\n                                                .withProtocolVersion(protocolVersion)\n                                                .withoutMetrics(); // The driver uses metrics 3 with conflict with our version\n        if (loadBalancingPolicy != null)\n            clusterBuilder.withLoadBalancingPolicy(loadBalancingPolicy);\n        clusterBuilder.withCompression(compression);\n        if (encryptionOptions.enabled)\n        {\n            SSLContext sslContext;\n            sslContext = SSLFactory.createSSLContext(encryptionOptions, true);\n            SSLOptions sslOptions = JdkSSLOptions.builder()\n                                                 .withSSLContext(sslContext)\n                                                 .withCipherSuites(encryptionOptions.cipher_suites).build();\n            clusterBuilder.withSSL(sslOptions);\n        }\n\n        if (authProvider != null)\n        {\n            clusterBuilder.withAuthProvider(authProvider);\n        }\n        else if (username != null)\n        {\n            clusterBuilder.withCredentials(username, password);\n        }\n\n        cluster = clusterBuilder.build();\n        Metadata metadata = cluster.getMetadata();\n        System.out.printf(\n                \"Connected to cluster: %s, max pending requests per connection %d, max connections per host %d%n\",\n                metadata.getClusterName(),\n                maxPendingPerConnection,\n                connectionsPerHost);\n        for (Host host : metadata.getAllHosts())\n        {\n            System.out.printf(\"Datatacenter: %s; Host: %s; Rack: %s%n\",\n                    host.getDatacenter(), host.getAddress(), host.getRack());\n        }\n\n        session = cluster.connect();\n    }"
        ]
    ],
    "98a08ebcf11a5124ddf865b5337c781a11377588": [
        [
            "AbstractCommitLogService::AbstractCommitLogService(CommitLog,String,long)",
            "  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  ",
            "    /**\n     * CommitLogService provides a fsync service for Allocations, fulfilling either the\n     * Batch or Periodic contract.\n     *\n     * Subclasses may be notified when a sync finishes by using the syncComplete WaitQueue.\n     */\n    AbstractCommitLogService(final CommitLog commitLog, final String name, final long pollIntervalMillis)\n    {\n        if (pollIntervalMillis < 1)\n            throw new IllegalArgumentException(String.format(\"Commit log flush interval must be positive: %dms\", pollIntervalMillis));\n\n        Runnable runnable = new Runnable()\n        {\n            public void run()\n            {\n                long firstLagAt = 0;\n                long totalSyncDuration = 0; // total time spent syncing since firstLagAt\n                long syncExceededIntervalBy = 0; // time that syncs exceeded pollInterval since firstLagAt\n                int lagCount = 0;\n                int syncCount = 0;\n\n                boolean run = true;\n                while (run)\n                {\n                    try\n                    {\n                        // always run once after shutdown signalled\n                        run = !shutdown;\n\n                        // sync and signal\n                        long syncStarted = System.currentTimeMillis();\n                        commitLog.sync(shutdown);\n                        lastSyncedAt = syncStarted;\n                        syncComplete.signalAll();\n\n\n                        // sleep any time we have left before the next one is due\n                        long now = System.currentTimeMillis();\n                        long sleep = syncStarted + pollIntervalMillis - now;\n                        if (sleep < 0)\n                        {\n                            // if we have lagged noticeably, update our lag counter\n                            if (firstLagAt == 0)\n                            {\n                                firstLagAt = now;\n                                totalSyncDuration = syncExceededIntervalBy = syncCount = lagCount = 0;\n                            }\n                            syncExceededIntervalBy -= sleep;\n                            lagCount++;\n                        }\n                        syncCount++;\n                        totalSyncDuration += now - syncStarted;\n\n                        if (firstLagAt > 0 && now - firstLagAt >= LAG_REPORT_INTERVAL)\n                        {\n                            logger.warn(String.format(\"Out of %d commit log syncs over the past %ds with average duration of %.2fms, %d have exceeded the configured commit interval by an average of %.2fms\",\n                                                      syncCount, (now - firstLagAt) / 1000, (double) totalSyncDuration / syncCount, lagCount, (double) syncExceededIntervalBy / lagCount));\n                            firstLagAt = 0;\n                        }\n\n                        // if we have lagged this round, we probably have work to do already so we don't sleep\n                        if (sleep < 0 || !run)\n                            continue;\n\n                        try\n                        {\n                            haveWork.tryAcquire(sleep, TimeUnit.MILLISECONDS);\n                        }\n                        catch (InterruptedException e)\n                        {\n                            throw new AssertionError();\n                        }\n                    }\n                    catch (Throwable t)\n                    {\n                        if (!CommitLog.handleCommitError(\"Failed to persist commits to disk\", t))\n                            break;\n\n                        // sleep for full poll-interval after an error, so we don't spam the log file\n                        try\n                        {\n                            haveWork.tryAcquire(pollIntervalMillis, TimeUnit.MILLISECONDS);\n                        }\n                        catch (InterruptedException e)\n                        {\n                            throw new AssertionError();\n                        }\n                    }\n                }\n            }\n        };\n\n        thread = new Thread(runnable, name);\n        thread.start();\n    }",
            "  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117 +\n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  ",
            "    /**\n     * CommitLogService provides a fsync service for Allocations, fulfilling either the\n     * Batch or Periodic contract.\n     *\n     * Subclasses may be notified when a sync finishes by using the syncComplete WaitQueue.\n     */\n    AbstractCommitLogService(final CommitLog commitLog, final String name, final long pollIntervalMillis)\n    {\n        if (pollIntervalMillis < 1)\n            throw new IllegalArgumentException(String.format(\"Commit log flush interval must be positive: %dms\", pollIntervalMillis));\n\n        Runnable runnable = new Runnable()\n        {\n            public void run()\n            {\n                long firstLagAt = 0;\n                long totalSyncDuration = 0; // total time spent syncing since firstLagAt\n                long syncExceededIntervalBy = 0; // time that syncs exceeded pollInterval since firstLagAt\n                int lagCount = 0;\n                int syncCount = 0;\n\n                boolean run = true;\n                while (run)\n                {\n                    try\n                    {\n                        // always run once after shutdown signalled\n                        run = !shutdown;\n\n                        // sync and signal\n                        long syncStarted = System.currentTimeMillis();\n                        commitLog.sync(shutdown);\n                        lastSyncedAt = syncStarted;\n                        syncComplete.signalAll();\n\n\n                        // sleep any time we have left before the next one is due\n                        long now = System.currentTimeMillis();\n                        long sleep = syncStarted + pollIntervalMillis - now;\n                        if (sleep < 0)\n                        {\n                            // if we have lagged noticeably, update our lag counter\n                            if (firstLagAt == 0)\n                            {\n                                firstLagAt = now;\n                                totalSyncDuration = syncExceededIntervalBy = syncCount = lagCount = 0;\n                            }\n                            syncExceededIntervalBy -= sleep;\n                            lagCount++;\n                        }\n                        syncCount++;\n                        totalSyncDuration += now - syncStarted;\n\n                        if (firstLagAt > 0 && now - firstLagAt >= LAG_REPORT_INTERVAL)\n                        {\n                            logger.warn(String.format(\"Out of %d commit log syncs over the past %ds with average duration of %.2fms, %d have exceeded the configured commit interval by an average of %.2fms\",\n                                                      syncCount, (now - firstLagAt) / 1000, (double) totalSyncDuration / syncCount, lagCount, (double) syncExceededIntervalBy / lagCount));\n                            firstLagAt = 0;\n                        }\n\n                        // if we have lagged this round, we probably have work to do already so we don't sleep\n                        if (sleep < 0 || !run)\n                            continue;\n\n                        try\n                        {\n                            haveWork.tryAcquire(sleep, TimeUnit.MILLISECONDS);\n                            haveWork.drainPermits();\n                        }\n                        catch (InterruptedException e)\n                        {\n                            throw new AssertionError();\n                        }\n                    }\n                    catch (Throwable t)\n                    {\n                        if (!CommitLog.handleCommitError(\"Failed to persist commits to disk\", t))\n                            break;\n\n                        // sleep for full poll-interval after an error, so we don't spam the log file\n                        try\n                        {\n                            haveWork.tryAcquire(pollIntervalMillis, TimeUnit.MILLISECONDS);\n                        }\n                        catch (InterruptedException e)\n                        {\n                            throw new AssertionError();\n                        }\n                    }\n                }\n            }\n        };\n\n        thread = new Thread(runnable, name);\n        thread.start();\n    }"
        ],
        [
            "BatchCommitLogService::maybeWaitForSync(CommitLogSegment)",
            "  29  \n  30  \n  31  \n  32  \n  33  \n  34  \n  35  ",
            "    protected void maybeWaitForSync(CommitLogSegment.Allocation alloc)\n    {\n        // wait until record has been safely persisted to disk\n        pending.incrementAndGet();\n        alloc.awaitDiskSync();\n        pending.decrementAndGet();\n    }",
            "  29  \n  30  \n  31  \n  32  \n  33 +\n  34  \n  35  \n  36  ",
            "    protected void maybeWaitForSync(CommitLogSegment.Allocation alloc)\n    {\n        // wait until record has been safely persisted to disk\n        pending.incrementAndGet();\n        haveWork.release();\n        alloc.awaitDiskSync();\n        pending.decrementAndGet();\n    }"
        ]
    ],
    "39ab9e05248ab346482f34c875cff6b9b9b6cad5": [
        [
            "JVMStabilityInspector::inspectThrowable(Throwable)",
            "  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  ",
            "    /**\n     * Certain Throwables and Exceptions represent \"Die\" conditions for the server.\n     * @param t\n     *      The Throwable to check for server-stop conditions\n     */\n    public static void inspectThrowable(Throwable t)\n    {\n        boolean isUnstable = false;\n        if (t instanceof OutOfMemoryError)\n            isUnstable = true;\n\n        if (DatabaseDescriptor.getDiskFailurePolicy() == Config.DiskFailurePolicy.die)\n            if (t instanceof FSError || t instanceof CorruptSSTableException)\n            isUnstable = true;\n\n        // Check for file handle exhaustion\n        if (t instanceof FileNotFoundException || t instanceof SocketException)\n            if (t.getMessage().contains(\"Too many open files\"))\n                isUnstable = true;\n\n        if (isUnstable)\n            killer.killCurrentJVM(t);\n    }",
            "  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69 +\n  70 +\n  71 +\n  72  ",
            "    /**\n     * Certain Throwables and Exceptions represent \"Die\" conditions for the server.\n     * This recursively checks the input Throwable's cause hierarchy until null.\n     * @param t\n     *      The Throwable to check for server-stop conditions\n     */\n    public static void inspectThrowable(Throwable t)\n    {\n        boolean isUnstable = false;\n        if (t instanceof OutOfMemoryError)\n            isUnstable = true;\n\n        if (DatabaseDescriptor.getDiskFailurePolicy() == Config.DiskFailurePolicy.die)\n            if (t instanceof FSError || t instanceof CorruptSSTableException)\n            isUnstable = true;\n\n        // Check for file handle exhaustion\n        if (t instanceof FileNotFoundException || t instanceof SocketException)\n            if (t.getMessage().contains(\"Too many open files\"))\n                isUnstable = true;\n\n        if (isUnstable)\n            killer.killCurrentJVM(t);\n\n        if (t.getCause() != null)\n            inspectThrowable(t.getCause());\n    }"
        ],
        [
            "JVMStabilityInspectorTest::testKill()",
            "  39  \n  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  ",
            "    @Test\n    public void testKill() throws Exception\n    {\n        KillerForTests killerForTests = new KillerForTests();\n        JVMStabilityInspector.Killer originalKiller = JVMStabilityInspector.replaceKiller(killerForTests);\n\n        Config.DiskFailurePolicy oldPolicy = DatabaseDescriptor.getDiskFailurePolicy();\n        Config.CommitFailurePolicy oldCommitPolicy = DatabaseDescriptor.getCommitFailurePolicy();\n        try\n        {\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new IOException());\n            assertFalse(killerForTests.wasKilled());\n\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new OutOfMemoryError());\n            assertTrue(killerForTests.wasKilled());\n\n            DatabaseDescriptor.setDiskFailurePolicy(Config.DiskFailurePolicy.die);\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new FSReadError(new IOException(), \"blah\"));\n            assertTrue(killerForTests.wasKilled());\n\n            DatabaseDescriptor.setCommitFailurePolicy(Config.CommitFailurePolicy.die);\n            killerForTests.reset();\n            JVMStabilityInspector.inspectCommitLogThrowable(new Throwable());\n            assertTrue(killerForTests.wasKilled());\n        }\n        finally\n        {\n            JVMStabilityInspector.replaceKiller(originalKiller);\n            DatabaseDescriptor.setDiskFailurePolicy(oldPolicy);\n            DatabaseDescriptor.setCommitFailurePolicy(oldCommitPolicy);\n        }\n    }",
            "  39  \n  40  \n  41  \n  42  \n  43  \n  44  \n  45  \n  46  \n  47  \n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66 +\n  67 +\n  68 +\n  69 +\n  70 +\n  71 +\n  72 +\n  73 +\n  74 +\n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  ",
            "    @Test\n    public void testKill() throws Exception\n    {\n        KillerForTests killerForTests = new KillerForTests();\n        JVMStabilityInspector.Killer originalKiller = JVMStabilityInspector.replaceKiller(killerForTests);\n\n        Config.DiskFailurePolicy oldPolicy = DatabaseDescriptor.getDiskFailurePolicy();\n        Config.CommitFailurePolicy oldCommitPolicy = DatabaseDescriptor.getCommitFailurePolicy();\n        try\n        {\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new IOException());\n            assertFalse(killerForTests.wasKilled());\n\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new OutOfMemoryError());\n            assertTrue(killerForTests.wasKilled());\n\n            DatabaseDescriptor.setDiskFailurePolicy(Config.DiskFailurePolicy.die);\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new FSReadError(new IOException(), \"blah\"));\n            assertTrue(killerForTests.wasKilled());\n\n            DatabaseDescriptor.setCommitFailurePolicy(Config.CommitFailurePolicy.die);\n            killerForTests.reset();\n            JVMStabilityInspector.inspectCommitLogThrowable(new Throwable());\n            assertTrue(killerForTests.wasKilled());\n\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new Exception(new IOException()));\n            assertFalse(killerForTests.wasKilled());\n\n            killerForTests.reset();\n            JVMStabilityInspector.inspectThrowable(new Exception(new OutOfMemoryError()));\n            assertTrue(killerForTests.wasKilled());\n\n        }\n        finally\n        {\n            JVMStabilityInspector.replaceKiller(originalKiller);\n            DatabaseDescriptor.setDiskFailurePolicy(oldPolicy);\n            DatabaseDescriptor.setCommitFailurePolicy(oldCommitPolicy);\n        }\n    }"
        ]
    ]
}