{
    "1410900f2c0e2f8819a1fb945109ca0d88f3a2f9": [
        [
            "PlatformProcessorImpl::context()",
            " 215  \n 216  \n 217 -\n 218 -\n 219 -\n 220 -\n 221 -\n 222 -\n 223 -\n 224 -\n 225 -\n 226  \n 227  ",
            "    /** {@inheritDoc} */\n    @Override public PlatformContext context() {\n        // This method is a single point of entry for all remote closures\n        // CPP platform does not currently support remote code execution\n        // Therefore, all remote execution attempts come from .NET\n        // Throw an error if current platform is not .NET\n        if (!PlatformUtils.PLATFORM_DOTNET.equals(interopCfg.platform())) {\n            throw new IgniteException(\".NET platform is not available [nodeId=\" + ctx.grid().localNode().id() + \"] \" +\n                \"(Use Apache.Ignite.Core.Ignition.Start() or Apache.Ignite.exe to start Ignite.NET nodes).\");\n        }\n\n        return platformCtx;\n    }",
            " 215  \n 216  \n 217  \n 218  ",
            "    /** {@inheritDoc} */\n    @Override public PlatformContext context() {\n        return platformCtx;\n    }"
        ],
        [
            "PlatformCacheEntryProcessorImpl::writeEntryAndProcessor(MutableEntry,BinaryRawWriter)",
            " 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146 -\n 147 -\n 148 -\n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  ",
            "    /**\n     * Writes mutable entry and entry processor to the stream.\n     *\n     * @param entry Entry to process.\n     * @param writer Writer.\n     */\n    private void writeEntryAndProcessor(MutableEntry entry, BinaryRawWriter writer) {\n        writer.writeObject(entry.getKey());\n        writer.writeObject(entry.getValue());\n\n        if (ptr != 0) {\n            // Execute locally - we have a pointer to native processor.\n            writer.writeBoolean(true);\n            writer.writeLong(ptr);\n        }\n        else {\n            // We are on a remote node. Send processor holder back to native.\n            writer.writeBoolean(false);\n            writer.writeObject(proc);\n        }\n    }",
            " 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156 +\n 157 +\n 158 +\n 159  ",
            "    /**\n     * Writes mutable entry and entry processor to the stream.\n     *\n     * @param entry Entry to process.\n     * @param writer Writer.\n     */\n    private void writeEntryAndProcessor(MutableEntry entry, BinaryRawWriter writer) {\n        if (ptr != 0) {\n            // Execute locally - we have a pointer to native processor.\n            writer.writeBoolean(true);\n            writer.writeLong(ptr);\n        }\n        else {\n            // We are on a remote node. Send processor holder back to native.\n            writer.writeBoolean(false);\n            writer.writeObject(proc);\n        }\n\n        writer.writeObject(entry.getKey());\n        writer.writeObject(entry.getValue());\n    }"
        ]
    ],
    "7cb3e687efbbfe7e72a8d7b047d03235b8f7ba72": [
        [
            "RestListener::RestListener(AgentConfiguration)",
            "  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68 -\n  69  ",
            "    /**\n     * @param cfg Config.\n     */\n    public RestListener(AgentConfiguration cfg) {\n        super();\n\n        this.cfg = cfg;\n\n        httpClient = HttpClientBuilder.create().build();\n    }",
            "  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69 +\n  70 +\n  71 +\n  72 +\n  73 +\n  74 +\n  75 +\n  76  ",
            "    /**\n     * @param cfg Config.\n     */\n    public RestListener(AgentConfiguration cfg) {\n        super();\n\n        this.cfg = cfg;\n\n        // Create a connection manager with custom configuration.\n        PoolingHttpClientConnectionManager connMgr = new PoolingHttpClientConnectionManager();\n\n        connMgr.setDefaultMaxPerRoute(Integer.MAX_VALUE);\n        connMgr.setMaxTotal(Integer.MAX_VALUE);\n\n        httpClient = HttpClientBuilder.create().setConnectionManager(connMgr).build();\n    }"
        ]
    ],
    "612e92ac99f0b8305ae9efe92dc32cb46eeb9358": [
        [
            "OdbcMessageParser::encode(OdbcResponse)",
            " 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257 -\n 258  \n 259 -\n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  ",
            "    /**\n     * Encode OdbcResponse to byte array.\n     *\n     * @param msg Message.\n     * @return Byte array.\n     */\n    public byte[] encode(OdbcResponse msg) {\n        assert msg != null;\n\n        // Creating new binary writer\n        BinaryWriterExImpl writer = marsh.writer(new BinaryHeapOutputStream(INIT_CAP));\n\n        // Writing status.\n        writer.writeByte((byte) msg.status());\n\n        if (msg.status() != OdbcResponse.STATUS_SUCCESS) {\n            writer.writeString(msg.error());\n\n            return writer.array();\n        }\n\n        Object res0 = msg.response();\n\n        if (res0 == null)\n            return writer.array();\n        if (res0 instanceof OdbcHandshakeResult) {\n            OdbcHandshakeResult res = (OdbcHandshakeResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Handshake result: \" + (res.accepted() ? \"accepted\" : \"rejected\"));\n\n            verConfirmed = res.accepted();\n\n            if (res.accepted()) {\n                verConfirmed = true;\n\n                writer.writeBoolean(true);\n            }\n            else {\n                writer.writeBoolean(false);\n                writer.writeString(res.protocolVersionSince());\n                writer.writeString(res.currentVersion());\n            }\n        }\n        else if (res0 instanceof OdbcQueryExecuteResult) {\n            OdbcQueryExecuteResult res = (OdbcQueryExecuteResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Resulting query ID: \" + res.getQueryId());\n\n            writer.writeLong(res.getQueryId());\n\n            Collection<OdbcColumnMeta> metas = res.getColumnsMetadata();\n\n            assert metas != null;\n\n            writer.writeInt(metas.size());\n\n            for (OdbcColumnMeta meta : metas)\n                meta.write(writer);\n        }\n        else if (res0 instanceof OdbcQueryFetchResult) {\n            OdbcQueryFetchResult res = (OdbcQueryFetchResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Resulting query ID: \" + res.queryId());\n\n            writer.writeLong(res.queryId());\n\n            Collection<?> items0 = res.items();\n\n            assert items0 != null;\n\n            writer.writeBoolean(res.last());\n\n            writer.writeInt(items0.size());\n\n            for (Object row0 : items0) {\n                if (row0 != null) {\n                    Collection<?> row = (Collection<?>)row0;\n\n                    writer.writeInt(row.size());\n\n                    for (Object obj : row) {\n                        if (obj instanceof java.sql.Timestamp)\n                            writer.writeTimestamp((java.sql.Timestamp)obj);\n                        else if (obj instanceof java.util.Date)\n                            writer.writeDate((java.util.Date)obj);\n                        else\n                            writer.writeObjectDetached(obj);\n                    }\n                }\n            }\n        }\n        else if (res0 instanceof OdbcQueryCloseResult) {\n            OdbcQueryCloseResult res = (OdbcQueryCloseResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Resulting query ID: \" + res.getQueryId());\n\n            writer.writeLong(res.getQueryId());\n        }\n        else if (res0 instanceof OdbcQueryGetColumnsMetaResult) {\n            OdbcQueryGetColumnsMetaResult res = (OdbcQueryGetColumnsMetaResult) res0;\n\n            Collection<OdbcColumnMeta> columnsMeta = res.meta();\n\n            assert columnsMeta != null;\n\n            writer.writeInt(columnsMeta.size());\n\n            for (OdbcColumnMeta columnMeta : columnsMeta)\n                columnMeta.write(writer);\n        }\n        else if (res0 instanceof OdbcQueryGetTablesMetaResult) {\n            OdbcQueryGetTablesMetaResult res = (OdbcQueryGetTablesMetaResult) res0;\n\n            Collection<OdbcTableMeta> tablesMeta = res.meta();\n\n            assert tablesMeta != null;\n\n            writer.writeInt(tablesMeta.size());\n\n            for (OdbcTableMeta tableMeta : tablesMeta)\n                tableMeta.writeBinary(writer);\n        }\n        else if (res0 instanceof OdbcQueryGetParamsMetaResult) {\n            OdbcQueryGetParamsMetaResult res = (OdbcQueryGetParamsMetaResult) res0;\n\n            byte[] typeIds = res.typeIds();\n\n            writer.writeObjectDetached(typeIds);\n        }\n        else\n            assert false : \"Should not reach here.\";\n\n        return writer.array();\n    }",
            " 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257 +\n 258 +\n 259 +\n 260 +\n 261 +\n 262 +\n 263 +\n 264 +\n 265 +\n 266 +\n 267  \n 268 +\n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  ",
            "    /**\n     * Encode OdbcResponse to byte array.\n     *\n     * @param msg Message.\n     * @return Byte array.\n     */\n    public byte[] encode(OdbcResponse msg) {\n        assert msg != null;\n\n        // Creating new binary writer\n        BinaryWriterExImpl writer = marsh.writer(new BinaryHeapOutputStream(INIT_CAP));\n\n        // Writing status.\n        writer.writeByte((byte) msg.status());\n\n        if (msg.status() != OdbcResponse.STATUS_SUCCESS) {\n            writer.writeString(msg.error());\n\n            return writer.array();\n        }\n\n        Object res0 = msg.response();\n\n        if (res0 == null)\n            return writer.array();\n        if (res0 instanceof OdbcHandshakeResult) {\n            OdbcHandshakeResult res = (OdbcHandshakeResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Handshake result: \" + (res.accepted() ? \"accepted\" : \"rejected\"));\n\n            verConfirmed = res.accepted();\n\n            if (res.accepted()) {\n                verConfirmed = true;\n\n                writer.writeBoolean(true);\n            }\n            else {\n                writer.writeBoolean(false);\n                writer.writeString(res.protocolVersionSince());\n                writer.writeString(res.currentVersion());\n            }\n        }\n        else if (res0 instanceof OdbcQueryExecuteResult) {\n            OdbcQueryExecuteResult res = (OdbcQueryExecuteResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Resulting query ID: \" + res.getQueryId());\n\n            writer.writeLong(res.getQueryId());\n\n            Collection<OdbcColumnMeta> metas = res.getColumnsMetadata();\n\n            assert metas != null;\n\n            writer.writeInt(metas.size());\n\n            for (OdbcColumnMeta meta : metas)\n                meta.write(writer);\n        }\n        else if (res0 instanceof OdbcQueryFetchResult) {\n            OdbcQueryFetchResult res = (OdbcQueryFetchResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Resulting query ID: \" + res.queryId());\n\n            writer.writeLong(res.queryId());\n\n            Collection<?> items0 = res.items();\n\n            assert items0 != null;\n\n            writer.writeBoolean(res.last());\n\n            writer.writeInt(items0.size());\n\n            for (Object row0 : items0) {\n                if (row0 != null) {\n                    Collection<?> row = (Collection<?>)row0;\n\n                    writer.writeInt(row.size());\n\n                    for (Object obj : row) {\n                        if (obj == null) {\n                            writer.writeObjectDetached(null);\n                            continue;\n                        }\n\n                        Class<?> cls = obj.getClass();\n\n                        if (cls == java.sql.Time.class)\n                            writer.writeTime((java.sql.Time)obj);\n                        else if (cls == java.sql.Timestamp.class)\n                            writer.writeTimestamp((java.sql.Timestamp)obj);\n                        else if (cls == java.sql.Date.class)\n                            writer.writeDate((java.util.Date)obj);\n                        else\n                            writer.writeObjectDetached(obj);\n                    }\n                }\n            }\n        }\n        else if (res0 instanceof OdbcQueryCloseResult) {\n            OdbcQueryCloseResult res = (OdbcQueryCloseResult) res0;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Resulting query ID: \" + res.getQueryId());\n\n            writer.writeLong(res.getQueryId());\n        }\n        else if (res0 instanceof OdbcQueryGetColumnsMetaResult) {\n            OdbcQueryGetColumnsMetaResult res = (OdbcQueryGetColumnsMetaResult) res0;\n\n            Collection<OdbcColumnMeta> columnsMeta = res.meta();\n\n            assert columnsMeta != null;\n\n            writer.writeInt(columnsMeta.size());\n\n            for (OdbcColumnMeta columnMeta : columnsMeta)\n                columnMeta.write(writer);\n        }\n        else if (res0 instanceof OdbcQueryGetTablesMetaResult) {\n            OdbcQueryGetTablesMetaResult res = (OdbcQueryGetTablesMetaResult) res0;\n\n            Collection<OdbcTableMeta> tablesMeta = res.meta();\n\n            assert tablesMeta != null;\n\n            writer.writeInt(tablesMeta.size());\n\n            for (OdbcTableMeta tableMeta : tablesMeta)\n                tableMeta.writeBinary(writer);\n        }\n        else if (res0 instanceof OdbcQueryGetParamsMetaResult) {\n            OdbcQueryGetParamsMetaResult res = (OdbcQueryGetParamsMetaResult) res0;\n\n            byte[] typeIds = res.typeIds();\n\n            writer.writeObjectDetached(typeIds);\n        }\n        else\n            assert false : \"Should not reach here.\";\n\n        return writer.array();\n    }"
        ]
    ],
    "eab8334bb49ceda249e742246d26f72539f9fa4c": [
        [
            "PlatformDotNetCacheStore::deleteAll(Collection)",
            " 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314 -\n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  ",
            "    /** {@inheritDoc} */\n    @Override public void deleteAll(final Collection<?> keys) {\n        try {\n            doInvoke(new IgniteInClosureX<BinaryRawWriterEx>() {\n                @Override public void applyx(BinaryRawWriterEx writer) throws IgniteCheckedException {\n                    writer.writeByte(OP_RMV_ALL);\n                    writer.writeLong(session());\n                    writer.writeString(ses.cacheName());\n                    writer.writeCollection(keys);\n                }\n            }, null);\n        }\n        catch (IgniteCheckedException e) {\n            throw new CacheWriterException(U.convertExceptionNoWrap(e));\n        }\n    }",
            " 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318 +\n 319 +\n 320 +\n 321 +\n 322 +\n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  ",
            "    /** {@inheritDoc} */\n    @Override public void deleteAll(final Collection<?> keys) {\n        try {\n            doInvoke(new IgniteInClosureX<BinaryRawWriterEx>() {\n                @Override public void applyx(BinaryRawWriterEx writer) throws IgniteCheckedException {\n                    writer.writeByte(OP_RMV_ALL);\n                    writer.writeLong(session());\n                    writer.writeString(ses.cacheName());\n\n                    writer.writeInt(keys.size());\n\n                    for (Object o : keys)\n                        writer.writeObject(o);\n                }\n            }, null);\n        }\n        catch (IgniteCheckedException e) {\n            throw new CacheWriterException(U.convertExceptionNoWrap(e));\n        }\n    }"
        ],
        [
            "PlatformDotNetCacheStore::loadAll(Iterable)",
            " 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204 -\n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  ",
            "    /** {@inheritDoc} */\n    @Override public Map<K, V> loadAll(final Iterable<? extends K> keys) {\n        try {\n            final Map<K, V> loaded = new HashMap<>();\n\n            final Collection keys0 = (Collection)keys;\n\n            doInvoke(new IgniteInClosureX<BinaryRawWriterEx>() {\n                @Override public void applyx(BinaryRawWriterEx writer) throws IgniteCheckedException {\n                    writer.writeByte(OP_LOAD_ALL);\n                    writer.writeLong(session());\n                    writer.writeString(ses.cacheName());\n                    writer.writeCollection(keys0);\n                }\n            }, new IgniteInClosureX<BinaryRawReaderEx>() {\n                @Override public void applyx(BinaryRawReaderEx reader) {\n                    int cnt = reader.readInt();\n\n                    for (int i = 0; i < cnt; i++)\n                        loaded.put((K) reader.readObjectDetached(), (V) reader.readObjectDetached());\n                }\n            });\n\n            return loaded;\n        }\n        catch (IgniteCheckedException e) {\n            throw new CacheLoaderException(e);\n        }\n    }",
            " 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204 +\n 205 +\n 206 +\n 207 +\n 208 +\n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  ",
            "    /** {@inheritDoc} */\n    @Override public Map<K, V> loadAll(final Iterable<? extends K> keys) {\n        try {\n            final Map<K, V> loaded = new HashMap<>();\n\n            final Collection keys0 = (Collection)keys;\n\n            doInvoke(new IgniteInClosureX<BinaryRawWriterEx>() {\n                @Override public void applyx(BinaryRawWriterEx writer) throws IgniteCheckedException {\n                    writer.writeByte(OP_LOAD_ALL);\n                    writer.writeLong(session());\n                    writer.writeString(ses.cacheName());\n\n                    writer.writeInt(keys0.size());\n\n                    for (Object o : keys0)\n                        writer.writeObject(o);\n                }\n            }, new IgniteInClosureX<BinaryRawReaderEx>() {\n                @Override public void applyx(BinaryRawReaderEx reader) {\n                    int cnt = reader.readInt();\n\n                    for (int i = 0; i < cnt; i++)\n                        loaded.put((K) reader.readObjectDetached(), (V) reader.readObjectDetached());\n                }\n            });\n\n            return loaded;\n        }\n        catch (IgniteCheckedException e) {\n            throw new CacheLoaderException(e);\n        }\n    }"
        ]
    ],
    "a245d620a6c4ca5c560171dcb6f69fa879a17481": [
        [
            "GridCacheDatabaseSharedManager::reserveHistoryForExchange()",
            " 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883 -\n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  \n 891  \n 892  \n 893  \n 894  \n 895  \n 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  ",
            "    /** {@inheritDoc} */\n    @Override public synchronized Map<Integer, Map<Integer, Long>> reserveHistoryForExchange() {\n        assert reservedForExchange == null : reservedForExchange;\n\n        reservedForExchange = new HashMap<>();\n\n        for (GridCacheContext cacheCtx : (Collection<GridCacheContext>)cctx.cacheContexts()) {\n            if (cacheCtx.isLocal())\n                continue;\n\n            for (GridDhtLocalPartition part : cacheCtx.topology().currentLocalPartitions()) {\n                if (part.state() != GridDhtPartitionState.OWNING || part.dataStore().size() <= ggWalRebalanceThreshold)\n                    continue;\n\n                CheckpointEntry cpEntry = searchCheckpointEntry(cacheCtx, part.id(), null);\n\n                try {\n                    if (cpEntry != null && cctx.wal().reserve(cpEntry.cpMark)) {\n                        Map<Integer, T2<Long, WALPointer>> cacheMap = reservedForExchange.get(cacheCtx.cacheId());\n\n                        if (cacheMap == null) {\n                            cacheMap = new HashMap<>();\n\n                            reservedForExchange.put(cacheCtx.cacheId(), cacheMap);\n                        }\n\n                        cacheMap.put(part.id(), new T2<>(cpEntry.partitionCounter(cacheCtx.cacheId(), part.id()), cpEntry.cpMark));\n                    }\n                }\n                catch (IgniteCheckedException ex) {\n                    U.error(log, \"Error while trying to reserve history\", ex);\n                }\n            }\n        }\n\n        Map<Integer, Map<Integer, Long>> resMap = new HashMap<>();\n\n        for (Map.Entry<Integer, Map<Integer, T2<Long, WALPointer>>> e : reservedForExchange.entrySet()) {\n            Map<Integer, Long> cacheMap = new HashMap<>();\n\n            for (Map.Entry<Integer, T2<Long, WALPointer>> e0 : e.getValue().entrySet())\n                cacheMap.put(e0.getKey(), e0.getValue().get1());\n\n            resMap.put(e.getKey(), cacheMap);\n        }\n\n        return resMap;\n    }",
            " 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907 +\n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  \n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932  \n 933  \n 934  \n 935  \n 936  \n 937  \n 938  \n 939  \n 940  \n 941  \n 942  \n 943  ",
            "    /** {@inheritDoc} */\n    @Override public synchronized Map<Integer, Map<Integer, Long>> reserveHistoryForExchange() {\n        assert reservedForExchange == null : reservedForExchange;\n\n        reservedForExchange = new HashMap<>();\n\n        for (GridCacheContext cacheCtx : (Collection<GridCacheContext>)cctx.cacheContexts()) {\n            if (cacheCtx.isLocal())\n                continue;\n\n            for (GridDhtLocalPartition part : cacheCtx.topology().currentLocalPartitions()) {\n                if (part.state() != GridDhtPartitionState.OWNING || part.dataStore().size() <= walRebalanceThreshold)\n                    continue;\n\n                CheckpointEntry cpEntry = searchCheckpointEntry(cacheCtx, part.id(), null);\n\n                try {\n                    if (cpEntry != null && cctx.wal().reserve(cpEntry.cpMark)) {\n                        Map<Integer, T2<Long, WALPointer>> cacheMap = reservedForExchange.get(cacheCtx.cacheId());\n\n                        if (cacheMap == null) {\n                            cacheMap = new HashMap<>();\n\n                            reservedForExchange.put(cacheCtx.cacheId(), cacheMap);\n                        }\n\n                        cacheMap.put(part.id(), new T2<>(cpEntry.partitionCounter(cacheCtx.cacheId(), part.id()), cpEntry.cpMark));\n                    }\n                }\n                catch (IgniteCheckedException ex) {\n                    U.error(log, \"Error while trying to reserve history\", ex);\n                }\n            }\n        }\n\n        Map<Integer, Map<Integer, Long>> resMap = new HashMap<>();\n\n        for (Map.Entry<Integer, Map<Integer, T2<Long, WALPointer>>> e : reservedForExchange.entrySet()) {\n            Map<Integer, Long> cacheMap = new HashMap<>();\n\n            for (Map.Entry<Integer, T2<Long, WALPointer>> e0 : e.getValue().entrySet())\n                cacheMap.put(e0.getKey(), e0.getValue().get1());\n\n            resMap.put(e.getKey(), cacheMap);\n        }\n\n        return resMap;\n    }"
        ],
        [
            "PageStoreEvictionSelfTest::testPageEviction()",
            " 109  \n 110  \n 111  \n 112  \n 113  \n 114 -\n 115  \n 116  \n 117  \n 118 -\n 119  ",
            "    /**\n     * @throws Exception If fail.\n     */\n    public void testPageEviction() throws Exception {\n        final IgniteEx ig = startGrid(0);\n        ig.getOrCreateCache(new CacheConfiguration<>(\"partitioned\"));\n\n        final PageMemory memory = getMemory(ig);\n\n        writeData(ig, memory, CU.cacheId(\"partitioned\"));\n    }",
            " 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122 +\n 123  ",
            "    /**\n     * @throws Exception If fail.\n     */\n    public void testPageEviction() throws Exception {\n        final IgniteEx ig = startGrid(0);\n\n        final PageMemory memory = getMemory(ig);\n\n        writeData(ig, memory, CU.cacheId(cacheName));\n    }"
        ],
        [
            "IgniteCacheDatabaseSharedManager::checkDefaultPolicyConfiguration(String,long,Collection)",
            " 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391 -\n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  ",
            "    /**\n     * @param dfltPlcName Default MemoryPolicy name.\n     * @param dfltPlcSize Default size of MemoryPolicy overridden by user (equals to -1 if wasn't specified by user).\n     * @param plcNames All MemoryPolicy names.\n     * @throws IgniteCheckedException In case of validation violation.\n     */\n    private static void checkDefaultPolicyConfiguration(\n        String dfltPlcName,\n        long dfltPlcSize,\n        Collection<String> plcNames\n    ) throws IgniteCheckedException {\n        if (dfltPlcSize != -1) {\n            if (!F.eq(dfltPlcName, MemoryConfiguration.DFLT_MEM_PLC_DEFAULT_NAME))\n                throw new IgniteCheckedException(\"User-defined MemoryPolicy configuration \" +\n                    \"and defaultMemoryPolicySize properties are set at the same time. \" +\n                    \"Delete either MemoryConfiguration.defaultMemoryPolicySize property \" +\n                    \"or user-defined default MemoryPolicy configuration\");\n\n            if (dfltPlcSize < MIN_PAGE_MEMORY_SIZE)\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy size is less than 1MB. \" +\n                        \"Use MemoryConfiguration.defaultMemoryPolicySize property to set correct size.\");\n\n            if (U.jvm32Bit() && dfltPlcSize > MAX_PAGE_MEMORY_INIT_SIZE_32_BIT)\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy size exceeds 2GB on 32-bit JVM \" +\n                    \"(use MemoryConfiguration.defaultMemoryPolicySize property to set correct size in bytes \" +\n                    \"or use 64-bit JVM) [size=\" + U.readableSize(dfltPlcSize, true) + ']'\n                );\n        }\n\n        if (!DFLT_MEM_PLC_DEFAULT_NAME.equals(dfltPlcName)) {\n            if (dfltPlcName.isEmpty())\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy name must be non-empty\");\n\n            if (!plcNames.contains(dfltPlcName))\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy name \" +\n                    \"must be presented among configured MemoryPolices: \" + dfltPlcName);\n        }\n    }",
            " 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405 +\n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  ",
            "    /**\n     * @param dfltPlcName Default MemoryPolicy name.\n     * @param dfltPlcSize Default size of MemoryPolicy overridden by user (equals to -1 if wasn't specified by user).\n     * @param plcNames All MemoryPolicy names.\n     * @throws IgniteCheckedException In case of validation violation.\n     */\n    private static void checkDefaultPolicyConfiguration(\n        String dfltPlcName,\n        long dfltPlcSize,\n        Collection<String> plcNames\n    ) throws IgniteCheckedException {\n        if (dfltPlcSize != MemoryConfiguration.DFLT_MEMORY_POLICY_MAX_SIZE) {\n            if (!F.eq(dfltPlcName, MemoryConfiguration.DFLT_MEM_PLC_DEFAULT_NAME))\n                throw new IgniteCheckedException(\"User-defined MemoryPolicy configuration \" +\n                    \"and defaultMemoryPolicySize properties are set at the same time. \" +\n                    \"Delete either MemoryConfiguration.defaultMemoryPolicySize property \" +\n                    \"or user-defined default MemoryPolicy configuration\");\n\n            if (dfltPlcSize < MIN_PAGE_MEMORY_SIZE)\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy size is less than 1MB. \" +\n                        \"Use MemoryConfiguration.defaultMemoryPolicySize property to set correct size.\");\n\n            if (U.jvm32Bit() && dfltPlcSize > MAX_PAGE_MEMORY_INIT_SIZE_32_BIT)\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy size exceeds 2GB on 32-bit JVM \" +\n                    \"(use MemoryConfiguration.defaultMemoryPolicySize property to set correct size in bytes \" +\n                    \"or use 64-bit JVM) [size=\" + U.readableSize(dfltPlcSize, true) + ']'\n                );\n        }\n\n        if (!DFLT_MEM_PLC_DEFAULT_NAME.equals(dfltPlcName)) {\n            if (dfltPlcName.isEmpty())\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy name must be non-empty\");\n\n            if (!plcNames.contains(dfltPlcName))\n                throw new IgniteCheckedException(\"User-defined default MemoryPolicy name \" +\n                    \"must be presented among configured MemoryPolices: \" + dfltPlcName);\n        }\n    }"
        ],
        [
            "IgnitePersistentStoreCacheRebalancingAbstractTest::testTopologyChangesWithConstantLoad()",
            " 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testTopologyChangesWithConstantLoad() throws Exception {\n        final int entriesCnt = 10_000;\n        int maxNodesCount = 4;\n        int topChanges = 20;\n        final String cacheName = \"indexed\";\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        final ConcurrentMap<Integer, TestValue> map = new ConcurrentHashMap<>();\n\n        Ignite ignite = startGrid(0);\n\n        IgniteCache<Integer, TestValue> cache = ignite.cache(cacheName);\n\n        for (int i = 0; i < entriesCnt; i++) {\n            cache.put(i, new TestValue(i, i));\n            map.put(i, new TestValue(i, i));\n        }\n\n        final AtomicInteger nodesCnt = new AtomicInteger();\n\n        IgniteInternalFuture fut = GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n            @Override public Void call() throws Exception {\n                while (true) {\n                    if (stop.get())\n                        return null;\n\n                    int k = ThreadLocalRandom.current().nextInt(entriesCnt);\n                    int v1 = ThreadLocalRandom.current().nextInt();\n                    int v2 = ThreadLocalRandom.current().nextInt();\n\n                    int n = nodesCnt.get();\n\n                    if (n <= 0)\n                        continue;\n\n                    Ignite ignite;\n\n                    try {\n                        ignite = grid(ThreadLocalRandom.current().nextInt(n));\n                    }\n                    catch (Exception ignored) {\n                        continue;\n                    }\n\n                    if (ignite == null)\n                        continue;\n\n                    Transaction tx = null;\n                    boolean success = true;\n\n                    if (explicitTx)\n                        tx = ignite.transactions().txStart();\n\n                    try {\n                        ignite.cache(cacheName).put(k, new TestValue(v1, v2));\n                    }\n                    catch (Exception e) {\n                        success = false;\n                    }\n                    finally {\n                        if (tx != null) {\n                            try {\n                                tx.commit();\n                            }\n                            catch (Exception e) {\n                                success = false;\n                            }\n                        }\n                    }\n\n                    if (success)\n                        map.put(k, new TestValue(v1, v2));\n                }\n            }\n        }, 1, \"load-runner\");\n\n        for (int i = 0; i < topChanges; i++) {\n            U.sleep(3_000);\n\n            boolean add;\n            if (nodesCnt.get() <= maxNodesCount / 2)\n                add = true;\n            else if (nodesCnt.get() > maxNodesCount)\n                add = false;\n            else\n                add = ThreadLocalRandom.current().nextBoolean();\n\n            if (add)\n                startGrid(nodesCnt.incrementAndGet());\n            else\n                stopGrid(nodesCnt.getAndDecrement());\n\n            awaitPartitionMapExchange();\n\n            cache.rebalance().get();\n        }\n\n        stop.set(true);\n\n        fut.get();\n\n        awaitPartitionMapExchange();\n\n        for (Map.Entry<Integer, TestValue> entry : map.entrySet())\n            assertEquals(Integer.toString(entry.getKey()), entry.getValue(), cache.get(entry.getKey()));\n    }",
            " 361  \n 362  \n 363  \n 364  \n 365 +\n 366 +\n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testTopologyChangesWithConstantLoad() throws Exception {\n        fail(\"only for one run, must be removed soon\");\n\n        final int entriesCnt = 10_000;\n        int maxNodesCount = 4;\n        int topChanges = 20;\n        final String cacheName = \"indexed\";\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        final ConcurrentMap<Integer, TestValue> map = new ConcurrentHashMap<>();\n\n        Ignite ignite = startGrid(0);\n\n        IgniteCache<Integer, TestValue> cache = ignite.cache(cacheName);\n\n        for (int i = 0; i < entriesCnt; i++) {\n            cache.put(i, new TestValue(i, i));\n            map.put(i, new TestValue(i, i));\n        }\n\n        final AtomicInteger nodesCnt = new AtomicInteger();\n\n        IgniteInternalFuture fut = GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n            @Override public Void call() throws Exception {\n                while (true) {\n                    if (stop.get())\n                        return null;\n\n                    int k = ThreadLocalRandom.current().nextInt(entriesCnt);\n                    int v1 = ThreadLocalRandom.current().nextInt();\n                    int v2 = ThreadLocalRandom.current().nextInt();\n\n                    int n = nodesCnt.get();\n\n                    if (n <= 0)\n                        continue;\n\n                    Ignite ignite;\n\n                    try {\n                        ignite = grid(ThreadLocalRandom.current().nextInt(n));\n                    }\n                    catch (Exception ignored) {\n                        continue;\n                    }\n\n                    if (ignite == null)\n                        continue;\n\n                    Transaction tx = null;\n                    boolean success = true;\n\n                    if (explicitTx)\n                        tx = ignite.transactions().txStart();\n\n                    try {\n                        ignite.cache(cacheName).put(k, new TestValue(v1, v2));\n                    }\n                    catch (Exception e) {\n                        success = false;\n                    }\n                    finally {\n                        if (tx != null) {\n                            try {\n                                tx.commit();\n                            }\n                            catch (Exception e) {\n                                success = false;\n                            }\n                        }\n                    }\n\n                    if (success)\n                        map.put(k, new TestValue(v1, v2));\n                }\n            }\n        }, 1, \"load-runner\");\n\n        for (int i = 0; i < topChanges; i++) {\n            U.sleep(3_000);\n\n            boolean add;\n            if (nodesCnt.get() <= maxNodesCount / 2)\n                add = true;\n            else if (nodesCnt.get() > maxNodesCount)\n                add = false;\n            else\n                add = ThreadLocalRandom.current().nextBoolean();\n\n            if (add)\n                startGrid(nodesCnt.incrementAndGet());\n            else\n                stopGrid(nodesCnt.getAndDecrement());\n\n            awaitPartitionMapExchange();\n\n            cache.rebalance().get();\n        }\n\n        stop.set(true);\n\n        fut.get();\n\n        awaitPartitionMapExchange();\n\n        for (Map.Entry<Integer, TestValue> entry : map.entrySet())\n            assertEquals(Integer.toString(entry.getKey()), entry.getValue(), cache.get(entry.getKey()));\n    }"
        ],
        [
            "IgniteCacheDatabaseSharedManager::checkSystemMemoryPolicySizeConfiguration(long,long)",
            " 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358 -\n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  ",
            "    /**\n     * @param sysCacheInitSize System cache initial size.\n     * @param sysCacheMaxSize System cache max size.\n     *\n     * @throws IgniteCheckedException In case of validation violation.\n     */\n    private void checkSystemMemoryPolicySizeConfiguration(long sysCacheInitSize, long sysCacheMaxSize) throws IgniteCheckedException {\n        if (sysCacheInitSize < MIN_PAGE_MEMORY_SIZE)\n            throw new IgniteCheckedException(\"Initial size for system cache must have size more than 10MB (use \" +\n                \"MemoryConfiguration.systemCacheInitialSize property to set correct size in bytes) \" +\n                \"[size=\" + U.readableSize(sysCacheInitSize, true) + ']'\n            );\n\n        if (U.jvm32Bit() && sysCacheInitSize > MAX_PAGE_MEMORY_INIT_SIZE_32_BIT)\n            throw new IgniteCheckedException(\"Initial size for system cache exceeds 2GB on 32-bit JVM (use \" +\n                \"MemoryPolicyConfiguration.systemCacheInitialSize property to set correct size in bytes \" +\n                \"or use 64-bit JVM) [size=\" + U.readableSize(sysCacheInitSize, true) + ']'\n            );\n\n        if (sysCacheMaxSize < sysCacheInitSize)\n            throw new IgniteCheckedException(\"MaxSize of system cache must not be smaller than \" +\n                \"initialSize [initSize=\" + U.readableSize(sysCacheInitSize, true) +\n                \", maxSize=\" + U.readableSize(sysCacheMaxSize, true) + \"]. \" +\n                \"Use MemoryConfiguration.systemCacheInitialSize/MemoryConfiguration.systemCacheMaxSize \" +\n                \"properties to set correct sizes in bytes.\"",
            " 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369 +\n 370 +\n 371 +\n 372 +\n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  ",
            "    /**\n     * @param sysCacheInitSize System cache initial size.\n     * @param sysCacheMaxSize System cache max size.\n     *\n     * @throws IgniteCheckedException In case of validation violation.\n     */\n    private static void checkSystemMemoryPolicySizeConfiguration(\n        long sysCacheInitSize,\n        long sysCacheMaxSize\n    ) throws IgniteCheckedException {\n        if (sysCacheInitSize < MIN_PAGE_MEMORY_SIZE)\n            throw new IgniteCheckedException(\"Initial size for system cache must have size more than 10MB (use \" +\n                \"MemoryConfiguration.systemCacheInitialSize property to set correct size in bytes) \" +\n                \"[size=\" + U.readableSize(sysCacheInitSize, true) + ']'\n            );\n\n        if (U.jvm32Bit() && sysCacheInitSize > MAX_PAGE_MEMORY_INIT_SIZE_32_BIT)\n            throw new IgniteCheckedException(\"Initial size for system cache exceeds 2GB on 32-bit JVM (use \" +\n                \"MemoryPolicyConfiguration.systemCacheInitialSize property to set correct size in bytes \" +\n                \"or use 64-bit JVM) [size=\" + U.readableSize(sysCacheInitSize, true) + ']'\n            );\n\n        if (sysCacheMaxSize < sysCacheInitSize)\n            throw new IgniteCheckedException(\"MaxSize of system cache must not be smaller than \" +\n                \"initialSize [initSize=\" + U.readableSize(sysCacheInitSize, true) +\n                \", maxSize=\" + U.readableSize(sysCacheMaxSize, true) + \"]. \" +\n                \"Use MemoryConfiguration.systemCacheInitialSize/MemoryConfiguration.systemCacheMaxSize \" +\n                \"properties to set correct sizes in bytes.\""
        ],
        [
            "IgniteCacheDatabaseSharedManager::init()",
            " 105  \n 106  \n 107  \n 108  \n 109 -\n 110 -\n 111  \n 112 -\n 113 -\n 114  \n 115 -\n 116  \n 117 -\n 118  \n 119 -\n 120  \n 121 -\n 122  \n 123 -\n 124  \n 125 -\n 126 -\n 127  ",
            "    /**\n     * @throws IgniteCheckedException If failed.\n     */\n    public void init() throws IgniteCheckedException {\n        if (memPlcMap == null) {\n            MemoryConfiguration memCfg = cctx.kernalContext().config().getMemoryConfiguration();\n\n            if (memCfg == null)\n                memCfg = new MemoryConfiguration();\n\n            validateConfiguration(memCfg);\n\n            pageSize = memCfg.getPageSize();\n\n            initPageMemoryPolicies(memCfg);\n\n            registerMetricsMBeans();\n\n            startMemoryPolicies();\n\n            initPageMemoryDataStructures(memCfg);\n        }\n    }",
            " 105  \n 106  \n 107  \n 108  \n 109 +\n 110  \n 111 +\n 112  \n 113 +\n 114  \n 115 +\n 116  \n 117 +\n 118  \n 119 +\n 120  \n 121 +\n 122  \n 123 +\n 124  ",
            "    /**\n     * @throws IgniteCheckedException If failed.\n     */\n    public void init() throws IgniteCheckedException {\n        MemoryConfiguration memCfg = cctx.kernalContext().config().getMemoryConfiguration();\n\n        assert memCfg != null;\n\n        validateConfiguration(memCfg);\n\n        pageSize = memCfg.getPageSize();\n\n        initPageMemoryPolicies(memCfg);\n\n        registerMetricsMBeans();\n\n        startMemoryPolicies();\n\n        initPageMemoryDataStructures(memCfg);\n    }"
        ],
        [
            "PageStoreEvictionSelfTest::createDbConfig()",
            "  73  \n  74  \n  75  \n  76  \n  77 -\n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84 -\n  85 -\n  86 -\n  87 -\n  88  \n  89 -\n  90  ",
            "    /**\n     * @return DB config.\n     */\n    private MemoryConfiguration createDbConfig() {\n        final MemoryConfiguration dbCfg = new MemoryConfiguration();\n\n        MemoryPolicyConfiguration memPlcCfg = new MemoryPolicyConfiguration();\n        memPlcCfg.setInitialSize(MEMORY_LIMIT);\n        memPlcCfg.setMaxSize(MEMORY_LIMIT);\n        memPlcCfg.setName(\"dfltMemPlc\");\n\n        dbCfg.setPageSize(PAGE_SIZE);\n        dbCfg.setConcurrencyLevel(NUMBER_OF_SEGMENTS);\n        dbCfg.setMemoryPolicies(memPlcCfg);\n        dbCfg.setDefaultMemoryPolicyName(\"dfltMemPlc\");\n\n        return dbCfg;\n    }",
            "  78  \n  79  \n  80  \n  81  \n  82 +\n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89 +\n  90 +\n  91 +\n  92 +\n  93  \n  94 +\n  95  ",
            "    /**\n     * @return DB config.\n     */\n    private MemoryConfiguration createDbConfig() {\n        final MemoryConfiguration memCfg = new MemoryConfiguration();\n\n        MemoryPolicyConfiguration memPlcCfg = new MemoryPolicyConfiguration();\n        memPlcCfg.setInitialSize(MEMORY_LIMIT);\n        memPlcCfg.setMaxSize(MEMORY_LIMIT);\n        memPlcCfg.setName(\"dfltMemPlc\");\n\n        memCfg.setPageSize(PAGE_SIZE);\n        memCfg.setConcurrencyLevel(NUMBER_OF_SEGMENTS);\n        memCfg.setMemoryPolicies(memPlcCfg);\n        memCfg.setDefaultMemoryPolicyName(\"dfltMemPlc\");\n\n        return memCfg;\n    }"
        ],
        [
            "PageStoreEvictionSelfTest::getConfiguration(String)",
            "  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  ",
            "    /** {@inheritDoc} */\n    @Override protected IgniteConfiguration getConfiguration(String gridName) throws Exception {\n        final IgniteConfiguration cfg = super.getConfiguration(gridName);\n\n        cfg.setPersistenceConfiguration(new PersistenceConfiguration());\n\n        cfg.setMemoryConfiguration(createDbConfig());\n\n        return cfg;\n    }",
            "  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73 +\n  74 +\n  75  \n  76  ",
            "    /** {@inheritDoc} */\n    @Override protected IgniteConfiguration getConfiguration(String gridName) throws Exception {\n        final IgniteConfiguration cfg = super.getConfiguration(gridName);\n\n        cfg.setPersistenceConfiguration(new PersistenceConfiguration());\n\n        cfg.setMemoryConfiguration(createDbConfig());\n\n        cfg.setCacheConfiguration(new CacheConfiguration<>(cacheName));\n\n        return cfg;\n    }"
        ],
        [
            "GridCacheDatabaseSharedManager::initDataBase()",
            " 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358 -\n 359  \n 360  \n 361  \n 362  \n 363 -\n 364 -\n 365  \n 366 -\n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  ",
            "    /**\n     *\n     */\n    @Override public void initDataBase() throws IgniteCheckedException {\n        Long cpBufSize = dbCfg.getCheckpointPageBufferSize();\n\n        if (dbCfg.getCheckpointThreads() > 1)\n            asyncRunner = new ThreadPoolExecutor(\n                dbCfg.getCheckpointThreads(),\n                dbCfg.getCheckpointThreads(),\n                30L,\n                TimeUnit.SECONDS,\n                new LinkedBlockingQueue<Runnable>()\n            );\n\n        // Intentionally use identity comparison to check if configuration default has changed.\n        //noinspection NumberEquality\n        if (cpBufSize == PersistenceConfiguration.DFLT_CHECKPOINT_PAGE_BUFFER_SIZE) {\n            MemoryConfiguration memCfg = cctx.kernalContext().config().getMemoryConfiguration();\n\n            // Limit the checkpoint page buffer size by 2GB.\n            //TODO find max page cache and use it instead of memCfg.getPageCacheSize() (replaced with Long.MAX_VALUE now)\n            long adjusted = Math.min(Long.MAX_VALUE / 4, 2 * 1024L * 1024L * 1024L);\n\n            if (memCfg != null && cpBufSize < adjusted) {\n                U.quietAndInfo(log,\n                    \"Default checkpoint page buffer size is too small, setting to an adjusted value: \"\n                        + U.readableSize(adjusted, false)\n                );\n\n                cpBufSize = adjusted;\n            }\n        }\n\n        checkpointPageBufSize = cpBufSize;\n\n        super.start0();\n    }",
            " 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358 +\n 359  \n 360  \n 361  \n 362 +\n 363 +\n 364 +\n 365 +\n 366 +\n 367 +\n 368 +\n 369 +\n 370 +\n 371 +\n 372 +\n 373 +\n 374 +\n 375 +\n 376 +\n 377 +\n 378 +\n 379 +\n 380 +\n 381 +\n 382  \n 383 +\n 384 +\n 385 +\n 386  \n 387 +\n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  ",
            "    /**\n     *\n     */\n    @Override public void initDataBase() throws IgniteCheckedException {\n        Long cpBufSize = dbCfg.getCheckpointPageBufferSize();\n\n        if (dbCfg.getCheckpointThreads() > 1)\n            asyncRunner = new ThreadPoolExecutor(\n                dbCfg.getCheckpointThreads(),\n                dbCfg.getCheckpointThreads(),\n                30L,\n                TimeUnit.SECONDS,\n                new LinkedBlockingQueue<Runnable>()\n            );\n\n        // Intentionally use identity comparison to check if configuration default has changed.\n        // Noinspection NumberEquality.\n        if (cpBufSize == PersistenceConfiguration.DFLT_CHECKPOINT_PAGE_BUFFER_SIZE) {\n            MemoryConfiguration memCfg = cctx.kernalContext().config().getMemoryConfiguration();\n\n            assert memCfg != null;\n\n            long totalSize = memCfg.getSystemCacheMaxSize();\n\n            if (memCfg.getMemoryPolicies() == null)\n                totalSize += MemoryConfiguration.DFLT_MEMORY_POLICY_MAX_SIZE;\n            else {\n                for (MemoryPolicyConfiguration memPlc : memCfg.getMemoryPolicies()) {\n                    if (Long.MAX_VALUE - memPlc.getMaxSize() > totalSize)\n                        totalSize += memPlc.getMaxSize();\n                    else {\n                        totalSize = Long.MAX_VALUE;\n\n                        break;\n                    }\n                }\n\n                assert totalSize > 0;\n            }\n\n            // Limit the checkpoint page buffer size by 2GB.\n            long dfltSize = 2 * 1024L * 1024L * 1024L;\n\n            long adjusted = Math.min(totalSize / 4, dfltSize);\n\n            if (cpBufSize < adjusted) {\n                U.quietAndInfo(log,\n                    \"Default checkpoint page buffer size is too small, setting to an adjusted value: \"\n                        + U.readableSize(adjusted, false)\n                );\n\n                cpBufSize = adjusted;\n            }\n        }\n\n        checkpointPageBufSize = cpBufSize;\n\n        super.start0();\n    }"
        ],
        [
            "PageMemoryNoStoreImpl::PageMemoryNoStoreImpl(IgniteLogger,DirectMemoryProvider,GridCacheSharedContext,int,MemoryPolicyConfiguration,MemoryMetricsImpl,boolean)",
            " 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185 -\n 186 -\n 187  ",
            "    /**\n     * @param log Logger.\n     * @param directMemoryProvider Memory allocator to use.\n     * @param sharedCtx Cache shared context.\n     * @param pageSize Page size.\n     * @param memPlcCfg Memory Policy configuration.\n     * @param memMetrics Memory Metrics.\n     * @param trackAcquiredPages If {@code true} tracks number of allocated pages (for tests purpose only).\n     */\n    public PageMemoryNoStoreImpl(\n        IgniteLogger log,\n        DirectMemoryProvider directMemoryProvider,\n        GridCacheSharedContext<?, ?> sharedCtx,\n        int pageSize,\n        MemoryPolicyConfiguration memPlcCfg,\n        MemoryMetricsImpl memMetrics,\n        boolean trackAcquiredPages\n    ) {\n        assert log != null || sharedCtx != null;\n        assert pageSize % 8 == 0;\n\n        this.log = sharedCtx != null ? sharedCtx.logger(PageMemoryNoStoreImpl.class) : log;\n        this.directMemoryProvider = directMemoryProvider;\n        this.trackAcquiredPages = trackAcquiredPages;\n        this.memMetrics = memMetrics;\n        memoryPolicyCfg = memPlcCfg;\n\n        sysPageSize = pageSize + PAGE_OVERHEAD;\n\n        assert sysPageSize % 8 == 0 : sysPageSize;\n\n        totalPages = (int)(memPlcCfg.getMaxSize() / sysPageSize);\n\n        // TODO configure concurrency level.\n        rwLock = new OffheapReadWriteLock(128);\n    }",
            " 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193 +\n 194  ",
            "    /**\n     * @param log Logger.\n     * @param directMemoryProvider Memory allocator to use.\n     * @param sharedCtx Cache shared context.\n     * @param pageSize Page size.\n     * @param memPlcCfg Memory Policy configuration.\n     * @param memMetrics Memory Metrics.\n     * @param trackAcquiredPages If {@code true} tracks number of allocated pages (for tests purpose only).\n     */\n    public PageMemoryNoStoreImpl(\n        IgniteLogger log,\n        DirectMemoryProvider directMemoryProvider,\n        GridCacheSharedContext<?, ?> sharedCtx,\n        int pageSize,\n        MemoryPolicyConfiguration memPlcCfg,\n        MemoryMetricsImpl memMetrics,\n        boolean trackAcquiredPages\n    ) {\n        assert log != null || sharedCtx != null;\n        assert pageSize % 8 == 0;\n\n        this.log = sharedCtx != null ? sharedCtx.logger(PageMemoryNoStoreImpl.class) : log;\n        this.directMemoryProvider = directMemoryProvider;\n        this.trackAcquiredPages = trackAcquiredPages;\n        this.memMetrics = memMetrics;\n        memoryPolicyCfg = memPlcCfg;\n\n        sysPageSize = pageSize + PAGE_OVERHEAD;\n\n        assert sysPageSize % 8 == 0 : sysPageSize;\n\n        totalPages = (int)(memPlcCfg.getMaxSize() / sysPageSize);\n\n        rwLock = new OffheapReadWriteLock(lockConcLvl);\n    }"
        ],
        [
            "MemoryConfiguration::setSystemCacheInitialSize(long)",
            " 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  ",
            "    /**\n     * Sets initial size of a memory region reserved for system cache.\n     *\n     * Default value is {@link #DFLT_SYS_CACHE_INIT_SIZE}\n     *\n     * @param sysCacheInitSize Size in bytes.\n     *\n     * @return {@code this} for chaining.\n     */\n    public MemoryConfiguration setSystemCacheInitialSize(long sysCacheInitSize) {\n        this.sysCacheInitSize = sysCacheInitSize;\n\n        return this;\n    }",
            " 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129 +\n 130 +\n 131  \n 132  \n 133  \n 134  ",
            "    /**\n     * Sets initial size of a memory region reserved for system cache.\n     *\n     * Default value is {@link #DFLT_SYS_CACHE_INIT_SIZE}\n     *\n     * @param sysCacheInitSize Size in bytes.\n     *\n     * @return {@code this} for chaining.\n     */\n    public MemoryConfiguration setSystemCacheInitialSize(long sysCacheInitSize) {\n        A.ensure(sysCacheMaxSize > 0, \"System cache initial size can not be less zero.\");\n\n        this.sysCacheInitSize = sysCacheInitSize;\n\n        return this;\n    }"
        ],
        [
            "MemoryConfiguration::createDefaultPolicyConfig()",
            " 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217 -\n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  ",
            "    /**\n     * Creates a configuration for the default memory policy that will instantiate the default memory region.\n     * To override settings of the default memory policy in order to create the default memory region with different\n     * parameters, create own memory policy first, pass it to\n     * {@link MemoryConfiguration#setMemoryPolicies(MemoryPolicyConfiguration...)} method and change the name of the\n     * default memory policy with {@link MemoryConfiguration#setDefaultMemoryPolicyName(String)}.\n     *\n     * @return default Memory policy configuration.\n     */\n    public MemoryPolicyConfiguration createDefaultPolicyConfig() {\n        MemoryPolicyConfiguration memPlc = new MemoryPolicyConfiguration();\n\n        long maxSize = (dfltMemPlcSize != null) ? dfltMemPlcSize : DFLT_MEMORY_POLICY_MAX_SIZE;\n\n        if (maxSize < DFLT_MEMORY_POLICY_INITIAL_SIZE)\n            memPlc.setInitialSize(maxSize);\n\n        memPlc.setMaxSize(maxSize);\n\n        return memPlc;\n    }",
            " 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221 +\n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  ",
            "    /**\n     * Creates a configuration for the default memory policy that will instantiate the default memory region.\n     * To override settings of the default memory policy in order to create the default memory region with different\n     * parameters, create own memory policy first, pass it to\n     * {@link MemoryConfiguration#setMemoryPolicies(MemoryPolicyConfiguration...)} method and change the name of the\n     * default memory policy with {@link MemoryConfiguration#setDefaultMemoryPolicyName(String)}.\n     *\n     * @return default Memory policy configuration.\n     */\n    public MemoryPolicyConfiguration createDefaultPolicyConfig() {\n        MemoryPolicyConfiguration memPlc = new MemoryPolicyConfiguration();\n\n        long maxSize = dfltMemPlcSize;\n\n        if (maxSize < DFLT_MEMORY_POLICY_INITIAL_SIZE)\n            memPlc.setInitialSize(maxSize);\n\n        memPlc.setMaxSize(maxSize);\n\n        return memPlc;\n    }"
        ],
        [
            "MemoryConfiguration::getDefaultMemoryPolicySize()",
            " 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254 -\n 255  ",
            "    /**\n     * Gets a size for default memory policy overridden by user.\n     *\n     * @return default memory policy size overridden by user or -1 if nothing was specified.\n     */\n    public long getDefaultMemoryPolicySize() {\n        return (dfltMemPlcSize != null) ? dfltMemPlcSize : -1;\n    }",
            " 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258 +\n 259  ",
            "    /**\n     * Gets a size for default memory policy overridden by user.\n     *\n     * @return default memory policy size overridden by user or {@link #DFLT_MEMORY_POLICY_MAX_SIZE} if nothing was specified.\n     */\n    public long getDefaultMemoryPolicySize() {\n        return dfltMemPlcSize;\n    }"
        ],
        [
            "PageMemoryNoStoreImpl::pageIndex(int)",
            " 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519 -\n 520  \n 521 -\n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  ",
            "    /**\n     * @param seqNo Page sequence number.\n     * @return Page index.\n     */\n    public int pageIndex(int seqNo) {\n        Segment[] segs = segments;\n\n        int low = 0, high = segs.length - 1;\n\n        while (low <= high) {\n            int mid = (low + high) >>> 1;\n\n            Segment seg = segs[mid];\n\n            int cmp = seg.containsPageBySequence(seqNo);\n\n            if (cmp < 0)\n                high = mid - 1;\n            else if (cmp > 0) {\n                low = mid + 1;\n            }\n            else\n                return seg.pageIndex(seqNo);\n        }\n\n        throw new IgniteException(\"Allocated page must always be present in one of the segments [seqNo=\" + seqNo +\n            \", segments=\" + Arrays.toString(segs) + ']');\n    }",
            " 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526 +\n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  ",
            "    /**\n     * @param seqNo Page sequence number.\n     * @return Page index.\n     */\n    public int pageIndex(int seqNo) {\n        Segment[] segs = segments;\n\n        int low = 0, high = segs.length - 1;\n\n        while (low <= high) {\n            int mid = (low + high) >>> 1;\n\n            Segment seg = segs[mid];\n\n            int cmp = seg.containsPageBySequence(seqNo);\n\n            if (cmp < 0)\n                high = mid - 1;\n            else if (cmp > 0)\n                low = mid + 1;\n            else\n                return seg.pageIndex(seqNo);\n        }\n\n        throw new IgniteException(\"Allocated page must always be present in one of the segments [seqNo=\" + seqNo +\n            \", segments=\" + Arrays.toString(segs) + ']');\n    }"
        ],
        [
            "IgniteCacheDatabaseSharedManager::addMemoryPolicy(MemoryConfiguration,MemoryPolicyConfiguration,String)",
            " 258  \n 259  \n 260  \n 261  \n 262  \n 263 -\n 264 -\n 265 -\n 266 -\n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273 -\n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  ",
            "    /**\n     * @param dbCfg Database config.\n     * @param memPlcCfg Memory policy config.\n     * @param memPlcName Memory policy name.\n     */\n    private void addMemoryPolicy(MemoryConfiguration dbCfg,\n                                 MemoryPolicyConfiguration memPlcCfg,\n                                 String memPlcName) {\n        String dfltMemPlcName = dbCfg.getDefaultMemoryPolicyName();\n\n        if (dfltMemPlcName == null)\n            dfltMemPlcName = DFLT_MEM_PLC_DEFAULT_NAME;\n\n        MemoryMetricsImpl memMetrics = new MemoryMetricsImpl(memPlcCfg);\n\n        MemoryPolicy memPlc = initMemory(dbCfg, memPlcCfg, memMetrics);\n\n        memPlcMap.put(memPlcName, memPlc);\n\n        memMetricsMap.put(memPlcName, memMetrics);\n\n        if (memPlcName.equals(dfltMemPlcName))\n            dfltMemPlc = memPlc;\n        else if (memPlcName.equals(DFLT_MEM_PLC_DEFAULT_NAME))\n            U.warn(log, \"Memory Policy with name 'default' isn't used as a default. \" +\n                    \"Please check Memory Policies configuration.\");\n    }",
            " 264  \n 265  \n 266  \n 267  \n 268  \n 269 +\n 270 +\n 271 +\n 272 +\n 273 +\n 274 +\n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281 +\n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  ",
            "    /**\n     * @param memCfg Database config.\n     * @param memPlcCfg Memory policy config.\n     * @param memPlcName Memory policy name.\n     */\n    private void addMemoryPolicy(\n        MemoryConfiguration memCfg,\n        MemoryPolicyConfiguration memPlcCfg,\n        String memPlcName\n    ) {\n        String dfltMemPlcName = memCfg.getDefaultMemoryPolicyName();\n\n        if (dfltMemPlcName == null)\n            dfltMemPlcName = DFLT_MEM_PLC_DEFAULT_NAME;\n\n        MemoryMetricsImpl memMetrics = new MemoryMetricsImpl(memPlcCfg);\n\n        MemoryPolicy memPlc = initMemory(memCfg, memPlcCfg, memMetrics);\n\n        memPlcMap.put(memPlcName, memPlc);\n\n        memMetricsMap.put(memPlcName, memMetrics);\n\n        if (memPlcName.equals(dfltMemPlcName))\n            dfltMemPlc = memPlc;\n        else if (memPlcName.equals(DFLT_MEM_PLC_DEFAULT_NAME))\n            U.warn(log, \"Memory Policy with name 'default' isn't used as a default. \" +\n                    \"Please check Memory Policies configuration.\");\n    }"
        ],
        [
            "MemoryConfiguration::setSystemCacheMaxSize(long)",
            " 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  ",
            "    /**\n     * Sets maximum memory region size reserved for system cache. The total size should not be less than 10 MB\n     * due to internal data structures overhead.\n     *\n     * @param sysCacheMaxSize Maximum size in bytes for system cache memory region.\n     *\n     * @return {@code this} for chaining.\n     */\n    public MemoryConfiguration setSystemCacheMaxSize(long sysCacheMaxSize) {\n        this.sysCacheMaxSize = sysCacheMaxSize;\n\n        return this;\n    }",
            " 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154 +\n 155 +\n 156  \n 157  \n 158  \n 159  ",
            "    /**\n     * Sets maximum memory region size reserved for system cache. The total size should not be less than 10 MB\n     * due to internal data structures overhead.\n     *\n     * @param sysCacheMaxSize Maximum size in bytes for system cache memory region.\n     *\n     * @return {@code this} for chaining.\n     */\n    public MemoryConfiguration setSystemCacheMaxSize(long sysCacheMaxSize) {\n        A.ensure(sysCacheMaxSize > 0, \"System cache max size can not be less zero.\");\n\n        this.sysCacheMaxSize = sysCacheMaxSize;\n\n        return this;\n    }"
        ]
    ],
    "d16e22c3af0411ff8bc88d0e1cd029d0da79e0b9": [
        [
            "DataStreamerImpl::addData(K,V)",
            " 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662 -\n 663 -\n 664 -\n 665  \n 666 -\n 667  \n 668  \n 669  \n 670  \n 671  ",
            "    /** {@inheritDoc} */\n    @Override public IgniteFuture<?> addData(K key, V val) {\n        A.notNull(key, \"key\");\n\n        if (val == null)\n            checkSecurityPermission(SecurityPermission.CACHE_REMOVE);\n        else\n            checkSecurityPermission(SecurityPermission.CACHE_PUT);\n\n        try {\n            KeyCacheObject key0 = cacheObjProc.toCacheKeyObject(cacheObjCtx, null, key, true);\n            CacheObject val0 = cacheObjProc.toCacheObject(cacheObjCtx, val, true);\n\n            return addDataInternal(Collections.singleton(new DataStreamerEntry(key0, val0)));\n        }\n        catch (Exception e) {\n            return new IgniteFinishedCacheFutureImpl<>(e);\n        }\n    }",
            " 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662 +\n 663 +\n 664  \n 665 +\n 666 +\n 667 +\n 668  \n 669  \n 670  \n 671  \n 672 +\n 673 +\n 674  ",
            "    /** {@inheritDoc} */\n    @Override public IgniteFuture<?> addData(K key, V val) {\n        A.notNull(key, \"key\");\n\n        if (val == null)\n            checkSecurityPermission(SecurityPermission.CACHE_REMOVE);\n        else\n            checkSecurityPermission(SecurityPermission.CACHE_PUT);\n\n        KeyCacheObject key0;\n        CacheObject val0;\n\n        try {\n            key0 = cacheObjProc.toCacheKeyObject(cacheObjCtx, null, key, true);\n            val0 = cacheObjProc.toCacheObject(cacheObjCtx, val, true);\n        }\n        catch (Exception e) {\n            return new IgniteFinishedCacheFutureImpl<>(e);\n        }\n\n        return addDataInternal(Collections.singleton(new DataStreamerEntry(key0, val0)));\n    }"
        ]
    ],
    "7adb11109bab5d83ed4f376b0cad42b026dd0a71": [
        [
            "GridDhtPartitionTopologyImpl::beforeExchange(GridDhtPartitionsExchangeFuture,boolean)",
            " 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447 -\n 448 -\n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455 -\n 456 -\n 457  \n 458  \n 459  \n 460  \n 461  \n 462 -\n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473 -\n 474 -\n 475 -\n 476 -\n 477 -\n 478  \n 479  \n 480 -\n 481 -\n 482 -\n 483 -\n 484 -\n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502 -\n 503 -\n 504 -\n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  ",
            "    /** {@inheritDoc} */\n    @Override public void beforeExchange(GridDhtPartitionsExchangeFuture exchFut, boolean affReady)\n        throws IgniteCheckedException {\n        DiscoveryEvent discoEvt = exchFut.discoveryEvent();\n\n        treatAllPartAsLoc = exchFut.activateCluster()\n            || (discoEvt.type() == EventType.EVT_NODE_JOINED\n            && discoEvt.eventNode().isLocal()\n            && !ctx.kernalContext().clientNode()\n        );\n\n        ClusterNode loc = ctx.localNode();\n\n        ctx.database().checkpointReadLock();\n\n        try {\n            synchronized (ctx.exchange().interruptLock()) {\n                if (Thread.currentThread().isInterrupted())\n                    throw new IgniteInterruptedCheckedException(\"Thread is interrupted: \" + Thread.currentThread());\n\n                U.writeLock(lock);\n\n                try {\n                    if (stopping)\n                        return;\n\n                    GridDhtPartitionExchangeId exchId = exchFut.exchangeId();assert topVer.equals(exchId.topologyVersion()) : \"Invalid topology version [topVer=\" +\n                        topVer + \", exchId=\" + exchId + ']';\n\n                    if (exchId.isLeft() && exchFut.serverNodeDiscoveryEvent())\n                        removeNode(exchId.nodeId());\n    \n                    ClusterNode oldest = discoCache.oldestAliveServerNodeWithCache();\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition map beforeExchange [exchId=\" + exchId + \", fullMap=\" + fullMapString() + ']');\n\n                    long updateSeq = this.updateSeq.incrementAndGet();\n\n                    cntrMap.clear();\n\n                    boolean grpStarted = exchFut.cacheGroupAddedOnExchange(grp.groupId(), grp.receivedFrom());// If this is the oldest node.\n\n                    if (oldest != null && (loc.equals(oldest) || grpStarted)) {\n                        if (node2part == null) {\n                            node2part = new GridDhtPartitionFullMap(oldest.id(), oldest.order(), updateSeq);\n\n                            if (log.isDebugEnabled())\n                                log.debug(\"Created brand new full topology map on oldest node [exchId=\" +\n                                    exchId + \", fullMap=\" + fullMapString() + ']');\n                        }\n                        else if (!node2part.valid()) {\n                            node2part = new GridDhtPartitionFullMap(oldest.id(), oldest.order(), updateSeq, node2part, false);\n\n                            if (log.isDebugEnabled())\n                                log.debug(\"Created new full topology map on oldest node [exchId=\" + exchId + \", fullMap=\" +\n                                    node2part + ']');\n                        }\n                        else if (!node2part.nodeId().equals(loc.id())) {\n                            node2part = new GridDhtPartitionFullMap(oldest.id(), oldest.order(), updateSeq, node2part, false);\n\n                            if (log.isDebugEnabled())\n                                log.debug(\"Copied old map into new map on oldest node (previous oldest node left) [exchId=\" +\n                                    exchId + \", fullMap=\" + fullMapString() + ']');\n                        }\n                    }\n\n                    if (grpStarted ||\n                        exchFut.discoveryEvent().type() == EVT_DISCOVERY_CUSTOM_EVT ||\n                        exchFut.serverNodeDiscoveryEvent()) {\n                        if (affReady)\n                            initPartitions0(exchFut, updateSeq);\n                        else {\n                            List<List<ClusterNode>> aff = grp.affinity().idealAssignment();\n\n                            createPartitions(aff, updateSeq);\n                        }\n                    }\n\n                    consistencyCheck();\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition map after beforeExchange [exchId=\" + exchId + \", fullMap=\" +\n                            fullMapString() + ']');\n                }\n                finally {\n                    lock.writeLock().unlock();\n                }\n            }\n        }\n        finally {\n            ctx.database().checkpointReadUnlock();\n        }\n    }",
            " 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447 +\n 448 +\n 449 +\n 450 +\n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457 +\n 458 +\n 459 +\n 460 +\n 461  \n 462  \n 463  \n 464  \n 465  \n 466 +\n 467  \n 468 +\n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478 +\n 479 +\n 480 +\n 481 +\n 482 +\n 483 +\n 484 +\n 485 +\n 486 +\n 487 +\n 488  \n 489  \n 490 +\n 491 +\n 492 +\n 493 +\n 494 +\n 495 +\n 496 +\n 497 +\n 498 +\n 499 +\n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517 +\n 518 +\n 519 +\n 520 +\n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  ",
            "    /** {@inheritDoc} */\n    @Override public void beforeExchange(GridDhtPartitionsExchangeFuture exchFut, boolean affReady)\n        throws IgniteCheckedException {\n        DiscoveryEvent discoEvt = exchFut.discoveryEvent();\n\n        treatAllPartAsLoc = exchFut.activateCluster()\n            || (discoEvt.type() == EventType.EVT_NODE_JOINED\n            && discoEvt.eventNode().isLocal()\n            && !ctx.kernalContext().clientNode()\n        );\n\n        ClusterNode loc = ctx.localNode();\n\n        ctx.database().checkpointReadLock();\n\n        try {\n            synchronized (ctx.exchange().interruptLock()) {\n                if (Thread.currentThread().isInterrupted())\n                    throw new IgniteInterruptedCheckedException(\"Thread is interrupted: \" + Thread.currentThread());\n\n                U.writeLock(lock);\n\n                try {\n                    if (stopping)\n                        return;\n\n                    GridDhtPartitionExchangeId exchId = exchFut.exchangeId();\n\n                    assert topVer.equals(exchId.topologyVersion()) : \"Invalid topology version [topVer=\" + topVer +\n                        \", exchId=\" + exchId + ']';\n\n                    if (exchId.isLeft() && exchFut.serverNodeDiscoveryEvent())\n                        removeNode(exchId.nodeId());\n    \n                    ClusterNode oldest = discoCache.oldestAliveServerNodeWithCache();\n\n                    if (log.isDebugEnabled()) {\n                        log.debug(\"Partition map beforeExchange [exchId=\" + exchId +\n                            \", fullMap=\" + fullMapString() + ']');\n                    }\n\n                    long updateSeq = this.updateSeq.incrementAndGet();\n\n                    cntrMap.clear();\n\n                    boolean grpStarted = exchFut.cacheGroupAddedOnExchange(grp.groupId(), grp.receivedFrom());\n\n                    // If this is the oldest node.\n                    if (oldest != null && (loc.equals(oldest) || grpStarted)) {\n                        if (node2part == null) {\n                            node2part = new GridDhtPartitionFullMap(oldest.id(), oldest.order(), updateSeq);\n\n                            if (log.isDebugEnabled())\n                                log.debug(\"Created brand new full topology map on oldest node [exchId=\" +\n                                    exchId + \", fullMap=\" + fullMapString() + ']');\n                        }\n                        else if (!node2part.valid()) {\n                            node2part = new GridDhtPartitionFullMap(oldest.id(),\n                                oldest.order(),\n                                updateSeq,\n                                node2part,\n                                false);\n\n                            if (log.isDebugEnabled()) {\n                                log.debug(\"Created new full topology map on oldest node [exchId=\" + exchId +\n                                    \", fullMap=\" + node2part + ']');\n                            }\n                        }\n                        else if (!node2part.nodeId().equals(loc.id())) {\n                            node2part = new GridDhtPartitionFullMap(oldest.id(),\n                                oldest.order(),\n                                updateSeq,\n                                node2part,\n                                false);\n\n                            if (log.isDebugEnabled()) {\n                                log.debug(\"Copied old map into new map on oldest node (previous oldest node left) [\" +\n                                    \"exchId=\" + exchId + \", fullMap=\" + fullMapString() + ']');\n                            }\n                        }\n                    }\n\n                    if (grpStarted ||\n                        exchFut.discoveryEvent().type() == EVT_DISCOVERY_CUSTOM_EVT ||\n                        exchFut.serverNodeDiscoveryEvent()) {\n                        if (affReady)\n                            initPartitions0(exchFut, updateSeq);\n                        else {\n                            List<List<ClusterNode>> aff = grp.affinity().idealAssignment();\n\n                            createPartitions(aff, updateSeq);\n                        }\n                    }\n\n                    consistencyCheck();\n\n                    if (log.isDebugEnabled()) {\n                        log.debug(\"Partition map after beforeExchange [exchId=\" + exchId +\n                            \", fullMap=\" + fullMapString() + ']');\n                    }\n                }\n                finally {\n                    lock.writeLock().unlock();\n                }\n            }\n        }\n        finally {\n            ctx.database().checkpointReadUnlock();\n        }\n    }"
        ]
    ],
    "770efe23ce58a62461c698b42b4d58c5791bceb2": [
        [
            "FileWriteAheadLogManager::FileWriteHandle::flushOrWait(FileWALPointer,boolean)",
            "1782  \n1783  \n1784  \n1785  \n1786  \n1787  \n1788  \n1789  \n1790  \n1791  \n1792  \n1793  \n1794  \n1795  \n1796  \n1797  \n1798  \n1799  \n1800  \n1801  \n1802  \n1803  \n1804  \n1805  \n1806  \n1807  \n1808  \n1809  \n1810  \n1811  \n1812  \n1813  \n1814  \n1815  \n1816  \n1817  \n1818  \n1819  \n1820  ",
            "        /**\n         * Flush or wait for concurrent flush completion.\n         *\n         * @param ptr Pointer.\n         * @throws IgniteCheckedException If failed.\n         */\n        private void flushOrWait(FileWALPointer ptr, boolean stop) throws IgniteCheckedException {\n            long expWritten;\n\n            if (ptr != null) {\n                // If requested obsolete file index, it must be already flushed by close.\n                if (ptr.index() != idx)\n                    return;\n\n                expWritten = ptr.fileOffset();\n            }\n            else // We read head position before the flush because otherwise we can get wrong position.\n                expWritten = recordOffset(head.get());\n\n            if (flush(ptr, stop))\n                return;\n\n            // Spin-wait for a while before acquiring the lock.\n            for (int i = 0; i < 64; i++) {\n                if (written >= expWritten)\n                    return;\n            }\n\n            // If we did not flush ourselves then await for concurrent flush to complete.\n            lock.lock();\n\n            try {\n                while (written < expWritten && envFailed == null)\n                    U.await(writeComplete);\n            }\n            finally {\n                lock.unlock();\n            }\n        }",
            "1782  \n1783  \n1784  \n1785  \n1786  \n1787  \n1788  \n1789  \n1790  \n1791  \n1792  \n1793  \n1794  \n1795  \n1796  \n1797  \n1798  \n1799  \n1800  \n1801  \n1802  \n1803 +\n1804 +\n1805 +\n1806 +\n1807 +\n1808 +\n1809 +\n1810  \n1811  \n1812  \n1813  \n1814  \n1815  \n1816  \n1817  \n1818  \n1819  \n1820  \n1821  \n1822  \n1823  \n1824  \n1825  \n1826  \n1827  ",
            "        /**\n         * Flush or wait for concurrent flush completion.\n         *\n         * @param ptr Pointer.\n         * @throws IgniteCheckedException If failed.\n         */\n        private void flushOrWait(FileWALPointer ptr, boolean stop) throws IgniteCheckedException {\n            long expWritten;\n\n            if (ptr != null) {\n                // If requested obsolete file index, it must be already flushed by close.\n                if (ptr.index() != idx)\n                    return;\n\n                expWritten = ptr.fileOffset();\n            }\n            else // We read head position before the flush because otherwise we can get wrong position.\n                expWritten = recordOffset(head.get());\n\n            if (flush(ptr, stop))\n                return;\n            else if (stop) {\n                FakeRecord fr = (FakeRecord)head.get();\n\n                assert fr.stop : \"Invalid fake record on top of the queue: \" + fr;\n\n                expWritten = recordOffset(fr);\n            }\n\n            // Spin-wait for a while before acquiring the lock.\n            for (int i = 0; i < 64; i++) {\n                if (written >= expWritten)\n                    return;\n            }\n\n            // If we did not flush ourselves then await for concurrent flush to complete.\n            lock.lock();\n\n            try {\n                while (written < expWritten && envFailed == null)\n                    U.await(writeComplete);\n            }\n            finally {\n                lock.unlock();\n            }\n        }"
        ],
        [
            "FileWriteAheadLogManager::FileWriteHandle::close(boolean)",
            "2046  \n2047  \n2048  \n2049  \n2050  \n2051  \n2052 -\n2053 -\n2054 -\n2055  \n2056  \n2057 -\n2058  \n2059 -\n2060  \n2061  \n2062  \n2063  \n2064  \n2065  \n2066  \n2067  \n2068  \n2069  \n2070  \n2071  \n2072  \n2073 -\n2074  \n2075 -\n2076 -\n2077  \n2078  \n2079  \n2080  \n2081  \n2082  \n2083  \n2084  \n2085  \n2086  \n2087  \n2088  \n2089  \n2090  \n2091  \n2092  ",
            "        /**\n         * @return {@code true} If this thread actually closed the segment.\n         * @throws IgniteCheckedException If failed.\n         * @throws StorageException If failed.\n         */\n        private boolean close(boolean rollOver) throws IgniteCheckedException, StorageException {\n            if (mode == WALMode.DEFAULT)\n                fsync(null, true);\n            else\n                flushOrWait(null, true);\n\n            assert stopped() : \"Segment is not closed after close flush: \" + head.get();\n\n            if (stop.compareAndSet(false, true)) {\n                try {\n                    int switchSegmentRecSize = RecordV1Serializer.REC_TYPE_SIZE + RecordV1Serializer.FILE_WAL_POINTER_SIZE;\n\n                    if (rollOver && written < (maxSegmentSize - switchSegmentRecSize)) {\n                        //it is expected there is sufficient space for this record because rollover should run early\n                        final ByteBuffer buf = ByteBuffer.allocate(switchSegmentRecSize);\n                        buf.put((byte)(WALRecord.RecordType.SWITCH_SEGMENT_RECORD.ordinal() + 1));\n\n                        final FileWALPointer pointer = new FileWALPointer(idx, (int)fileIO.position(), -1);\n                        RecordV1Serializer.putPosition(buf, pointer);\n\n                        buf.rewind();\n\n                        fileIO.write(buf, written);\n\n                        if (mode == WALMode.DEFAULT)\n                            fileIO.force();\n                    }\n\n                    fileIO.close();\n                }\n                catch (IOException e) {\n                    throw new IgniteCheckedException(e);\n                }\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Closed WAL write handle [idx=\" + idx + \"]\");\n\n                return true;\n            }\n            else\n                return false;\n        }",
            "2053  \n2054  \n2055  \n2056  \n2057  \n2058  \n2059 +\n2060  \n2061  \n2062 +\n2063  \n2064  \n2065  \n2066  \n2067  \n2068  \n2069  \n2070  \n2071  \n2072  \n2073  \n2074  \n2075  \n2076  \n2077 +\n2078 +\n2079 +\n2080 +\n2081 +\n2082 +\n2083 +\n2084 +\n2085 +\n2086 +\n2087 +\n2088 +\n2089 +\n2090 +\n2091  \n2092 +\n2093  \n2094  \n2095  \n2096  \n2097  \n2098  \n2099  \n2100  \n2101  \n2102  \n2103  \n2104  \n2105  \n2106  \n2107  \n2108  ",
            "        /**\n         * @return {@code true} If this thread actually closed the segment.\n         * @throws IgniteCheckedException If failed.\n         * @throws StorageException If failed.\n         */\n        private boolean close(boolean rollOver) throws IgniteCheckedException, StorageException {\n            if (stop.compareAndSet(false, true)) {\n                flushOrWait(null, true);\n\n                assert stopped() : \"Segment is not closed after close flush: \" + head.get();\n\n                try {\n                    int switchSegmentRecSize = RecordV1Serializer.REC_TYPE_SIZE + RecordV1Serializer.FILE_WAL_POINTER_SIZE;\n\n                    if (rollOver && written < (maxSegmentSize - switchSegmentRecSize)) {\n                        //it is expected there is sufficient space for this record because rollover should run early\n                        final ByteBuffer buf = ByteBuffer.allocate(switchSegmentRecSize);\n                        buf.put((byte)(WALRecord.RecordType.SWITCH_SEGMENT_RECORD.ordinal() + 1));\n\n                        final FileWALPointer pointer = new FileWALPointer(idx, (int)fileIO.position(), -1);\n                        RecordV1Serializer.putPosition(buf, pointer);\n\n                        buf.rewind();\n\n                        int rem = buf.remaining();\n\n                        while (rem > 0) {\n                            int written0 = fileIO.write(buf, written);\n\n                            written += written0;\n\n                            rem -= written0;\n                        }\n                    }\n\n                    // Do the final fsync.\n                    if (mode == WALMode.DEFAULT) {\n                        fileIO.force();\n\n                        lastFsyncPos = written;\n                    }\n\n                    fileIO.close();\n                }\n                catch (IOException e) {\n                    throw new IgniteCheckedException(e);\n                }\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Closed WAL write handle [idx=\" + idx + \"]\");\n\n                return true;\n            }\n            else\n                return false;\n        }"
        ]
    ],
    "2c9057a3eb060cb5beb8ae9bc4173d15d99433e4": [
        [
            "GridDhtPartitionsExchangeFuture::topologyVersion()",
            " 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368 -\n 369  ",
            "    /** {@inheritDoc} */\n    @Override public AffinityTopologyVersion topologyVersion() {\n        /*\n        Should not be called before exchange is finished since result version can change in\n        case of merged exchanges.\n         */\n        assert exchangeDone() : \"Should not be called before exchange is finished\";\n\n        return exchCtx.events().topologyVersion();\n    }",
            " 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368 +\n 369  ",
            "    /** {@inheritDoc} */\n    @Override public AffinityTopologyVersion topologyVersion() {\n        /*\n        Should not be called before exchange is finished since result version can change in\n        case of merged exchanges.\n         */\n        assert exchangeDone() : \"Should not be called before exchange is finished\";\n\n        return isDone() ? result() : exchCtx.events().topologyVersion();\n    }"
        ]
    ],
    "5c8c492005868e6ee2bad1fb8daac5b202da52dd": [
        [
            "JdbcThinDatabaseMetadata::columnRow(JdbcColumnMeta,int)",
            " 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838 -\n 839 -\n 840 -\n 841 -\n 842 -\n 843 -\n 844 -\n 845 -\n 846 -\n 847 -\n 848 -\n 849 -\n 850 -\n 851 -\n 852 -\n 853 -\n 854 -\n 855 -\n 856 -\n 857 -\n 858  \n 859  \n 860  ",
            "    /**\n     * @param colMeta Column metadata.\n     * @param pos Ordinal position.\n     * @return Column metadata row.\n     */\n    private List<Object> columnRow(JdbcColumnMeta colMeta, int pos) {\n        List<Object> row = new ArrayList<>(20);\n\n        row.add((String)null);\n        row.add(colMeta.schemaName());\n        row.add(colMeta.tableName());\n        row.add(colMeta.columnName());\n        row.add(colMeta.dataType());\n        row.add(colMeta.dataTypeName());\n        row.add((Integer)null);\n        row.add((Integer)null);\n        row.add(10);\n        row.add(colMeta.isNullable() ? 1 : 0);\n        row.add((String)null);\n        row.add((String)null);\n        row.add(Integer.MAX_VALUE);\n        row.add(pos);\n        row.add(\"YES\");\n        row.add((String)null);\n        row.add((String)null);\n        row.add((String)null);\n        row.add((Short)null);\n        row.add(\"NO\");\n\n        return row;\n    }",
            " 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843 +\n 844 +\n 845 +\n 846 +\n 847 +\n 848 +\n 849 +\n 850 +\n 851 +\n 852 +\n 853 +\n 854 +\n 855 +\n 856 +\n 857 +\n 858 +\n 859 +\n 860 +\n 861 +\n 862 +\n 863 +\n 864 +\n 865 +\n 866 +\n 867  \n 868  \n 869  ",
            "    /**\n     * @param colMeta Column metadata.\n     * @param pos Ordinal position.\n     * @return Column metadata row.\n     */\n    private List<Object> columnRow(JdbcColumnMeta colMeta, int pos) {\n        List<Object> row = new ArrayList<>(20);\n\n        row.add((String)null);                  // 1. TABLE_CAT\n        row.add(colMeta.schemaName());          // 2. TABLE_SCHEM\n        row.add(colMeta.tableName());           // 3. TABLE_NAME\n        row.add(colMeta.columnName());          // 4. COLUMN_NAME\n        row.add(colMeta.dataType());            // 5. DATA_TYPE\n        row.add(colMeta.dataTypeName());        // 6. TYPE_NAME\n        row.add((Integer)null);                 // 7. COLUMN_SIZE\n        row.add((Integer)null);                 // 8. BUFFER_LENGTH\n        row.add((Integer)null);                 // 9. DECIMAL_DIGITS\n        row.add(10);                            // 10. NUM_PREC_RADIX\n        row.add(colMeta.isNullable() ? columnNullable : columnNoNulls);  // 11. NULLABLE\n        row.add((String)null);                  // 12. REMARKS\n        row.add((String)null);                  // 13. COLUMN_DEF\n        row.add(colMeta.dataType());            // 14. SQL_DATA_TYPE\n        row.add((Integer)null);                 // 15. SQL_DATETIME_SUB\n        row.add(Integer.MAX_VALUE);             // 16. CHAR_OCTET_LENGTH\n        row.add(pos);                           // 17. ORDINAL_POSITION\n        row.add(colMeta.isNullable() ? \"YES\" : \"NO\"); // 18. IS_NULLABLE\n        row.add((String)null);                  // 19. SCOPE_CATALOG\n        row.add((String)null);                  // 20. SCOPE_SCHEMA\n        row.add((String)null);                  // 21. SCOPE_TABLE\n        row.add((Short)null);                   // 22. SOURCE_DATA_TYPE\n        row.add(\"NO\");                          // 23. IS_AUTOINCREMENT\n        row.add(\"NO\");                          // 23. IS_GENERATEDCOLUMN\n\n        return row;\n    }"
        ],
        [
            "JdbcDatabaseMetadata::getColumns(String,String,String,String)",
            " 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818 -\n 819 -\n 820 -\n 821 -\n 822 -\n 823 -\n 824 -\n 825 -\n 826 -\n 827 -\n 828  ",
            "    /** {@inheritDoc} */\n    @Override public ResultSet getColumns(String catalog, String schemaPtrn, String tblNamePtrn,\n        String colNamePtrn) throws SQLException {\n        updateMetaData();\n\n        List<List<?>> rows = new LinkedList<>();\n\n        int cnt = 0;\n\n        if (validCatalogPattern(catalog)) {\n            for (Map.Entry<String, Map<String, Map<String, ColumnInfo>>> schema : meta.entrySet()) {\n                if (matches(schema.getKey(), schemaPtrn)) {\n                    for (Map.Entry<String, Map<String, ColumnInfo>> tbl : schema.getValue().entrySet()) {\n                        if (matches(tbl.getKey(), tblNamePtrn)) {\n                            for (Map.Entry<String, ColumnInfo> col : tbl.getValue().entrySet()) {\n                                rows.add(columnRow(schema.getKey(), tbl.getKey(), col.getKey(),\n                                    JdbcUtils.type(col.getValue().typeName()), JdbcUtils.typeName(col.getValue().typeName()),\n                                    !col.getValue().isNotNull(), ++cnt));\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        return new JdbcResultSet(true, null,\n            conn.createStatement0(),\n            Collections.<String>emptyList(),\n            Arrays.asList(\"TABLE_CAT\", \"TABLE_SCHEM\", \"TABLE_NAME\", \"COLUMN_NAME\", \"DATA_TYPE\",\n                \"TYPE_NAME\", \"COLUMN_SIZE\", \"DECIMAL_DIGITS\", \"NUM_PREC_RADIX\", \"NULLABLE\",\n                \"REMARKS\", \"COLUMN_DEF\", \"CHAR_OCTET_LENGTH\", \"ORDINAL_POSITION\", \"IS_NULLABLE\",\n                \"SCOPE_CATLOG\", \"SCOPE_SCHEMA\", \"SCOPE_TABLE\", \"SOURCE_DATA_TYPE\", \"IS_AUTOINCREMENT\"),\n            Arrays.asList(String.class.getName(), String.class.getName(), String.class.getName(),\n                String.class.getName(), Integer.class.getName(), String.class.getName(), Integer.class.getName(),\n                Integer.class.getName(), Integer.class.getName(), Integer.class.getName(), String.class.getName(),\n                String.class.getName(), Integer.class.getName(), Integer.class.getName(), String.class.getName(),\n                String.class.getName(), String.class.getName(), String.class.getName(), Short.class.getName(),\n                String.class.getName()),\n            rows, true",
            " 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818 +\n 819 +\n 820 +\n 821 +\n 822 +\n 823 +\n 824 +\n 825 +\n 826 +\n 827 +\n 828 +\n 829 +\n 830 +\n 831 +\n 832 +\n 833 +\n 834 +\n 835 +\n 836 +\n 837 +\n 838 +\n 839 +\n 840 +\n 841 +\n 842 +\n 843 +\n 844 +\n 845 +\n 846 +\n 847 +\n 848 +\n 849 +\n 850 +\n 851 +\n 852 +\n 853 +\n 854 +\n 855 +\n 856 +\n 857 +\n 858 +\n 859 +\n 860 +\n 861 +\n 862 +\n 863 +\n 864 +\n 865 +\n 866 +\n 867 +\n 868  ",
            "    /** {@inheritDoc} */\n    @Override public ResultSet getColumns(String catalog, String schemaPtrn, String tblNamePtrn,\n        String colNamePtrn) throws SQLException {\n        updateMetaData();\n\n        List<List<?>> rows = new LinkedList<>();\n\n        int cnt = 0;\n\n        if (validCatalogPattern(catalog)) {\n            for (Map.Entry<String, Map<String, Map<String, ColumnInfo>>> schema : meta.entrySet()) {\n                if (matches(schema.getKey(), schemaPtrn)) {\n                    for (Map.Entry<String, Map<String, ColumnInfo>> tbl : schema.getValue().entrySet()) {\n                        if (matches(tbl.getKey(), tblNamePtrn)) {\n                            for (Map.Entry<String, ColumnInfo> col : tbl.getValue().entrySet()) {\n                                rows.add(columnRow(schema.getKey(), tbl.getKey(), col.getKey(),\n                                    JdbcUtils.type(col.getValue().typeName()), JdbcUtils.typeName(col.getValue().typeName()),\n                                    !col.getValue().isNotNull(), ++cnt));\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        return new JdbcResultSet(true, null,\n            conn.createStatement0(),\n            Collections.<String>emptyList(),\n            Arrays.asList(\n                \"TABLE_CAT\",        // 1\n                \"TABLE_SCHEM\",      // 2\n                \"TABLE_NAME\",       // 3\n                \"COLUMN_NAME\",      // 4\n                \"DATA_TYPE\",        // 5\n                \"TYPE_NAME\",        // 6\n                \"COLUMN_SIZE\",      // 7\n                \"BUFFER_LENGTH\",    // 8\n                \"DECIMAL_DIGITS\",   // 9\n                \"NUM_PREC_RADIX\",   // 10\n                \"NULLABLE\",         // 11\n                \"REMARKS\",          // 12\n                \"COLUMN_DEF\",       // 13\n                \"SQL_DATA_TYPE\",    // 14\n                \"SQL_DATETIME_SUB\", // 15\n                \"CHAR_OCTET_LENGTH\", // 16\n                \"ORDINAL_POSITION\",  // 17\n                \"IS_NULLABLE\",      // 18\n                \"SCOPE_CATLOG\",     // 19\n                \"SCOPE_SCHEMA\",     // 20\n                \"SCOPE_TABLE\",      // 21\n                \"SOURCE_DATA_TYPE\", // 22\n                \"IS_AUTOINCREMENT\", // 23\n                \"IS_GENERATEDCOLUMN\"), // 23\n            Arrays.asList(\n                String.class.getName(),     // 1\n                String.class.getName(),     // 2\n                String.class.getName(),     // 3\n                String.class.getName(),     // 4\n                Integer.class.getName(),    // 5\n                String.class.getName(),     // 6\n                Integer.class.getName(),    // 7\n                Integer.class.getName(),    // 8\n                Integer.class.getName(),    // 9\n                Integer.class.getName(),    // 10\n                Integer.class.getName(),    // 11\n                String.class.getName(),     // 12\n                String.class.getName(),     // 13\n                Integer.class.getName(),    // 14\n                Integer.class.getName(),    // 15\n                Integer.class.getName(),    // 16\n                Integer.class.getName(),    // 17\n                String.class.getName(),     // 18\n                String.class.getName(),     // 19\n                String.class.getName(),     // 20\n                String.class.getName(),     // 21\n                Short.class.getName(),      // 22\n                String.class.getName(),     // 23\n                String.class.getName()),    // 24\n            rows, true"
        ],
        [
            "JdbcMetadataSelfTest::testGetColumns()",
            " 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testGetColumns() throws Exception {\n        try (Connection conn = DriverManager.getConnection(BASE_URL)) {\n            DatabaseMetaData meta = conn.getMetaData();\n\n            ResultSet rs = meta.getColumns(\"\", \"pers\", \"PERSON\", \"%\");\n\n            assertNotNull(rs);\n\n            Collection<String> names = new ArrayList<>(2);\n\n            names.add(\"NAME\");\n            names.add(\"AGE\");\n            names.add(\"ORGID\");\n\n            int cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assertTrue(names.remove(name));\n\n                if (\"NAME\".equals(name)) {\n                    assertEquals(VARCHAR, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"VARCHAR\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(0, rs.getInt(\"NULLABLE\"));\n                } else if (\"AGE\".equals(name)) {\n                    assertEquals(INTEGER, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"INTEGER\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(0, rs.getInt(\"NULLABLE\"));\n                } else if (\"ORGID\".equals(name)) {\n                    assertEquals(INTEGER, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"INTEGER\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(1, rs.getInt(\"NULLABLE\"));\n                }\n\n                cnt++;\n            }\n\n            assertTrue(names.isEmpty());\n            assertEquals(3, cnt);\n\n            rs = meta.getColumns(\"\", \"org\", \"ORGANIZATION\", \"%\");\n\n            assertNotNull(rs);\n\n            names.add(\"ID\");\n            names.add(\"NAME\");\n\n            cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assertTrue(names.remove(name));\n\n                if (\"id\".equals(name)) {\n                    assertEquals(INTEGER, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"INTEGER\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(0, rs.getInt(\"NULLABLE\"));\n                } else if (\"name\".equals(name)) {\n                    assertEquals(VARCHAR, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"VARCHAR\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(1, rs.getInt(\"NULLABLE\"));\n                }\n\n                cnt++;\n            }\n\n            assertTrue(names.isEmpty());\n            assertEquals(2, cnt);\n        }\n    }",
            " 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223 +\n 224 +\n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242 +\n 243 +\n 244  \n 245  \n 246  \n 247  \n 248 +\n 249 +\n 250  \n 251  \n 252  \n 253  \n 254 +\n 255 +\n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282 +\n 283 +\n 284  \n 285  \n 286  \n 287  \n 288 +\n 289 +\n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testGetColumns() throws Exception {\n        try (Connection conn = DriverManager.getConnection(BASE_URL)) {\n            DatabaseMetaData meta = conn.getMetaData();\n\n            ResultSet rs = meta.getColumns(\"\", \"pers\", \"PERSON\", \"%\");\n\n            assertNotNull(rs);\n\n            assertEquals(24, rs.getMetaData().getColumnCount());\n\n            Collection<String> names = new ArrayList<>(2);\n\n            names.add(\"NAME\");\n            names.add(\"AGE\");\n            names.add(\"ORGID\");\n\n            int cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assertTrue(names.remove(name));\n\n                if (\"NAME\".equals(name)) {\n                    assertEquals(VARCHAR, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"VARCHAR\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(0, rs.getInt(\"NULLABLE\"));\n                    assertEquals(0, rs.getInt(11)); // nullable column by index\n                    assertEquals(\"NO\", rs.getString(\"IS_NULLABLE\"));\n                } else if (\"AGE\".equals(name)) {\n                    assertEquals(INTEGER, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"INTEGER\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(0, rs.getInt(\"NULLABLE\"));\n                    assertEquals(0, rs.getInt(11)); // nullable column by index\n                    assertEquals(\"NO\", rs.getString(\"IS_NULLABLE\"));\n                } else if (\"ORGID\".equals(name)) {\n                    assertEquals(INTEGER, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"INTEGER\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(1, rs.getInt(\"NULLABLE\"));\n                    assertEquals(1, rs.getInt(11)); // nullable column by index\n                    assertEquals(\"YES\", rs.getString(\"IS_NULLABLE\"));\n                }\n\n                cnt++;\n            }\n\n            assertTrue(names.isEmpty());\n            assertEquals(3, cnt);\n\n            rs = meta.getColumns(\"\", \"org\", \"ORGANIZATION\", \"%\");\n\n            assertNotNull(rs);\n\n            names.add(\"ID\");\n            names.add(\"NAME\");\n\n            cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assertTrue(names.remove(name));\n\n                if (\"id\".equals(name)) {\n                    assertEquals(INTEGER, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"INTEGER\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(0, rs.getInt(\"NULLABLE\"));\n                    assertEquals(0, rs.getInt(11)); // nullable column by index\n                    assertEquals(\"NO\", rs.getString(\"IS_NULLABLE\"));\n                } else if (\"name\".equals(name)) {\n                    assertEquals(VARCHAR, rs.getInt(\"DATA_TYPE\"));\n                    assertEquals(\"VARCHAR\", rs.getString(\"TYPE_NAME\"));\n                    assertEquals(1, rs.getInt(\"NULLABLE\"));\n                    assertEquals(1, rs.getInt(11)); // nullable column by index\n                    assertEquals(\"YES\", rs.getString(\"IS_NULLABLE\"));\n                }\n\n                cnt++;\n            }\n\n            assertTrue(names.isEmpty());\n            assertEquals(2, cnt);\n        }\n    }"
        ],
        [
            "JdbcThinDatabaseMetadata::getColumns(String,String,String,String)",
            " 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796 -\n 797 -\n 798 -\n 799 -\n 800 -\n 801 -\n 802 -\n 803 -\n 804 -\n 805 -\n 806 -\n 807 -\n 808 -\n 809 -\n 810 -\n 811 -\n 812 -\n 813 -\n 814 -\n 815 -\n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  ",
            "    /** {@inheritDoc} */\n    @Override public ResultSet getColumns(String catalog, String schemaPtrn, String tblNamePtrn, String colNamePtrn)\n        throws SQLException {\n        conn.ensureNotClosed();\n\n        final List<JdbcColumnMeta> meta = Arrays.asList(\n            new JdbcColumnMeta(null, null, \"TABLE_CAT\", String.class),\n            new JdbcColumnMeta(null, null, \"TABLE_SCHEM\", String.class),\n            new JdbcColumnMeta(null, null, \"TABLE_NAME\", String.class),\n            new JdbcColumnMeta(null, null, \"COLUMN_NAME\", String.class),\n            new JdbcColumnMeta(null, null, \"DATA_TYPE\", Short.class),\n            new JdbcColumnMeta(null, null, \"TYPE_NAME\", String.class),\n            new JdbcColumnMeta(null, null, \"COLUMN_SIZE\", Integer.class),\n            new JdbcColumnMeta(null, null, \"DECIMAL_DIGITS\", Integer.class),\n            new JdbcColumnMeta(null, null, \"NUM_PREC_RADIX\", Short.class),\n            new JdbcColumnMeta(null, null, \"NULLABLE\", Short.class),\n            new JdbcColumnMeta(null, null, \"REMARKS\", String.class),\n            new JdbcColumnMeta(null, null, \"COLUMN_DEF\", String.class),\n            new JdbcColumnMeta(null, null, \"CHAR_OCTET_LENGTH\", Integer.class),\n            new JdbcColumnMeta(null, null, \"ORDINAL_POSITION\", Integer.class),\n            new JdbcColumnMeta(null, null, \"IS_NULLABLE\", String.class),\n            new JdbcColumnMeta(null, null, \"SCOPE_CATLOG\", String.class),\n            new JdbcColumnMeta(null, null, \"SCOPE_SCHEMA\", String.class),\n            new JdbcColumnMeta(null, null, \"SCOPE_TABLE\", String.class),\n            new JdbcColumnMeta(null, null, \"SOURCE_DATA_TYPE\", Short.class),\n            new JdbcColumnMeta(null, null, \"IS_AUTOINCREMENT\", String.class));\n\n        if (!validCatalogPattern(catalog))\n            return new JdbcThinResultSet(Collections.<List<Object>>emptyList(), meta);\n\n        JdbcMetaColumnsResult res = conn.sendRequest(new JdbcMetaColumnsRequest(schemaPtrn, tblNamePtrn, colNamePtrn));\n\n        List<List<Object>> rows = new LinkedList<>();\n\n        for (int i = 0; i < res.meta().size(); ++i)\n            rows.add(columnRow(res.meta().get(i), i + 1));\n\n        return new JdbcThinResultSet(rows, meta);\n    }",
            " 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796 +\n 797 +\n 798 +\n 799 +\n 800 +\n 801 +\n 802 +\n 803 +\n 804 +\n 805 +\n 806 +\n 807 +\n 808 +\n 809 +\n 810 +\n 811 +\n 812 +\n 813 +\n 814 +\n 815 +\n 816 +\n 817 +\n 818 +\n 819 +\n 820 +\n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  ",
            "    /** {@inheritDoc} */\n    @Override public ResultSet getColumns(String catalog, String schemaPtrn, String tblNamePtrn, String colNamePtrn)\n        throws SQLException {\n        conn.ensureNotClosed();\n\n        final List<JdbcColumnMeta> meta = Arrays.asList(\n            new JdbcColumnMeta(null, null, \"TABLE_CAT\", String.class),      // 1\n            new JdbcColumnMeta(null, null, \"TABLE_SCHEM\", String.class),    // 2\n            new JdbcColumnMeta(null, null, \"TABLE_NAME\", String.class),     // 3\n            new JdbcColumnMeta(null, null, \"COLUMN_NAME\", String.class),    // 4\n            new JdbcColumnMeta(null, null, \"DATA_TYPE\", Short.class),       // 5\n            new JdbcColumnMeta(null, null, \"TYPE_NAME\", String.class),      // 6\n            new JdbcColumnMeta(null, null, \"COLUMN_SIZE\", Integer.class),   // 7\n            new JdbcColumnMeta(null, null, \"BUFFER_LENGTH \", Integer.class), // 8\n            new JdbcColumnMeta(null, null, \"DECIMAL_DIGITS\", Integer.class), // 9\n            new JdbcColumnMeta(null, null, \"NUM_PREC_RADIX\", Short.class),  // 10\n            new JdbcColumnMeta(null, null, \"NULLABLE\", Short.class),        // 11\n            new JdbcColumnMeta(null, null, \"REMARKS\", String.class),        // 12\n            new JdbcColumnMeta(null, null, \"COLUMN_DEF\", String.class),     // 13\n            new JdbcColumnMeta(null, null, \"SQL_DATA_TYPE\", Integer.class), // 14\n            new JdbcColumnMeta(null, null, \"SQL_DATETIME_SUB\", Integer.class), // 15\n            new JdbcColumnMeta(null, null, \"CHAR_OCTET_LENGTH\", Integer.class), // 16\n            new JdbcColumnMeta(null, null, \"ORDINAL_POSITION\", Integer.class), // 17\n            new JdbcColumnMeta(null, null, \"IS_NULLABLE\", String.class),    // 18\n            new JdbcColumnMeta(null, null, \"SCOPE_CATLOG\", String.class),   // 19\n            new JdbcColumnMeta(null, null, \"SCOPE_SCHEMA\", String.class),   // 20\n            new JdbcColumnMeta(null, null, \"SCOPE_TABLE\", String.class),    // 21\n            new JdbcColumnMeta(null, null, \"SOURCE_DATA_TYPE\", Short.class), // 22\n            new JdbcColumnMeta(null, null, \"IS_AUTOINCREMENT\", String.class), // 23\n            new JdbcColumnMeta(null, null, \"IS_GENERATEDCOLUMN \", String.class) // 24\n        );\n\n        if (!validCatalogPattern(catalog))\n            return new JdbcThinResultSet(Collections.<List<Object>>emptyList(), meta);\n\n        JdbcMetaColumnsResult res = conn.sendRequest(new JdbcMetaColumnsRequest(schemaPtrn, tblNamePtrn, colNamePtrn));\n\n        List<List<Object>> rows = new LinkedList<>();\n\n        for (int i = 0; i < res.meta().size(); ++i)\n            rows.add(columnRow(res.meta().get(i), i + 1));\n\n        return new JdbcThinResultSet(rows, meta);\n    }"
        ],
        [
            "JdbcDatabaseMetadata::columnRow(String,String,String,int,String,boolean,int)",
            " 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846 -\n 847 -\n 848 -\n 849 -\n 850 -\n 851 -\n 852 -\n 853 -\n 854 -\n 855 -\n 856 -\n 857 -\n 858 -\n 859 -\n 860 -\n 861 -\n 862 -\n 863 -\n 864 -\n 865 -\n 866  \n 867  \n 868  ",
            "    /**\n     * @param schema Schema name.\n     * @param tbl Table name.\n     * @param col Column name.\n     * @param type Type.\n     * @param typeName Type name.\n     * @param nullable Nullable flag.\n     * @param pos Ordinal position.\n     * @return Column metadata row.\n     */\n    private List<Object> columnRow(String schema, String tbl, String col, int type, String typeName,\n        boolean nullable, int pos) {\n        List<Object> row = new ArrayList<>(20);\n\n        row.add(null);\n        row.add(schema);\n        row.add(tbl);\n        row.add(col);\n        row.add(type);\n        row.add(typeName);\n        row.add(null);\n        row.add(null);\n        row.add(10);\n        row.add(nullable ? columnNullable : columnNoNulls);\n        row.add(null);\n        row.add(null);\n        row.add(Integer.MAX_VALUE);\n        row.add(pos);\n        row.add(\"YES\");\n        row.add(null);\n        row.add(null);\n        row.add(null);\n        row.add(null);\n        row.add(\"NO\");\n\n        return row;\n    }",
            " 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  \n 886 +\n 887 +\n 888 +\n 889 +\n 890 +\n 891 +\n 892 +\n 893 +\n 894 +\n 895 +\n 896 +\n 897 +\n 898 +\n 899 +\n 900 +\n 901 +\n 902 +\n 903 +\n 904 +\n 905 +\n 906 +\n 907 +\n 908 +\n 909 +\n 910  \n 911  \n 912  ",
            "    /**\n     * @param schema Schema name.\n     * @param tbl Table name.\n     * @param col Column name.\n     * @param type Type.\n     * @param typeName Type name.\n     * @param nullable Nullable flag.\n     * @param pos Ordinal position.\n     * @return Column metadata row.\n     */\n    private List<Object> columnRow(String schema, String tbl, String col, int type, String typeName,\n        boolean nullable, int pos) {\n        List<Object> row = new ArrayList<>(20);\n\n        row.add(null);                  // 1. TABLE_CAT\n        row.add(schema);                // 2. TABLE_SCHEM\n        row.add(tbl);                   // 3. TABLE_NAME\n        row.add(col);                   // 4. COLUMN_NAME\n        row.add(type);                  // 5. DATA_TYPE\n        row.add(typeName);              // 6. TYPE_NAME\n        row.add(null);                  // 7. COLUMN_SIZE\n        row.add(null);                  // 8. BUFFER_LENGTH\n        row.add(null);                  // 9. DECIMAL_DIGITS\n        row.add(10);                    // 10. NUM_PREC_RADIX\n        row.add(nullable ? columnNullable : columnNoNulls); // 11. NULLABLE\n        row.add(null);                  // 12. REMARKS\n        row.add(null);                  // 13. COLUMN_DEF\n        row.add(type);                  // 14. SQL_DATA_TYPE\n        row.add(null);                  // 15. SQL_DATETIME_SUB\n        row.add(Integer.MAX_VALUE);     // 16. CHAR_OCTET_LENGTH\n        row.add(pos);                   // 17. ORDINAL_POSITION\n        row.add(nullable ? \"YES\" : \"NO\"); // 18. IS_NULLABLE\n        row.add(null);                  // 19. SCOPE_CATALOG\n        row.add(null);                  // 20. SCOPE_SCHEMA\n        row.add(null);                  // 21. SCOPE_TABLE\n        row.add(null);                  // 22. SOURCE_DATA_TYPE\n        row.add(\"NO\");                  // 23. IS_AUTOINCREMENT\n        row.add(\"NO\");                  // 24. IS_GENERATEDCOLUMN\n\n        return row;\n    }"
        ],
        [
            "JdbcThinMetadataSelfTest::testGetColumns()",
            " 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testGetColumns() throws Exception {\n        try (Connection conn = DriverManager.getConnection(URL)) {\n            conn.setSchema(\"pers\");\n\n            DatabaseMetaData meta = conn.getMetaData();\n\n            ResultSet rs = meta.getColumns(\"\", \"pers\", \"PERSON\", \"%\");\n\n            assert rs != null;\n\n            Collection<String> names = new ArrayList<>(2);\n\n            names.add(\"NAME\");\n            names.add(\"AGE\");\n            names.add(\"ORGID\");\n\n            int cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assert names.remove(name);\n\n                if (\"NAME\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == VARCHAR;\n                    assert \"VARCHAR\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                } else if (\"ORGID\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == INTEGER;\n                    assert \"INTEGER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 1;\n                } else if (\"AGE\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == INTEGER;\n                    assert \"INTEGER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n                else if (\"_KEY\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == OTHER;\n                    assert \"OTHER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n                else if (\"_VAL\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == OTHER;\n                    assert \"OTHER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n\n                cnt++;\n            }\n\n            assert names.isEmpty();\n            assert cnt == 3;\n\n            rs = meta.getColumns(\"\", \"org\", \"ORGANIZATION\", \"%\");\n\n            assert rs != null;\n\n            names.add(\"ID\");\n            names.add(\"NAME\");\n\n            cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assert names.remove(name);\n\n                if (\"id\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == INTEGER;\n                    assert \"INTEGER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                } else if (\"name\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == VARCHAR;\n                    assert \"VARCHAR\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 1;\n                }\n                if (\"_KEY\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == VARCHAR;\n                    assert \"VARCHAR\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n                if (\"_VAL\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == OTHER;\n                    assert \"OTHER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n\n                cnt++;\n            }\n\n            assert names.isEmpty();\n            assert cnt == 2;\n        }\n    }",
            " 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263 +\n 264 +\n 265 +\n 266 +\n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286 +\n 287 +\n 288  \n 289  \n 290  \n 291  \n 292 +\n 293 +\n 294  \n 295  \n 296  \n 297  \n 298 +\n 299 +\n 300  \n 301  \n 302  \n 303  \n 304  \n 305 +\n 306 +\n 307  \n 308  \n 309  \n 310  \n 311  \n 312 +\n 313 +\n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testGetColumns() throws Exception {\n        try (Connection conn = DriverManager.getConnection(URL)) {\n            conn.setSchema(\"pers\");\n\n            DatabaseMetaData meta = conn.getMetaData();\n\n            ResultSet rs = meta.getColumns(\"\", \"pers\", \"PERSON\", \"%\");\n\n            ResultSetMetaData rsMeta = rs.getMetaData();\n\n            assert rsMeta.getColumnCount() == 24 : \"Invalid columns count: \" + rsMeta.getColumnCount();\n\n            assert rs != null;\n\n            Collection<String> names = new ArrayList<>(2);\n\n            names.add(\"NAME\");\n            names.add(\"AGE\");\n            names.add(\"ORGID\");\n\n            int cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assert names.remove(name);\n\n                if (\"NAME\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == VARCHAR;\n                    assert \"VARCHAR\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                    assert rs.getInt(11) == 0; // nullable column by index\n                    assert rs.getString(\"IS_NULLABLE\").equals(\"NO\");\n                } else if (\"ORGID\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == INTEGER;\n                    assert \"INTEGER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 1;\n                    assert rs.getInt(11) == 1;  // nullable column by index\n                    assert rs.getString(\"IS_NULLABLE\").equals(\"YES\");\n                } else if (\"AGE\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == INTEGER;\n                    assert \"INTEGER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                    assert rs.getInt(11) == 0;  // nullable column by index\n                    assert rs.getString(\"IS_NULLABLE\").equals(\"NO\");\n                }\n                else if (\"_KEY\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == OTHER;\n                    assert \"OTHER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                    assert rs.getInt(11) == 0;  // nullable column by index\n                    assert rs.getString(\"IS_NULLABLE\").equals(\"NO\");\n                }\n                else if (\"_VAL\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == OTHER;\n                    assert \"OTHER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                    assert rs.getInt(11) == 0;  // nullable column by index\n                    assert rs.getString(\"IS_NULLABLE\").equals(\"NO\");\n                }\n\n                cnt++;\n            }\n\n            assert names.isEmpty();\n            assert cnt == 3;\n\n            rs = meta.getColumns(\"\", \"org\", \"ORGANIZATION\", \"%\");\n\n            assert rs != null;\n\n            names.add(\"ID\");\n            names.add(\"NAME\");\n\n            cnt = 0;\n\n            while (rs.next()) {\n                String name = rs.getString(\"COLUMN_NAME\");\n\n                assert names.remove(name);\n\n                if (\"id\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == INTEGER;\n                    assert \"INTEGER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                } else if (\"name\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == VARCHAR;\n                    assert \"VARCHAR\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 1;\n                }\n                if (\"_KEY\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == VARCHAR;\n                    assert \"VARCHAR\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n                if (\"_VAL\".equals(name)) {\n                    assert rs.getInt(\"DATA_TYPE\") == OTHER;\n                    assert \"OTHER\".equals(rs.getString(\"TYPE_NAME\"));\n                    assert rs.getInt(\"NULLABLE\") == 0;\n                }\n\n                cnt++;\n            }\n\n            assert names.isEmpty();\n            assert cnt == 2;\n        }\n    }"
        ]
    ],
    "5b3ad97b939bee6f3e272f93c75e920208cb7491": [
        [
            "PlatformConfigurationUtils::readCacheConfiguration(BinaryRawReaderEx)",
            " 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  ",
            "    /**\n     * Reads cache configuration from a stream.\n     *\n     * @param in Stream.\n     * @return Cache configuration.\n     */\n    public static CacheConfiguration readCacheConfiguration(BinaryRawReaderEx in) {\n        assert in != null;\n\n        CacheConfiguration ccfg = new CacheConfiguration();\n\n        ccfg.setAtomicityMode(CacheAtomicityMode.fromOrdinal(in.readInt()));\n        ccfg.setBackups(in.readInt());\n        ccfg.setCacheMode(CacheMode.fromOrdinal(in.readInt()));\n        ccfg.setCopyOnRead(in.readBoolean());\n        ccfg.setEagerTtl(in.readBoolean());\n        ccfg.setInvalidate(in.readBoolean());\n        ccfg.setStoreKeepBinary(in.readBoolean());\n        ccfg.setLoadPreviousValue(in.readBoolean());\n        ccfg.setDefaultLockTimeout(in.readLong());\n        //noinspection deprecation\n        ccfg.setLongQueryWarningTimeout(in.readLong());\n        ccfg.setMaxConcurrentAsyncOperations(in.readInt());\n        ccfg.setName(in.readString());\n        ccfg.setReadFromBackup(in.readBoolean());\n        ccfg.setRebalanceBatchSize(in.readInt());\n        ccfg.setRebalanceDelay(in.readLong());\n        ccfg.setRebalanceMode(CacheRebalanceMode.fromOrdinal(in.readInt()));\n        ccfg.setRebalanceThrottle(in.readLong());\n        ccfg.setRebalanceTimeout(in.readLong());\n        ccfg.setSqlEscapeAll(in.readBoolean());\n        ccfg.setWriteBehindBatchSize(in.readInt());\n        ccfg.setWriteBehindEnabled(in.readBoolean());\n        ccfg.setWriteBehindFlushFrequency(in.readLong());\n        ccfg.setWriteBehindFlushSize(in.readInt());\n        ccfg.setWriteBehindFlushThreadCount(in.readInt());\n        ccfg.setWriteBehindCoalescing(in.readBoolean());\n        ccfg.setWriteSynchronizationMode(CacheWriteSynchronizationMode.fromOrdinal(in.readInt()));\n        ccfg.setReadThrough(in.readBoolean());\n        ccfg.setWriteThrough(in.readBoolean());\n        ccfg.setStatisticsEnabled(in.readBoolean());\n\n        String dataRegionName = in.readString();\n\n        if (dataRegionName != null)\n            //noinspection deprecation\n            ccfg.setMemoryPolicyName(dataRegionName);\n\n        ccfg.setPartitionLossPolicy(PartitionLossPolicy.fromOrdinal((byte)in.readInt()));\n        ccfg.setGroupName(in.readString());\n\n        Object storeFactory = in.readObjectDetached();\n\n        if (storeFactory != null)\n            ccfg.setCacheStoreFactory(new PlatformDotNetCacheStoreFactoryNative(storeFactory));\n\n        ccfg.setSqlIndexMaxInlineSize(in.readInt());\n\n        int qryEntCnt = in.readInt();\n\n        if (qryEntCnt > 0) {\n            Collection<QueryEntity> entities = new ArrayList<>(qryEntCnt);\n\n            for (int i = 0; i < qryEntCnt; i++)\n                entities.add(readQueryEntity(in));\n\n            ccfg.setQueryEntities(entities);\n        }\n\n        if (in.readBoolean())\n            ccfg.setNearConfiguration(readNearConfiguration(in));\n\n        ccfg.setEvictionPolicy(readEvictionPolicy(in));\n        if (ccfg.getEvictionPolicy() != null)\n            ccfg.setOnheapCacheEnabled(true);\n\n        ccfg.setAffinity(readAffinityFunction(in));\n        ccfg.setExpiryPolicyFactory(readExpiryPolicyFactory(in));\n\n        int pluginCnt = in.readInt();\n\n        if (pluginCnt > 0) {\n            ArrayList<CachePluginConfiguration> plugins = new ArrayList<>();\n\n            for (int i = 0; i < pluginCnt; i++) {\n                if (in.readBoolean()) {\n                    // Java cache plugin.\n                    readCachePluginConfiguration(ccfg, in);\n                } else {\n                    // Platform cache plugin.\n                    plugins.add(new PlatformCachePluginConfiguration(in.readObjectDetached()));\n                }\n            }\n\n            if (ccfg.getPluginConfigurations() != null) {\n                Collections.addAll(plugins, ccfg.getPluginConfigurations());\n            }\n\n            ccfg.setPluginConfigurations(plugins.toArray(new CachePluginConfiguration[plugins.size()]));\n        }\n\n        return ccfg;\n    }",
            " 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227 +\n 228 +\n 229 +\n 230 +\n 231 +\n 232 +\n 233 +\n 234 +\n 235 +\n 236 +\n 237 +\n 238 +\n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  ",
            "    /**\n     * Reads cache configuration from a stream.\n     *\n     * @param in Stream.\n     * @return Cache configuration.\n     */\n    public static CacheConfiguration readCacheConfiguration(BinaryRawReaderEx in) {\n        assert in != null;\n\n        CacheConfiguration ccfg = new CacheConfiguration();\n\n        ccfg.setAtomicityMode(CacheAtomicityMode.fromOrdinal(in.readInt()));\n        ccfg.setBackups(in.readInt());\n        ccfg.setCacheMode(CacheMode.fromOrdinal(in.readInt()));\n        ccfg.setCopyOnRead(in.readBoolean());\n        ccfg.setEagerTtl(in.readBoolean());\n        ccfg.setInvalidate(in.readBoolean());\n        ccfg.setStoreKeepBinary(in.readBoolean());\n        ccfg.setLoadPreviousValue(in.readBoolean());\n        ccfg.setDefaultLockTimeout(in.readLong());\n        //noinspection deprecation\n        ccfg.setLongQueryWarningTimeout(in.readLong());\n        ccfg.setMaxConcurrentAsyncOperations(in.readInt());\n        ccfg.setName(in.readString());\n        ccfg.setReadFromBackup(in.readBoolean());\n        ccfg.setRebalanceBatchSize(in.readInt());\n        ccfg.setRebalanceDelay(in.readLong());\n        ccfg.setRebalanceMode(CacheRebalanceMode.fromOrdinal(in.readInt()));\n        ccfg.setRebalanceThrottle(in.readLong());\n        ccfg.setRebalanceTimeout(in.readLong());\n        ccfg.setSqlEscapeAll(in.readBoolean());\n        ccfg.setWriteBehindBatchSize(in.readInt());\n        ccfg.setWriteBehindEnabled(in.readBoolean());\n        ccfg.setWriteBehindFlushFrequency(in.readLong());\n        ccfg.setWriteBehindFlushSize(in.readInt());\n        ccfg.setWriteBehindFlushThreadCount(in.readInt());\n        ccfg.setWriteBehindCoalescing(in.readBoolean());\n        ccfg.setWriteSynchronizationMode(CacheWriteSynchronizationMode.fromOrdinal(in.readInt()));\n        ccfg.setReadThrough(in.readBoolean());\n        ccfg.setWriteThrough(in.readBoolean());\n        ccfg.setStatisticsEnabled(in.readBoolean());\n\n        String dataRegionName = in.readString();\n\n        if (dataRegionName != null)\n            //noinspection deprecation\n            ccfg.setMemoryPolicyName(dataRegionName);\n\n        ccfg.setPartitionLossPolicy(PartitionLossPolicy.fromOrdinal((byte)in.readInt()));\n        ccfg.setGroupName(in.readString());\n\n        Object storeFactory = in.readObjectDetached();\n\n        if (storeFactory != null)\n            ccfg.setCacheStoreFactory(new PlatformDotNetCacheStoreFactoryNative(storeFactory));\n\n        ccfg.setSqlIndexMaxInlineSize(in.readInt());\n\n        int qryEntCnt = in.readInt();\n\n        if (qryEntCnt > 0) {\n            Collection<QueryEntity> entities = new ArrayList<>(qryEntCnt);\n\n            for (int i = 0; i < qryEntCnt; i++)\n                entities.add(readQueryEntity(in));\n\n            ccfg.setQueryEntities(entities);\n        }\n\n        if (in.readBoolean())\n            ccfg.setNearConfiguration(readNearConfiguration(in));\n\n        ccfg.setEvictionPolicy(readEvictionPolicy(in));\n        if (ccfg.getEvictionPolicy() != null)\n            ccfg.setOnheapCacheEnabled(true);\n\n        ccfg.setAffinity(readAffinityFunction(in));\n        ccfg.setExpiryPolicyFactory(readExpiryPolicyFactory(in));\n\n        int keyCnt = in.readInt();\n\n        if (keyCnt > 0) {\n            CacheKeyConfiguration[] keys = new CacheKeyConfiguration[keyCnt];\n\n            for (int i = 0; i < keyCnt; i++) {\n                keys[i] = new CacheKeyConfiguration(in.readString(), in.readString());\n            }\n\n            ccfg.setKeyConfiguration(keys);\n        }\n\n        int pluginCnt = in.readInt();\n\n        if (pluginCnt > 0) {\n            ArrayList<CachePluginConfiguration> plugins = new ArrayList<>();\n\n            for (int i = 0; i < pluginCnt; i++) {\n                if (in.readBoolean()) {\n                    // Java cache plugin.\n                    readCachePluginConfiguration(ccfg, in);\n                } else {\n                    // Platform cache plugin.\n                    plugins.add(new PlatformCachePluginConfiguration(in.readObjectDetached()));\n                }\n            }\n\n            if (ccfg.getPluginConfigurations() != null) {\n                Collections.addAll(plugins, ccfg.getPluginConfigurations());\n            }\n\n            ccfg.setPluginConfigurations(plugins.toArray(new CachePluginConfiguration[plugins.size()]));\n        }\n\n        return ccfg;\n    }"
        ],
        [
            "PlatformConfigurationUtils::writeCacheConfiguration(BinaryRawWriter,CacheConfiguration)",
            " 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854  \n 855  \n 856  \n 857  \n 858  \n 859  \n 860  \n 861  \n 862  \n 863  \n 864  \n 865  \n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  \n 891  \n 892  \n 893  \n 894  \n 895  \n 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  \n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932  \n 933  \n 934  \n 935  \n 936  \n 937  ",
            "    /**\n     * Writes cache configuration.\n     *\n     * @param writer Writer.\n     * @param ccfg Configuration.\n     */\n    public static void writeCacheConfiguration(BinaryRawWriter writer, CacheConfiguration ccfg) {\n        assert writer != null;\n        assert ccfg != null;\n\n        writeEnumInt(writer, ccfg.getAtomicityMode(), CacheConfiguration.DFLT_CACHE_ATOMICITY_MODE);\n        writer.writeInt(ccfg.getBackups());\n        writeEnumInt(writer, ccfg.getCacheMode(), CacheConfiguration.DFLT_CACHE_MODE);\n        writer.writeBoolean(ccfg.isCopyOnRead());\n        writer.writeBoolean(ccfg.isEagerTtl());\n        writer.writeBoolean(ccfg.isInvalidate());\n        writer.writeBoolean(ccfg.isStoreKeepBinary());\n        writer.writeBoolean(ccfg.isLoadPreviousValue());\n        writer.writeLong(ccfg.getDefaultLockTimeout());\n        //noinspection deprecation\n        writer.writeLong(ccfg.getLongQueryWarningTimeout());\n        writer.writeInt(ccfg.getMaxConcurrentAsyncOperations());\n        writer.writeString(ccfg.getName());\n        writer.writeBoolean(ccfg.isReadFromBackup());\n        writer.writeInt(ccfg.getRebalanceBatchSize());\n        writer.writeLong(ccfg.getRebalanceDelay());\n        writeEnumInt(writer, ccfg.getRebalanceMode(), CacheConfiguration.DFLT_REBALANCE_MODE);\n        writer.writeLong(ccfg.getRebalanceThrottle());\n        writer.writeLong(ccfg.getRebalanceTimeout());\n        writer.writeBoolean(ccfg.isSqlEscapeAll());\n        writer.writeInt(ccfg.getWriteBehindBatchSize());\n        writer.writeBoolean(ccfg.isWriteBehindEnabled());\n        writer.writeLong(ccfg.getWriteBehindFlushFrequency());\n        writer.writeInt(ccfg.getWriteBehindFlushSize());\n        writer.writeInt(ccfg.getWriteBehindFlushThreadCount());\n        writer.writeBoolean(ccfg.getWriteBehindCoalescing());\n        writeEnumInt(writer, ccfg.getWriteSynchronizationMode());\n        writer.writeBoolean(ccfg.isReadThrough());\n        writer.writeBoolean(ccfg.isWriteThrough());\n        writer.writeBoolean(ccfg.isStatisticsEnabled());\n        //noinspection deprecation\n        writer.writeString(ccfg.getMemoryPolicyName());\n        writer.writeInt(ccfg.getPartitionLossPolicy().ordinal());\n        writer.writeString(ccfg.getGroupName());\n\n        if (ccfg.getCacheStoreFactory() instanceof PlatformDotNetCacheStoreFactoryNative)\n            writer.writeObject(((PlatformDotNetCacheStoreFactoryNative)ccfg.getCacheStoreFactory()).getNativeFactory());\n        else\n            writer.writeObject(null);\n\n        writer.writeInt(ccfg.getSqlIndexMaxInlineSize());\n\n        Collection<QueryEntity> qryEntities = ccfg.getQueryEntities();\n\n        if (qryEntities != null) {\n            writer.writeInt(qryEntities.size());\n\n            for (QueryEntity e : qryEntities)\n                writeQueryEntity(writer, e);\n        }\n        else\n            writer.writeInt(0);\n\n        NearCacheConfiguration nearCfg = ccfg.getNearConfiguration();\n\n        if (nearCfg != null) {\n            writer.writeBoolean(true);\n\n            writeNearConfiguration(writer, nearCfg);\n        }\n        else\n            writer.writeBoolean(false);\n\n        writeEvictionPolicy(writer, ccfg.getEvictionPolicy());\n        writeAffinityFunction(writer, ccfg.getAffinity());\n        writeExpiryPolicyFactory(writer, ccfg.getExpiryPolicyFactory());\n\n        CachePluginConfiguration[] plugins = ccfg.getPluginConfigurations();\n        if (plugins != null) {\n            int cnt = 0;\n\n            for (CachePluginConfiguration cfg : plugins) {\n                if (cfg instanceof PlatformCachePluginConfiguration)\n                    cnt++;\n            }\n\n            writer.writeInt(cnt);\n\n            for (CachePluginConfiguration cfg : plugins) {\n                if (cfg instanceof PlatformCachePluginConfiguration) {\n                    writer.writeBoolean(false);  // Pure platform plugin.\n                    writer.writeObject(((PlatformCachePluginConfiguration) cfg).nativeCfg());\n                }\n            }\n        }\n    }",
            " 855  \n 856  \n 857  \n 858  \n 859  \n 860  \n 861  \n 862  \n 863  \n 864  \n 865  \n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  \n 881  \n 882  \n 883  \n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  \n 891  \n 892  \n 893  \n 894  \n 895  \n 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  \n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932 +\n 933 +\n 934 +\n 935 +\n 936 +\n 937 +\n 938 +\n 939 +\n 940 +\n 941 +\n 942 +\n 943 +\n 944 +\n 945  \n 946  \n 947  \n 948  \n 949  \n 950  \n 951  \n 952  \n 953  \n 954  \n 955  \n 956  \n 957  \n 958  \n 959  \n 960  \n 961  \n 962  \n 963  ",
            "    /**\n     * Writes cache configuration.\n     *\n     * @param writer Writer.\n     * @param ccfg Configuration.\n     */\n    public static void writeCacheConfiguration(BinaryRawWriter writer, CacheConfiguration ccfg) {\n        assert writer != null;\n        assert ccfg != null;\n\n        writeEnumInt(writer, ccfg.getAtomicityMode(), CacheConfiguration.DFLT_CACHE_ATOMICITY_MODE);\n        writer.writeInt(ccfg.getBackups());\n        writeEnumInt(writer, ccfg.getCacheMode(), CacheConfiguration.DFLT_CACHE_MODE);\n        writer.writeBoolean(ccfg.isCopyOnRead());\n        writer.writeBoolean(ccfg.isEagerTtl());\n        writer.writeBoolean(ccfg.isInvalidate());\n        writer.writeBoolean(ccfg.isStoreKeepBinary());\n        writer.writeBoolean(ccfg.isLoadPreviousValue());\n        writer.writeLong(ccfg.getDefaultLockTimeout());\n        //noinspection deprecation\n        writer.writeLong(ccfg.getLongQueryWarningTimeout());\n        writer.writeInt(ccfg.getMaxConcurrentAsyncOperations());\n        writer.writeString(ccfg.getName());\n        writer.writeBoolean(ccfg.isReadFromBackup());\n        writer.writeInt(ccfg.getRebalanceBatchSize());\n        writer.writeLong(ccfg.getRebalanceDelay());\n        writeEnumInt(writer, ccfg.getRebalanceMode(), CacheConfiguration.DFLT_REBALANCE_MODE);\n        writer.writeLong(ccfg.getRebalanceThrottle());\n        writer.writeLong(ccfg.getRebalanceTimeout());\n        writer.writeBoolean(ccfg.isSqlEscapeAll());\n        writer.writeInt(ccfg.getWriteBehindBatchSize());\n        writer.writeBoolean(ccfg.isWriteBehindEnabled());\n        writer.writeLong(ccfg.getWriteBehindFlushFrequency());\n        writer.writeInt(ccfg.getWriteBehindFlushSize());\n        writer.writeInt(ccfg.getWriteBehindFlushThreadCount());\n        writer.writeBoolean(ccfg.getWriteBehindCoalescing());\n        writeEnumInt(writer, ccfg.getWriteSynchronizationMode());\n        writer.writeBoolean(ccfg.isReadThrough());\n        writer.writeBoolean(ccfg.isWriteThrough());\n        writer.writeBoolean(ccfg.isStatisticsEnabled());\n        //noinspection deprecation\n        writer.writeString(ccfg.getMemoryPolicyName());\n        writer.writeInt(ccfg.getPartitionLossPolicy().ordinal());\n        writer.writeString(ccfg.getGroupName());\n\n        if (ccfg.getCacheStoreFactory() instanceof PlatformDotNetCacheStoreFactoryNative)\n            writer.writeObject(((PlatformDotNetCacheStoreFactoryNative)ccfg.getCacheStoreFactory()).getNativeFactory());\n        else\n            writer.writeObject(null);\n\n        writer.writeInt(ccfg.getSqlIndexMaxInlineSize());\n\n        Collection<QueryEntity> qryEntities = ccfg.getQueryEntities();\n\n        if (qryEntities != null) {\n            writer.writeInt(qryEntities.size());\n\n            for (QueryEntity e : qryEntities)\n                writeQueryEntity(writer, e);\n        }\n        else\n            writer.writeInt(0);\n\n        NearCacheConfiguration nearCfg = ccfg.getNearConfiguration();\n\n        if (nearCfg != null) {\n            writer.writeBoolean(true);\n\n            writeNearConfiguration(writer, nearCfg);\n        }\n        else\n            writer.writeBoolean(false);\n\n        writeEvictionPolicy(writer, ccfg.getEvictionPolicy());\n        writeAffinityFunction(writer, ccfg.getAffinity());\n        writeExpiryPolicyFactory(writer, ccfg.getExpiryPolicyFactory());\n\n        CacheKeyConfiguration[] keys = ccfg.getKeyConfiguration();\n\n        if (keys != null) {\n            writer.writeInt(keys.length);\n\n            for (CacheKeyConfiguration key : keys) {\n                writer.writeString(key.getTypeName());\n                writer.writeString(key.getAffinityKeyFieldName());\n            }\n        } else {\n            writer.writeInt(0);\n        }\n\n        CachePluginConfiguration[] plugins = ccfg.getPluginConfigurations();\n        if (plugins != null) {\n            int cnt = 0;\n\n            for (CachePluginConfiguration cfg : plugins) {\n                if (cfg instanceof PlatformCachePluginConfiguration)\n                    cnt++;\n            }\n\n            writer.writeInt(cnt);\n\n            for (CachePluginConfiguration cfg : plugins) {\n                if (cfg instanceof PlatformCachePluginConfiguration) {\n                    writer.writeBoolean(false);  // Pure platform plugin.\n                    writer.writeObject(((PlatformCachePluginConfiguration) cfg).nativeCfg());\n                }\n            }\n        }\n    }"
        ]
    ],
    "49b835812a607a116c4dbc99ce60ed1684229b34": [
        [
            "UnwrapDataEntry::unwrappedKey()",
            "  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  ",
            "    /**\n     * Unwraps key value from cache key object into primitive boxed type or source class. If client classes were used\n     * in key, call of this method requires classes to be available in classpath\n     *\n     * @return Key which was placed into cache. Or null if failed\n     */\n    public Object unwrappedKey() {\n        try {\n            if (keepBinary && key instanceof BinaryObject)\n                return key;\n            Object unwrapped = key.value(cacheObjValCtx, false);\n            if (unwrapped instanceof BinaryObject) {\n                if (keepBinary)\n                    return unwrapped;\n                unwrapped = ((BinaryObject)unwrapped).deserialize();\n            }\n            return unwrapped;\n        }\n        catch (Exception e) {\n            cacheObjValCtx.kernalContext().log(UnwrapDataEntry.class)\n                .error(\"Unable to convert key [\" + key + \"]\", e);\n            return null;\n        }\n    }",
            "  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77 +\n  78  \n  79 +\n  80  \n  81  \n  82  \n  83  \n  84  \n  85 +\n  86  \n  87  \n  88  \n  89  \n  90  \n  91 +\n  92  \n  93  \n  94  ",
            "    /**\n     * Unwraps key value from cache key object into primitive boxed type or source class. If client classes were used\n     * in key, call of this method requires classes to be available in classpath.\n     *\n     * @return Key which was placed into cache. Or null if failed to convert.\n     */\n    public Object unwrappedKey() {\n        try {\n            if (keepBinary && key instanceof BinaryObject)\n                return key;\n\n            Object unwrapped = key.value(cacheObjValCtx, false);\n\n            if (unwrapped instanceof BinaryObject) {\n                if (keepBinary)\n                    return unwrapped;\n                unwrapped = ((BinaryObject)unwrapped).deserialize();\n            }\n\n            return unwrapped;\n        }\n        catch (Exception e) {\n            cacheObjValCtx.kernalContext().log(UnwrapDataEntry.class)\n                .error(\"Unable to convert key [\" + key + \"]\", e);\n\n            return null;\n        }\n    }"
        ],
        [
            "StandaloneWalRecordsIterator::postProcessDataEntry(IgniteCacheObjectProcessor,CacheObjectContext,DataEntry)",
            " 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341 -\n 342 -\n 343 -\n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  ",
            "    /**\n     * Converts entry or lazy data entry into unwrapped entry\n     * @param processor cache object processor for de-serializing objects.\n     * @param fakeCacheObjCtx cache object context for de-serializing binary and unwrapping objects.\n     * @param dataEntry entry to process\n     * @return post precessed entry\n     * @throws IgniteCheckedException if failed\n     */\n    @NotNull\n    private DataEntry postProcessDataEntry(\n        final IgniteCacheObjectProcessor processor,\n        final CacheObjectContext fakeCacheObjCtx,\n        final DataEntry dataEntry) throws IgniteCheckedException {\n\n        final KeyCacheObject key;\n        final CacheObject val;\n        final File marshallerMappingFileStoreDir =\n            fakeCacheObjCtx.kernalContext().marshallerContext().getMarshallerMappingFileStoreDir();\n\n        if (dataEntry instanceof LazyDataEntry) {\n            final LazyDataEntry lazyDataEntry = (LazyDataEntry)dataEntry;\n            key = processor.toKeyCacheObject(fakeCacheObjCtx,\n                lazyDataEntry.getKeyType(),\n                lazyDataEntry.getKeyBytes());\n            val = processor.toCacheObject(fakeCacheObjCtx,\n                lazyDataEntry.getValType(),\n                lazyDataEntry.getValBytes());\n        }\n        else {\n            key = dataEntry.key();\n            val = dataEntry.value();\n        }\n\n        return new UnwrapDataEntry(\n            dataEntry.cacheId(),\n            key,\n            val,\n            dataEntry.op(),\n            dataEntry.nearXidVersion(),\n            dataEntry.writeVersion(),\n            dataEntry.expireTime(),\n            dataEntry.partitionId(),\n            dataEntry.partitionCounter(),\n            fakeCacheObjCtx,\n            keepBinary || marshallerMappingFileStoreDir == null);\n    }",
            " 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338 +\n 339  \n 340  \n 341  \n 342 +\n 343 +\n 344 +\n 345 +\n 346 +\n 347 +\n 348 +\n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  ",
            "    /**\n     * Converts entry or lazy data entry into unwrapped entry\n     * @param processor cache object processor for de-serializing objects.\n     * @param fakeCacheObjCtx cache object context for de-serializing binary and unwrapping objects.\n     * @param dataEntry entry to process\n     * @return post precessed entry\n     * @throws IgniteCheckedException if failed\n     */\n    @NotNull\n    private DataEntry postProcessDataEntry(\n        final IgniteCacheObjectProcessor processor,\n        final CacheObjectContext fakeCacheObjCtx,\n        final DataEntry dataEntry) throws IgniteCheckedException {\n\n        final KeyCacheObject key;\n        final CacheObject val;\n        final File marshallerMappingFileStoreDir =\n            fakeCacheObjCtx.kernalContext().marshallerContext().getMarshallerMappingFileStoreDir();\n\n        if (dataEntry instanceof LazyDataEntry) {\n            final LazyDataEntry lazyDataEntry = (LazyDataEntry)dataEntry;\n\n            key = processor.toKeyCacheObject(fakeCacheObjCtx,\n                lazyDataEntry.getKeyType(),\n                lazyDataEntry.getKeyBytes());\n\n            final byte type = lazyDataEntry.getValType();\n\n            val = type == 0 ? null :\n                processor.toCacheObject(fakeCacheObjCtx,\n                    type,\n                    lazyDataEntry.getValBytes());\n        }\n        else {\n            key = dataEntry.key();\n            val = dataEntry.value();\n        }\n\n        return new UnwrapDataEntry(\n            dataEntry.cacheId(),\n            key,\n            val,\n            dataEntry.op(),\n            dataEntry.nearXidVersion(),\n            dataEntry.writeVersion(),\n            dataEntry.expireTime(),\n            dataEntry.partitionId(),\n            dataEntry.partitionCounter(),\n            fakeCacheObjCtx,\n            keepBinary || marshallerMappingFileStoreDir == null);\n    }"
        ],
        [
            "DataEntry::DataEntry(int,KeyCacheObject,CacheObject,GridCacheOperation,GridCacheVersion,GridCacheVersion,long,int,long)",
            "  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81 -\n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  ",
            "    /**\n     * @param cacheId Cache ID.\n     * @param key Key.\n     * @param val Value.\n     * @param op Operation.\n     * @param nearXidVer Near transaction version.\n     * @param writeVer Write version.\n     * @param expireTime Expire time.\n     * @param partId Partition ID.\n     * @param partCnt Partition counter.\n     */\n    public DataEntry(\n        int cacheId,\n        KeyCacheObject key,\n        CacheObject val,\n        GridCacheOperation op,\n        GridCacheVersion nearXidVer,\n        GridCacheVersion writeVer,\n        long expireTime,\n        int partId,\n        long partCnt\n    ) {\n        this.cacheId = cacheId;\n        this.key = key;\n        this.val = val;\n        this.op = op;\n        this.nearXidVer = nearXidVer;\n        this.writeVer = writeVer;\n        this.expireTime = expireTime;\n        this.partId = partId;\n        this.partCnt = partCnt;\n\n        // Only CREATE, UPDATE and DELETE operations should be stored in WAL.\n        assert op == GridCacheOperation.CREATE || op == GridCacheOperation.UPDATE || op == GridCacheOperation.DELETE : op;\n    }",
            "  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82 +\n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  ",
            "    /**\n     * @param cacheId Cache ID.\n     * @param key Key.\n     * @param val Value or null for delete operation.\n     * @param op Operation.\n     * @param nearXidVer Near transaction version.\n     * @param writeVer Write version.\n     * @param expireTime Expire time.\n     * @param partId Partition ID.\n     * @param partCnt Partition counter.\n     */\n    public DataEntry(\n        int cacheId,\n        KeyCacheObject key,\n        @Nullable CacheObject val,\n        GridCacheOperation op,\n        GridCacheVersion nearXidVer,\n        GridCacheVersion writeVer,\n        long expireTime,\n        int partId,\n        long partCnt\n    ) {\n        this.cacheId = cacheId;\n        this.key = key;\n        this.val = val;\n        this.op = op;\n        this.nearXidVer = nearXidVer;\n        this.writeVer = writeVer;\n        this.expireTime = expireTime;\n        this.partId = partId;\n        this.partCnt = partCnt;\n\n        // Only CREATE, UPDATE and DELETE operations should be stored in WAL.\n        assert op == GridCacheOperation.CREATE || op == GridCacheOperation.UPDATE || op == GridCacheOperation.DELETE : op;\n    }"
        ],
        [
            "UnwrapDataEntry::unwrappedValue()",
            "  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  ",
            "    /**\n     * Unwraps value value from cache value object into primitive boxed type or source class. If client classes were\n     * used in key, call of this method requires classes to be available in classpath\n     *\n     * @return Value which was placed into cache. Or null if failed\n     */\n    public Object unwrappedValue() {\n        try {\n            if (keepBinary && val instanceof BinaryObject)\n                return val;\n            return val.value(cacheObjValCtx, false);\n        }\n        catch (Exception e) {\n            cacheObjValCtx.kernalContext().log(UnwrapDataEntry.class)\n                .error(\"Unable to convert value [\" + value() + \"]\", e);\n            return null;\n        }\n    }",
            "  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104 +\n 105 +\n 106 +\n 107  \n 108  \n 109 +\n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  ",
            "    /**\n     * Unwraps value value from cache value object into primitive boxed type or source class. If client classes were\n     * used in key, call of this method requires classes to be available in classpath.\n     *\n     * @return Value which was placed into cache. Or null for delete operation or for failure.\n     */\n    public Object unwrappedValue() {\n        try {\n            if (val == null)\n                return null;\n\n            if (keepBinary && val instanceof BinaryObject)\n                return val;\n\n            return val.value(cacheObjValCtx, false);\n        }\n        catch (Exception e) {\n            cacheObjValCtx.kernalContext().log(UnwrapDataEntry.class)\n                .error(\"Unable to convert value [\" + value() + \"]\", e);\n            return null;\n        }\n    }"
        ],
        [
            "IgniteWalReaderTest::createWalIteratorFactory(String,String)",
            " 915 -\n 916 -\n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  ",
            "    @NotNull private IgniteWalIteratorFactory createWalIteratorFactory(String subfolderName,\n        String workDir) throws IgniteCheckedException {\n        final File binaryMeta = U.resolveWorkDirectory(workDir, \"binary_meta\", false);\n        final File binaryMetaWithConsId = new File(binaryMeta, subfolderName);\n        final File marshallerMapping = U.resolveWorkDirectory(workDir, \"marshaller\", false);\n\n        return new IgniteWalIteratorFactory(log,\n            PAGE_SIZE,\n            binaryMetaWithConsId,\n            marshallerMapping);\n    }",
            " 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922 +\n 923 +\n 924 +\n 925 +\n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932  \n 933  \n 934  ",
            "    /**\n     * @param subfolderName Subfolder name.\n     * @param workDir Work directory.\n     * @return WAL iterator factory.\n     * @throws IgniteCheckedException If failed.\n     */\n    @NotNull private IgniteWalIteratorFactory createWalIteratorFactory(\n        String subfolderName,\n        String workDir\n    ) throws IgniteCheckedException {\n        final File binaryMeta = U.resolveWorkDirectory(workDir, \"binary_meta\", false);\n        final File binaryMetaWithConsId = new File(binaryMeta, subfolderName);\n        final File marshallerMapping = U.resolveWorkDirectory(workDir, \"marshaller\", false);\n\n        return new IgniteWalIteratorFactory(log,\n            PAGE_SIZE,\n            binaryMetaWithConsId,\n            marshallerMapping);\n    }"
        ]
    ],
    "edfa353eba7c87c802df9e32678cb253549949b3": [
        [
            "Log4J2Logger::createConsoleLogger()",
            " 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356 -\n 357 -\n 358  \n 359 -\n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366 -\n 367 -\n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  ",
            "    /**\n     * Creates console appender with some reasonable default logging settings.\n     *\n     * @return Logger with auto configured console appender.\n     */\n    public static Logger createConsoleLogger() {\n        LoggerContext ctx = (LoggerContext)LogManager.getContext(true);\n\n        Configuration cfg = ctx.getConfiguration();\n\n        PatternLayout layout = PatternLayout.createLayout(\"[%d{ABSOLUTE}][%-5p][%t][%c{1}] %m%n\", null, null,\n            Charset.defaultCharset(), false, false, null, null);\n\n        final Appender consoleApp = ConsoleAppender.createAppender(layout, null, null, CONSOLE_APPENDER, null, null);\n        consoleApp.start();\n\n        AppenderRef ref = AppenderRef.createAppenderRef(CONSOLE_APPENDER, Level.TRACE, null);\n\n        AppenderRef[] refs = {ref};\n\n        LoggerConfig logCfg = LoggerConfig.createLogger(\"false\", Level.INFO, LogManager.ROOT_LOGGER_NAME, \"\",\n            refs, null, null, null);\n\n        logCfg.addAppender(consoleApp, null, null);\n        cfg.addAppender(consoleApp);\n\n        cfg.addLogger(LogManager.ROOT_LOGGER_NAME, logCfg);\n\n        ctx.updateLoggers(cfg);\n\n        return (Logger)LogManager.getContext().getLogger(LogManager.ROOT_LOGGER_NAME);\n    }",
            " 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356 +\n 357 +\n 358 +\n 359 +\n 360 +\n 361 +\n 362 +\n 363 +\n 364 +\n 365 +\n 366 +\n 367 +\n 368 +\n 369 +\n 370 +\n 371 +\n 372 +\n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380 +\n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  ",
            "    /**\n     * Creates console appender with some reasonable default logging settings.\n     *\n     * @return Logger with auto configured console appender.\n     */\n    public static Logger createConsoleLogger() {\n        LoggerContext ctx = (LoggerContext)LogManager.getContext(true);\n\n        Configuration cfg = ctx.getConfiguration();\n\n        PatternLayout.Builder builder = PatternLayout.newBuilder();\n\n        builder\n            .withPattern(\"%d{ABSOLUTE}][%-5p][%t][%c{1}] %m%n\")\n            .withCharset(Charset.defaultCharset())\n            .withAlwaysWriteExceptions(false)\n            .withNoConsoleNoAnsi(false);\n\n        PatternLayout layout = builder.build();\n\n        ConsoleAppender.Builder consoleAppenderBuilder = ConsoleAppender.newBuilder();\n\n        consoleAppenderBuilder\n            .withName(CONSOLE_APPENDER)\n            .withLayout(layout);\n\n        ConsoleAppender consoleApp = consoleAppenderBuilder.build();\n\n        consoleApp.start();\n\n        AppenderRef ref = AppenderRef.createAppenderRef(CONSOLE_APPENDER, Level.TRACE, null);\n\n        AppenderRef[] refs = {ref};\n\n        LoggerConfig logCfg = LoggerConfig.createLogger(false, Level.INFO, LogManager.ROOT_LOGGER_NAME, \"\", refs, null, null, null);\n\n        logCfg.addAppender(consoleApp, null, null);\n        cfg.addAppender(consoleApp);\n\n        cfg.addLogger(LogManager.ROOT_LOGGER_NAME, logCfg);\n\n        ctx.updateLoggers(cfg);\n\n        return (Logger)LogManager.getContext().getLogger(LogManager.ROOT_LOGGER_NAME);\n    }"
        ]
    ],
    "a760e6e72a716f59a0110954c1efb665215cfcaf": [
        [
            "IgniteWalHistoryReservationsSelfTest::testRemovesArePreloadedIfHistoryIsAvailable()",
            " 195  \n 196  \n 197  \n 198  \n 199 -\n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testRemovesArePreloadedIfHistoryIsAvailable() throws Exception {\n        System.setProperty(IGNITE_WAL_REBALANCE_THRESHOLD, \"0\");\n\n        int entryCnt = 10_000;\n\n        Ignite ig0 = startGrids(2);\n\n        IgniteCache<Integer, Integer> cache = ig0.cache(\"cache1\");\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n        stopGrid(1);\n\n        for (int k = 0; k < entryCnt; k += 2)\n            cache.remove(k);\n\n        forceCheckpoint();\n\n        Ignite ig1 = startGrid(1);\n\n        IgniteCache<Integer, Integer> cache1 = ig1.cache(\"cache1\");\n\n        assertEquals(entryCnt / 2, cache.size());\n        assertEquals(entryCnt / 2, cache1.size());\n\n        for (Integer k = 0; k < entryCnt; k++) {\n            if (k % 2 == 0) {\n                assertTrue(\"k=\" + k, !cache.containsKey(k));\n                assertTrue(\"k=\" + k, !cache1.containsKey(k));\n            }\n            else {\n                assertEquals(\"k=\" + k, k, cache.get(k));\n                assertEquals(\"k=\" + k, k, cache1.get(k));\n            }\n        }\n    }",
            " 195  \n 196  \n 197  \n 198  \n 199 +\n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testRemovesArePreloadedIfHistoryIsAvailable() throws Exception {\n        System.setProperty(IGNITE_PDS_WAL_REBALANCE_THRESHOLD, \"0\");\n\n        int entryCnt = 10_000;\n\n        Ignite ig0 = startGrids(2);\n\n        IgniteCache<Integer, Integer> cache = ig0.cache(\"cache1\");\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n        stopGrid(1);\n\n        for (int k = 0; k < entryCnt; k += 2)\n            cache.remove(k);\n\n        forceCheckpoint();\n\n        Ignite ig1 = startGrid(1);\n\n        IgniteCache<Integer, Integer> cache1 = ig1.cache(\"cache1\");\n\n        assertEquals(entryCnt / 2, cache.size());\n        assertEquals(entryCnt / 2, cache1.size());\n\n        for (Integer k = 0; k < entryCnt; k++) {\n            if (k % 2 == 0) {\n                assertTrue(\"k=\" + k, !cache.containsKey(k));\n                assertTrue(\"k=\" + k, !cache1.containsKey(k));\n            }\n            else {\n                assertEquals(\"k=\" + k, k, cache.get(k));\n                assertEquals(\"k=\" + k, k, cache1.get(k));\n            }\n        }\n    }"
        ],
        [
            "IgniteWalHistoryReservationsSelfTest::testReservedOnExchange()",
            "  99  \n 100  \n 101  \n 102  \n 103 -\n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testReservedOnExchange() throws Exception {\n        System.setProperty(IGNITE_WAL_REBALANCE_THRESHOLD, \"0\");\n\n        final int entryCnt = 10_000;\n        final int initGridCnt = 4;\n\n        final IgniteEx ig0 = (IgniteEx)startGrids(initGridCnt);\n\n        IgniteCache<Object, Object> cache = ig0.cache(\"cache1\");\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k * 2);\n\n        forceCheckpoint();\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n\n        Lock lock = cache.lock(0);\n\n        lock.lock();\n\n        try {\n            GridTestUtils.runAsync(new Runnable() {\n                @Override public void run() {\n                    try {\n                        startGrid(initGridCnt);\n                    }\n                    catch (Exception e) {\n                        fail(e.getMessage());\n                    }\n                }\n            });\n\n            boolean reserved = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n                @Override public boolean apply() {\n                    for (int g = 0; g < initGridCnt; g++) {\n                        IgniteEx ig = grid(g);\n\n                        FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                        Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                        synchronized (archiver) {\n                            Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                            if (reserved.isEmpty())\n                                return false;\n                        }\n                    }\n\n                    return true;\n                }\n            }, 10_000);\n\n            assert reserved;\n        }\n        finally {\n            lock.unlock();\n        }\n\n        boolean released = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n            @Override public boolean apply() {\n                for (int g = 0; g < initGridCnt; g++) {\n                    IgniteEx ig = grid(g);\n\n                    FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                    Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                    synchronized (archiver) {\n                        Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                        if (!reserved.isEmpty())\n                            return false;\n                    }\n                }\n\n                return true;\n            }\n        }, 10_000);\n\n        assert released;\n    }",
            "  99  \n 100  \n 101  \n 102  \n 103 +\n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testReservedOnExchange() throws Exception {\n        System.setProperty(IGNITE_PDS_WAL_REBALANCE_THRESHOLD, \"0\");\n\n        final int entryCnt = 10_000;\n        final int initGridCnt = 4;\n\n        final IgniteEx ig0 = (IgniteEx)startGrids(initGridCnt);\n\n        IgniteCache<Object, Object> cache = ig0.cache(\"cache1\");\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k * 2);\n\n        forceCheckpoint();\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n\n        Lock lock = cache.lock(0);\n\n        lock.lock();\n\n        try {\n            GridTestUtils.runAsync(new Runnable() {\n                @Override public void run() {\n                    try {\n                        startGrid(initGridCnt);\n                    }\n                    catch (Exception e) {\n                        fail(e.getMessage());\n                    }\n                }\n            });\n\n            boolean reserved = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n                @Override public boolean apply() {\n                    for (int g = 0; g < initGridCnt; g++) {\n                        IgniteEx ig = grid(g);\n\n                        FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                        Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                        synchronized (archiver) {\n                            Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                            if (reserved.isEmpty())\n                                return false;\n                        }\n                    }\n\n                    return true;\n                }\n            }, 10_000);\n\n            assert reserved;\n        }\n        finally {\n            lock.unlock();\n        }\n\n        boolean released = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n            @Override public boolean apply() {\n                for (int g = 0; g < initGridCnt; g++) {\n                    IgniteEx ig = grid(g);\n\n                    FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                    Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                    synchronized (archiver) {\n                        Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                        if (!reserved.isEmpty())\n                            return false;\n                    }\n                }\n\n                return true;\n            }\n        }, 10_000);\n\n        assert released;\n    }"
        ],
        [
            "IgniteWalHistoryReservationsSelfTest::testNodeLeftDuringExchange()",
            " 286  \n 287  \n 288  \n 289  \n 290 -\n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testNodeLeftDuringExchange() throws Exception {\n        System.setProperty(IGNITE_WAL_REBALANCE_THRESHOLD, \"0\");\n\n        final int entryCnt = 10_000;\n        final int initGridCnt = 4;\n\n        final IgniteEx ig0 = (IgniteEx)startGrids(initGridCnt);\n\n        IgniteCache<Object, Object> cache = ig0.cache(\"cache1\");\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n        Lock lock = cache.lock(0);\n\n        lock.lock();\n\n        try {\n            GridTestUtils.runAsync(new Runnable() {\n                @Override public void run() {\n                    try {\n                        startGrid(initGridCnt);\n                    }\n                    catch (Exception e) {\n                        fail(e.getMessage());\n                    }\n                }\n            });\n\n            boolean reserved = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n                @Override public boolean apply() {\n                    for (int g = 0; g < initGridCnt; g++) {\n                        IgniteEx ig = grid(g);\n\n                        FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                        Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                        synchronized (archiver) {\n                            Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                            if (reserved.isEmpty())\n                                return false;\n                        }\n                    }\n\n                    return true;\n                }\n            }, 10_000);\n\n            assert reserved;\n\n            stopGrid(Integer.toString(initGridCnt - 1), true, false);\n        }\n        finally {\n            lock.unlock();\n        }\n\n        boolean released = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n            @Override public boolean apply() {\n                for (int g = 0; g < initGridCnt - 1; g++) {\n                    IgniteEx ig = grid(g);\n\n                    FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                    Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                    synchronized (archiver) {\n                        Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                        if (!reserved.isEmpty())\n                            return false;\n                    }\n                }\n\n                return true;\n            }\n        }, 10_000);\n\n        assert released;\n\n        awaitPartitionMapExchange();\n    }",
            " 286  \n 287  \n 288  \n 289  \n 290 +\n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testNodeLeftDuringExchange() throws Exception {\n        System.setProperty(IGNITE_PDS_WAL_REBALANCE_THRESHOLD, \"0\");\n\n        final int entryCnt = 10_000;\n        final int initGridCnt = 4;\n\n        final IgniteEx ig0 = (IgniteEx)startGrids(initGridCnt);\n\n        IgniteCache<Object, Object> cache = ig0.cache(\"cache1\");\n\n        for (int k = 0; k < entryCnt; k++)\n            cache.put(k, k);\n\n        forceCheckpoint();\n\n        Lock lock = cache.lock(0);\n\n        lock.lock();\n\n        try {\n            GridTestUtils.runAsync(new Runnable() {\n                @Override public void run() {\n                    try {\n                        startGrid(initGridCnt);\n                    }\n                    catch (Exception e) {\n                        fail(e.getMessage());\n                    }\n                }\n            });\n\n            boolean reserved = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n                @Override public boolean apply() {\n                    for (int g = 0; g < initGridCnt; g++) {\n                        IgniteEx ig = grid(g);\n\n                        FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                        Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                        synchronized (archiver) {\n                            Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                            if (reserved.isEmpty())\n                                return false;\n                        }\n                    }\n\n                    return true;\n                }\n            }, 10_000);\n\n            assert reserved;\n\n            stopGrid(Integer.toString(initGridCnt - 1), true, false);\n        }\n        finally {\n            lock.unlock();\n        }\n\n        boolean released = GridTestUtils.waitForCondition(new GridAbsPredicate() {\n            @Override public boolean apply() {\n                for (int g = 0; g < initGridCnt - 1; g++) {\n                    IgniteEx ig = grid(g);\n\n                    FileWriteAheadLogManager wal = (FileWriteAheadLogManager)ig.context().cache().context().wal();\n\n                    Object archiver = GridTestUtils.getFieldValue(wal, \"archiver\");\n\n                    synchronized (archiver) {\n                        Map reserved = GridTestUtils.getFieldValue(archiver, \"reserved\");\n\n                        if (!reserved.isEmpty())\n                            return false;\n                    }\n                }\n\n                return true;\n            }\n        }, 10_000);\n\n        assert released;\n\n        awaitPartitionMapExchange();\n    }"
        ],
        [
            "IgniteWalHistoryReservationsSelfTest::afterTest()",
            "  88  \n  89  \n  90 -\n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  ",
            "    /** {@inheritDoc} */\n    @Override protected void afterTest() throws Exception {\n        System.clearProperty(IGNITE_WAL_REBALANCE_THRESHOLD);\n\n        client = false;\n\n        stopAllGrids();\n\n        deleteWorkFiles();\n    }",
            "  88  \n  89  \n  90 +\n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  ",
            "    /** {@inheritDoc} */\n    @Override protected void afterTest() throws Exception {\n        System.clearProperty(IGNITE_PDS_WAL_REBALANCE_THRESHOLD);\n\n        client = false;\n\n        stopAllGrids();\n\n        deleteWorkFiles();\n    }"
        ]
    ],
    "e7ee88aa82b3c59eb1ae671e2d33f1307f17162e": [
        [
            "IgniteCachePartitionLossPolicySelfTest::checkLostPartition(boolean,boolean)",
            " 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  ",
            "    /**\n     * @param canWrite {@code True} if writes are allowed.\n     * @param safe {@code True} if lost partition should trigger exception.\n     * @throws Exception if failed.\n     */\n    private void checkLostPartition(boolean canWrite, boolean safe) throws Exception {\n        assert partLossPlc != null;\n\n        int part = prepareTopology();\n\n        for (Ignite ig : G.allGrids()) {\n            info(\"Checking node: \" + ig.cluster().localNode().id());\n\n            IgniteCache<Integer, Integer> cache = ig.cache(CACHE_NAME);\n\n            verifyCacheOps(canWrite, safe, part, ig);\n\n            // Check we can read and write to lost partition in recovery mode.\n            IgniteCache<Integer, Integer> recoverCache = cache.withPartitionRecover();\n\n            for (int lostPart : recoverCache.lostPartitions()) {\n                recoverCache.get(lostPart);\n                recoverCache.put(lostPart, lostPart);\n            }\n\n            // Check that writing in recover mode does not clear partition state.\n            verifyCacheOps(canWrite, safe, part, ig);\n        }\n\n        // Check that partition state does not change after we start a new node.\n        IgniteEx grd = startGrid(3);\n\n        info(\"Newly started node: \" + grd.cluster().localNode().id());\n\n        for (Ignite ig : G.allGrids())\n            verifyCacheOps(canWrite, safe, part, ig);\n\n        ignite(0).resetLostPartitions(Collections.singletonList(CACHE_NAME));\n\n        awaitPartitionMapExchange(true, true, null);\n\n        for (Ignite ig : G.allGrids()) {\n            IgniteCache<Integer, Integer> cache = ig.cache(CACHE_NAME);\n\n            assertTrue(cache.lostPartitions().isEmpty());\n\n            int parts = ig.affinity(CACHE_NAME).partitions();\n\n            for (int i = 0; i < parts; i++) {\n                cache.get(i);\n\n                cache.put(i, i);\n            }\n        }\n    }",
            " 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164 +\n 165 +\n 166 +\n 167 +\n 168 +\n 169 +\n 170 +\n 171 +\n 172 +\n 173 +\n 174 +\n 175 +\n 176 +\n 177 +\n 178 +\n 179 +\n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  ",
            "    /**\n     * @param canWrite {@code True} if writes are allowed.\n     * @param safe {@code True} if lost partition should trigger exception.\n     * @throws Exception if failed.\n     */\n    private void checkLostPartition(boolean canWrite, boolean safe) throws Exception {\n        assert partLossPlc != null;\n\n        int part = prepareTopology();\n\n        // Wait for all grids (servers and client) have same topology version\n        // to make sure that all nodes received map with lost partition.\n        GridTestUtils.waitForCondition(() -> {\n            AffinityTopologyVersion last = null;\n            for (Ignite ig : G.allGrids()) {\n                AffinityTopologyVersion ver = ((IgniteEx) ig).context().cache().context().exchange().readyAffinityVersion();\n\n                if (last != null && !last.equals(ver))\n                    return false;\n\n                last = ver;\n            }\n\n            return true;\n        }, 10000);\n\n        for (Ignite ig : G.allGrids()) {\n            info(\"Checking node: \" + ig.cluster().localNode().id());\n\n            IgniteCache<Integer, Integer> cache = ig.cache(CACHE_NAME);\n\n            verifyCacheOps(canWrite, safe, part, ig);\n\n            // Check we can read and write to lost partition in recovery mode.\n            IgniteCache<Integer, Integer> recoverCache = cache.withPartitionRecover();\n\n            for (int lostPart : recoverCache.lostPartitions()) {\n                recoverCache.get(lostPart);\n                recoverCache.put(lostPart, lostPart);\n            }\n\n            // Check that writing in recover mode does not clear partition state.\n            verifyCacheOps(canWrite, safe, part, ig);\n        }\n\n        // Check that partition state does not change after we start a new node.\n        IgniteEx grd = startGrid(3);\n\n        info(\"Newly started node: \" + grd.cluster().localNode().id());\n\n        for (Ignite ig : G.allGrids())\n            verifyCacheOps(canWrite, safe, part, ig);\n\n        ignite(0).resetLostPartitions(Collections.singletonList(CACHE_NAME));\n\n        awaitPartitionMapExchange(true, true, null);\n\n        for (Ignite ig : G.allGrids()) {\n            IgniteCache<Integer, Integer> cache = ig.cache(CACHE_NAME);\n\n            assertTrue(cache.lostPartitions().isEmpty());\n\n            int parts = ig.affinity(CACHE_NAME).partitions();\n\n            for (int i = 0; i < parts; i++) {\n                cache.get(i);\n\n                cache.put(i, i);\n            }\n        }\n    }"
        ]
    ],
    "bf55814d2cd689ab6165c65e5a41e123234d4d54": [
        [
            "DemoComputeTask::DemoComputeJob::execute()",
            "  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93 -\n  94 -\n  95  \n  96  \n  97 -\n  98  ",
            "        /** {@inheritDoc} */\n        @Override public Object execute() throws IgniteException {\n            try {\n                Thread.sleep(rnd.nextInt(50));\n            }\n            catch (InterruptedException e) {\n                // Restore interrupt status\n                Thread.currentThread().interrupt();\n\n                throw new IgniteInterruptedException(e);\n            }\n\n            return rnd.nextInt(10000);\n        }",
            "  85  \n  86  \n  87  \n  88  \n  89 +\n  90 +\n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97 +\n  98  ",
            "        /** {@inheritDoc} */\n        @Override public Object execute() throws IgniteException {\n            try {\n                Thread.sleep(rnd.nextInt(50));\n\n                return rnd.nextInt(10000);\n            }\n            catch (InterruptedException e) {\n                // Restore interrupt status\n                Thread.currentThread().interrupt();\n            }\n\n            return null;\n        }"
        ]
    ],
    "794e1d3643021319e7aaa0707b288bf6791b44be": [
        [
            "GridSpringTransactionManagerSelfTest::beforeTestsStarted()",
            "  77  \n  78  \n  79  \n  80  \n  81 -\n  82  \n  83  ",
            "    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void beforeTestsStarted() throws Exception {\n        startGrid();\n    }",
            "  71  \n  72 +\n  73  \n  74  ",
            "    /** {@inheritDoc} */\n    @Override protected void beforeTestsStarted() throws Exception {\n        startGrid();\n    }"
        ],
        [
            "GridSpringTransactionManagerSelfTest::beforeTest()",
            "  93  \n  94  \n  95  \n  96  \n  97 -\n  98  \n  99  \n 100  \n 101  ",
            "    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void beforeTest() throws Exception {\n        ApplicationContext applicationContext = new GenericXmlApplicationContext(\"config/spring-transactions.xml\");\n\n        service = (GridSpringTransactionService)applicationContext.getBean(\"gridSpringTransactionService\");\n    }",
            "  81  \n  82 +\n  83  \n  84  \n  85  \n  86  ",
            "    /** {@inheritDoc} */\n    @Override protected void beforeTest() throws Exception {\n        ApplicationContext applicationContext = new GenericXmlApplicationContext(\"config/spring-transactions.xml\");\n\n        service = (GridSpringTransactionService)applicationContext.getBean(\"gridSpringTransactionService\");\n    }"
        ],
        [
            "GridSpringTransactionManagerSelfTest::afterTest()",
            " 103  \n 104  \n 105  \n 106  \n 107 -\n 108  \n 109  ",
            "    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void afterTest() throws Exception {\n        grid().cache(CACHE_NAME).removeAll();\n    }",
            "  88  \n  89 +\n  90  \n  91  ",
            "    /** {@inheritDoc} */\n    @Override protected void afterTest() throws Exception {\n        grid().cache(CACHE_NAME).removeAll();\n    }"
        ],
        [
            "IgniteCacheTxIteratorSelfTest::TestClass::hashCode()",
            " 219  \n 220  \n 221  \n 222  \n 223 -\n 224  \n 225  ",
            "        /**\n         * {@inheritDoc}\n         */\n        @Override\n        public int hashCode() {\n            return data != null ? data.hashCode() : 0;\n        }",
            " 216  \n 217 +\n 218  \n 219  ",
            "        /** {@inheritDoc} */\n        @Override public int hashCode() {\n            return data != null ? data.hashCode() : 0;\n        }"
        ],
        [
            "IgniteCacheTxIteratorSelfTest::TestClass::toString()",
            " 227  \n 228  \n 229  \n 230  \n 231 -\n 232  \n 233  ",
            "        /**\n         * {@inheritDoc}\n         */\n        @Override\n        public String toString() {\n            return S.toString(TestClass.class, this);\n        }",
            " 221  \n 222 +\n 223  \n 224  ",
            "        /** {@inheritDoc} */\n        @Override public String toString() {\n            return S.toString(TestClass.class, this);\n        }"
        ],
        [
            "GridSpringTransactionManagerSelfTest::getTestIgniteInstanceName()",
            "  69  \n  70  \n  71  \n  72  \n  73 -\n  74  \n  75  ",
            "    /**\n     * {@inheritDoc}\n     */\n    @Override\n    public String getTestIgniteInstanceName() {\n        return \"testGrid\";\n    }",
            "  66  \n  67 +\n  68  \n  69  ",
            "    /** {@inheritDoc} */\n    @Override public String getTestIgniteInstanceName() {\n        return \"testGrid\";\n    }"
        ],
        [
            "GridSpringTransactionManagerSelfTest::afterTestsStopped()",
            "  85  \n  86  \n  87  \n  88  \n  89 -\n  90  \n  91  ",
            "    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected void afterTestsStopped() throws Exception {\n        stopAllGrids();\n    }",
            "  76  \n  77 +\n  78  \n  79  ",
            "    /** {@inheritDoc} */\n    @Override protected void afterTestsStopped() throws Exception {\n        stopAllGrids();\n    }"
        ],
        [
            "GridSpringTransactionManagerSelfTest::getConfiguration(String)",
            "  46  \n  47  \n  48  \n  49  \n  50 -\n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  ",
            "    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {\n        IgniteConfiguration cfg = super.getConfiguration(igniteInstanceName);\n\n        CacheConfiguration cache = new CacheConfiguration(DEFAULT_CACHE_NAME);\n\n        cache.setName(CACHE_NAME);\n        cache.setAtomicityMode(CacheAtomicityMode.TRANSACTIONAL);\n\n        cfg.setCacheConfiguration(cache);\n\n        TcpDiscoverySpi disco = new TcpDiscoverySpi();\n\n        disco.setIpFinder(IP_FINDER);\n\n        cfg.setDiscoverySpi(disco);\n\n        return cfg;\n    }",
            "  46  \n  47 +\n  48  \n  49  \n  50  \n  51  \n  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  ",
            "    /** {@inheritDoc} */\n    @Override protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {\n        IgniteConfiguration cfg = super.getConfiguration(igniteInstanceName);\n\n        CacheConfiguration cache = new CacheConfiguration(DEFAULT_CACHE_NAME);\n\n        cache.setName(CACHE_NAME);\n        cache.setAtomicityMode(CacheAtomicityMode.TRANSACTIONAL);\n\n        cfg.setCacheConfiguration(cache);\n\n        TcpDiscoverySpi disco = new TcpDiscoverySpi();\n\n        disco.setIpFinder(IP_FINDER);\n\n        cfg.setDiscoverySpi(disco);\n\n        return cfg;\n    }"
        ],
        [
            "IgniteCacheTxIteratorSelfTest::TestClass::equals(Object)",
            " 203  \n 204  \n 205  \n 206  \n 207 -\n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  ",
            "        /**\n         * {@inheritDoc}\n         */\n        @Override\n        public boolean equals(final Object o) {\n            if (this == o)\n                return true;\n            if (o == null || getClass() != o.getClass())\n                return false;\n\n            final TestClass testCls = (TestClass)o;\n\n            return data != null ? data.equals(testCls.data) : testCls.data == null;\n\n        }",
            " 203  \n 204 +\n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  ",
            "        /** {@inheritDoc} */\n        @Override public boolean equals(final Object o) {\n            if (this == o)\n                return true;\n            if (o == null || getClass() != o.getClass())\n                return false;\n\n            final TestClass testCls = (TestClass)o;\n\n            return data != null ? data.equals(testCls.data) : testCls.data == null;\n\n        }"
        ]
    ],
    "0020e417cfaf36da513c2063dc081514498a1597": [
        [
            "ClientListenerNioListener::onHandshake(GridNioSession,byte)",
            " 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  ",
            "    /**\n     * Perform handshake.\n     *\n     * @param ses Session.\n     * @param msg Message bytes.\n     */\n    private void onHandshake(GridNioSession ses, byte[] msg) {\n        BinaryInputStream stream = new BinaryHeapInputStream(msg);\n\n        BinaryReaderExImpl reader = new BinaryReaderExImpl(null, stream, null, true);\n\n        byte cmd = reader.readByte();\n\n        if (cmd != ClientListenerRequest.HANDSHAKE) {\n            U.warn(log, \"Unexpected client request (will close session): \" + ses.remoteAddress());\n\n            ses.close();\n\n            return;\n        }\n\n        short verMajor = reader.readShort();\n        short verMinor = reader.readShort();\n        short verMaintenance = reader.readShort();\n\n        ClientListenerProtocolVersion ver = ClientListenerProtocolVersion.create(verMajor, verMinor, verMaintenance);\n\n        BinaryWriterExImpl writer = new BinaryWriterExImpl(null, new BinaryHeapOutputStream(8), null, null);\n\n        byte clientType = reader.readByte();\n\n        ClientListenerConnectionContext connCtx = null;\n\n        try {\n            connCtx = prepareContext(ses, clientType);\n\n            ensureClientPermissions(clientType);\n\n            if (connCtx.isVersionSupported(ver)) {\n                connCtx.initializeFromHandshake(ver, reader);\n\n                ses.addMeta(CONN_CTX_META_KEY, connCtx);\n            }\n            else\n                throw new IgniteCheckedException(\"Unsupported version.\");\n\n            connCtx.handler().writeHandshake(writer);\n        }\n        catch (IgniteAccessControlException authEx) {\n            writer.writeBoolean(false);\n\n            writer.writeShort((short)0);\n            writer.writeShort((short)0);\n            writer.writeShort((short)0);\n\n            writer.doWriteString(authEx.getMessage());\n\n            if (ver.compareTo(ClientConnectionContext.VER_1_1_0) >= 0)\n                writer.writeInt(ClientStatus.AUTH_FAILED);\n        }\n        catch (IgniteCheckedException e) {\n            U.warn(log, \"Error during handshake [rmtAddr=\" + ses.remoteAddress() + \", msg=\" + e.getMessage() + ']');\n\n            ClientListenerProtocolVersion currVer;\n\n            if (connCtx == null)\n                currVer = ClientListenerProtocolVersion.create(0, 0, 0);\n            else\n                currVer = connCtx.currentVersion();\n\n            writer.writeBoolean(false);\n\n            writer.writeShort(currVer.major());\n            writer.writeShort(currVer.minor());\n            writer.writeShort(currVer.maintenance());\n\n            writer.doWriteString(e.getMessage());\n\n            if (ver.compareTo(ClientConnectionContext.VER_1_1_0) >= 0)\n                writer.writeInt(ClientStatus.FAILED);\n        }\n\n        ses.send(writer.array());\n    }",
            " 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236 +\n 237 +\n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  ",
            "    /**\n     * Perform handshake.\n     *\n     * @param ses Session.\n     * @param msg Message bytes.\n     */\n    private void onHandshake(GridNioSession ses, byte[] msg) {\n        BinaryInputStream stream = new BinaryHeapInputStream(msg);\n\n        BinaryReaderExImpl reader = new BinaryReaderExImpl(null, stream, null, true);\n\n        byte cmd = reader.readByte();\n\n        if (cmd != ClientListenerRequest.HANDSHAKE) {\n            U.warn(log, \"Unexpected client request (will close session): \" + ses.remoteAddress());\n\n            ses.close();\n\n            return;\n        }\n\n        short verMajor = reader.readShort();\n        short verMinor = reader.readShort();\n        short verMaintenance = reader.readShort();\n\n        ClientListenerProtocolVersion ver = ClientListenerProtocolVersion.create(verMajor, verMinor, verMaintenance);\n\n        BinaryWriterExImpl writer = new BinaryWriterExImpl(null, new BinaryHeapOutputStream(8), null, null);\n\n        byte clientType = reader.readByte();\n\n        ClientListenerConnectionContext connCtx = null;\n\n        try {\n            connCtx = prepareContext(ses, clientType);\n\n            ensureClientPermissions(clientType);\n\n            if (connCtx.isVersionSupported(ver)) {\n                connCtx.initializeFromHandshake(ver, reader);\n\n                ses.addMeta(CONN_CTX_META_KEY, connCtx);\n            }\n            else\n                throw new IgniteCheckedException(\"Unsupported version.\");\n\n            connCtx.handler().writeHandshake(writer);\n\n            ses.addMeta(CONN_CTX_HANDSHAKE_PASSED, true);\n        }\n        catch (IgniteAccessControlException authEx) {\n            writer.writeBoolean(false);\n\n            writer.writeShort((short)0);\n            writer.writeShort((short)0);\n            writer.writeShort((short)0);\n\n            writer.doWriteString(authEx.getMessage());\n\n            if (ver.compareTo(ClientConnectionContext.VER_1_1_0) >= 0)\n                writer.writeInt(ClientStatus.AUTH_FAILED);\n        }\n        catch (IgniteCheckedException e) {\n            U.warn(log, \"Error during handshake [rmtAddr=\" + ses.remoteAddress() + \", msg=\" + e.getMessage() + ']');\n\n            ClientListenerProtocolVersion currVer;\n\n            if (connCtx == null)\n                currVer = ClientListenerProtocolVersion.create(0, 0, 0);\n            else\n                currVer = connCtx.currentVersion();\n\n            writer.writeBoolean(false);\n\n            writer.writeShort(currVer.major());\n            writer.writeShort(currVer.minor());\n            writer.writeShort(currVer.maintenance());\n\n            writer.doWriteString(e.getMessage());\n\n            if (ver.compareTo(ClientConnectionContext.VER_1_1_0) >= 0)\n                writer.writeInt(ClientStatus.FAILED);\n        }\n\n        ses.send(writer.array());\n    }"
        ],
        [
            "ClientListenerNioListener::onMessage(GridNioSession,byte)",
            " 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131 -\n 132 -\n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  ",
            "    /** {@inheritDoc} */\n    @Override public void onMessage(GridNioSession ses, byte[] msg) {\n        assert msg != null;\n\n        ClientListenerConnectionContext connCtx = ses.meta(CONN_CTX_META_KEY);\n\n        if (connCtx == null) {\n            onHandshake(ses, msg);\n\n            ses.addMeta(CONN_CTX_HANDSHAKE_PASSED, true);\n\n            return;\n        }\n\n        ClientListenerMessageParser parser = connCtx.parser();\n        ClientListenerRequestHandler handler = connCtx.handler();\n\n        ClientListenerRequest req;\n\n        try {\n            req = parser.decode(msg);\n        }\n        catch (Exception e) {\n            U.error(log, \"Failed to parse client request.\", e);\n\n            ses.close();\n\n            return;\n        }\n\n        assert req != null;\n\n        try {\n            long startTime = 0;\n\n            if (log.isDebugEnabled()) {\n                startTime = System.nanoTime();\n\n                log.debug(\"Client request received [reqId=\" + req.requestId() + \", addr=\" +\n                    ses.remoteAddress() + \", req=\" + req + ']');\n            }\n\n            ClientListenerResponse resp = handler.handle(req);\n\n            if (resp != null) {\n                if (log.isDebugEnabled()) {\n                    long dur = (System.nanoTime() - startTime) / 1000;\n\n                    log.debug(\"Client request processed [reqId=\" + req.requestId() + \", dur(mcs)=\" + dur +\n                        \", resp=\" + resp.status() + ']');\n                }\n\n                byte[] outMsg = parser.encode(resp);\n\n                ses.send(outMsg);\n            }\n        }\n        catch (Exception e) {\n            U.error(log, \"Failed to process client request [req=\" + req + ']', e);\n\n            ses.send(parser.encode(handler.handleException(e, req)));\n        }\n    }",
            " 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  ",
            "    /** {@inheritDoc} */\n    @Override public void onMessage(GridNioSession ses, byte[] msg) {\n        assert msg != null;\n\n        ClientListenerConnectionContext connCtx = ses.meta(CONN_CTX_META_KEY);\n\n        if (connCtx == null) {\n            onHandshake(ses, msg);\n\n            return;\n        }\n\n        ClientListenerMessageParser parser = connCtx.parser();\n        ClientListenerRequestHandler handler = connCtx.handler();\n\n        ClientListenerRequest req;\n\n        try {\n            req = parser.decode(msg);\n        }\n        catch (Exception e) {\n            U.error(log, \"Failed to parse client request.\", e);\n\n            ses.close();\n\n            return;\n        }\n\n        assert req != null;\n\n        try {\n            long startTime = 0;\n\n            if (log.isDebugEnabled()) {\n                startTime = System.nanoTime();\n\n                log.debug(\"Client request received [reqId=\" + req.requestId() + \", addr=\" +\n                    ses.remoteAddress() + \", req=\" + req + ']');\n            }\n\n            ClientListenerResponse resp = handler.handle(req);\n\n            if (resp != null) {\n                if (log.isDebugEnabled()) {\n                    long dur = (System.nanoTime() - startTime) / 1000;\n\n                    log.debug(\"Client request processed [reqId=\" + req.requestId() + \", dur(mcs)=\" + dur +\n                        \", resp=\" + resp.status() + ']');\n                }\n\n                byte[] outMsg = parser.encode(resp);\n\n                ses.send(outMsg);\n            }\n        }\n        catch (Exception e) {\n            U.error(log, \"Failed to process client request [req=\" + req + ']', e);\n\n            ses.send(parser.encode(handler.handleException(e, req)));\n        }\n    }"
        ]
    ],
    "c2369ff70a5c19f4931039e3fd45d6db758fdb0e": [
        [
            "GridCommandHandlerTest::testCacheAffinity()",
            " 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751 -\n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760 -\n 761  \n 762  \n 763  \n 764  ",
            "    /**\n     *\n     */\n    public void testCacheAffinity() throws Exception {\n        Ignite ignite = startGrid();\n\n        ignite.cluster().active(true);\n\n        IgniteCache<Object, Object> cache1 = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setName(\"cacheAf\"));\n\n        for (int i = 0; i < 100; i++)\n            cache1.put(i, i);\n\n        injectTestSystemOut();\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"list\", \".*\"));\n\n        assertTrue(testOut.toString().contains(\"cacheName=cacheAf\"));\n        assertTrue(testOut.toString().contains(\"prim=32\"));\n        assertTrue(testOut.toString().contains(\"mapped=32\"));\n        assertTrue(testOut.toString().contains(\"affCls=RendezvousAffinityFunction\"));\n    }",
            " 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742 +\n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751 +\n 752  \n 753  \n 754  \n 755  ",
            "    /**\n     *\n     */\n    public void testCacheAffinity() throws Exception {\n        Ignite ignite = startGrid();\n\n        ignite.cluster().active(true);\n\n        IgniteCache<Object, Object> cache1 = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setName(DEFAULT_CACHE_NAME));\n\n        for (int i = 0; i < 100; i++)\n            cache1.put(i, i);\n\n        injectTestSystemOut();\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"list\", \".*\"));\n\n        assertTrue(testOut.toString().contains(\"cacheName=\" + DEFAULT_CACHE_NAME));\n        assertTrue(testOut.toString().contains(\"prim=32\"));\n        assertTrue(testOut.toString().contains(\"mapped=32\"));\n        assertTrue(testOut.toString().contains(\"affCls=RendezvousAffinityFunction\"));\n    }"
        ],
        [
            "GridCommandHandlerTest::testCacheGroups()",
            " 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715 -\n 716 -\n 717 -\n 718 -\n 719 -\n 720 -\n 721 -\n 722  \n 723  \n 724  \n 725 -\n 726  \n 727 -\n 728 -\n 729 -\n 730 -\n 731 -\n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  ",
            "    /**\n     *\n     */\n    public void testCacheGroups() throws Exception {\n        Ignite ignite = startGrid();\n\n        ignite.cluster().active(true);\n\n        IgniteCache<Object, Object> cache1 = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setGroupName(\"G100\")\n            .setName(\"cacheG1\"));\n\n        IgniteCache<Object, Object> cache2 = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setGroupName(\"G100\")\n            .setName(\"cacheG2\"));\n\n        for (int i = 0; i < 100; i++) {\n            cache1.put(i, i);\n\n            cache2.put(i, i);\n        }\n\n        injectTestSystemOut();\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"list\", \".*\", \"groups\"));\n\n        assertTrue(testOut.toString().contains(\"G100\"));\n    }",
            " 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715 +\n 716  \n 717  \n 718  \n 719 +\n 720  \n 721 +\n 722 +\n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  ",
            "    /**\n     *\n     */\n    public void testCacheGroups() throws Exception {\n        Ignite ignite = startGrid();\n\n        ignite.cluster().active(true);\n\n        IgniteCache<Object, Object> cache = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setGroupName(\"G100\")\n            .setName(DEFAULT_CACHE_NAME));\n\n        for (int i = 0; i < 100; i++)\n            cache.put(i, i);\n\n        injectTestSystemOut();\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"list\", \".*\", \"groups\"));\n\n        assertTrue(testOut.toString().contains(\"G100\"));\n    }"
        ],
        [
            "GridCommandHandlerTest::testCacheIdleVerify()",
            " 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590 -\n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603 -\n 604  \n 605  \n 606  \n 607  \n 608  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testCacheIdleVerify() throws Exception {\n        Ignite ignite = startGrids(2);\n\n        ignite.cluster().active(true);\n\n        IgniteCache<Object, Object> cache = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setName(\"cacheIV\"));\n\n        for (int i = 0; i < 100; i++)\n            cache.put(i, i);\n\n        injectTestSystemOut();\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"idle_verify\"));\n\n        assertTrue(testOut.toString().contains(\"no conflicts have been found\"));\n\n        HashSet<Integer> clearKeys = new HashSet<>(Arrays.asList(1, 2, 3, 4, 5, 6));\n\n        ((IgniteEx)ignite).context().cache().cache(\"cacheIV\").clearLocallyAll(clearKeys, true, true, true);\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"idle_verify\"));\n\n        assertTrue(testOut.toString().contains(\"conflict partitions\"));\n    }",
            " 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590 +\n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603 +\n 604  \n 605  \n 606  \n 607  \n 608  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    public void testCacheIdleVerify() throws Exception {\n        Ignite ignite = startGrids(2);\n\n        ignite.cluster().active(true);\n\n        IgniteCache<Object, Object> cache = ignite.createCache(new CacheConfiguration<>()\n            .setAffinity(new RendezvousAffinityFunction(false, 32))\n            .setBackups(1)\n            .setName(DEFAULT_CACHE_NAME));\n\n        for (int i = 0; i < 100; i++)\n            cache.put(i, i);\n\n        injectTestSystemOut();\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"idle_verify\"));\n\n        assertTrue(testOut.toString().contains(\"no conflicts have been found\"));\n\n        HashSet<Integer> clearKeys = new HashSet<>(Arrays.asList(1, 2, 3, 4, 5, 6));\n\n        ((IgniteEx)ignite).context().cache().cache(DEFAULT_CACHE_NAME).clearLocallyAll(clearKeys, true, true, true);\n\n        assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"idle_verify\"));\n\n        assertTrue(testOut.toString().contains(\"conflict partitions\"));\n    }"
        ],
        [
            "GridCommandHandlerTest::testCacheContention()",
            " 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627 -\n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  ",
            "    /**\n     *\n     */\n    public void testCacheContention() throws Exception {\n        int cnt = 10;\n\n        final ExecutorService svc = Executors.newFixedThreadPool(cnt);\n\n        try {\n            Ignite ignite = startGrids(2);\n\n            ignite.cluster().active(true);\n\n            final IgniteCache<Object, Object> cache = ignite.createCache(new CacheConfiguration<>()\n                .setAffinity(new RendezvousAffinityFunction(false, 32))\n                .setAtomicityMode(TRANSACTIONAL)\n                .setBackups(1)\n                .setName(\"cacheCont\"));\n\n            final CountDownLatch l = new CountDownLatch(1);\n\n            final CountDownLatch l2 = new CountDownLatch(1);\n\n            svc.submit(new Runnable() {\n                @Override public void run() {\n                    try (final Transaction tx = ignite.transactions().txStart()) {\n                        cache.put(0, 0);\n\n                        l.countDown();\n\n                        U.awaitQuiet(l2);\n\n                        tx.commit();\n                    }\n                }\n            });\n\n            for (int i = 0; i < cnt - 1; i++) {\n                svc.submit(new Runnable() {\n                    @Override public void run() {\n                        U.awaitQuiet(l);\n\n                        try (final Transaction tx = ignite.transactions().txStart()) {\n                            cache.get(0);\n\n                            tx.commit();\n                        }\n                    }\n                });\n            }\n\n            U.awaitQuiet(l);\n\n            Thread.sleep(300);\n\n            injectTestSystemOut();\n\n            assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"contention\", \"5\"));\n\n            l2.countDown();\n\n            assertTrue(testOut.toString().contains(\"TxEntry\"));\n            assertTrue(testOut.toString().contains(\"op=READ\"));\n            assertTrue(testOut.toString().contains(\"op=CREATE\"));\n            assertTrue(testOut.toString().contains(\"id=\" + ignite(0).cluster().localNode().id()));\n            assertTrue(testOut.toString().contains(\"id=\" + ignite(1).cluster().localNode().id()));\n        }\n        finally {\n            svc.shutdown();\n            svc.awaitTermination(100, TimeUnit.DAYS);\n        }\n    }",
            " 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627 +\n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  ",
            "    /**\n     *\n     */\n    public void testCacheContention() throws Exception {\n        int cnt = 10;\n\n        final ExecutorService svc = Executors.newFixedThreadPool(cnt);\n\n        try {\n            Ignite ignite = startGrids(2);\n\n            ignite.cluster().active(true);\n\n            final IgniteCache<Object, Object> cache = ignite.createCache(new CacheConfiguration<>()\n                .setAffinity(new RendezvousAffinityFunction(false, 32))\n                .setAtomicityMode(TRANSACTIONAL)\n                .setBackups(1)\n                .setName(DEFAULT_CACHE_NAME));\n\n            final CountDownLatch l = new CountDownLatch(1);\n\n            final CountDownLatch l2 = new CountDownLatch(1);\n\n            svc.submit(new Runnable() {\n                @Override public void run() {\n                    try (final Transaction tx = ignite.transactions().txStart()) {\n                        cache.put(0, 0);\n\n                        l.countDown();\n\n                        U.awaitQuiet(l2);\n\n                        tx.commit();\n                    }\n                }\n            });\n\n            for (int i = 0; i < cnt - 1; i++) {\n                svc.submit(new Runnable() {\n                    @Override public void run() {\n                        U.awaitQuiet(l);\n\n                        try (final Transaction tx = ignite.transactions().txStart()) {\n                            cache.get(0);\n\n                            tx.commit();\n                        }\n                    }\n                });\n            }\n\n            U.awaitQuiet(l);\n\n            Thread.sleep(300);\n\n            injectTestSystemOut();\n\n            assertEquals(EXIT_CODE_OK, execute(\"--cache\", \"contention\", \"5\"));\n\n            l2.countDown();\n\n            assertTrue(testOut.toString().contains(\"TxEntry\"));\n            assertTrue(testOut.toString().contains(\"op=READ\"));\n            assertTrue(testOut.toString().contains(\"op=CREATE\"));\n            assertTrue(testOut.toString().contains(\"id=\" + ignite(0).cluster().localNode().id()));\n            assertTrue(testOut.toString().contains(\"id=\" + ignite(1).cluster().localNode().id()));\n        }\n        finally {\n            svc.shutdown();\n            svc.awaitTermination(100, TimeUnit.DAYS);\n        }\n    }"
        ]
    ],
    "2bf48e5417816c2211402dfacf5678f6a67014bd": [
        [
            "GridAbstractTest::getDefaultTestTimeout()",
            "2177  \n2178  \n2179  \n2180  \n2181  \n2182  \n2183  \n2184  \n2185  \n2186 -\n2187  ",
            "    /**\n     * @return Default test case timeout.\n     */\n    private long getDefaultTestTimeout() {\n        String timeout = GridTestProperties.getProperty(\"test.timeout\");\n\n        if (timeout != null)\n            return Long.parseLong(timeout);\n\n        return DFLT_TEST_TIMEOUT;\n    }",
            "2174  \n2175  \n2176  \n2177  \n2178  \n2179  \n2180  \n2181  \n2182  \n2183 +\n2184  ",
            "    /**\n     * @return Default test case timeout.\n     */\n    private long getDefaultTestTimeout() {\n        String timeout = GridTestProperties.getProperty(\"test.timeout\");\n\n        if (timeout != null)\n            return Long.parseLong(timeout);\n\n        return GridTestUtils.DFLT_TEST_TIMEOUT;\n    }"
        ]
    ],
    "f9be391856ceff2268249fccbfd3c5ca0132378e": [
        [
            "IgniteCacheDatabaseSharedManager::createPageEvictionTracker(MemoryPolicyConfiguration,PageMemory)",
            " 899  \n 900  \n 901  \n 902  \n 903  \n 904 -\n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  ",
            "    /**\n     * @param plc Memory Policy Configuration.\n     * @param pageMem Page memory.\n     */\n    private PageEvictionTracker createPageEvictionTracker(MemoryPolicyConfiguration plc, PageMemory pageMem) {\n        if (plc.getPageEvictionMode() == DataPageEvictionMode.DISABLED)\n            return new NoOpPageEvictionTracker();\n\n        assert pageMem instanceof PageMemoryNoStoreImpl : pageMem.getClass();\n\n        PageMemoryNoStoreImpl pageMem0 = (PageMemoryNoStoreImpl)pageMem;\n\n        if (Boolean.getBoolean(\"override.fair.fifo.page.eviction.tracker\"))\n            return new FairFifoPageEvictionTracker(pageMem0, plc, cctx);\n\n        switch (plc.getPageEvictionMode()) {\n            case RANDOM_LRU:\n                return new RandomLruPageEvictionTracker(pageMem0, plc, cctx);\n            case RANDOM_2_LRU:\n                return new Random2LruPageEvictionTracker(pageMem0, plc, cctx);\n            default:\n                return new NoOpPageEvictionTracker();\n        }\n    }",
            " 899  \n 900  \n 901  \n 902  \n 903  \n 904 +\n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  ",
            "    /**\n     * @param plc Memory Policy Configuration.\n     * @param pageMem Page memory.\n     */\n    private PageEvictionTracker createPageEvictionTracker(MemoryPolicyConfiguration plc, PageMemory pageMem) {\n        if (plc.getPageEvictionMode() == DataPageEvictionMode.DISABLED || cctx.gridConfig().isPersistentStoreEnabled())\n            return new NoOpPageEvictionTracker();\n\n        assert pageMem instanceof PageMemoryNoStoreImpl : pageMem.getClass();\n\n        PageMemoryNoStoreImpl pageMem0 = (PageMemoryNoStoreImpl)pageMem;\n\n        if (Boolean.getBoolean(\"override.fair.fifo.page.eviction.tracker\"))\n            return new FairFifoPageEvictionTracker(pageMem0, plc, cctx);\n\n        switch (plc.getPageEvictionMode()) {\n            case RANDOM_LRU:\n                return new RandomLruPageEvictionTracker(pageMem0, plc, cctx);\n            case RANDOM_2_LRU:\n                return new Random2LruPageEvictionTracker(pageMem0, plc, cctx);\n            default:\n                return new NoOpPageEvictionTracker();\n        }\n    }"
        ],
        [
            "GridCacheDatabaseSharedManager::checkPolicyEvictionProperties(MemoryPolicyConfiguration,MemoryConfiguration)",
            " 687  \n 688  \n 689  \n 690  \n 691 -\n 692  ",
            "    /** {@inheritDoc} */\n    @Override protected void checkPolicyEvictionProperties(MemoryPolicyConfiguration plcCfg, MemoryConfiguration dbCfg)\n        throws IgniteCheckedException {\n        if (plcCfg.getPageEvictionMode() != DataPageEvictionMode.DISABLED)\n            throw new IgniteCheckedException(\"Page eviction is not compatible with persistence: \" + plcCfg.getName());\n    }",
            " 689  \n 690  \n 691  \n 692  \n 693 +\n 694 +\n 695  ",
            "    /** {@inheritDoc} */\n    @Override protected void checkPolicyEvictionProperties(MemoryPolicyConfiguration plcCfg, MemoryConfiguration dbCfg)\n        throws IgniteCheckedException {\n        if (plcCfg.getPageEvictionMode() != DataPageEvictionMode.DISABLED)\n            U.warn(log, \"Page eviction mode for [\" + plcCfg.getName() + \"] memory region is ignored \" +\n                \"because Ignite Native Persistence is enabled\");\n    }"
        ],
        [
            "IgnitePdsEvictionTest::createDbConfig()",
            "  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  ",
            "    /**\n     * @return DB config.\n     */\n    private MemoryConfiguration createDbConfig() {\n        final MemoryConfiguration memCfg = new MemoryConfiguration();\n\n        MemoryPolicyConfiguration memPlcCfg = new MemoryPolicyConfiguration();\n        memPlcCfg.setInitialSize(MEMORY_LIMIT);\n        memPlcCfg.setMaxSize(MEMORY_LIMIT);\n        memPlcCfg.setName(\"dfltMemPlc\");\n\n        memCfg.setPageSize(PAGE_SIZE);\n        memCfg.setConcurrencyLevel(NUMBER_OF_SEGMENTS);\n        memCfg.setMemoryPolicies(memPlcCfg);\n        memCfg.setDefaultMemoryPolicyName(\"dfltMemPlc\");\n\n        return memCfg;\n    }",
            "  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88 +\n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  ",
            "    /**\n     * @return DB config.\n     */\n    private MemoryConfiguration createDbConfig() {\n        final MemoryConfiguration memCfg = new MemoryConfiguration();\n\n        MemoryPolicyConfiguration memPlcCfg = new MemoryPolicyConfiguration();\n        memPlcCfg.setInitialSize(MEMORY_LIMIT);\n        memPlcCfg.setMaxSize(MEMORY_LIMIT);\n        memPlcCfg.setPageEvictionMode(DataPageEvictionMode.RANDOM_LRU);\n        memPlcCfg.setName(\"dfltMemPlc\");\n\n        memCfg.setPageSize(PAGE_SIZE);\n        memCfg.setConcurrencyLevel(NUMBER_OF_SEGMENTS);\n        memCfg.setMemoryPolicies(memPlcCfg);\n        memCfg.setDefaultMemoryPolicyName(\"dfltMemPlc\");\n\n        return memCfg;\n    }"
        ]
    ],
    "b3ae58eccb35369041342e4a5d9bb5f661417d41": [
        [
            "PageMemoryImpl::refreshOutdatedPage(Segment,int,long,boolean)",
            " 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649 -\n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  ",
            "    /**\n     * @param seg Segment.\n     * @param cacheId Cache ID.\n     * @param pageId Page ID.\n     * @param rmv {@code True} if page should be removed.\n     * @return Relative pointer to refreshed page.\n     */\n    private long refreshOutdatedPage(Segment seg, int cacheId, long pageId, boolean rmv) {\n        assert seg.writeLock().isHeldByCurrentThread();\n\n        int tag = seg.partTag(cacheId, PageIdUtils.partId(pageId));\n\n        long relPtr = seg.loadedPages.refresh(cacheId, PageIdUtils.effectivePageId(pageId), tag);\n\n        long absPtr = seg.absolute(relPtr);\n\n        GridUnsafe.setMemory(absPtr + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n        long tmpBufPtr = PageHeader.tempBufferPointer(absPtr);\n\n        if (tmpBufPtr != INVALID_REL_PTR) {\n            GridUnsafe.setMemory(checkpointPool.absolute(tmpBufPtr) + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n            PageHeader.tempBufferPointer(absPtr, INVALID_REL_PTR);\n            PageHeader.dirty(absPtr, false);\n\n            // We pinned the page when allocated the temp buffer, release it now.\n            PageHeader.releasePage(absPtr);\n\n            checkpointPool.releaseFreePage(tmpBufPtr);\n        }\n\n        if (rmv)\n            seg.loadedPages.remove(cacheId, PageIdUtils.effectivePageId(pageId), tag);\n\n        return relPtr;\n    }",
            " 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643 +\n 644 +\n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661 +\n 662 +\n 663 +\n 664 +\n 665 +\n 666 +\n 667  \n 668  ",
            "    /**\n     * @param seg Segment.\n     * @param cacheId Cache ID.\n     * @param pageId Page ID.\n     * @param rmv {@code True} if page should be removed.\n     * @return Relative pointer to refreshed page.\n     */\n    private long refreshOutdatedPage(Segment seg, int cacheId, long pageId, boolean rmv) {\n        assert seg.writeLock().isHeldByCurrentThread();\n\n        int tag = seg.partTag(cacheId, PageIdUtils.partId(pageId));\n\n        long relPtr = seg.loadedPages.refresh(cacheId, PageIdUtils.effectivePageId(pageId), tag);\n\n        long absPtr = seg.absolute(relPtr);\n\n        GridUnsafe.setMemory(absPtr + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n        PageHeader.dirty(absPtr, false);\n\n        long tmpBufPtr = PageHeader.tempBufferPointer(absPtr);\n\n        if (tmpBufPtr != INVALID_REL_PTR) {\n            GridUnsafe.setMemory(checkpointPool.absolute(tmpBufPtr) + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n            PageHeader.tempBufferPointer(absPtr, INVALID_REL_PTR);\n\n            // We pinned the page when allocated the temp buffer, release it now.\n            PageHeader.releasePage(absPtr);\n\n            checkpointPool.releaseFreePage(tmpBufPtr);\n        }\n\n        if (rmv)\n            seg.loadedPages.remove(cacheId, PageIdUtils.effectivePageId(pageId), tag);\n\n        if (seg.segCheckpointPages != null)\n            seg.segCheckpointPages.remove(new FullPageId(pageId, cacheId));\n\n        if (seg.dirtyPages != null)\n            seg.dirtyPages.remove(new FullPageId(pageId, cacheId));\n\n        return relPtr;\n    }"
        ],
        [
            "GridCacheDatabaseSharedManager::restorePartitionState(Map)",
            "1528  \n1529  \n1530  \n1531  \n1532  \n1533  \n1534  \n1535  \n1536  \n1537  \n1538  \n1539  \n1540  \n1541  \n1542  \n1543  \n1544  \n1545  \n1546  \n1547  \n1548  \n1549  \n1550  \n1551  \n1552  \n1553  \n1554  \n1555  \n1556  \n1557  \n1558  \n1559  \n1560  \n1561  \n1562  \n1563  \n1564 -\n1565 -\n1566 -\n1567 -\n1568  \n1569  \n1570  \n1571  \n1572  \n1573  \n1574  \n1575  \n1576  \n1577  \n1578  \n1579  \n1580  \n1581  \n1582  \n1583  \n1584  \n1585  \n1586  \n1587  \n1588  \n1589  \n1590  \n1591  \n1592  \n1593  \n1594  \n1595  \n1596  \n1597  \n1598  ",
            "    /**\n     * @param partStates Partition states.\n     * @throws IgniteCheckedException If failed to restore.\n     */\n    private void restorePartitionState(\n        Map<T2<Integer, Integer>, T2<Integer, Long>> partStates\n    ) throws IgniteCheckedException {\n        for (CacheGroupContext grp : cctx.cache().cacheGroups()) {\n            if (grp.isLocal() || !grp.affinityNode()) {\n                // Local cache has no partitions and its states.\n                continue;\n            }\n\n            int grpId = grp.groupId();\n\n            PageMemoryEx pageMem = (PageMemoryEx)grp.memoryPolicy().pageMemory();\n\n            for (int i = 0; i < grp.affinity().partitions(); i++) {\n                if (storeMgr.exists(grpId, i)) {\n                    storeMgr.ensure(grpId, i);\n\n                    if (storeMgr.pages(grpId, i) <= 1)\n                        continue;\n\n                    long partMetaId = pageMem.partitionMetaPageId(grpId, i);\n                    long partMetaPage = pageMem.acquirePage(grpId, partMetaId);\n                    try {\n                        long pageAddr = pageMem.writeLock(grpId, partMetaId, partMetaPage);\n\n                        boolean changed = false;\n\n                        try {\n                            PagePartitionMetaIO io = PagePartitionMetaIO.VERSIONS.forPage(pageAddr);\n\n                            T2<Integer, Long> fromWal = partStates.get(new T2<>(grpId, i));\n\n                            GridDhtLocalPartition part = grp.topology().forceCreatePartition(i);\n\n                            assert part != null;\n\n                            if (fromWal != null) {\n                                int stateId = fromWal.get1();\n\n                                io.setPartitionState(pageAddr, (byte)stateId);\n\n                                changed = updateState(part, stateId);\n\n                                if (stateId == GridDhtPartitionState.OWNING.ordinal()) {\n                                    grp.offheap().onPartitionInitialCounterUpdated(i, fromWal.get2());\n\n                                    if (part.initialUpdateCounter() < fromWal.get2()) {\n                                        part.initialUpdateCounter(fromWal.get2());\n\n                                        changed = true;\n                                    }\n                                }\n                            }\n                            else\n                                changed = updateState(part, (int)io.getPartitionState(pageAddr));\n                        }\n                        finally {\n                            pageMem.writeUnlock(grpId, partMetaId, partMetaPage, null, changed);\n                        }\n                    }\n                    finally {\n                        pageMem.releasePage(grpId, partMetaId, partMetaPage);\n                    }\n                }\n            }\n        }\n    }",
            "1528  \n1529  \n1530  \n1531  \n1532  \n1533  \n1534  \n1535  \n1536  \n1537  \n1538  \n1539  \n1540  \n1541  \n1542  \n1543  \n1544  \n1545  \n1546  \n1547  \n1548  \n1549  \n1550  \n1551  \n1552 +\n1553 +\n1554 +\n1555 +\n1556 +\n1557 +\n1558 +\n1559  \n1560  \n1561  \n1562  \n1563  \n1564  \n1565  \n1566  \n1567  \n1568  \n1569  \n1570  \n1571  \n1572  \n1573  \n1574  \n1575  \n1576  \n1577  \n1578  \n1579  \n1580  \n1581  \n1582  \n1583  \n1584  \n1585  \n1586  \n1587  \n1588  \n1589  \n1590  \n1591  \n1592  \n1593  \n1594  \n1595  \n1596  \n1597  \n1598  \n1599  \n1600  \n1601  ",
            "    /**\n     * @param partStates Partition states.\n     * @throws IgniteCheckedException If failed to restore.\n     */\n    private void restorePartitionState(\n        Map<T2<Integer, Integer>, T2<Integer, Long>> partStates\n    ) throws IgniteCheckedException {\n        for (CacheGroupContext grp : cctx.cache().cacheGroups()) {\n            if (grp.isLocal() || !grp.affinityNode()) {\n                // Local cache has no partitions and its states.\n                continue;\n            }\n\n            int grpId = grp.groupId();\n\n            PageMemoryEx pageMem = (PageMemoryEx)grp.memoryPolicy().pageMemory();\n\n            for (int i = 0; i < grp.affinity().partitions(); i++) {\n                if (storeMgr.exists(grpId, i)) {\n                    storeMgr.ensure(grpId, i);\n\n                    if (storeMgr.pages(grpId, i) <= 1)\n                        continue;\n\n                    GridDhtLocalPartition part = grp.topology().forceCreatePartition(i);\n\n                    assert part != null;\n\n                    // TODO: https://issues.apache.org/jira/browse/IGNITE-6097\n                    grp.offheap().onPartitionInitialCounterUpdated(i, 0);\n\n                    long partMetaId = pageMem.partitionMetaPageId(grpId, i);\n                    long partMetaPage = pageMem.acquirePage(grpId, partMetaId);\n                    try {\n                        long pageAddr = pageMem.writeLock(grpId, partMetaId, partMetaPage);\n\n                        boolean changed = false;\n\n                        try {\n                            PagePartitionMetaIO io = PagePartitionMetaIO.VERSIONS.forPage(pageAddr);\n\n                            T2<Integer, Long> fromWal = partStates.get(new T2<>(grpId, i));\n\n                            if (fromWal != null) {\n                                int stateId = fromWal.get1();\n\n                                io.setPartitionState(pageAddr, (byte)stateId);\n\n                                changed = updateState(part, stateId);\n\n                                if (stateId == GridDhtPartitionState.OWNING.ordinal()) {\n                                    grp.offheap().onPartitionInitialCounterUpdated(i, fromWal.get2());\n\n                                    if (part.initialUpdateCounter() < fromWal.get2()) {\n                                        part.initialUpdateCounter(fromWal.get2());\n\n                                        changed = true;\n                                    }\n                                }\n                            }\n                            else\n                                changed = updateState(part, (int)io.getPartitionState(pageAddr));\n                        }\n                        finally {\n                            pageMem.writeUnlock(grpId, partMetaId, partMetaPage, null, changed);\n                        }\n                    }\n                    finally {\n                        pageMem.releasePage(grpId, partMetaId, partMetaPage);\n                    }\n                }\n            }\n        }\n    }"
        ],
        [
            "GridDhtPartitionTopologyImpl::localPartition0(int,AffinityTopologyVersion,boolean,boolean,boolean)",
            " 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786  \n 787  \n 788  ",
            "    /**\n     * @param p Partition number.\n     * @param topVer Topology version.\n     * @param create Create flag.\n     * @param updateSeq Update sequence.\n     * @return Local partition.\n     */\n    @SuppressWarnings(\"TooBroadScope\")\n    private GridDhtLocalPartition localPartition0(int p,\n        AffinityTopologyVersion topVer,\n        boolean create,\n        boolean showRenting,\n        boolean updateSeq) {\n        GridDhtLocalPartition loc;\n\n        loc = locParts.get(p);\n\n        GridDhtPartitionState state = loc != null ? loc.state() : null;\n\n        if (loc != null && state != EVICTED && (state != RENTING || showRenting))\n            return loc;\n\n        if (!create)\n            return null;\n\n        boolean created = false;\n\n        lock.writeLock().lock();\n\n        try {\n            loc = locParts.get(p);\n\n            state = loc != null ? loc.state() : null;\n\n            boolean belongs = partitionLocalNode(p, topVer);\n\n            if (loc != null && state == EVICTED) {\n                locParts.set(p, loc = null);\n\n                if (!belongs)\n                    throw new GridDhtInvalidPartitionException(p, \"Adding entry to evicted partition \" +\n                        \"(often may be caused by inconsistent 'key.hashCode()' implementation) \" +\n                        \"[part=\" + p + \", topVer=\" + topVer + \", this.topVer=\" + this.topVer + ']');\n            }\n            else if (loc != null && state == RENTING && !showRenting)\n                throw new GridDhtInvalidPartitionException(p, \"Adding entry to partition that is concurrently \" +\n                    \"evicted [part=\" + p + \", shouldBeMoving=\" + loc.reload() + \", belongs=\" + belongs +\n                    \", topVer=\" + topVer + \", curTopVer=\" + this.topVer + \"]\");\n\n            if (loc == null) {\n                if (!belongs)\n                    throw new GridDhtInvalidPartitionException(p, \"Creating partition which does not belong to \" +\n                        \"local node (often may be caused by inconsistent 'key.hashCode()' implementation) \" +\n                        \"[part=\" + p + \", topVer=\" + topVer + \", this.topVer=\" + this.topVer + ']');\n\n                locParts.set(p, loc = new GridDhtLocalPartition(ctx, grp, p));\n\n                if (updateSeq)\n                    this.updateSeq.incrementAndGet();\n\n                created = true;\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Created local partition: \" + loc);\n            }\n        }\n        finally {\n            lock.writeLock().unlock();\n        }\n\n        if (created && ctx.pageStore() != null) {\n            try {\n                ctx.pageStore().onPartitionCreated(grp.groupId(), p);\n            }\n            catch (IgniteCheckedException e) {\n                // TODO ignite-db\n                throw new IgniteException(e);\n            }\n        }\n\n        return loc;\n    }",
            " 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753 +\n 754 +\n 755 +\n 756 +\n 757 +\n 758 +\n 759 +\n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786  \n 787  \n 788  \n 789  \n 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  ",
            "    /**\n     * @param p Partition number.\n     * @param topVer Topology version.\n     * @param create Create flag.\n     * @param updateSeq Update sequence.\n     * @return Local partition.\n     */\n    @SuppressWarnings(\"TooBroadScope\")\n    private GridDhtLocalPartition localPartition0(int p,\n        AffinityTopologyVersion topVer,\n        boolean create,\n        boolean showRenting,\n        boolean updateSeq) {\n        GridDhtLocalPartition loc;\n\n        loc = locParts.get(p);\n\n        GridDhtPartitionState state = loc != null ? loc.state() : null;\n\n        if (loc != null && state != EVICTED && (state != RENTING || showRenting))\n            return loc;\n\n        if (!create)\n            return null;\n\n        boolean created = false;\n\n        lock.writeLock().lock();\n\n        try {\n            loc = locParts.get(p);\n\n            state = loc != null ? loc.state() : null;\n\n            boolean belongs = partitionLocalNode(p, topVer);\n\n            if (loc != null && state == EVICTED) {\n                try {\n                    loc.rent(false).get();\n                }\n                catch (IgniteCheckedException ex) {\n                    throw new IgniteException(ex);\n                }\n\n                locParts.set(p, loc = null);\n\n                if (!belongs)\n                    throw new GridDhtInvalidPartitionException(p, \"Adding entry to evicted partition \" +\n                        \"(often may be caused by inconsistent 'key.hashCode()' implementation) \" +\n                        \"[part=\" + p + \", topVer=\" + topVer + \", this.topVer=\" + this.topVer + ']');\n            }\n            else if (loc != null && state == RENTING && !showRenting)\n                throw new GridDhtInvalidPartitionException(p, \"Adding entry to partition that is concurrently \" +\n                    \"evicted [part=\" + p + \", shouldBeMoving=\" + loc.reload() + \", belongs=\" + belongs +\n                    \", topVer=\" + topVer + \", curTopVer=\" + this.topVer + \"]\");\n\n            if (loc == null) {\n                if (!belongs)\n                    throw new GridDhtInvalidPartitionException(p, \"Creating partition which does not belong to \" +\n                        \"local node (often may be caused by inconsistent 'key.hashCode()' implementation) \" +\n                        \"[part=\" + p + \", topVer=\" + topVer + \", this.topVer=\" + this.topVer + ']');\n\n                locParts.set(p, loc = new GridDhtLocalPartition(ctx, grp, p));\n\n                if (updateSeq)\n                    this.updateSeq.incrementAndGet();\n\n                created = true;\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Created local partition: \" + loc);\n            }\n        }\n        finally {\n            lock.writeLock().unlock();\n        }\n\n        if (created && ctx.pageStore() != null) {\n            try {\n                ctx.pageStore().onPartitionCreated(grp.groupId(), p);\n            }\n            catch (IgniteCheckedException e) {\n                // TODO ignite-db\n                throw new IgniteException(e);\n            }\n        }\n\n        return loc;\n    }"
        ],
        [
            "GridDhtPartitionTopologyImpl::createPartition(int)",
            " 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  ",
            "    /**\n     * @param p Partition number.\n     * @return Partition.\n     */\n    private GridDhtLocalPartition createPartition(int p) {\n        assert lock.isWriteLockedByCurrentThread();\n\n        GridDhtLocalPartition loc = locParts.get(p);\n\n        if (loc == null || loc.state() == EVICTED) {\n            locParts.set(p, loc = new GridDhtLocalPartition(ctx, grp, p));\n\n            T2<Long, Long> cntr = cntrMap.get(p);\n\n            if (cntr != null)\n                loc.updateCounter(cntr.get2());\n\n            if (ctx.pageStore() != null) {\n                try {\n                    ctx.pageStore().onPartitionCreated(grp.groupId(), p);\n                }\n                catch (IgniteCheckedException e) {\n                    // TODO ignite-db\n                    throw new IgniteException(e);\n                }\n            }\n        }\n\n        return loc;\n    }",
            " 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661  \n 662  \n 663 +\n 664 +\n 665 +\n 666 +\n 667 +\n 668 +\n 669 +\n 670 +\n 671 +\n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  ",
            "    /**\n     * @param p Partition number.\n     * @return Partition.\n     */\n    private GridDhtLocalPartition createPartition(int p) {\n        assert lock.isWriteLockedByCurrentThread();\n\n        GridDhtLocalPartition loc = locParts.get(p);\n\n        if (loc == null || loc.state() == EVICTED) {\n            if (loc != null) {\n                try {\n                    loc.rent(false).get();\n                }\n                catch (IgniteCheckedException e) {\n                    throw new IgniteException(e);\n                }\n            }\n\n            locParts.set(p, loc = new GridDhtLocalPartition(ctx, grp, p));\n\n            T2<Long, Long> cntr = cntrMap.get(p);\n\n            if (cntr != null)\n                loc.updateCounter(cntr.get2());\n\n            if (ctx.pageStore() != null) {\n                try {\n                    ctx.pageStore().onPartitionCreated(grp.groupId(), p);\n                }\n                catch (IgniteCheckedException e) {\n                    // TODO ignite-db\n                    throw new IgniteException(e);\n                }\n            }\n        }\n\n        return loc;\n    }"
        ]
    ],
    "f3a61e4a4753b31ecdcef0864e8c095214b6a4ae": [
        [
            "FileWriteAheadLogManager::FileDecompressor::run()",
            "2066  \n2067  \n2068 -\n2069 -\n2070  \n2071  \n2072 -\n2073  \n2074  \n2075  \n2076  \n2077  \n2078  \n2079  \n2080  \n2081  \n2082  \n2083  \n2084  \n2085  \n2086  \n2087  \n2088  \n2089  \n2090 -\n2091  \n2092  \n2093  \n2094  \n2095  \n2096  \n2097  \n2098  \n2099  \n2100 -\n2101 -\n2102 -\n2103 -\n2104 -\n2105  \n2106 -\n2107 -\n2108 -\n2109 -\n2110  \n2111  \n2112  ",
            "        /** {@inheritDoc} */\n        @Override public void run() {\n            Throwable err = null;\n\n            while (!Thread.currentThread().isInterrupted() && !stopped) {\n                try {\n                    long segmentToDecompress = segmentsQueue.take();\n\n                    if (stopped)\n                        break;\n\n                    File zip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".zip\");\n                    File unzipTmp = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".tmp\");\n                    File unzip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress));\n\n                    try (ZipInputStream zis = new ZipInputStream(new BufferedInputStream(new FileInputStream(zip)));\n                        FileIO io = ioFactory.create(unzipTmp)) {\n                        zis.getNextEntry();\n\n                        int bytesRead;\n                        while ((bytesRead = zis.read(arr)) > 0)\n                            io.write(arr, 0, bytesRead);\n                    }\n\n                    Files.move(unzipTmp.toPath(), unzip.toPath());\n\n                    synchronized (this) {\n                        decompressionFutures.remove(segmentToDecompress).onDone();\n                    }\n                }\n                catch (InterruptedException ignore) {\n                    Thread.currentThread().interrupt();\n                }\n                catch (Throwable t) {\n                    err = t;\n                }\n                finally {\n                    if (err == null && !stopped)\n                        err = new IllegalStateException(\"Thread \" + getName() + \" is terminated unexpectedly\");\n\n                    if (err instanceof OutOfMemoryError)\n                        cctx.kernalContext().failure().process(new FailureContext(CRITICAL_ERROR, err));\n                    else if (err != null)\n                        cctx.kernalContext().failure().process(new FailureContext(SYSTEM_WORKER_TERMINATION, err));\n                }\n            }\n        }",
            "2067  \n2068  \n2069  \n2070 +\n2071 +\n2072  \n2073 +\n2074  \n2075  \n2076  \n2077  \n2078  \n2079  \n2080  \n2081  \n2082  \n2083  \n2084  \n2085  \n2086  \n2087  \n2088  \n2089  \n2090  \n2091 +\n2092 +\n2093 +\n2094 +\n2095 +\n2096 +\n2097 +\n2098 +\n2099 +\n2100 +\n2101  \n2102  \n2103  \n2104  \n2105  \n2106  \n2107  \n2108  \n2109  \n2110 +\n2111 +\n2112 +\n2113  \n2114 +\n2115 +\n2116  \n2117  \n2118  ",
            "        /** {@inheritDoc} */\n        @Override public void run() {\n            while (!Thread.currentThread().isInterrupted() && !stopped) {\n                long segmentToDecompress = -1L;\n\n                try {\n                    segmentToDecompress = segmentsQueue.take();\n\n                    if (stopped)\n                        break;\n\n                    File zip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".zip\");\n                    File unzipTmp = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".tmp\");\n                    File unzip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress));\n\n                    try (ZipInputStream zis = new ZipInputStream(new BufferedInputStream(new FileInputStream(zip)));\n                        FileIO io = ioFactory.create(unzipTmp)) {\n                        zis.getNextEntry();\n\n                        int bytesRead;\n                        while ((bytesRead = zis.read(arr)) > 0)\n                            io.write(arr, 0, bytesRead);\n                    }\n\n                    try {\n                        Files.move(unzipTmp.toPath(), unzip.toPath());\n                    }\n                    catch (FileAlreadyExistsException e) {\n                        U.error(log, \"Can't rename temporary unzipped segment: raw segment is already present \" +\n                            \"[tmp=\" + unzipTmp + \", raw=\" + unzip + \"]\", e);\n\n                        if (!unzipTmp.delete())\n                            U.error(log, \"Can't delete temporary unzipped segment [tmp=\" + unzipTmp + \"]\");\n                    }\n\n                    synchronized (this) {\n                        decompressionFutures.remove(segmentToDecompress).onDone();\n                    }\n                }\n                catch (InterruptedException ignore) {\n                    Thread.currentThread().interrupt();\n                }\n                catch (Throwable t) {\n                    if (!stopped && segmentToDecompress != -1L) {\n                        IgniteCheckedException e = new IgniteCheckedException(\"Error during WAL segment \" +\n                            \"decompression [segmentIdx=\" + segmentToDecompress + \"]\", t);\n\n                        decompressionFutures.remove(segmentToDecompress).onDone(e);\n                    }\n                }\n            }\n        }"
        ],
        [
            "FsyncModeFileWriteAheadLogManager::FileDecompressor::run()",
            "1874  \n1875  \n1876 -\n1877 -\n1878  \n1879  \n1880 -\n1881  \n1882  \n1883  \n1884  \n1885  \n1886  \n1887  \n1888  \n1889  \n1890  \n1891  \n1892  \n1893  \n1894  \n1895  \n1896  \n1897  \n1898 -\n1899  \n1900  \n1901  \n1902  \n1903  \n1904  \n1905  \n1906  \n1907  \n1908 -\n1909 -\n1910 -\n1911 -\n1912 -\n1913  \n1914 -\n1915 -\n1916 -\n1917 -\n1918  \n1919  \n1920  ",
            "        /** {@inheritDoc} */\n        @Override public void run() {\n            Throwable err = null;\n\n            while (!Thread.currentThread().isInterrupted() && !stopped) {\n                try {\n                    long segmentToDecompress = segmentsQueue.take();\n\n                    if (stopped)\n                        break;\n\n                    File zip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".zip\");\n                    File unzipTmp = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".tmp\");\n                    File unzip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress));\n\n                    try (ZipInputStream zis = new ZipInputStream(new BufferedInputStream(new FileInputStream(zip)));\n                        FileIO io = ioFactory.create(unzipTmp)) {\n                        zis.getNextEntry();\n\n                        int bytesRead;\n                        while ((bytesRead = zis.read(arr)) > 0)\n                            io.write(arr, 0, bytesRead);\n                    }\n\n                    Files.move(unzipTmp.toPath(), unzip.toPath());\n\n                    synchronized (this) {\n                        decompressionFutures.remove(segmentToDecompress).onDone();\n                    }\n                }\n                catch (InterruptedException ignore) {\n                    Thread.currentThread().interrupt();\n                }\n                catch (Throwable t) {\n                    err = t;\n                }\n                finally {\n                    if (err == null && !stopped)\n                        err = new IllegalStateException(\"Thread \" + getName() + \" is terminated unexpectedly\");\n\n                    if (err instanceof OutOfMemoryError)\n                        cctx.kernalContext().failure().process(new FailureContext(CRITICAL_ERROR, err));\n                    else if (err != null)\n                        cctx.kernalContext().failure().process(new FailureContext(SYSTEM_WORKER_TERMINATION, err));\n                }\n            }\n        }",
            "1875  \n1876  \n1877  \n1878 +\n1879 +\n1880  \n1881 +\n1882  \n1883  \n1884  \n1885  \n1886  \n1887  \n1888  \n1889  \n1890  \n1891  \n1892  \n1893  \n1894  \n1895  \n1896  \n1897  \n1898  \n1899 +\n1900 +\n1901 +\n1902 +\n1903 +\n1904 +\n1905 +\n1906 +\n1907 +\n1908 +\n1909  \n1910  \n1911  \n1912  \n1913  \n1914  \n1915  \n1916  \n1917  \n1918 +\n1919 +\n1920 +\n1921  \n1922 +\n1923 +\n1924  \n1925  \n1926  ",
            "        /** {@inheritDoc} */\n        @Override public void run() {\n            while (!Thread.currentThread().isInterrupted() && !stopped) {\n                long segmentToDecompress = -1L;\n\n                try {\n                    segmentToDecompress = segmentsQueue.take();\n\n                    if (stopped)\n                        break;\n\n                    File zip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".zip\");\n                    File unzipTmp = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress) + \".tmp\");\n                    File unzip = new File(walArchiveDir, FileDescriptor.fileName(segmentToDecompress));\n\n                    try (ZipInputStream zis = new ZipInputStream(new BufferedInputStream(new FileInputStream(zip)));\n                        FileIO io = ioFactory.create(unzipTmp)) {\n                        zis.getNextEntry();\n\n                        int bytesRead;\n                        while ((bytesRead = zis.read(arr)) > 0)\n                            io.write(arr, 0, bytesRead);\n                    }\n\n                    try {\n                        Files.move(unzipTmp.toPath(), unzip.toPath());\n                    }\n                    catch (FileAlreadyExistsException e) {\n                        U.error(log, \"Can't rename temporary unzipped segment: raw segment is already present \" +\n                            \"[tmp=\" + unzipTmp + \", raw=\" + unzip + ']', e);\n\n                        if (!unzipTmp.delete())\n                            U.error(log, \"Can't delete temporary unzipped segment [tmp=\" + unzipTmp + ']');\n                    }\n\n                    synchronized (this) {\n                        decompressionFutures.remove(segmentToDecompress).onDone();\n                    }\n                }\n                catch (InterruptedException ignore) {\n                    Thread.currentThread().interrupt();\n                }\n                catch (Throwable t) {\n                    if (!stopped && segmentToDecompress != -1L) {\n                        IgniteCheckedException e = new IgniteCheckedException(\"Error during WAL segment \" +\n                            \"decompression [segmentIdx=\" + segmentToDecompress + ']', t);\n\n                        decompressionFutures.remove(segmentToDecompress).onDone(e);\n                    }\n                }\n            }\n        }"
        ]
    ],
    "a45677cf0b6b6ffa524fc10932c002d3b879f943": [
        [
            "VisorQueryTask::VisorQueryJob::run(VisorQueryTaskArg)",
            "  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102 -\n 103 -\n 104 -\n 105 -\n 106 -\n 107 -\n 108 -\n 109 -\n 110 -\n 111 -\n 112 -\n 113 -\n 114 -\n 115 -\n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  ",
            "        /** {@inheritDoc} */\n        @Override protected VisorEither<VisorQueryResult> run(final VisorQueryTaskArg arg) {\n            try {\n                UUID nid = ignite.localNode().id();\n\n                SqlFieldsQuery qry = new SqlFieldsQuery(arg.getQueryText());\n                qry.setPageSize(arg.getPageSize());\n                qry.setLocal(arg.isLocal());\n                qry.setDistributedJoins(arg.isDistributedJoins());\n                qry.setEnforceJoinOrder(arg.isEnforceJoinOrder());\n                qry.setReplicatedOnly(arg.isReplicatedOnly());\n                qry.setLazy(arg.getLazy());\n\n                long start = U.currentTimeMillis();\n\n                FieldsQueryCursor<List<?>> qryCursor;\n\n                String cacheName = arg.getCacheName();\n\n                if (F.isEmpty(cacheName))\n                    qryCursor = ignite.context().query().querySqlFieldsNoCache(qry, true);\n                else {\n                    IgniteCache<Object, Object> c = ignite.cache(cacheName);\n\n                    if (c == null)\n                        throw new SQLException(\"Fail to execute query. Cache not found: \" + cacheName);\n\n                    try {\n                        qryCursor = c.withKeepBinary().query(qry);\n                    }\n                    catch (CacheException e) {\n                        // Work around for DDL without explicit schema name.\n                        if (X.hasCause(e, IgniteSQLException.class)\n                            && e.getMessage().contains(\"can only be executed on PUBLIC schema\")) {\n                            qry.setSchema(\"PUBLIC\");\n\n                            qryCursor = c.withKeepBinary().query(qry);\n                        }\n                        else\n                            throw e;\n                    }\n                }\n\n                VisorQueryCursor<List<?>> cur = new VisorQueryCursor<>(qryCursor);\n\n                Collection<GridQueryFieldMetadata> meta = cur.fieldsMeta();\n\n                if (meta == null)\n                    return new VisorEither<>(\n                        new VisorExceptionWrapper(new SQLException(\"Fail to execute query. No metadata available.\")));\n                else {\n                    List<VisorQueryField> names = new ArrayList<>(meta.size());\n\n                    for (GridQueryFieldMetadata col : meta)\n                        names.add(new VisorQueryField(col.schemaName(), col.typeName(),\n                            col.fieldName(), col.fieldTypeName()));\n\n                    List<Object[]> rows = fetchSqlQueryRows(cur, arg.getPageSize());\n\n                    // Query duration + fetch duration.\n                    long duration = U.currentTimeMillis() - start;\n\n                    boolean hasNext = cur.hasNext();\n\n                    // Generate query ID to store query cursor in node local storage.\n                    String qryId = SQL_QRY_NAME + \"-\" + UUID.randomUUID();\n\n                    if (hasNext) {\n                        ignite.cluster().<String, VisorQueryCursor<List<?>>>nodeLocalMap().put(qryId, cur);\n\n                        scheduleResultSetHolderRemoval(qryId, ignite);\n                    }\n                    else\n                        cur.close();\n\n                    return new VisorEither<>(new VisorQueryResult(nid, qryId, names, rows, hasNext, duration));\n                }\n            }\n            catch (Throwable e) {\n                return new VisorEither<>(new VisorExceptionWrapper(e));\n            }\n        }",
            "  75  \n  76  \n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102 +\n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  ",
            "        /** {@inheritDoc} */\n        @Override protected VisorEither<VisorQueryResult> run(final VisorQueryTaskArg arg) {\n            try {\n                UUID nid = ignite.localNode().id();\n\n                SqlFieldsQuery qry = new SqlFieldsQuery(arg.getQueryText());\n                qry.setPageSize(arg.getPageSize());\n                qry.setLocal(arg.isLocal());\n                qry.setDistributedJoins(arg.isDistributedJoins());\n                qry.setEnforceJoinOrder(arg.isEnforceJoinOrder());\n                qry.setReplicatedOnly(arg.isReplicatedOnly());\n                qry.setLazy(arg.getLazy());\n\n                long start = U.currentTimeMillis();\n\n                FieldsQueryCursor<List<?>> qryCursor;\n\n                String cacheName = arg.getCacheName();\n\n                if (F.isEmpty(cacheName))\n                    qryCursor = ignite.context().query().querySqlFieldsNoCache(qry, true);\n                else {\n                    IgniteCache<Object, Object> c = ignite.cache(cacheName);\n\n                    if (c == null)\n                        throw new SQLException(\"Fail to execute query. Cache not found: \" + cacheName);\n\n                    qryCursor = c.withKeepBinary().query(qry);\n                }\n\n                VisorQueryCursor<List<?>> cur = new VisorQueryCursor<>(qryCursor);\n\n                Collection<GridQueryFieldMetadata> meta = cur.fieldsMeta();\n\n                if (meta == null)\n                    return new VisorEither<>(\n                        new VisorExceptionWrapper(new SQLException(\"Fail to execute query. No metadata available.\")));\n                else {\n                    List<VisorQueryField> names = new ArrayList<>(meta.size());\n\n                    for (GridQueryFieldMetadata col : meta)\n                        names.add(new VisorQueryField(col.schemaName(), col.typeName(),\n                            col.fieldName(), col.fieldTypeName()));\n\n                    List<Object[]> rows = fetchSqlQueryRows(cur, arg.getPageSize());\n\n                    // Query duration + fetch duration.\n                    long duration = U.currentTimeMillis() - start;\n\n                    boolean hasNext = cur.hasNext();\n\n                    // Generate query ID to store query cursor in node local storage.\n                    String qryId = SQL_QRY_NAME + \"-\" + UUID.randomUUID();\n\n                    if (hasNext) {\n                        ignite.cluster().<String, VisorQueryCursor<List<?>>>nodeLocalMap().put(qryId, cur);\n\n                        scheduleResultSetHolderRemoval(qryId, ignite);\n                    }\n                    else\n                        cur.close();\n\n                    return new VisorEither<>(new VisorQueryResult(nid, qryId, names, rows, hasNext, duration));\n                }\n            }\n            catch (Throwable e) {\n                return new VisorEither<>(new VisorExceptionWrapper(e));\n            }\n        }"
        ]
    ],
    "bb56dc6d4843c426b0d5f0015abe8dc3af794276": [
        [
            "IgniteCompatibilityAbstractTest::startGrid(String,String,IgniteInClosure,IgniteInClosure)",
            " 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156 -\n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  ",
            "    /**\n     * Starts new Ignite instance of given version and name <b>in separate JVM</b>.\n     *\n     * Uses an ignite-core artifact in the Maven local repository, if it isn't exists there, it will be downloaded and\n     * stored via Maven.\n     *\n     * @param igniteInstanceName Instance name.\n     * @param ver Ignite version. Dots separated, 3-digit version.\n     * @param cfgClo IgniteInClosure for post-configuration.\n     * @param clo IgniteInClosure for actions on started Ignite.\n     * @return Started grid.\n     * @throws Exception In case of an error.\n     */\n    protected IgniteEx startGrid(final String igniteInstanceName, final String ver,\n        IgniteInClosure<IgniteConfiguration> cfgClo, IgniteInClosure<Ignite> clo) throws Exception {\n        assert isMultiJvm() : \"MultiJvm mode must be switched on for the node stop properly.\";\n\n        assert !igniteInstanceName.equals(getTestIgniteInstanceName(0)) : \"Use default instance name for local nodes only.\";\n\n        final String cfgCloPath = IgniteCompatibilityNodeRunner.storeToFile(cfgClo);\n        final String cloPath = IgniteCompatibilityNodeRunner.storeToFile(clo);\n\n        final IgniteConfiguration cfg = getConfiguration(igniteInstanceName); // stub - won't be used at node startup\n\n        IgniteProcessProxy ignite = new IgniteProcessProxy(cfg, log, locJvmInstance, true) {\n            @Override protected IgniteLogger logger(IgniteLogger log, Object ctgr) {\n                return ListenedGridTestLog4jLogger.createLogger(ctgr + \"#\" + ver.replaceAll(\"\\\\.\", \"_\"));\n            }\n\n            @Override protected String igniteNodeRunnerClassName() throws Exception {\n                return IgniteCompatibilityNodeRunner.class.getCanonicalName();\n            }\n\n            @Override protected String params(IgniteConfiguration cfg, boolean resetDiscovery) throws Exception {\n                return cfgCloPath + \" \" + igniteInstanceName + \" \"\n                    + getId() + \" \"\n                    + (rmJvmInstance == null ? getId() : ((IgniteProcessProxy)rmJvmInstance).getId())\n                    + (cloPath == null ? \"\" : \" \" + cloPath);\n            }\n\n            @Override protected Collection<String> filteredJvmArgs() throws Exception {\n                Collection<String> filteredJvmArgs = new ArrayList<>();\n\n                filteredJvmArgs.add(\"-ea\");\n\n                for (String arg : U.jvmArgs()) {\n                    if (arg.startsWith(\"-Xmx\") || arg.startsWith(\"-Xms\"))\n                        filteredJvmArgs.add(arg);\n                }\n\n                final Collection<Dependency> dependencies = getDependencies(ver);\n\n                Set<String> excluded = getExcluded(ver, dependencies);\n\n                StringBuilder pathBuilder = new StringBuilder();\n\n                for (URL url : CompatibilityTestsUtils.classLoaderUrls(CLASS_LOADER)) {\n                    String path = url.getPath();\n\n                    if (excluded.stream().noneMatch(path::contains))\n                        pathBuilder.append(path).append(File.pathSeparator);\n                }\n\n                for (Dependency dependency : dependencies) {\n                    final String artifactVer = Optional.ofNullable(dependency.version()).orElse(ver);\n\n                    String pathToArtifact = MavenUtils.getPathToIgniteArtifact(dependency.groupId(),\n                        dependency.artifactId(), artifactVer, dependency.classifier());\n\n                    pathBuilder.append(pathToArtifact).append(File.pathSeparator);\n                }\n\n                filteredJvmArgs.add(\"-cp\");\n                filteredJvmArgs.add(pathBuilder.toString());\n\n                final Collection<String> jvmParms = getJvmParams();\n\n                if (jvmParms != null)\n                    filteredJvmArgs.addAll(jvmParms);\n\n                return filteredJvmArgs;\n            }\n        };\n\n        if (locJvmInstance == null) {\n            CountDownLatch nodeJoinedLatch = new CountDownLatch(1);\n\n            UUID nodeId = ignite.getId();\n\n            ListenedGridTestLog4jLogger log = (ListenedGridTestLog4jLogger)ignite.log();\n\n            log.addListener(nodeId, new LoggedJoinNodeClosure(nodeJoinedLatch, nodeId));\n\n            final long nodeJoinTimeout = getNodeJoinTimeout();\n            final boolean joined = nodeJoinedLatch.await(nodeJoinTimeout, TimeUnit.MILLISECONDS);\n\n            assertTrue(\"Node has not joined [id=\" + nodeId + \"]/\" +\n                \"or does not completed its startup during timeout: \" + nodeJoinTimeout + \" ms.\", joined);\n\n            log.removeListener(nodeId);\n        }\n\n        if (rmJvmInstance == null)\n            rmJvmInstance = ignite;\n\n        return ignite;\n    }",
            " 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156 +\n 157 +\n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  ",
            "    /**\n     * Starts new Ignite instance of given version and name <b>in separate JVM</b>.\n     *\n     * Uses an ignite-core artifact in the Maven local repository, if it isn't exists there, it will be downloaded and\n     * stored via Maven.\n     *\n     * @param igniteInstanceName Instance name.\n     * @param ver Ignite version. Dots separated, 3-digit version.\n     * @param cfgClo IgniteInClosure for post-configuration.\n     * @param clo IgniteInClosure for actions on started Ignite.\n     * @return Started grid.\n     * @throws Exception In case of an error.\n     */\n    protected IgniteEx startGrid(final String igniteInstanceName, final String ver,\n        IgniteInClosure<IgniteConfiguration> cfgClo, IgniteInClosure<Ignite> clo) throws Exception {\n        assert isMultiJvm() : \"MultiJvm mode must be switched on for the node stop properly.\";\n\n        assert !igniteInstanceName.equals(getTestIgniteInstanceName(0)) : \"Use default instance name for local nodes only.\";\n\n        final String cfgCloPath = IgniteCompatibilityNodeRunner.storeToFile(cfgClo);\n        final String cloPath = IgniteCompatibilityNodeRunner.storeToFile(clo);\n\n        final IgniteConfiguration cfg = getConfiguration(igniteInstanceName); // stub - won't be used at node startup\n\n        IgniteProcessProxy ignite = new IgniteProcessProxy(cfg, log, locJvmInstance, true) {\n            @Override protected IgniteLogger logger(IgniteLogger log, Object ctgr) {\n                return ListenedGridTestLog4jLogger.createLogger(ctgr + \"#\" + ver.replaceAll(\"\\\\.\", \"_\"));\n            }\n\n            @Override protected String igniteNodeRunnerClassName() throws Exception {\n                return IgniteCompatibilityNodeRunner.class.getCanonicalName();\n            }\n\n            @Override protected String params(IgniteConfiguration cfg, boolean resetDiscovery) throws Exception {\n                return cfgCloPath + \" \" + igniteInstanceName + \" \"\n                    + getId() + \" \"\n                    + (rmJvmInstance == null ? getId() : ((IgniteProcessProxy)rmJvmInstance).getId()) + \" \"\n                    + ver\n                    + (cloPath == null ? \"\" : \" \" + cloPath);\n            }\n\n            @Override protected Collection<String> filteredJvmArgs() throws Exception {\n                Collection<String> filteredJvmArgs = new ArrayList<>();\n\n                filteredJvmArgs.add(\"-ea\");\n\n                for (String arg : U.jvmArgs()) {\n                    if (arg.startsWith(\"-Xmx\") || arg.startsWith(\"-Xms\"))\n                        filteredJvmArgs.add(arg);\n                }\n\n                final Collection<Dependency> dependencies = getDependencies(ver);\n\n                Set<String> excluded = getExcluded(ver, dependencies);\n\n                StringBuilder pathBuilder = new StringBuilder();\n\n                for (URL url : CompatibilityTestsUtils.classLoaderUrls(CLASS_LOADER)) {\n                    String path = url.getPath();\n\n                    if (excluded.stream().noneMatch(path::contains))\n                        pathBuilder.append(path).append(File.pathSeparator);\n                }\n\n                for (Dependency dependency : dependencies) {\n                    final String artifactVer = Optional.ofNullable(dependency.version()).orElse(ver);\n\n                    String pathToArtifact = MavenUtils.getPathToIgniteArtifact(dependency.groupId(),\n                        dependency.artifactId(), artifactVer, dependency.classifier());\n\n                    pathBuilder.append(pathToArtifact).append(File.pathSeparator);\n                }\n\n                filteredJvmArgs.add(\"-cp\");\n                filteredJvmArgs.add(pathBuilder.toString());\n\n                final Collection<String> jvmParms = getJvmParams();\n\n                if (jvmParms != null)\n                    filteredJvmArgs.addAll(jvmParms);\n\n                return filteredJvmArgs;\n            }\n        };\n\n        if (locJvmInstance == null) {\n            CountDownLatch nodeJoinedLatch = new CountDownLatch(1);\n\n            UUID nodeId = ignite.getId();\n\n            ListenedGridTestLog4jLogger log = (ListenedGridTestLog4jLogger)ignite.log();\n\n            log.addListener(nodeId, new LoggedJoinNodeClosure(nodeJoinedLatch, nodeId));\n\n            final long nodeJoinTimeout = getNodeJoinTimeout();\n            final boolean joined = nodeJoinedLatch.await(nodeJoinTimeout, TimeUnit.MILLISECONDS);\n\n            assertTrue(\"Node has not joined [id=\" + nodeId + \"]/\" +\n                \"or does not completed its startup during timeout: \" + nodeJoinTimeout + \" ms.\", joined);\n\n            log.removeListener(nodeId);\n        }\n\n        if (rmJvmInstance == null)\n            rmJvmInstance = ignite;\n\n        return ignite;\n    }"
        ],
        [
            "IgniteCompatibilityNodeRunner::main(String)",
            "  52  \n  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76 -\n  77  \n  78  \n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102 -\n 103 -\n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  ",
            "    /**\n     * Starts {@link Ignite} with test's default configuration.\n     *\n     * Command-line arguments specification:\n     * <pre>\n     * args[0] - required - path to closure for tuning IgniteConfiguration before node startup;\n     * args[1] - required - name of the starting node;\n     * args[2] - required - id of the starting node;\n     * args[3] - required - sync-id of a node for synchronization of startup. Must be equals\n     * to arg[2] in case of starting the first node in the Ignite cluster;\n     * args[4] - optional - path to closure for actions after node startup.\n     * </pre>\n     *\n     * @param args Command-line arguments.\n     * @throws Exception In case of an error.\n     */\n    public static void main(String[] args) throws Exception {\n        try {\n            X.println(GridJavaProcess.PID_MSG_PREFIX + U.jvmPid());\n\n            X.println(\"Starting Ignite Node... Args=\" + Arrays.toString(args));\n\n            if (args.length < 3) {\n                throw new IllegalArgumentException(\"At least four arguments expected:\" +\n                    \" [path/to/closure/file] [ignite-instance-name] [node-id] [sync-node-id] [optional/path/to/closure/file]\");\n            }\n\n            final Thread watchdog = delayedDumpClasspath();\n\n            IgniteConfiguration cfg = CompatibilityTestsFacade.getConfiguration();\n\n            IgniteInClosure<IgniteConfiguration> cfgClo = readClosureFromFileAndDelete(args[0]);\n\n            cfgClo.apply(cfg);\n\n            final UUID nodeId = UUID.fromString(args[2]);\n            final UUID syncNodeId = UUID.fromString(args[3]);\n\n            // Ignite instance name and id must be set according to arguments\n            // it's used for nodes managing: start, stop etc.\n            cfg.setIgniteInstanceName(args[1]);\n            cfg.setNodeId(nodeId);\n\n            final Ignite ignite = Ignition.start(cfg);\n\n            assert ignite.cluster().node(syncNodeId) != null : \"Node has not joined [id=\" + nodeId + \"]\";\n\n            // It needs to set private static field 'ignite' of the IgniteNodeRunner class via reflection\n            GridTestUtils.setFieldValue(new IgniteNodeRunner(), \"ignite\", ignite);\n\n            if (args.length == 5) {\n                IgniteInClosure<Ignite> clo = readClosureFromFileAndDelete(args[4]);\n\n                clo.apply(ignite);\n            }\n\n            X.println(IgniteCompatibilityAbstractTest.SYNCHRONIZATION_LOG_MESSAGE + nodeId);\n\n            watchdog.interrupt();\n        }\n        catch (Throwable e) {\n            e.printStackTrace();\n\n            X.println(\"Dumping classpath, error occurred: \" + e);\n\n            dumpClasspath();\n\n            throw e;\n        }\n    }",
            "  53  \n  54  \n  55  \n  56  \n  57  \n  58  \n  59  \n  60  \n  61  \n  62  \n  63  \n  64  \n  65  \n  66  \n  67  \n  68  \n  69  \n  70  \n  71  \n  72  \n  73  \n  74  \n  75  \n  76  \n  77  \n  78 +\n  79  \n  80  \n  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88  \n  89  \n  90  \n  91 +\n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102 +\n 103 +\n 104 +\n 105  \n 106  \n 107  \n 108 +\n 109 +\n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  ",
            "    /**\n     * Starts {@link Ignite} with test's default configuration.\n     *\n     * Command-line arguments specification:\n     * <pre>\n     * args[0] - required - path to closure for tuning IgniteConfiguration before node startup;\n     * args[1] - required - name of the starting node;\n     * args[2] - required - id of the starting node;\n     * args[3] - required - sync-id of a node for synchronization of startup. Must be equals\n     * to arg[2] in case of starting the first node in the Ignite cluster;\n     * args[4] - required - expected Ignite's version to check at startup;\n     * args[5] - optional - path to closure for actions after node startup.\n     * </pre>\n     *\n     * @param args Command-line arguments.\n     * @throws Exception In case of an error.\n     */\n    public static void main(String[] args) throws Exception {\n        try {\n            X.println(GridJavaProcess.PID_MSG_PREFIX + U.jvmPid());\n\n            X.println(\"Starting Ignite Node... Args=\" + Arrays.toString(args));\n\n            if (args.length < 3) {\n                throw new IllegalArgumentException(\"At least four arguments expected:\" +\n                    \" [path/to/closure/file] [ignite-instance-name] [node-id] [sync-node-id] [node-ver] [optional/path/to/closure/file]\");\n            }\n\n            final Thread watchdog = delayedDumpClasspath();\n\n            IgniteConfiguration cfg = CompatibilityTestsFacade.getConfiguration();\n\n            IgniteInClosure<IgniteConfiguration> cfgClo = readClosureFromFileAndDelete(args[0]);\n\n            cfgClo.apply(cfg);\n\n            final UUID nodeId = UUID.fromString(args[2]);\n            final UUID syncNodeId = UUID.fromString(args[3]);\n            final IgniteProductVersion expNodeVer = IgniteProductVersion.fromString(args[4]);\n\n            // Ignite instance name and id must be set according to arguments\n            // it's used for nodes managing: start, stop etc.\n            cfg.setIgniteInstanceName(args[1]);\n            cfg.setNodeId(nodeId);\n\n            final Ignite ignite = Ignition.start(cfg);\n\n            assert ignite.cluster().node(syncNodeId) != null : \"Node has not joined [id=\" + nodeId + \"]\";\n\n            assert ignite.cluster().localNode().version().compareToIgnoreTimestamp(expNodeVer) == 0 : \"Node is of unexpected \" +\n                \"version: [act=\" + ignite.cluster().localNode().version() + \", exp=\" + expNodeVer + ']';\n\n            // It needs to set private static field 'ignite' of the IgniteNodeRunner class via reflection\n            GridTestUtils.setFieldValue(new IgniteNodeRunner(), \"ignite\", ignite);\n\n            if (args.length == 6) {\n                IgniteInClosure<Ignite> clo = readClosureFromFileAndDelete(args[5]);\n\n                clo.apply(ignite);\n            }\n\n            X.println(IgniteCompatibilityAbstractTest.SYNCHRONIZATION_LOG_MESSAGE + nodeId);\n\n            watchdog.interrupt();\n        }\n        catch (Throwable e) {\n            e.printStackTrace();\n\n            X.println(\"Dumping classpath, error occurred: \" + e);\n\n            dumpClasspath();\n\n            throw e;\n        }\n    }"
        ]
    ],
    "de3499fe773b493ca1f385473fdfad0897cb4002": [
        [
            "PageMemoryImpl::beforeReleaseWrite(FullPageId,long,boolean)",
            "1673  \n1674  \n1675  \n1676 -\n1677 -\n1678 -\n1679 -\n1680 -\n1681 -\n1682 -\n1683 -\n1684 -\n1685 -\n1686  ",
            "    /**\n     *\n     */\n    void beforeReleaseWrite(FullPageId pageId, long ptr, boolean pageWalRec) {\n        if (walMgr != null && (pageWalRec || walMgr.isAlwaysWriteFullPages()) && !walMgr.disabled(pageId.groupId())) {\n            try {\n                walMgr.log(new PageSnapshot(pageId, ptr, pageSize(), realPageSize(pageId.groupId())));\n            }\n            catch (IgniteCheckedException e) {\n                // TODO ignite-db.\n                throw new IgniteException(e);\n            }\n        }\n    }",
            "1681  \n1682  \n1683  \n1684 +\n1685 +\n1686 +\n1687 +\n1688 +\n1689 +\n1690  ",
            "    /**\n     *\n     */\n    void beforeReleaseWrite(FullPageId pageId, long ptr, boolean pageWalRec) throws IgniteCheckedException {\n        boolean walIsNotDisable = walMgr != null && !walMgr.disabled(pageId.groupId());\n        boolean pageRecOrAlwaysWriteFullPage = walMgr != null && (pageWalRec || walMgr.isAlwaysWriteFullPages());\n\n        if (pageRecOrAlwaysWriteFullPage && walIsNotDisable)\n            walMgr.log(new PageSnapshot(pageId, ptr, pageSize(), realPageSize(pageId.groupId())));\n    }"
        ],
        [
            "PageMemoryImpl::writeUnlockPage(long,FullPageId,Boolean,boolean,boolean)",
            "1518  \n1519  \n1520  \n1521  \n1522  \n1523  \n1524  \n1525  \n1526  \n1527  \n1528  \n1529  \n1530  \n1531  \n1532  \n1533  \n1534  \n1535 -\n1536 -\n1537 -\n1538 -\n1539 -\n1540  \n1541 -\n1542  \n1543 -\n1544 -\n1545  \n1546 -\n1547  \n1548 -\n1549  \n1550 -\n1551 -\n1552 -\n1553  \n1554 -\n1555 -\n1556  \n1557 -\n1558 -\n1559 -\n1560 -\n1561 -\n1562  \n1563 -\n1564  \n1565  ",
            "    /**\n     * @param page Page pointer.\n     * @param fullId full page ID.\n     * @param walPlc\n     * @param walPlc Full page WAL record policy.\n     * @param markDirty set dirty flag to page.\n     * @param restore\n     */\n    private void writeUnlockPage(\n        long page,\n        FullPageId fullId,\n        Boolean walPlc,\n        boolean markDirty,\n        boolean restore\n    ) {\n        boolean wasDirty = isDirty(page);\n\n        //if page is for restore, we shouldn't mark it as changed\n        if (!restore && markDirty && !wasDirty && changeTracker != null)\n            changeTracker.apply(page, fullId, this);\n\n        boolean pageWalRec = markDirty && walPlc != FALSE && (walPlc == TRUE || !wasDirty);\n\n        assert PageIO.getCrc(page + PAGE_OVERHEAD) == 0; //TODO GG-11480\n\n        if (markDirty)\n            setDirty(fullId, page, markDirty, false);\n\n        beforeReleaseWrite(fullId, page + PAGE_OVERHEAD, pageWalRec);\n\n        long pageId = PageIO.getPageId(page + PAGE_OVERHEAD);\n\n        assert pageId != 0 : U.hexLong(PageHeader.readPageId(page));\n        assert PageIO.getVersion(page + PAGE_OVERHEAD) != 0 : U.hexLong(pageId);\n        assert PageIO.getType(page + PAGE_OVERHEAD) != 0 : U.hexLong(pageId);\n\n        try {\n            rwLock.writeUnlock(page + PAGE_LOCK_OFFSET, PageIdUtils.tag(pageId));\n\n            if (throttlingPlc != ThrottlingPolicy.DISABLED && !restore && markDirty && !wasDirty)\n                writeThrottle.onMarkDirty(isInCheckpoint(fullId));\n        }\n        catch (AssertionError ex) {\n            U.error(log, \"Failed to unlock page [fullPageId=\" + fullId + \", binPage=\" + U.toHexString(page, systemPageSize()) + ']');\n\n            throw ex;\n        }\n    }",
            "1518  \n1519  \n1520  \n1521  \n1522  \n1523  \n1524  \n1525  \n1526  \n1527  \n1528  \n1529  \n1530  \n1531  \n1532  \n1533  \n1534  \n1535 +\n1536 +\n1537 +\n1538 +\n1539  \n1540 +\n1541  \n1542 +\n1543  \n1544 +\n1545 +\n1546  \n1547 +\n1548 +\n1549 +\n1550 +\n1551 +\n1552 +\n1553 +\n1554 +\n1555  \n1556 +\n1557 +\n1558 +\n1559  \n1560 +\n1561 +\n1562  \n1563 +\n1564 +\n1565 +\n1566 +\n1567 +\n1568 +\n1569  \n1570 +\n1571 +\n1572  \n1573  ",
            "    /**\n     * @param page Page pointer.\n     * @param fullId full page ID.\n     * @param walPlc\n     * @param walPlc Full page WAL record policy.\n     * @param markDirty set dirty flag to page.\n     * @param restore\n     */\n    private void writeUnlockPage(\n        long page,\n        FullPageId fullId,\n        Boolean walPlc,\n        boolean markDirty,\n        boolean restore\n    ) {\n        boolean wasDirty = isDirty(page);\n\n        try {\n            //if page is for restore, we shouldn't mark it as changed\n            if (!restore && markDirty && !wasDirty && changeTracker != null)\n                changeTracker.apply(page, fullId, this);\n\n            boolean pageWalRec = markDirty && walPlc != FALSE && (walPlc == TRUE || !wasDirty);\n\n            assert PageIO.getCrc(page + PAGE_OVERHEAD) == 0; //TODO GG-11480\n\n            if (markDirty)\n                setDirty(fullId, page, markDirty, false);\n\n            beforeReleaseWrite(fullId, page + PAGE_OVERHEAD, pageWalRec);\n        }\n        catch (IgniteCheckedException e) {\n            throw new IgniteException(e);\n        }\n        // Always release the lock.\n        finally {\n            long pageId = PageIO.getPageId(page + PAGE_OVERHEAD);\n\n            assert pageId != 0 : U.hexLong(PageHeader.readPageId(page));\n            assert PageIO.getVersion(page + PAGE_OVERHEAD) != 0 : U.hexLong(pageId);\n            assert PageIO.getType(page + PAGE_OVERHEAD) != 0 : U.hexLong(pageId);\n\n            try {\n                rwLock.writeUnlock(page + PAGE_LOCK_OFFSET, PageIdUtils.tag(pageId));\n\n                if (throttlingPlc != ThrottlingPolicy.DISABLED && !restore && markDirty && !wasDirty)\n                    writeThrottle.onMarkDirty(isInCheckpoint(fullId));\n            }\n            catch (AssertionError ex) {\n                U.error(log, \"Failed to unlock page [fullPageId=\" + fullId +\n                    \", binPage=\" + U.toHexString(page, systemPageSize()) + ']');\n\n                throw ex;\n            }\n        }\n    }"
        ]
    ],
    "a1897dfd1f82cb85260c1d05e778a609bf30511b": [
        [
            "CacheSerializableTransactionsTest::testNoOptimisticExceptionOnChangingTopology()",
            "4371  \n4372  \n4373  \n4374  \n4375  \n4376  \n4377  \n4378  \n4379  \n4380  \n4381  \n4382  \n4383  \n4384  \n4385  \n4386  \n4387  \n4388  \n4389  \n4390  \n4391  \n4392  \n4393  \n4394  \n4395  \n4396  \n4397  \n4398  \n4399  \n4400  \n4401  \n4402  \n4403  \n4404  \n4405  \n4406  \n4407  \n4408  \n4409  \n4410  \n4411  \n4412  \n4413  \n4414  \n4415  \n4416  \n4417  \n4418  \n4419  \n4420  \n4421  \n4422  \n4423  \n4424  \n4425  \n4426  \n4427  \n4428  \n4429  \n4430  \n4431  \n4432  \n4433  \n4434  \n4435  \n4436  \n4437  \n4438  \n4439  \n4440  \n4441  \n4442  \n4443  \n4444  \n4445  \n4446  \n4447  \n4448  \n4449  \n4450  \n4451  \n4452  \n4453  \n4454  \n4455  \n4456  \n4457  \n4458  \n4459  \n4460  \n4461  \n4462  \n4463  \n4464  \n4465  \n4466  \n4467  \n4468  \n4469  \n4470  \n4471  \n4472  \n4473  \n4474  \n4475  \n4476  \n4477  \n4478  \n4479  \n4480  \n4481  \n4482  \n4483  \n4484  \n4485  \n4486  \n4487  \n4488  \n4489  \n4490  \n4491  \n4492  \n4493  \n4494 -\n4495  \n4496  \n4497  \n4498  \n4499  \n4500  \n4501  \n4502  \n4503  \n4504  \n4505  \n4506  \n4507  \n4508  \n4509  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testNoOptimisticExceptionOnChangingTopology() throws Exception {\n        if (FAST)\n            return;\n\n        final AtomicBoolean finished = new AtomicBoolean();\n\n        final List<String> cacheNames = new ArrayList<>();\n\n        Ignite srv = ignite(1);\n\n        try {\n            {\n                CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, false, false);\n                ccfg.setName(\"cache1\");\n                ccfg.setRebalanceMode(SYNC);\n\n                srv.createCache(ccfg);\n\n                cacheNames.add(ccfg.getName());\n            }\n\n            {\n                // Store enabled.\n                CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, true, false);\n                ccfg.setName(\"cache2\");\n                ccfg.setRebalanceMode(SYNC);\n\n                srv.createCache(ccfg);\n\n                cacheNames.add(ccfg.getName());\n            }\n\n            {\n                // Eviction.\n                CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, false, false);\n                ccfg.setName(\"cache3\");\n                ccfg.setRebalanceMode(SYNC);\n\n                LruEvictionPolicy plc = new LruEvictionPolicy();\n\n                plc.setMaxSize(100);\n\n                ccfg.setEvictionPolicy(plc);\n\n                ccfg.setOnheapCacheEnabled(true);\n\n                srv.createCache(ccfg);\n\n                cacheNames.add(ccfg.getName());\n            }\n\n            IgniteInternalFuture<?> restartFut = restartFuture(finished, null);\n\n            List<IgniteInternalFuture<?>> futs = new ArrayList<>();\n\n            final int KEYS_PER_THREAD = 100;\n\n            for (int i = 1; i < SRVS + CLIENTS; i++) {\n                final Ignite node = ignite(i);\n\n                final int minKey = i * KEYS_PER_THREAD;\n                final int maxKey = minKey + KEYS_PER_THREAD;\n\n                // Threads update non-intersecting keys, optimistic exception should not be thrown.\n\n                futs.add(GridTestUtils.runAsync(new Callable<Void>() {\n                    @Override public Void call() throws Exception {\n                        try {\n                            log.info(\"Started update thread [node=\" + node.name() +\n                                \", minKey=\" + minKey +\n                                \", maxKey=\" + maxKey + ']');\n\n                            final ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                            List<IgniteCache<Integer, Integer>> caches = new ArrayList<>();\n\n                            for (String cacheName : cacheNames)\n                                caches.add(node.<Integer, Integer>cache(cacheName));\n\n                            assertEquals(3, caches.size());\n\n                            int iter = 0;\n\n                            while (!finished.get()) {\n                                int keyCnt = rnd.nextInt(1, 10);\n\n                                final Set<Integer> keys = new LinkedHashSet<>();\n\n                                while (keys.size() < keyCnt)\n                                    keys.add(rnd.nextInt(minKey, maxKey));\n\n                                for (final IgniteCache<Integer, Integer> cache : caches) {\n                                    doInTransaction(node, OPTIMISTIC, SERIALIZABLE, new Callable<Void>() {\n                                        @Override public Void call() throws Exception {\n                                            for (Integer key : keys)\n                                                randomOperation(rnd, cache, key);\n\n                                            return null;\n                                        }\n                                    });\n                                }\n\n                                if (iter % 100 == 0)\n                                    log.info(\"Iteration: \" + iter);\n\n                                iter++;\n                            }\n\n                            return null;\n                        }\n                        catch (Throwable e) {\n                            log.error(\"Unexpected error: \" + e, e);\n\n                            throw e;\n                        }\n                    }\n                }, \"update-thread-\" + i));\n            }\n\n            U.sleep(60_000);\n\n            finished.set(true);\n\n            restartFut.get();\n\n            for (IgniteInternalFuture<?> fut : futs)\n                fut.get();\n        }\n        finally {\n            finished.set(true);\n\n            for (String cacheName : cacheNames)\n                destroyCache(cacheName);\n        }\n    }",
            "4373  \n4374  \n4375  \n4376  \n4377  \n4378  \n4379  \n4380  \n4381  \n4382  \n4383  \n4384  \n4385  \n4386  \n4387  \n4388  \n4389  \n4390  \n4391  \n4392  \n4393  \n4394  \n4395  \n4396  \n4397  \n4398  \n4399  \n4400  \n4401  \n4402  \n4403  \n4404  \n4405  \n4406  \n4407  \n4408  \n4409  \n4410  \n4411  \n4412  \n4413  \n4414  \n4415  \n4416  \n4417  \n4418  \n4419  \n4420  \n4421  \n4422  \n4423  \n4424  \n4425  \n4426  \n4427  \n4428  \n4429  \n4430  \n4431  \n4432  \n4433  \n4434  \n4435  \n4436  \n4437  \n4438  \n4439  \n4440  \n4441  \n4442  \n4443  \n4444  \n4445  \n4446  \n4447  \n4448  \n4449  \n4450  \n4451  \n4452  \n4453  \n4454  \n4455  \n4456  \n4457  \n4458  \n4459  \n4460  \n4461  \n4462  \n4463  \n4464  \n4465  \n4466  \n4467  \n4468  \n4469  \n4470  \n4471  \n4472  \n4473  \n4474  \n4475  \n4476  \n4477  \n4478  \n4479  \n4480  \n4481  \n4482  \n4483  \n4484  \n4485  \n4486  \n4487  \n4488  \n4489  \n4490  \n4491  \n4492  \n4493  \n4494  \n4495  \n4496 +\n4497  \n4498  \n4499  \n4500  \n4501  \n4502  \n4503  \n4504  \n4505  \n4506  \n4507  \n4508  \n4509  \n4510  \n4511  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testNoOptimisticExceptionOnChangingTopology() throws Exception {\n        if (FAST)\n            return;\n\n        final AtomicBoolean finished = new AtomicBoolean();\n\n        final List<String> cacheNames = new ArrayList<>();\n\n        Ignite srv = ignite(1);\n\n        try {\n            {\n                CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, false, false);\n                ccfg.setName(\"cache1\");\n                ccfg.setRebalanceMode(SYNC);\n\n                srv.createCache(ccfg);\n\n                cacheNames.add(ccfg.getName());\n            }\n\n            {\n                // Store enabled.\n                CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, true, false);\n                ccfg.setName(\"cache2\");\n                ccfg.setRebalanceMode(SYNC);\n\n                srv.createCache(ccfg);\n\n                cacheNames.add(ccfg.getName());\n            }\n\n            {\n                // Eviction.\n                CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, false, false);\n                ccfg.setName(\"cache3\");\n                ccfg.setRebalanceMode(SYNC);\n\n                LruEvictionPolicy plc = new LruEvictionPolicy();\n\n                plc.setMaxSize(100);\n\n                ccfg.setEvictionPolicy(plc);\n\n                ccfg.setOnheapCacheEnabled(true);\n\n                srv.createCache(ccfg);\n\n                cacheNames.add(ccfg.getName());\n            }\n\n            IgniteInternalFuture<?> restartFut = restartFuture(finished, null);\n\n            List<IgniteInternalFuture<?>> futs = new ArrayList<>();\n\n            final int KEYS_PER_THREAD = 100;\n\n            for (int i = 1; i < SRVS + CLIENTS; i++) {\n                final Ignite node = ignite(i);\n\n                final int minKey = i * KEYS_PER_THREAD;\n                final int maxKey = minKey + KEYS_PER_THREAD;\n\n                // Threads update non-intersecting keys, optimistic exception should not be thrown.\n\n                futs.add(GridTestUtils.runAsync(new Callable<Void>() {\n                    @Override public Void call() throws Exception {\n                        try {\n                            log.info(\"Started update thread [node=\" + node.name() +\n                                \", minKey=\" + minKey +\n                                \", maxKey=\" + maxKey + ']');\n\n                            final ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                            List<IgniteCache<Integer, Integer>> caches = new ArrayList<>();\n\n                            for (String cacheName : cacheNames)\n                                caches.add(node.<Integer, Integer>cache(cacheName));\n\n                            assertEquals(3, caches.size());\n\n                            int iter = 0;\n\n                            while (!finished.get()) {\n                                int keyCnt = rnd.nextInt(1, 10);\n\n                                final Set<Integer> keys = new LinkedHashSet<>();\n\n                                while (keys.size() < keyCnt)\n                                    keys.add(rnd.nextInt(minKey, maxKey));\n\n                                for (final IgniteCache<Integer, Integer> cache : caches) {\n                                    doInTransaction(node, OPTIMISTIC, SERIALIZABLE, new Callable<Void>() {\n                                        @Override public Void call() throws Exception {\n                                            for (Integer key : keys)\n                                                randomOperation(rnd, cache, key);\n\n                                            return null;\n                                        }\n                                    });\n                                }\n\n                                if (iter % 100 == 0)\n                                    log.info(\"Iteration: \" + iter);\n\n                                iter++;\n                            }\n\n                            return null;\n                        }\n                        catch (Throwable e) {\n                            log.error(\"Unexpected error: \" + e, e);\n\n                            throw e;\n                        }\n                    }\n                }, \"update-thread-\" + i));\n            }\n\n            U.sleep(SF.applyLB(60_000, 5_000));\n\n            finished.set(true);\n\n            restartFut.get();\n\n            for (IgniteInternalFuture<?> fut : futs)\n                fut.get();\n        }\n        finally {\n            finished.set(true);\n\n            for (String cacheName : cacheNames)\n                destroyCache(cacheName);\n        }\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::testCommunicationFailureResolve_KillCoordinator_5()",
            "3041  \n3042  \n3043  \n3044  \n3045  \n3046  \n3047  \n3048  \n3049  \n3050  \n3051  \n3052  \n3053  \n3054  \n3055  \n3056  \n3057 -\n3058  \n3059  \n3060  \n3061  \n3062  \n3063  \n3064  \n3065  \n3066  \n3067  \n3068  \n3069  \n3070  \n3071  \n3072  \n3073  \n3074  \n3075  \n3076  \n3077  \n3078  \n3079  \n3080  \n3081  \n3082  \n3083  \n3084  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testCommunicationFailureResolve_KillCoordinator_5() throws Exception {\n        sesTimeout = 2000;\n\n        testCommSpi = true;\n        commFailureRslvr = KillCoordinatorCommunicationFailureResolver.FACTORY;\n\n        startGrids(10);\n\n        int crd = 0;\n\n        int nodeIdx = 10;\n\n        for (int i = 0; i < 10; i++) {\n            info(\"Iteration: \" + i);\n\n            for (Ignite node : G.allGrids())\n                ZkTestCommunicationSpi.testSpi(node).initCheckResult(10);\n\n            UUID crdId = ignite(crd).cluster().localNode().id();\n\n            ZookeeperDiscoverySpi spi = spi(ignite(crd + 1));\n\n            try {\n                spi.resolveCommunicationFailure(spi.getNode(crdId), new Exception(\"test\"));\n\n                fail(\"Exception is not thrown\");\n            }\n            catch (IgniteSpiException e) {\n                assertTrue(\"Unexpected exception: \" + e, e.getCause() instanceof ClusterTopologyCheckedException);\n            }\n\n            waitForTopology(9);\n\n            startGrid(nodeIdx++);\n\n            waitForTopology(10);\n\n            crd++;\n        }\n    }",
            "3042  \n3043  \n3044  \n3045  \n3046  \n3047  \n3048  \n3049  \n3050  \n3051  \n3052  \n3053  \n3054  \n3055  \n3056  \n3057  \n3058 +\n3059  \n3060  \n3061  \n3062  \n3063  \n3064  \n3065  \n3066  \n3067  \n3068  \n3069  \n3070  \n3071  \n3072  \n3073  \n3074  \n3075  \n3076  \n3077  \n3078  \n3079  \n3080  \n3081  \n3082  \n3083  \n3084  \n3085  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testCommunicationFailureResolve_KillCoordinator_5() throws Exception {\n        sesTimeout = 2000;\n\n        testCommSpi = true;\n        commFailureRslvr = KillCoordinatorCommunicationFailureResolver.FACTORY;\n\n        startGrids(10);\n\n        int crd = 0;\n\n        int nodeIdx = 10;\n\n        for (int i = 0; i < SF.applyLB(10, 2); i++) {\n            info(\"Iteration: \" + i);\n\n            for (Ignite node : G.allGrids())\n                ZkTestCommunicationSpi.testSpi(node).initCheckResult(10);\n\n            UUID crdId = ignite(crd).cluster().localNode().id();\n\n            ZookeeperDiscoverySpi spi = spi(ignite(crd + 1));\n\n            try {\n                spi.resolveCommunicationFailure(spi.getNode(crdId), new Exception(\"test\"));\n\n                fail(\"Exception is not thrown\");\n            }\n            catch (IgniteSpiException e) {\n                assertTrue(\"Unexpected exception: \" + e, e.getCause() instanceof ClusterTopologyCheckedException);\n            }\n\n            waitForTopology(9);\n\n            startGrid(nodeIdx++);\n\n            waitForTopology(10);\n\n            crd++;\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxTenNodesTwoBackups()",
            " 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554 -\n 555  \n 556  \n 557  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxTenNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 10;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithTx(duration, 5, 5, 3);\n    }",
            " 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557 +\n 558  \n 559  \n 560  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxTenNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 10;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithTx(duration, 5, 5, 3);\n    }"
        ],
        [
            "CacheSerializableTransactionsTest::accountTx(boolean,boolean,boolean,boolean)",
            "4111  \n4112  \n4113  \n4114  \n4115  \n4116  \n4117  \n4118  \n4119  \n4120  \n4121  \n4122  \n4123  \n4124  \n4125  \n4126  \n4127  \n4128  \n4129  \n4130  \n4131 -\n4132 -\n4133  \n4134  \n4135  \n4136  \n4137  \n4138  \n4139  \n4140  \n4141 -\n4142  \n4143 -\n4144  \n4145  \n4146  \n4147  \n4148  \n4149  \n4150  \n4151  \n4152  \n4153  \n4154  \n4155  \n4156  \n4157  \n4158  \n4159  \n4160  \n4161  \n4162  \n4163  \n4164  \n4165  \n4166  \n4167  \n4168  \n4169  \n4170  \n4171  \n4172  \n4173  \n4174  \n4175  \n4176  \n4177  \n4178  \n4179  \n4180  \n4181  \n4182  \n4183  \n4184  \n4185  \n4186  \n4187  \n4188  \n4189  \n4190  \n4191  \n4192  \n4193  \n4194  \n4195  \n4196  \n4197  \n4198  \n4199  \n4200  \n4201  \n4202  \n4203  \n4204  \n4205  \n4206  \n4207  \n4208  \n4209  \n4210  \n4211  \n4212  \n4213  \n4214  \n4215  \n4216  \n4217  \n4218  \n4219  \n4220  \n4221  \n4222  \n4223  \n4224  \n4225  \n4226  \n4227  \n4228  \n4229  \n4230  \n4231  \n4232  \n4233  \n4234  \n4235  \n4236  \n4237  \n4238  \n4239  \n4240  \n4241  \n4242  \n4243  \n4244  \n4245  \n4246  \n4247  \n4248  \n4249  \n4250  \n4251  \n4252  \n4253  \n4254  \n4255  \n4256  \n4257  \n4258  \n4259  \n4260  \n4261  \n4262  \n4263  \n4264  \n4265  \n4266  \n4267  \n4268  \n4269  \n4270  \n4271  \n4272  \n4273  \n4274  \n4275  \n4276  \n4277  \n4278  \n4279  \n4280  \n4281  \n4282  \n4283  \n4284  \n4285  \n4286  \n4287  \n4288  \n4289  \n4290  \n4291  \n4292  \n4293  \n4294  \n4295  \n4296  \n4297  \n4298  \n4299  \n4300  \n4301  \n4302  \n4303  \n4304  \n4305  \n4306  \n4307  \n4308  \n4309  \n4310  \n4311  \n4312  \n4313  \n4314  \n4315  \n4316  \n4317  \n4318  \n4319  \n4320  \n4321  \n4322  \n4323  \n4324  \n4325  \n4326  \n4327  \n4328  \n4329  \n4330  \n4331  \n4332  \n4333  \n4334  \n4335  \n4336  \n4337  \n4338  \n4339  \n4340  \n4341  \n4342  \n4343  \n4344  \n4345  \n4346  \n4347  \n4348  \n4349  \n4350  \n4351  \n4352  \n4353  \n4354  \n4355  \n4356  \n4357  \n4358  \n4359  \n4360  \n4361  \n4362  \n4363  \n4364  \n4365  \n4366  \n4367  \n4368  \n4369  ",
            "    /**\n     * @param getAll If {@code true} uses getAll/putAll in transaction.\n     * @param nearCache If {@code true} near cache is enabled.\n     * @param nonSer If {@code true} starts threads executing non-serializable transactions.\n     * @param restart If {@code true} restarts one node.\n     * @throws Exception If failed.\n     */\n    private void accountTx(final boolean getAll,\n        final boolean nearCache,\n        final boolean nonSer,\n        final boolean restart) throws Exception {\n        final Ignite srv = ignite(1);\n\n        CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, false, false);\n\n        final String cacheName = srv.createCache(ccfg).getName();\n\n        try {\n            final List<Ignite> clients = clients();\n\n            final int ACCOUNTS = 100;\n            final int VAL_PER_ACCOUNT = 10_000;\n\n            IgniteCache<Integer, Account> srvCache = srv.cache(cacheName);\n\n            for (int i = 0; i < ACCOUNTS; i++)\n                srvCache.put(i, new Account(VAL_PER_ACCOUNT));\n\n            final AtomicInteger idx = new AtomicInteger();\n\n            final int THREADS = 20;\n\n            final long testTime = 30_000;\n\n            final long stopTime = System.currentTimeMillis() + testTime;\n\n            IgniteInternalFuture<?> nonSerFut = null;\n\n            if (nonSer) {\n                nonSerFut = runMultiThreadedAsync(new Callable<Void>() {\n                    @Override public Void call() throws Exception {\n                        int nodeIdx = idx.getAndIncrement() % clients.size();\n\n                        Ignite node = clients.get(nodeIdx);\n\n                        Thread.currentThread().setName(\"update-pessimistic-\" + node.name());\n\n                        log.info(\"Pessimistic tx thread: \" + node.name());\n\n                        final IgniteTransactions txs = node.transactions();\n\n                        final IgniteCache<Integer, Account> cache =\n                            nearCache ? node.createNearCache(cacheName, new NearCacheConfiguration<Integer, Account>()) :\n                                node.<Integer, Account>cache(cacheName);\n\n                        assertNotNull(cache);\n\n                        ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                        while (U.currentTimeMillis() < stopTime) {\n                            int id1 = rnd.nextInt(ACCOUNTS);\n\n                            int id2 = rnd.nextInt(ACCOUNTS);\n\n                            while (id2 == id1)\n                                id2 = rnd.nextInt(ACCOUNTS);\n\n                            if (id1 > id2) {\n                                int tmp = id1;\n                                id1 = id2;\n                                id2 = tmp;\n                            }\n\n                            try (Transaction tx = txs.txStart(PESSIMISTIC, REPEATABLE_READ)) {\n                                Account a1 = cache.get(id1);\n                                Account a2 = cache.get(id2);\n\n                                assertNotNull(a1);\n                                assertNotNull(a2);\n\n                                if (a1.value() > 0) {\n                                    a1 = new Account(a1.value() - 1);\n                                    a2 = new Account(a2.value() + 1);\n                                }\n\n                                cache.put(id1, a1);\n                                cache.put(id2, a2);\n\n                                tx.commit();\n                            }\n                        }\n\n                        return null;\n                    }\n                }, 10, \"non-ser-thread\");\n            }\n\n            final IgniteInternalFuture<?> fut = runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    int nodeIdx = idx.getAndIncrement() % clients.size();\n\n                    Ignite node = clients.get(nodeIdx);\n\n                    Thread.currentThread().setName(\"update-\" + node.name());\n\n                    log.info(\"Tx thread: \" + node.name());\n\n                    final IgniteTransactions txs = node.transactions();\n\n                    final IgniteCache<Integer, Account> cache =\n                        nearCache ? node.createNearCache(cacheName, new NearCacheConfiguration<Integer, Account>()) :\n                            node.<Integer, Account>cache(cacheName);\n\n                    assertNotNull(cache);\n\n                    ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                    while (U.currentTimeMillis() < stopTime) {\n                        int id1 = rnd.nextInt(ACCOUNTS);\n\n                        int id2 = rnd.nextInt(ACCOUNTS);\n\n                        while (id2 == id1)\n                            id2 = rnd.nextInt(ACCOUNTS);\n\n                        try {\n                            while (true) {\n                                try {\n                                    try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                        if (getAll) {\n                                            Map<Integer, Account> map = cache.getAll(F.asSet(id1, id2));\n\n                                            Account a1 = cache.get(id1);\n                                            Account a2 = cache.get(id2);\n\n                                            assertNotNull(a1);\n                                            assertNotNull(a2);\n\n                                            if (a1.value() > 0) {\n                                                a1 = new Account(a1.value() - 1);\n                                                a2 = new Account(a2.value() + 1);\n                                            }\n\n                                            map.put(id1, a1);\n                                            map.put(id2, a2);\n\n                                            cache.putAll(map);\n                                        }\n                                        else {\n                                            Account a1 = cache.get(id1);\n                                            Account a2 = cache.get(id2);\n\n                                            assertNotNull(a1);\n                                            assertNotNull(a2);\n\n                                            if (a1.value() > 0) {\n                                                a1 = new Account(a1.value() - 1);\n                                                a2 = new Account(a2.value() + 1);\n                                            }\n\n                                            cache.put(id1, a1);\n                                            cache.put(id2, a2);\n                                        }\n\n                                        tx.commit();\n                                    }\n\n                                    break;\n                                }\n                                catch (TransactionOptimisticException ignore) {\n                                    // Retry.\n                                }\n                                catch (IgniteException | CacheException e) {\n                                    assertTrue(\"Unexpected exception [err=\" + e + \", cause=\" + e.getCause() + ']',\n                                        restart && X.hasCause(e, ClusterTopologyCheckedException.class));\n                                }\n                            }\n                        }\n                        catch (Throwable e) {\n                            log.error(\"Unexpected error: \" + e, e);\n\n                            throw e;\n                        }\n                    }\n\n                    return null;\n                }\n            }, THREADS, \"tx-thread\");\n\n            IgniteInternalFuture<?> restartFut = restart ? restartFuture(null, fut) : null;\n\n            fut.get(testTime + 30_000);\n\n            if (nonSerFut != null)\n                nonSerFut.get();\n\n            if (restartFut != null)\n                restartFut.get();\n\n            int sum = 0;\n\n            for (int i = 0; i < ACCOUNTS; i++) {\n                Account a = srvCache.get(i);\n\n                assertNotNull(a);\n                assertTrue(a.value() >= 0);\n\n                log.info(\"Account: \" + a.value());\n\n                sum += a.value();\n            }\n\n            assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n\n            for (int node = 0; node < SRVS + CLIENTS; node++) {\n                log.info(\"Verify node: \" + node);\n\n                Ignite ignite = ignite(node);\n\n                IgniteCache<Integer, Account> cache = ignite.cache(cacheName);\n\n                sum = 0;\n\n                try (Transaction tx = ignite.transactions().txStart(OPTIMISTIC, SERIALIZABLE)) {\n                    Map<Integer, Account> map = new HashMap<>();\n\n                    for (int i = 0; i < ACCOUNTS; i++) {\n                        Account a = cache.get(i);\n\n                        assertNotNull(a);\n\n                        map.put(i, a);\n\n                        sum += a.value();\n                    }\n\n                    Account a1 = map.get(0);\n                    Account a2 = map.get(1);\n\n                    if (a1.value() > 0) {\n                        a1 = new Account(a1.value() - 1);\n                        a2 = new Account(a2.value() + 1);\n\n                        map.put(0, a1);\n                        map.put(1, a2);\n                    }\n\n                    cache.putAll(map);\n\n                    tx.commit();\n                }\n\n                assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n            }\n        }\n        finally {\n            destroyCache(cacheName);\n        }\n    }",
            "4113  \n4114  \n4115  \n4116  \n4117  \n4118  \n4119  \n4120  \n4121  \n4122  \n4123  \n4124  \n4125  \n4126  \n4127  \n4128  \n4129  \n4130  \n4131  \n4132  \n4133 +\n4134 +\n4135  \n4136  \n4137  \n4138  \n4139  \n4140  \n4141  \n4142  \n4143 +\n4144  \n4145 +\n4146  \n4147  \n4148  \n4149  \n4150  \n4151  \n4152  \n4153  \n4154  \n4155  \n4156  \n4157  \n4158  \n4159  \n4160  \n4161  \n4162  \n4163  \n4164  \n4165  \n4166  \n4167  \n4168  \n4169  \n4170  \n4171  \n4172  \n4173  \n4174  \n4175  \n4176  \n4177  \n4178  \n4179  \n4180  \n4181  \n4182  \n4183  \n4184  \n4185  \n4186  \n4187  \n4188  \n4189  \n4190  \n4191  \n4192  \n4193  \n4194  \n4195  \n4196  \n4197  \n4198  \n4199  \n4200  \n4201  \n4202  \n4203  \n4204  \n4205  \n4206  \n4207  \n4208  \n4209  \n4210  \n4211  \n4212  \n4213  \n4214  \n4215  \n4216  \n4217  \n4218  \n4219  \n4220  \n4221  \n4222  \n4223  \n4224  \n4225  \n4226  \n4227  \n4228  \n4229  \n4230  \n4231  \n4232  \n4233  \n4234  \n4235  \n4236  \n4237  \n4238  \n4239  \n4240  \n4241  \n4242  \n4243  \n4244  \n4245  \n4246  \n4247  \n4248  \n4249  \n4250  \n4251  \n4252  \n4253  \n4254  \n4255  \n4256  \n4257  \n4258  \n4259  \n4260  \n4261  \n4262  \n4263  \n4264  \n4265  \n4266  \n4267  \n4268  \n4269  \n4270  \n4271  \n4272  \n4273  \n4274  \n4275  \n4276  \n4277  \n4278  \n4279  \n4280  \n4281  \n4282  \n4283  \n4284  \n4285  \n4286  \n4287  \n4288  \n4289  \n4290  \n4291  \n4292  \n4293  \n4294  \n4295  \n4296  \n4297  \n4298  \n4299  \n4300  \n4301  \n4302  \n4303  \n4304  \n4305  \n4306  \n4307  \n4308  \n4309  \n4310  \n4311  \n4312  \n4313  \n4314  \n4315  \n4316  \n4317  \n4318  \n4319  \n4320  \n4321  \n4322  \n4323  \n4324  \n4325  \n4326  \n4327  \n4328  \n4329  \n4330  \n4331  \n4332  \n4333  \n4334  \n4335  \n4336  \n4337  \n4338  \n4339  \n4340  \n4341  \n4342  \n4343  \n4344  \n4345  \n4346  \n4347  \n4348  \n4349  \n4350  \n4351  \n4352  \n4353  \n4354  \n4355  \n4356  \n4357  \n4358  \n4359  \n4360  \n4361  \n4362  \n4363  \n4364  \n4365  \n4366  \n4367  \n4368  \n4369  \n4370  \n4371  ",
            "    /**\n     * @param getAll If {@code true} uses getAll/putAll in transaction.\n     * @param nearCache If {@code true} near cache is enabled.\n     * @param nonSer If {@code true} starts threads executing non-serializable transactions.\n     * @param restart If {@code true} restarts one node.\n     * @throws Exception If failed.\n     */\n    private void accountTx(final boolean getAll,\n        final boolean nearCache,\n        final boolean nonSer,\n        final boolean restart) throws Exception {\n        final Ignite srv = ignite(1);\n\n        CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, false, false);\n\n        final String cacheName = srv.createCache(ccfg).getName();\n\n        try {\n            final List<Ignite> clients = clients();\n\n            final int ACCOUNTS = SF.applyLB(100, 10);\n            final int VAL_PER_ACCOUNT = SF.applyLB(10_000, 50);\n\n            IgniteCache<Integer, Account> srvCache = srv.cache(cacheName);\n\n            for (int i = 0; i < ACCOUNTS; i++)\n                srvCache.put(i, new Account(VAL_PER_ACCOUNT));\n\n            final AtomicInteger idx = new AtomicInteger();\n\n            final int THREADS =  SF.applyLB(20, 5);\n\n            final long testTime =  SF.applyLB(30_000, 5_000);\n\n            final long stopTime = System.currentTimeMillis() + testTime;\n\n            IgniteInternalFuture<?> nonSerFut = null;\n\n            if (nonSer) {\n                nonSerFut = runMultiThreadedAsync(new Callable<Void>() {\n                    @Override public Void call() throws Exception {\n                        int nodeIdx = idx.getAndIncrement() % clients.size();\n\n                        Ignite node = clients.get(nodeIdx);\n\n                        Thread.currentThread().setName(\"update-pessimistic-\" + node.name());\n\n                        log.info(\"Pessimistic tx thread: \" + node.name());\n\n                        final IgniteTransactions txs = node.transactions();\n\n                        final IgniteCache<Integer, Account> cache =\n                            nearCache ? node.createNearCache(cacheName, new NearCacheConfiguration<Integer, Account>()) :\n                                node.<Integer, Account>cache(cacheName);\n\n                        assertNotNull(cache);\n\n                        ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                        while (U.currentTimeMillis() < stopTime) {\n                            int id1 = rnd.nextInt(ACCOUNTS);\n\n                            int id2 = rnd.nextInt(ACCOUNTS);\n\n                            while (id2 == id1)\n                                id2 = rnd.nextInt(ACCOUNTS);\n\n                            if (id1 > id2) {\n                                int tmp = id1;\n                                id1 = id2;\n                                id2 = tmp;\n                            }\n\n                            try (Transaction tx = txs.txStart(PESSIMISTIC, REPEATABLE_READ)) {\n                                Account a1 = cache.get(id1);\n                                Account a2 = cache.get(id2);\n\n                                assertNotNull(a1);\n                                assertNotNull(a2);\n\n                                if (a1.value() > 0) {\n                                    a1 = new Account(a1.value() - 1);\n                                    a2 = new Account(a2.value() + 1);\n                                }\n\n                                cache.put(id1, a1);\n                                cache.put(id2, a2);\n\n                                tx.commit();\n                            }\n                        }\n\n                        return null;\n                    }\n                }, 10, \"non-ser-thread\");\n            }\n\n            final IgniteInternalFuture<?> fut = runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    int nodeIdx = idx.getAndIncrement() % clients.size();\n\n                    Ignite node = clients.get(nodeIdx);\n\n                    Thread.currentThread().setName(\"update-\" + node.name());\n\n                    log.info(\"Tx thread: \" + node.name());\n\n                    final IgniteTransactions txs = node.transactions();\n\n                    final IgniteCache<Integer, Account> cache =\n                        nearCache ? node.createNearCache(cacheName, new NearCacheConfiguration<Integer, Account>()) :\n                            node.<Integer, Account>cache(cacheName);\n\n                    assertNotNull(cache);\n\n                    ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                    while (U.currentTimeMillis() < stopTime) {\n                        int id1 = rnd.nextInt(ACCOUNTS);\n\n                        int id2 = rnd.nextInt(ACCOUNTS);\n\n                        while (id2 == id1)\n                            id2 = rnd.nextInt(ACCOUNTS);\n\n                        try {\n                            while (true) {\n                                try {\n                                    try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                        if (getAll) {\n                                            Map<Integer, Account> map = cache.getAll(F.asSet(id1, id2));\n\n                                            Account a1 = cache.get(id1);\n                                            Account a2 = cache.get(id2);\n\n                                            assertNotNull(a1);\n                                            assertNotNull(a2);\n\n                                            if (a1.value() > 0) {\n                                                a1 = new Account(a1.value() - 1);\n                                                a2 = new Account(a2.value() + 1);\n                                            }\n\n                                            map.put(id1, a1);\n                                            map.put(id2, a2);\n\n                                            cache.putAll(map);\n                                        }\n                                        else {\n                                            Account a1 = cache.get(id1);\n                                            Account a2 = cache.get(id2);\n\n                                            assertNotNull(a1);\n                                            assertNotNull(a2);\n\n                                            if (a1.value() > 0) {\n                                                a1 = new Account(a1.value() - 1);\n                                                a2 = new Account(a2.value() + 1);\n                                            }\n\n                                            cache.put(id1, a1);\n                                            cache.put(id2, a2);\n                                        }\n\n                                        tx.commit();\n                                    }\n\n                                    break;\n                                }\n                                catch (TransactionOptimisticException ignore) {\n                                    // Retry.\n                                }\n                                catch (IgniteException | CacheException e) {\n                                    assertTrue(\"Unexpected exception [err=\" + e + \", cause=\" + e.getCause() + ']',\n                                        restart && X.hasCause(e, ClusterTopologyCheckedException.class));\n                                }\n                            }\n                        }\n                        catch (Throwable e) {\n                            log.error(\"Unexpected error: \" + e, e);\n\n                            throw e;\n                        }\n                    }\n\n                    return null;\n                }\n            }, THREADS, \"tx-thread\");\n\n            IgniteInternalFuture<?> restartFut = restart ? restartFuture(null, fut) : null;\n\n            fut.get(testTime + 30_000);\n\n            if (nonSerFut != null)\n                nonSerFut.get();\n\n            if (restartFut != null)\n                restartFut.get();\n\n            int sum = 0;\n\n            for (int i = 0; i < ACCOUNTS; i++) {\n                Account a = srvCache.get(i);\n\n                assertNotNull(a);\n                assertTrue(a.value() >= 0);\n\n                log.info(\"Account: \" + a.value());\n\n                sum += a.value();\n            }\n\n            assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n\n            for (int node = 0; node < SRVS + CLIENTS; node++) {\n                log.info(\"Verify node: \" + node);\n\n                Ignite ignite = ignite(node);\n\n                IgniteCache<Integer, Account> cache = ignite.cache(cacheName);\n\n                sum = 0;\n\n                try (Transaction tx = ignite.transactions().txStart(OPTIMISTIC, SERIALIZABLE)) {\n                    Map<Integer, Account> map = new HashMap<>();\n\n                    for (int i = 0; i < ACCOUNTS; i++) {\n                        Account a = cache.get(i);\n\n                        assertNotNull(a);\n\n                        map.put(i, a);\n\n                        sum += a.value();\n                    }\n\n                    Account a1 = map.get(0);\n                    Account a2 = map.get(1);\n\n                    if (a1.value() > 0) {\n                        a1 = new Account(a1.value() - 1);\n                        a2 = new Account(a2.value() + 1);\n\n                        map.put(0, a1);\n                        map.put(1, a2);\n                    }\n\n                    cache.putAll(map);\n\n                    tx.commit();\n                }\n\n                assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n            }\n        }\n        finally {\n            destroyCache(cacheName);\n        }\n    }"
        ],
        [
            "CacheSerializableTransactionsTest::testTxCommit()",
            " 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446 -\n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testTxCommit() throws Exception {\n        Ignite ignite0 = ignite(0);\n        Ignite ignite1 = ignite(1);\n\n        final IgniteTransactions txs0 = ignite0.transactions();\n        final IgniteTransactions txs1 = ignite1.transactions();\n\n        for (CacheConfiguration<Integer, Integer> ccfg : cacheConfigurations()) {\n            logCacheInfo(ccfg);\n\n            try {\n                IgniteCache<Integer, Integer> cache0 = ignite0.createCache(ccfg);\n                IgniteCache<Integer, Integer> cache1 = ignite1.cache(ccfg.getName());\n\n                List<Integer> keys = testKeys(cache0);\n\n                for (Integer key : keys) {\n                    log.info(\"Test key: \" + key);\n\n                    Integer expVal = null;\n\n                    for (int i = 0; i < 100; i++) {\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, i);\n\n                            tx.commit();\n\n                            expVal = i;\n                        }\n\n                        try (Transaction tx = txs1.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache1.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache1.put(key, val);\n\n                            tx.commit();\n                        }\n\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, val);\n\n                            tx.commit();\n                        }\n                    }\n\n                    checkValue(key, expVal, cache0.getName());\n\n                    cache0.remove(key);\n\n                    try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                        Integer val = cache0.get(key);\n\n                        assertNull(val);\n\n                        cache0.put(key, expVal + 1);\n\n                        tx.commit();\n                    }\n\n                    checkValue(key, expVal + 1, cache0.getName());\n                }\n            }\n            finally {\n                destroyCache(ccfg.getName());\n            }\n        }\n    }",
            " 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441 +\n 442  \n 443  \n 444  \n 445  \n 446  \n 447 +\n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testTxCommit() throws Exception {\n        Ignite ignite0 = ignite(0);\n        Ignite ignite1 = ignite(1);\n\n        final IgniteTransactions txs0 = ignite0.transactions();\n        final IgniteTransactions txs1 = ignite1.transactions();\n\n        for (CacheConfiguration<Integer, Integer> ccfg : cacheConfigurations()) {\n            logCacheInfo(ccfg);\n\n            try {\n                IgniteCache<Integer, Integer> cache0 = ignite0.createCache(ccfg);\n                IgniteCache<Integer, Integer> cache1 = ignite1.cache(ccfg.getName());\n\n                List<Integer> keys = testKeys(cache0);\n\n                final int ITERATIONS_COUNT = SF.applyLB(100, 5);\n                for (Integer key : keys) {\n                    log.info(\"Test key: \" + key);\n\n                    Integer expVal = null;\n\n                    for (int i = 0; i < ITERATIONS_COUNT; i++) {\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, i);\n\n                            tx.commit();\n\n                            expVal = i;\n                        }\n\n                        try (Transaction tx = txs1.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache1.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache1.put(key, val);\n\n                            tx.commit();\n                        }\n\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, val);\n\n                            tx.commit();\n                        }\n                    }\n\n                    checkValue(key, expVal, cache0.getName());\n\n                    cache0.remove(key);\n\n                    try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                        Integer val = cache0.get(key);\n\n                        assertNull(val);\n\n                        cache0.put(key, expVal + 1);\n\n                        tx.commit();\n                    }\n\n                    checkValue(key, expVal + 1, cache0.getName());\n                }\n            }\n            finally {\n                destroyCache(ccfg.getName());\n            }\n        }\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::testStartStopWithClients()",
            "2108  \n2109  \n2110  \n2111  \n2112  \n2113  \n2114  \n2115  \n2116  \n2117  \n2118  \n2119  \n2120  \n2121 -\n2122  \n2123  \n2124  \n2125  \n2126  \n2127  \n2128  \n2129  \n2130  \n2131  \n2132  \n2133  \n2134  \n2135  \n2136  \n2137  \n2138  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testStartStopWithClients() throws Exception {\n        final int SRVS = 3;\n\n        startGrids(SRVS);\n\n        clientMode(true);\n\n        final int THREADS = 30;\n\n        for (int i = 0; i < 5; i++) {\n            info(\"Iteration: \" + i);\n\n            startGridsMultiThreaded(SRVS, THREADS);\n\n            waitForTopology(SRVS + THREADS);\n\n            GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                @Override public void apply(Integer idx) {\n                    stopGrid(idx + SRVS);\n                }\n            }, THREADS, \"stop-node\");\n\n            waitForTopology(SRVS);\n\n            checkEventsConsistency();\n        }\n    }",
            "2109  \n2110  \n2111  \n2112  \n2113  \n2114  \n2115  \n2116  \n2117  \n2118  \n2119  \n2120  \n2121  \n2122 +\n2123  \n2124  \n2125  \n2126  \n2127  \n2128  \n2129  \n2130  \n2131  \n2132  \n2133  \n2134  \n2135  \n2136  \n2137  \n2138  \n2139  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testStartStopWithClients() throws Exception {\n        final int SRVS = 3;\n\n        startGrids(SRVS);\n\n        clientMode(true);\n\n        final int THREADS = 30;\n\n        for (int i = 0; i < SF.applyLB(5, 2); i++) {\n            info(\"Iteration: \" + i);\n\n            startGridsMultiThreaded(SRVS, THREADS);\n\n            waitForTopology(SRVS + THREADS);\n\n            GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                @Override public void apply(Integer idx) {\n                    stopGrid(idx + SRVS);\n                }\n            }, THREADS, \"stop-node\");\n\n            waitForTopology(SRVS);\n\n            checkEventsConsistency();\n        }\n    }"
        ],
        [
            "CacheSerializableTransactionsTest::testTxRollback()",
            " 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528 -\n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testTxRollback() throws Exception {\n        Ignite ignite0 = ignite(0);\n        Ignite ignite1 = ignite(1);\n\n        final IgniteTransactions txs0 = ignite0.transactions();\n        final IgniteTransactions txs1 = ignite1.transactions();\n\n        for (CacheConfiguration<Integer, Integer> ccfg : cacheConfigurations()) {\n            logCacheInfo(ccfg);\n\n            try {\n                IgniteCache<Integer, Integer> cache0 = ignite0.createCache(ccfg);\n                IgniteCache<Integer, Integer> cache1 = ignite1.cache(ccfg.getName());\n\n                List<Integer> keys = testKeys(cache0);\n\n                for (Integer key : keys) {\n                    log.info(\"Test key: \" + key);\n\n                    Integer expVal = null;\n\n                    for (int i = 0; i < 100; i++) {\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, i);\n\n                            tx.rollback();\n                        }\n\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, i);\n\n                            tx.commit();\n\n                            expVal = i;\n                        }\n\n                        try (Transaction tx = txs1.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache1.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache1.put(key, val);\n\n                            tx.commit();\n                        }\n                    }\n\n                    checkValue(key, expVal, cache0.getName());\n                }\n            }\n            finally {\n                destroyCache(ccfg.getName());\n            }\n        }\n    }",
            " 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529 +\n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testTxRollback() throws Exception {\n        Ignite ignite0 = ignite(0);\n        Ignite ignite1 = ignite(1);\n\n        final IgniteTransactions txs0 = ignite0.transactions();\n        final IgniteTransactions txs1 = ignite1.transactions();\n\n        for (CacheConfiguration<Integer, Integer> ccfg : cacheConfigurations()) {\n            logCacheInfo(ccfg);\n\n            try {\n                IgniteCache<Integer, Integer> cache0 = ignite0.createCache(ccfg);\n                IgniteCache<Integer, Integer> cache1 = ignite1.cache(ccfg.getName());\n\n                List<Integer> keys = testKeys(cache0);\n\n                for (Integer key : keys) {\n                    log.info(\"Test key: \" + key);\n\n                    Integer expVal = null;\n\n                    for (int i = 0; i < SF.applyLB(100, 10); i++) {\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, i);\n\n                            tx.rollback();\n                        }\n\n                        try (Transaction tx = txs0.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache0.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache0.put(key, i);\n\n                            tx.commit();\n\n                            expVal = i;\n                        }\n\n                        try (Transaction tx = txs1.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                            Integer val = cache1.get(key);\n\n                            assertEquals(expVal, val);\n\n                            cache1.put(key, val);\n\n                            tx.commit();\n                        }\n                    }\n\n                    checkValue(key, expVal, cache0.getName());\n                }\n            }\n            finally {\n                destroyCache(ccfg.getName());\n            }\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxSixNodesTwoBackups()",
            " 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486 -\n 487  \n 488  \n 489  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxSixNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 6;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithTx(duration, 3, 3, 3);\n    }",
            " 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489 +\n 490  \n 491  \n 492  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxSixNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 6;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithTx(duration, 3, 3, 3);\n    }"
        ],
        [
            "IgniteCacheCrossCacheTxFailoverTest::crossCacheTxFailover(CacheMode,boolean,TransactionConcurrency,TransactionIsolation)",
            " 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302 -\n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  ",
            "    /**\n     * @param cacheMode Cache mode.\n     * @param sameAff If {@code false} uses different number of partitions for caches.\n     * @param concurrency Transaction concurrency.\n     * @param isolation Transaction isolation.\n     * @throws Exception If failed.\n     */\n    private void crossCacheTxFailover(CacheMode cacheMode,\n        boolean sameAff,\n        final TransactionConcurrency concurrency,\n        final TransactionIsolation isolation) throws Exception {\n        IgniteKernal ignite0 = (IgniteKernal)ignite(0);\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        try {\n            ignite0.createCache(cacheConfiguration(CACHE1, cacheMode, 256));\n            ignite0.createCache(cacheConfiguration(CACHE2, cacheMode, sameAff ? 256 : 128));\n\n            final AtomicInteger threadIdx = new AtomicInteger();\n\n            IgniteInternalFuture<?> fut = runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    int idx = threadIdx.getAndIncrement();\n\n                    Ignite ignite = ignite(idx % GRID_CNT);\n\n                    log.info(\"Started update thread [node=\" + ignite.name() +\n                        \", client=\" + ignite.configuration().isClientMode() + ']');\n\n                    IgniteCache<TestKey, TestValue> cache1 = ignite.cache(CACHE1);\n                    IgniteCache<TestKey, TestValue> cache2 = ignite.cache(CACHE2);\n\n                    assertNotSame(cache1, cache2);\n\n                    IgniteTransactions txs = ignite.transactions();\n\n                    ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                    long iter = 0;\n\n                    while (!stop.get()) {\n                        boolean sameKey = rnd.nextBoolean();\n\n                        try {\n                            try (Transaction tx = txs.txStart(concurrency, isolation)) {\n                                if (sameKey) {\n                                    TestKey key = new TestKey(rnd.nextLong(KEY_RANGE));\n\n                                    cacheOperation(rnd, cache1, key);\n                                    cacheOperation(rnd, cache2, key);\n                                }\n                                else {\n                                    TestKey key1 = new TestKey(rnd.nextLong(KEY_RANGE));\n                                    TestKey key2 = new TestKey(key1.key() + 1);\n\n                                    cacheOperation(rnd, cache1, key1);\n                                    cacheOperation(rnd, cache2, key2);\n                                }\n\n                                tx.commit();\n                            }\n                        }\n                        catch (CacheException | IgniteException e) {\n                            log.info(\"Update error: \" + e);\n                        }\n\n                        if (iter++ % 500 == 0)\n                            log.info(\"Iteration: \" + iter);\n                    }\n\n                    return null;\n                }\n\n                /**\n                 * @param rnd Random.\n                 * @param cache Cache.\n                 * @param key Key.\n                 */\n                private void cacheOperation(ThreadLocalRandom rnd, IgniteCache<TestKey, TestValue> cache, TestKey key) {\n                    switch (rnd.nextInt(4)) {\n                        case 0:\n                            cache.put(key, new TestValue(rnd.nextLong()));\n\n                            break;\n\n                        case 1:\n                            cache.remove(key);\n\n                            break;\n\n                        case 2:\n                            cache.invoke(key, new TestEntryProcessor(rnd.nextBoolean() ? 1L : null));\n\n                            break;\n\n                        case 3:\n                            cache.get(key);\n\n                            break;\n\n                        default:\n                            assert false;\n                    }\n                }\n            }, 10, \"tx-thread\");\n\n            long stopTime = System.currentTimeMillis() + 3 * 60_000;\n\n            long topVer = ignite0.cluster().topologyVersion();\n\n            boolean failed = false;\n\n            while (System.currentTimeMillis() < stopTime) {\n                log.info(\"Start node.\");\n\n                IgniteKernal ignite = (IgniteKernal)startGrid(GRID_CNT);\n\n                assertFalse(ignite.configuration().isClientMode());\n\n                topVer++;\n\n                IgniteInternalFuture<?> affFut = ignite.context().cache().context().exchange().affinityReadyFuture(\n                    new AffinityTopologyVersion(topVer));\n\n                try {\n                    if (affFut != null)\n                        affFut.get(30_000);\n                }\n                catch (IgniteFutureTimeoutCheckedException ignored) {\n                    log.error(\"Failed to wait for affinity future after start: \" + topVer);\n\n                    failed = true;\n\n                    break;\n                }\n\n                Thread.sleep(500);\n\n                log.info(\"Stop node.\");\n\n                stopGrid(GRID_CNT);\n\n                topVer++;\n\n                affFut = ignite0.context().cache().context().exchange().affinityReadyFuture(\n                    new AffinityTopologyVersion(topVer));\n\n                try {\n                    if (affFut != null)\n                        affFut.get(30_000);\n                }\n                catch (IgniteFutureTimeoutCheckedException ignored) {\n                    log.error(\"Failed to wait for affinity future after stop: \" + topVer);\n\n                    failed = true;\n\n                    break;\n                }\n            }\n\n            stop.set(true);\n\n            fut.get();\n\n            assertFalse(\"Test failed, see log for details.\", failed);\n        }\n        finally {\n            stop.set(true);\n\n            ignite0.destroyCache(CACHE1);\n            ignite0.destroyCache(CACHE2);\n\n            AffinityTopologyVersion topVer = ignite0.context().cache().context().exchange().lastTopologyFuture().get();\n\n            for (Ignite ignite : G.allGrids())\n                ((IgniteKernal)ignite).context().cache().context().exchange().affinityReadyFuture(topVer).get();\n\n            awaitPartitionMapExchange();\n        }\n    }",
            " 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303 +\n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  ",
            "    /**\n     * @param cacheMode Cache mode.\n     * @param sameAff If {@code false} uses different number of partitions for caches.\n     * @param concurrency Transaction concurrency.\n     * @param isolation Transaction isolation.\n     * @throws Exception If failed.\n     */\n    private void crossCacheTxFailover(CacheMode cacheMode,\n        boolean sameAff,\n        final TransactionConcurrency concurrency,\n        final TransactionIsolation isolation) throws Exception {\n        IgniteKernal ignite0 = (IgniteKernal)ignite(0);\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        try {\n            ignite0.createCache(cacheConfiguration(CACHE1, cacheMode, 256));\n            ignite0.createCache(cacheConfiguration(CACHE2, cacheMode, sameAff ? 256 : 128));\n\n            final AtomicInteger threadIdx = new AtomicInteger();\n\n            IgniteInternalFuture<?> fut = runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    int idx = threadIdx.getAndIncrement();\n\n                    Ignite ignite = ignite(idx % GRID_CNT);\n\n                    log.info(\"Started update thread [node=\" + ignite.name() +\n                        \", client=\" + ignite.configuration().isClientMode() + ']');\n\n                    IgniteCache<TestKey, TestValue> cache1 = ignite.cache(CACHE1);\n                    IgniteCache<TestKey, TestValue> cache2 = ignite.cache(CACHE2);\n\n                    assertNotSame(cache1, cache2);\n\n                    IgniteTransactions txs = ignite.transactions();\n\n                    ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                    long iter = 0;\n\n                    while (!stop.get()) {\n                        boolean sameKey = rnd.nextBoolean();\n\n                        try {\n                            try (Transaction tx = txs.txStart(concurrency, isolation)) {\n                                if (sameKey) {\n                                    TestKey key = new TestKey(rnd.nextLong(KEY_RANGE));\n\n                                    cacheOperation(rnd, cache1, key);\n                                    cacheOperation(rnd, cache2, key);\n                                }\n                                else {\n                                    TestKey key1 = new TestKey(rnd.nextLong(KEY_RANGE));\n                                    TestKey key2 = new TestKey(key1.key() + 1);\n\n                                    cacheOperation(rnd, cache1, key1);\n                                    cacheOperation(rnd, cache2, key2);\n                                }\n\n                                tx.commit();\n                            }\n                        }\n                        catch (CacheException | IgniteException e) {\n                            log.info(\"Update error: \" + e);\n                        }\n\n                        if (iter++ % 500 == 0)\n                            log.info(\"Iteration: \" + iter);\n                    }\n\n                    return null;\n                }\n\n                /**\n                 * @param rnd Random.\n                 * @param cache Cache.\n                 * @param key Key.\n                 */\n                private void cacheOperation(ThreadLocalRandom rnd, IgniteCache<TestKey, TestValue> cache, TestKey key) {\n                    switch (rnd.nextInt(4)) {\n                        case 0:\n                            cache.put(key, new TestValue(rnd.nextLong()));\n\n                            break;\n\n                        case 1:\n                            cache.remove(key);\n\n                            break;\n\n                        case 2:\n                            cache.invoke(key, new TestEntryProcessor(rnd.nextBoolean() ? 1L : null));\n\n                            break;\n\n                        case 3:\n                            cache.get(key);\n\n                            break;\n\n                        default:\n                            assert false;\n                    }\n                }\n            }, 10, \"tx-thread\");\n\n            long stopTime = System.currentTimeMillis() + SF.applyLB(3 * 60_000, 20_000);\n\n            long topVer = ignite0.cluster().topologyVersion();\n\n            boolean failed = false;\n\n            while (System.currentTimeMillis() < stopTime) {\n                log.info(\"Start node.\");\n\n                IgniteKernal ignite = (IgniteKernal)startGrid(GRID_CNT);\n\n                assertFalse(ignite.configuration().isClientMode());\n\n                topVer++;\n\n                IgniteInternalFuture<?> affFut = ignite.context().cache().context().exchange().affinityReadyFuture(\n                    new AffinityTopologyVersion(topVer));\n\n                try {\n                    if (affFut != null)\n                        affFut.get(30_000);\n                }\n                catch (IgniteFutureTimeoutCheckedException ignored) {\n                    log.error(\"Failed to wait for affinity future after start: \" + topVer);\n\n                    failed = true;\n\n                    break;\n                }\n\n                Thread.sleep(500);\n\n                log.info(\"Stop node.\");\n\n                stopGrid(GRID_CNT);\n\n                topVer++;\n\n                affFut = ignite0.context().cache().context().exchange().affinityReadyFuture(\n                    new AffinityTopologyVersion(topVer));\n\n                try {\n                    if (affFut != null)\n                        affFut.get(30_000);\n                }\n                catch (IgniteFutureTimeoutCheckedException ignored) {\n                    log.error(\"Failed to wait for affinity future after stop: \" + topVer);\n\n                    failed = true;\n\n                    break;\n                }\n            }\n\n            stop.set(true);\n\n            fut.get();\n\n            assertFalse(\"Test failed, see log for details.\", failed);\n        }\n        finally {\n            stop.set(true);\n\n            ignite0.destroyCache(CACHE1);\n            ignite0.destroyCache(CACHE2);\n\n            AffinityTopologyVersion topVer = ignite0.context().cache().context().exchange().lastTopologyFuture().get();\n\n            for (Ignite ignite : G.allGrids())\n                ((IgniteKernal)ignite).context().cache().context().exchange().affinityReadyFuture(topVer).get();\n\n            awaitPartitionMapExchange();\n        }\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::concurrentStartStop(int)",
            "1801  \n1802  \n1803  \n1804  \n1805  \n1806  \n1807  \n1808  \n1809  \n1810  \n1811  \n1812 -\n1813  \n1814  \n1815  \n1816  \n1817  \n1818  \n1819  \n1820  \n1821  \n1822  \n1823  \n1824  \n1825  \n1826  \n1827  \n1828  \n1829  \n1830  \n1831  \n1832  \n1833  \n1834  \n1835  \n1836  \n1837  \n1838  \n1839  \n1840  \n1841  \n1842  \n1843  \n1844  \n1845  \n1846  \n1847  \n1848  ",
            "    /**\n     * @param initNodes Number of initially started nnodes.\n     * @throws Exception If failed.\n     */\n    private void concurrentStartStop(final int initNodes) throws Exception {\n        startGrids(initNodes);\n\n        final int NODES = 5;\n\n        long topVer = initNodes;\n\n        for (int i = 0; i < 10; i++) {\n            info(\"Iteration: \" + i);\n\n            DiscoveryEvent[] expEvts = new DiscoveryEvent[NODES];\n\n            startGridsMultiThreaded(initNodes, NODES);\n\n            for (int j = 0; j < NODES; j++)\n                expEvts[j] = joinEvent(++topVer);\n\n            checkEvents(ignite(0), expEvts);\n\n            checkEventsConsistency();\n\n            final CyclicBarrier b = new CyclicBarrier(NODES);\n\n            GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                @Override public void apply(Integer idx) {\n                    try {\n                        b.await();\n\n                        stopGrid(initNodes + idx);\n                    }\n                    catch (Exception e) {\n                        e.printStackTrace();\n\n                        fail();\n                    }\n                }\n            }, NODES, \"stop-node\");\n\n            for (int j = 0; j < NODES; j++)\n                expEvts[j] = failEvent(++topVer);\n\n            checkEventsConsistency();\n        }\n    }",
            "1802  \n1803  \n1804  \n1805  \n1806  \n1807  \n1808  \n1809  \n1810  \n1811  \n1812  \n1813 +\n1814  \n1815  \n1816  \n1817  \n1818  \n1819  \n1820  \n1821  \n1822  \n1823  \n1824  \n1825  \n1826  \n1827  \n1828  \n1829  \n1830  \n1831  \n1832  \n1833  \n1834  \n1835  \n1836  \n1837  \n1838  \n1839  \n1840  \n1841  \n1842  \n1843  \n1844  \n1845  \n1846  \n1847  \n1848  \n1849  ",
            "    /**\n     * @param initNodes Number of initially started nnodes.\n     * @throws Exception If failed.\n     */\n    private void concurrentStartStop(final int initNodes) throws Exception {\n        startGrids(initNodes);\n\n        final int NODES = 5;\n\n        long topVer = initNodes;\n\n        for (int i = 0; i < SF.applyLB(10, 2); i++) {\n            info(\"Iteration: \" + i);\n\n            DiscoveryEvent[] expEvts = new DiscoveryEvent[NODES];\n\n            startGridsMultiThreaded(initNodes, NODES);\n\n            for (int j = 0; j < NODES; j++)\n                expEvts[j] = joinEvent(++topVer);\n\n            checkEvents(ignite(0), expEvts);\n\n            checkEventsConsistency();\n\n            final CyclicBarrier b = new CyclicBarrier(NODES);\n\n            GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                @Override public void apply(Integer idx) {\n                    try {\n                        b.await();\n\n                        stopGrid(initNodes + idx);\n                    }\n                    catch (Exception e) {\n                        e.printStackTrace();\n\n                        fail();\n                    }\n                }\n            }, NODES, \"stop-node\");\n\n            for (int j = 0; j < NODES; j++)\n                expEvts[j] = failEvent(++topVer);\n\n            checkEventsConsistency();\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxFourNodesNoBackups()",
            " 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384 -\n 385  \n 386  \n 387  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxFourNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 60000;\n\n        checkRestartWithTx(duration, 2, 2, 3);\n    }",
            " 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387 +\n 388  \n 389  \n 390  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxFourNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(60_000, 5_000);\n\n        checkRestartWithTx(duration, 2, 2, 3);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutEightNodesTwoBackups()",
            " 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503 -\n 504  \n 505  \n 506  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutEightNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 8;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithPut(duration, 4, 4);\n    }",
            " 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506 +\n 507  \n 508  \n 509  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutEightNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 8;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithPut(duration, 4, 4);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutSixNodesTwoBackups()",
            " 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469 -\n 470  \n 471  \n 472  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutSixNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 6;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithPut(duration, 3, 3);\n    }",
            " 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472 +\n 473  \n 474  \n 475  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutSixNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 6;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithPut(duration, 3, 3);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutFourNodesOneBackupsOffheapEvict()",
            " 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418 -\n 419  \n 420  \n 421  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutFourNodesOneBackupsOffheapEvict() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = true;\n\n        long duration = 60000;\n\n        checkRestartWithPut(duration, 2, 2);\n    }",
            " 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421 +\n 422  \n 423  \n 424  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutFourNodesOneBackupsOffheapEvict() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = true;\n\n        long duration = SF.applyLB(60_000, 5_000);\n\n        checkRestartWithPut(duration, 2, 2);\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::topologyChangeWithRestarts(boolean,boolean)",
            "2178  \n2179  \n2180  \n2181  \n2182  \n2183  \n2184  \n2185  \n2186  \n2187  \n2188  \n2189 -\n2190  \n2191  \n2192  \n2193  \n2194  \n2195  \n2196  \n2197  \n2198  \n2199  \n2200  \n2201  \n2202  \n2203  \n2204  \n2205  \n2206  \n2207  \n2208  \n2209  \n2210  \n2211  \n2212  \n2213  \n2214  \n2215  \n2216  \n2217  \n2218  \n2219  \n2220  \n2221  \n2222  \n2223  \n2224  \n2225  \n2226  \n2227  \n2228  \n2229  \n2230  \n2231  \n2232  \n2233  \n2234  \n2235  \n2236  \n2237  \n2238  \n2239  \n2240  \n2241  \n2242  \n2243  \n2244  \n2245  \n2246  \n2247  \n2248  \n2249  \n2250  \n2251  \n2252  \n2253  \n2254  \n2255  \n2256  \n2257  \n2258  \n2259  \n2260  \n2261  \n2262  \n2263  \n2264  \n2265  \n2266  \n2267  \n2268  \n2269  \n2270  \n2271  \n2272  \n2273  \n2274  \n2275  \n2276  \n2277  ",
            "    /**\n     * @param restartZk If {@code true} in background restarts on of ZK servers.\n     * @param closeClientSock If {@code true} in background closes zk clients' sockets.\n     * @throws Exception If failed.\n     */\n    private void topologyChangeWithRestarts(boolean restartZk, boolean closeClientSock) throws Exception {\n        sesTimeout = 30_000;\n\n        if (closeClientSock)\n            testSockNio = true;\n\n        long stopTime = System.currentTimeMillis() + 60_000;\n\n        AtomicBoolean stop = new AtomicBoolean();\n\n        IgniteInternalFuture<?> fut1 = null;\n\n        IgniteInternalFuture<?> fut2 = null;\n\n        try {\n            fut1 = restartZk ? startRestartZkServers(stopTime, stop) : null;\n            fut2 = closeClientSock ? startCloseZkClientSocket(stopTime, stop) : null;\n\n            int INIT_NODES = 10;\n\n            startGridsMultiThreaded(INIT_NODES);\n\n            final int MAX_NODES = 20;\n\n            final List<Integer> startedNodes = new ArrayList<>();\n\n            for (int i = 0; i < INIT_NODES; i++)\n                startedNodes.add(i);\n\n            ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n            final AtomicInteger startIdx = new AtomicInteger(INIT_NODES);\n\n            while (System.currentTimeMillis() < stopTime) {\n                if (startedNodes.size() >= MAX_NODES) {\n                    int stopNodes = rnd.nextInt(5) + 1;\n\n                    log.info(\"Next, stop nodes: \" + stopNodes);\n\n                    final List<Integer> idxs = new ArrayList<>();\n\n                    while (idxs.size() < stopNodes) {\n                        Integer stopIdx = rnd.nextInt(startedNodes.size());\n\n                        if (!idxs.contains(stopIdx))\n                            idxs.add(startedNodes.get(stopIdx));\n                    }\n\n                    GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                        @Override public void apply(Integer threadIdx) {\n                            int stopNodeIdx = idxs.get(threadIdx);\n\n                            info(\"Stop node: \" + stopNodeIdx);\n\n                            stopGrid(stopNodeIdx);\n                        }\n                    }, stopNodes, \"stop-node\");\n\n                    startedNodes.removeAll(idxs);\n                }\n                else {\n                    int startNodes = rnd.nextInt(5) + 1;\n\n                    log.info(\"Next, start nodes: \" + startNodes);\n\n                    GridTestUtils.runMultiThreaded(new Callable<Void>() {\n                        @Override public Void call() throws Exception {\n                            int idx = startIdx.incrementAndGet();\n\n                            log.info(\"Start node: \" + idx);\n\n                            startGrid(idx);\n\n                            synchronized (startedNodes) {\n                                startedNodes.add(idx);\n                            }\n\n                            return null;\n                        }\n                    }, startNodes, \"start-node\");\n                }\n\n                U.sleep(rnd.nextInt(100) + 1);\n            }\n        }\n        finally {\n            stop.set(true);\n        }\n\n        if (fut1 != null)\n            fut1.get();\n\n        if (fut2 != null)\n            fut2.get();\n    }",
            "2179  \n2180  \n2181  \n2182  \n2183  \n2184  \n2185  \n2186  \n2187  \n2188  \n2189  \n2190 +\n2191  \n2192  \n2193  \n2194  \n2195  \n2196  \n2197  \n2198  \n2199  \n2200  \n2201  \n2202  \n2203  \n2204  \n2205  \n2206  \n2207  \n2208  \n2209  \n2210  \n2211  \n2212  \n2213  \n2214  \n2215  \n2216  \n2217  \n2218  \n2219  \n2220  \n2221  \n2222  \n2223  \n2224  \n2225  \n2226  \n2227  \n2228  \n2229  \n2230  \n2231  \n2232  \n2233  \n2234  \n2235  \n2236  \n2237  \n2238  \n2239  \n2240  \n2241  \n2242  \n2243  \n2244  \n2245  \n2246  \n2247  \n2248  \n2249  \n2250  \n2251  \n2252  \n2253  \n2254  \n2255  \n2256  \n2257  \n2258  \n2259  \n2260  \n2261  \n2262  \n2263  \n2264  \n2265  \n2266  \n2267  \n2268  \n2269  \n2270  \n2271  \n2272  \n2273  \n2274  \n2275  \n2276  \n2277  \n2278  ",
            "    /**\n     * @param restartZk If {@code true} in background restarts on of ZK servers.\n     * @param closeClientSock If {@code true} in background closes zk clients' sockets.\n     * @throws Exception If failed.\n     */\n    private void topologyChangeWithRestarts(boolean restartZk, boolean closeClientSock) throws Exception {\n        sesTimeout = 30_000;\n\n        if (closeClientSock)\n            testSockNio = true;\n\n        long stopTime = System.currentTimeMillis() + SF.applyLB(60_000, 5_000);\n\n        AtomicBoolean stop = new AtomicBoolean();\n\n        IgniteInternalFuture<?> fut1 = null;\n\n        IgniteInternalFuture<?> fut2 = null;\n\n        try {\n            fut1 = restartZk ? startRestartZkServers(stopTime, stop) : null;\n            fut2 = closeClientSock ? startCloseZkClientSocket(stopTime, stop) : null;\n\n            int INIT_NODES = 10;\n\n            startGridsMultiThreaded(INIT_NODES);\n\n            final int MAX_NODES = 20;\n\n            final List<Integer> startedNodes = new ArrayList<>();\n\n            for (int i = 0; i < INIT_NODES; i++)\n                startedNodes.add(i);\n\n            ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n            final AtomicInteger startIdx = new AtomicInteger(INIT_NODES);\n\n            while (System.currentTimeMillis() < stopTime) {\n                if (startedNodes.size() >= MAX_NODES) {\n                    int stopNodes = rnd.nextInt(5) + 1;\n\n                    log.info(\"Next, stop nodes: \" + stopNodes);\n\n                    final List<Integer> idxs = new ArrayList<>();\n\n                    while (idxs.size() < stopNodes) {\n                        Integer stopIdx = rnd.nextInt(startedNodes.size());\n\n                        if (!idxs.contains(stopIdx))\n                            idxs.add(startedNodes.get(stopIdx));\n                    }\n\n                    GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                        @Override public void apply(Integer threadIdx) {\n                            int stopNodeIdx = idxs.get(threadIdx);\n\n                            info(\"Stop node: \" + stopNodeIdx);\n\n                            stopGrid(stopNodeIdx);\n                        }\n                    }, stopNodes, \"stop-node\");\n\n                    startedNodes.removeAll(idxs);\n                }\n                else {\n                    int startNodes = rnd.nextInt(5) + 1;\n\n                    log.info(\"Next, start nodes: \" + startNodes);\n\n                    GridTestUtils.runMultiThreaded(new Callable<Void>() {\n                        @Override public Void call() throws Exception {\n                            int idx = startIdx.incrementAndGet();\n\n                            log.info(\"Start node: \" + idx);\n\n                            startGrid(idx);\n\n                            synchronized (startedNodes) {\n                                startedNodes.add(idx);\n                            }\n\n                            return null;\n                        }\n                    }, startNodes, \"start-node\");\n                }\n\n                U.sleep(rnd.nextInt(100) + 1);\n            }\n        }\n        finally {\n            stop.set(true);\n        }\n\n        if (fut1 != null)\n            fut1.get();\n\n        if (fut2 != null)\n            fut2.get();\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutTenNodesTwoBackups()",
            " 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537 -\n 538  \n 539  \n 540  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutTenNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 10;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithPut(duration, 5, 5);\n    }",
            " 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540 +\n 541  \n 542  \n 543  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutTenNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 10;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithPut(duration, 5, 5);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxEightNodesTwoBackups()",
            " 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520 -\n 521  \n 522  \n 523  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxEightNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 8;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithTx(duration, 4, 4, 3);\n    }",
            " 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523 +\n 524  \n 525  \n 526  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxEightNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 8;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithTx(duration, 4, 4, 3);\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::randomTopologyChanges(boolean,boolean)",
            "4497  \n4498  \n4499  \n4500  \n4501  \n4502  \n4503  \n4504  \n4505  \n4506  \n4507  \n4508  \n4509  \n4510  \n4511  \n4512  \n4513  \n4514 -\n4515  \n4516  \n4517  \n4518  \n4519  \n4520  \n4521  \n4522  \n4523  \n4524  \n4525  \n4526  \n4527  \n4528  \n4529  \n4530  \n4531  \n4532  \n4533  \n4534  \n4535  \n4536  \n4537  \n4538  \n4539  \n4540  \n4541  \n4542  \n4543  \n4544  \n4545  \n4546  \n4547  \n4548  \n4549  \n4550  \n4551  \n4552  \n4553  \n4554  \n4555  \n4556  \n4557  \n4558  \n4559  \n4560  \n4561  \n4562  \n4563  \n4564  \n4565  \n4566  \n4567  \n4568  \n4569  \n4570  \n4571  \n4572  \n4573  \n4574  \n4575  \n4576  \n4577  \n4578  \n4579  \n4580  \n4581  \n4582  \n4583  \n4584  \n4585  \n4586  \n4587  \n4588  \n4589  \n4590  \n4591  \n4592  \n4593  \n4594  \n4595  \n4596  \n4597  \n4598  \n4599  \n4600  \n4601  \n4602  \n4603  ",
            "    /**\n     * @param restartZk If {@code true} in background restarts on of ZK servers.\n     * @param closeClientSock If {@code true} in background closes zk clients' sockets.\n     * @throws Exception If failed.\n     */\n    private void randomTopologyChanges(boolean restartZk, boolean closeClientSock) throws Exception {\n        sesTimeout = 30_000;\n\n        if (closeClientSock)\n            testSockNio = true;\n\n        List<Integer> startedNodes = new ArrayList<>();\n        List<String> startedCaches = new ArrayList<>();\n\n        int nextNodeIdx = 0;\n        int nextCacheIdx = 0;\n\n        long stopTime = System.currentTimeMillis() + 60_000;\n\n        int MAX_NODES = 20;\n        int MAX_CACHES = 10;\n\n        AtomicBoolean stop = new AtomicBoolean();\n\n        IgniteInternalFuture<?> fut1 = restartZk ? startRestartZkServers(stopTime, stop) : null;\n        IgniteInternalFuture<?> fut2 = closeClientSock ? startCloseZkClientSocket(stopTime, stop) : null;\n\n        try {\n            ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n            while (System.currentTimeMillis() < stopTime) {\n                if (startedNodes.size() > 0 && rnd.nextInt(10) == 0) {\n                    boolean startCache = startedCaches.size() < 2 ||\n                        (startedCaches.size() < MAX_CACHES && rnd.nextInt(5) != 0);\n\n                    int nodeIdx = startedNodes.get(rnd.nextInt(startedNodes.size()));\n\n                    if (startCache) {\n                        String cacheName = \"cache-\" + nextCacheIdx++;\n\n                        log.info(\"Next, start new cache [cacheName=\" + cacheName +\n                            \", node=\" + nodeIdx +\n                            \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                            \", curCaches=\" + startedCaches.size() + ']');\n\n                        ignite(nodeIdx).createCache(new CacheConfiguration<>(cacheName));\n\n                        startedCaches.add(cacheName);\n                    }\n                    else {\n                        if (startedCaches.size() > 1) {\n                            String cacheName = startedCaches.get(rnd.nextInt(startedCaches.size()));\n\n                            log.info(\"Next, stop cache [nodeIdx=\" + nodeIdx +\n                                \", node=\" + nodeIdx +\n                                \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                                \", cacheName=\" + startedCaches.size() + ']');\n\n                            ignite(nodeIdx).destroyCache(cacheName);\n\n                            assertTrue(startedCaches.remove(cacheName));\n                        }\n                    }\n                }\n                else {\n                    boolean startNode = startedNodes.size() < 2 ||\n                        (startedNodes.size() < MAX_NODES && rnd.nextInt(5) != 0);\n\n                    if (startNode) {\n                        int nodeIdx = nextNodeIdx++;\n\n                        log.info(\"Next, start new node [nodeIdx=\" + nodeIdx +\n                            \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                            \", curNodes=\" + startedNodes.size() + ']');\n\n                        startGrid(nodeIdx);\n\n                        assertTrue(startedNodes.add(nodeIdx));\n                    }\n                    else {\n                        if (startedNodes.size() > 1) {\n                            int nodeIdx = startedNodes.get(rnd.nextInt(startedNodes.size()));\n\n                            log.info(\"Next, stop [nodeIdx=\" + nodeIdx +\n                                \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                                \", curNodes=\" + startedNodes.size() + ']');\n\n                            stopGrid(nodeIdx);\n\n                            assertTrue(startedNodes.remove((Integer)nodeIdx));\n                        }\n                    }\n                }\n\n                U.sleep(rnd.nextInt(100) + 1);\n            }\n        }\n        finally {\n            stop.set(true);\n        }\n\n        if (fut1 != null)\n            fut1.get();\n\n        if (fut2 != null)\n            fut2.get();\n    }",
            "4498  \n4499  \n4500  \n4501  \n4502  \n4503  \n4504  \n4505  \n4506  \n4507  \n4508  \n4509  \n4510  \n4511  \n4512  \n4513  \n4514  \n4515 +\n4516  \n4517  \n4518  \n4519  \n4520  \n4521  \n4522  \n4523  \n4524  \n4525  \n4526  \n4527  \n4528  \n4529  \n4530  \n4531  \n4532  \n4533  \n4534  \n4535  \n4536  \n4537  \n4538  \n4539  \n4540  \n4541  \n4542  \n4543  \n4544  \n4545  \n4546  \n4547  \n4548  \n4549  \n4550  \n4551  \n4552  \n4553  \n4554  \n4555  \n4556  \n4557  \n4558  \n4559  \n4560  \n4561  \n4562  \n4563  \n4564  \n4565  \n4566  \n4567  \n4568  \n4569  \n4570  \n4571  \n4572  \n4573  \n4574  \n4575  \n4576  \n4577  \n4578  \n4579  \n4580  \n4581  \n4582  \n4583  \n4584  \n4585  \n4586  \n4587  \n4588  \n4589  \n4590  \n4591  \n4592  \n4593  \n4594  \n4595  \n4596  \n4597  \n4598  \n4599  \n4600  \n4601  \n4602  \n4603  \n4604  ",
            "    /**\n     * @param restartZk If {@code true} in background restarts on of ZK servers.\n     * @param closeClientSock If {@code true} in background closes zk clients' sockets.\n     * @throws Exception If failed.\n     */\n    private void randomTopologyChanges(boolean restartZk, boolean closeClientSock) throws Exception {\n        sesTimeout = 30_000;\n\n        if (closeClientSock)\n            testSockNio = true;\n\n        List<Integer> startedNodes = new ArrayList<>();\n        List<String> startedCaches = new ArrayList<>();\n\n        int nextNodeIdx = 0;\n        int nextCacheIdx = 0;\n\n        long stopTime = System.currentTimeMillis() + SF.applyLB(60_000, 5_000);\n\n        int MAX_NODES = 20;\n        int MAX_CACHES = 10;\n\n        AtomicBoolean stop = new AtomicBoolean();\n\n        IgniteInternalFuture<?> fut1 = restartZk ? startRestartZkServers(stopTime, stop) : null;\n        IgniteInternalFuture<?> fut2 = closeClientSock ? startCloseZkClientSocket(stopTime, stop) : null;\n\n        try {\n            ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n            while (System.currentTimeMillis() < stopTime) {\n                if (startedNodes.size() > 0 && rnd.nextInt(10) == 0) {\n                    boolean startCache = startedCaches.size() < 2 ||\n                        (startedCaches.size() < MAX_CACHES && rnd.nextInt(5) != 0);\n\n                    int nodeIdx = startedNodes.get(rnd.nextInt(startedNodes.size()));\n\n                    if (startCache) {\n                        String cacheName = \"cache-\" + nextCacheIdx++;\n\n                        log.info(\"Next, start new cache [cacheName=\" + cacheName +\n                            \", node=\" + nodeIdx +\n                            \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                            \", curCaches=\" + startedCaches.size() + ']');\n\n                        ignite(nodeIdx).createCache(new CacheConfiguration<>(cacheName));\n\n                        startedCaches.add(cacheName);\n                    }\n                    else {\n                        if (startedCaches.size() > 1) {\n                            String cacheName = startedCaches.get(rnd.nextInt(startedCaches.size()));\n\n                            log.info(\"Next, stop cache [nodeIdx=\" + nodeIdx +\n                                \", node=\" + nodeIdx +\n                                \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                                \", cacheName=\" + startedCaches.size() + ']');\n\n                            ignite(nodeIdx).destroyCache(cacheName);\n\n                            assertTrue(startedCaches.remove(cacheName));\n                        }\n                    }\n                }\n                else {\n                    boolean startNode = startedNodes.size() < 2 ||\n                        (startedNodes.size() < MAX_NODES && rnd.nextInt(5) != 0);\n\n                    if (startNode) {\n                        int nodeIdx = nextNodeIdx++;\n\n                        log.info(\"Next, start new node [nodeIdx=\" + nodeIdx +\n                            \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                            \", curNodes=\" + startedNodes.size() + ']');\n\n                        startGrid(nodeIdx);\n\n                        assertTrue(startedNodes.add(nodeIdx));\n                    }\n                    else {\n                        if (startedNodes.size() > 1) {\n                            int nodeIdx = startedNodes.get(rnd.nextInt(startedNodes.size()));\n\n                            log.info(\"Next, stop [nodeIdx=\" + nodeIdx +\n                                \", crd=\" + (startedNodes.isEmpty() ? null : Collections.min(startedNodes)) +\n                                \", curNodes=\" + startedNodes.size() + ']');\n\n                            stopGrid(nodeIdx);\n\n                            assertTrue(startedNodes.remove((Integer)nodeIdx));\n                        }\n                    }\n                }\n\n                U.sleep(rnd.nextInt(100) + 1);\n            }\n        }\n        finally {\n            stop.set(true);\n        }\n\n        if (fut1 != null)\n            fut1.get();\n\n        if (fut2 != null)\n            fut2.get();\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::disconnectOnServersLeft(int,int)",
            "3805  \n3806  \n3807  \n3808  \n3809  \n3810  \n3811  \n3812  \n3813  \n3814  \n3815  \n3816  \n3817 -\n3818  \n3819  \n3820  \n3821  \n3822  \n3823  \n3824  \n3825  \n3826  \n3827  \n3828  \n3829  \n3830  \n3831  \n3832  \n3833  \n3834  \n3835  \n3836  \n3837  \n3838  \n3839  \n3840  \n3841  \n3842  \n3843  \n3844  \n3845  \n3846  \n3847  \n3848  \n3849  \n3850  \n3851  \n3852  \n3853  \n3854  \n3855  \n3856  \n3857  \n3858  \n3859  \n3860  \n3861  \n3862  \n3863  \n3864  \n3865  \n3866  \n3867  \n3868  \n3869  \n3870  \n3871  \n3872  \n3873  \n3874  ",
            "    /**\n     * @param srvs Number of servers.\n     * @param clients Number of clients.\n     * @throws Exception If failed.\n     */\n    private void disconnectOnServersLeft(int srvs, int clients) throws Exception {\n        startGridsMultiThreaded(srvs);\n\n        clientMode(true);\n\n        startGridsMultiThreaded(srvs, clients);\n\n        for (int i = 0; i < 5; i++) {\n            info(\"Iteration: \" + i);\n\n            final CountDownLatch disconnectLatch = new CountDownLatch(clients);\n            final CountDownLatch reconnectLatch = new CountDownLatch(clients);\n\n            IgnitePredicate<Event> p = new IgnitePredicate<Event>() {\n                @Override public boolean apply(Event evt) {\n                    if (evt.type() == EVT_CLIENT_NODE_DISCONNECTED) {\n                        log.info(\"Disconnected: \" + evt);\n\n                        disconnectLatch.countDown();\n                    }\n                    else if (evt.type() == EVT_CLIENT_NODE_RECONNECTED) {\n                        log.info(\"Reconnected: \" + evt);\n\n                        reconnectLatch.countDown();\n\n                        return false;\n                    }\n\n                    return true;\n                }\n            };\n\n            for (int c = 0; c < clients; c++) {\n                Ignite client = ignite(srvs + c);\n\n                assertTrue(client.configuration().isClientMode());\n\n                client.events().localListen(p, EVT_CLIENT_NODE_DISCONNECTED, EVT_CLIENT_NODE_RECONNECTED);\n            }\n\n            log.info(\"Stop all servers.\");\n\n            GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                @Override public void apply(Integer threadIdx) {\n                    stopGrid(getTestIgniteInstanceName(threadIdx), true, false);\n                }\n            }, srvs, \"stop-server\");\n\n            waitReconnectEvent(log, disconnectLatch);\n\n            evts.clear();\n\n            clientMode(false);\n\n            log.info(\"Restart servers.\");\n\n            startGridsMultiThreaded(0, srvs);\n\n            waitReconnectEvent(log, reconnectLatch);\n\n            waitForTopology(srvs + clients);\n\n            log.info(\"Reconnect finished.\");\n        }\n    }",
            "3806  \n3807  \n3808  \n3809  \n3810  \n3811  \n3812  \n3813  \n3814  \n3815  \n3816  \n3817  \n3818 +\n3819  \n3820  \n3821  \n3822  \n3823  \n3824  \n3825  \n3826  \n3827  \n3828  \n3829  \n3830  \n3831  \n3832  \n3833  \n3834  \n3835  \n3836  \n3837  \n3838  \n3839  \n3840  \n3841  \n3842  \n3843  \n3844  \n3845  \n3846  \n3847  \n3848  \n3849  \n3850  \n3851  \n3852  \n3853  \n3854  \n3855  \n3856  \n3857  \n3858  \n3859  \n3860  \n3861  \n3862  \n3863  \n3864  \n3865  \n3866  \n3867  \n3868  \n3869  \n3870  \n3871  \n3872  \n3873  \n3874  \n3875  ",
            "    /**\n     * @param srvs Number of servers.\n     * @param clients Number of clients.\n     * @throws Exception If failed.\n     */\n    private void disconnectOnServersLeft(int srvs, int clients) throws Exception {\n        startGridsMultiThreaded(srvs);\n\n        clientMode(true);\n\n        startGridsMultiThreaded(srvs, clients);\n\n        for (int i = 0; i < SF.applyLB(5, 2); i++) {\n            info(\"Iteration: \" + i);\n\n            final CountDownLatch disconnectLatch = new CountDownLatch(clients);\n            final CountDownLatch reconnectLatch = new CountDownLatch(clients);\n\n            IgnitePredicate<Event> p = new IgnitePredicate<Event>() {\n                @Override public boolean apply(Event evt) {\n                    if (evt.type() == EVT_CLIENT_NODE_DISCONNECTED) {\n                        log.info(\"Disconnected: \" + evt);\n\n                        disconnectLatch.countDown();\n                    }\n                    else if (evt.type() == EVT_CLIENT_NODE_RECONNECTED) {\n                        log.info(\"Reconnected: \" + evt);\n\n                        reconnectLatch.countDown();\n\n                        return false;\n                    }\n\n                    return true;\n                }\n            };\n\n            for (int c = 0; c < clients; c++) {\n                Ignite client = ignite(srvs + c);\n\n                assertTrue(client.configuration().isClientMode());\n\n                client.events().localListen(p, EVT_CLIENT_NODE_DISCONNECTED, EVT_CLIENT_NODE_RECONNECTED);\n            }\n\n            log.info(\"Stop all servers.\");\n\n            GridTestUtils.runMultiThreaded(new IgniteInClosure<Integer>() {\n                @Override public void apply(Integer threadIdx) {\n                    stopGrid(getTestIgniteInstanceName(threadIdx), true, false);\n                }\n            }, srvs, \"stop-server\");\n\n            waitReconnectEvent(log, disconnectLatch);\n\n            evts.clear();\n\n            clientMode(false);\n\n            log.info(\"Restart servers.\");\n\n            startGridsMultiThreaded(0, srvs);\n\n            waitReconnectEvent(log, reconnectLatch);\n\n            waitForTopology(srvs + clients);\n\n            log.info(\"Reconnect finished.\");\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutTwoNodesNoBackups()",
            " 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299 -\n 300  \n 301  \n 302  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutTwoNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 30000;\n\n        checkRestartWithPut(duration, 1, 1);\n    }",
            " 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302 +\n 303  \n 304  \n 305  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutTwoNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(30_000, 3_000);\n\n        checkRestartWithPut(duration, 1, 1);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxFourNodesOneBackupsOffheapEvict()",
            " 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452 -\n 453  \n 454  \n 455  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxFourNodesOneBackupsOffheapEvict() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 100_000;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = true;\n\n        long duration = 30_000;\n\n        checkRestartWithTx(duration, 2, 2, 100);\n    }",
            " 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455 +\n 456  \n 457  \n 458  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxFourNodesOneBackupsOffheapEvict() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 100_000;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = true;\n\n        long duration = SF.applyLB(30_000, 3_000);\n\n        checkRestartWithTx(duration, 2, 2, 100);\n    }"
        ],
        [
            "CacheSerializableTransactionsTest::testReadWriteAccountTx()",
            "2908  \n2909  \n2910  \n2911  \n2912  \n2913  \n2914  \n2915  \n2916  \n2917  \n2918  \n2919  \n2920  \n2921  \n2922 -\n2923 -\n2924  \n2925  \n2926  \n2927  \n2928  \n2929  \n2930  \n2931  \n2932  \n2933  \n2934  \n2935  \n2936  \n2937  \n2938  \n2939  \n2940  \n2941  \n2942  \n2943  \n2944  \n2945  \n2946  \n2947  \n2948  \n2949  \n2950  \n2951  \n2952  \n2953  \n2954  \n2955  \n2956  \n2957  \n2958  \n2959  \n2960  \n2961  \n2962  \n2963  \n2964  \n2965  \n2966  \n2967  \n2968  \n2969  \n2970  \n2971  \n2972  \n2973  \n2974  \n2975  \n2976  \n2977  \n2978  \n2979  \n2980  \n2981  \n2982  \n2983  \n2984  \n2985  \n2986  \n2987  \n2988  \n2989  \n2990  \n2991  \n2992  \n2993  \n2994  \n2995  \n2996  \n2997  \n2998  \n2999  \n3000  \n3001  \n3002  \n3003  \n3004  \n3005  \n3006  \n3007  \n3008  \n3009  \n3010  \n3011  \n3012  \n3013  \n3014  \n3015  \n3016  \n3017  \n3018  \n3019  \n3020  \n3021  \n3022  \n3023  \n3024  \n3025  \n3026  \n3027  \n3028  \n3029  \n3030  \n3031  \n3032  \n3033  \n3034  \n3035  \n3036  \n3037  \n3038  \n3039  \n3040  \n3041  \n3042  \n3043  \n3044  \n3045  \n3046  \n3047  \n3048  \n3049  \n3050  \n3051  \n3052  \n3053  \n3054  \n3055  \n3056  \n3057  \n3058  \n3059  \n3060 -\n3061  \n3062  \n3063  \n3064  \n3065  \n3066  \n3067  \n3068  \n3069  \n3070  \n3071  \n3072  \n3073  \n3074  \n3075  \n3076  \n3077  \n3078  \n3079  \n3080  \n3081  \n3082  \n3083  \n3084  \n3085  \n3086  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testReadWriteAccountTx() throws Exception {\n        final CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED,\n            FULL_SYNC,\n            1,\n            false,\n            false);\n\n        ignite(0).createCache(ccfg);\n\n        try {\n            final int ACCOUNTS = 50;\n            final int VAL_PER_ACCOUNT = 1000;\n\n            IgniteCache<Integer, Account> cache0 = ignite(0).cache(ccfg.getName());\n\n            final Set<Integer> keys = new HashSet<>();\n\n            for (int i = 0; i < ACCOUNTS; i++) {\n                cache0.put(i, new Account(VAL_PER_ACCOUNT));\n\n                keys.add(i);\n            }\n\n            final List<Ignite> clients = clients();\n\n            final AtomicBoolean stop = new AtomicBoolean();\n\n            final AtomicInteger idx = new AtomicInteger();\n\n            IgniteInternalFuture<?> readFut = GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    try {\n                        int threadIdx = idx.getAndIncrement();\n\n                        int nodeIdx = threadIdx % (SRVS + CLIENTS);\n\n                        Ignite node = ignite(nodeIdx);\n\n                        IgniteCache<Integer, Account> cache = node.cache(ccfg.getName());\n\n                        IgniteTransactions txs = node.transactions();\n\n                        Integer putKey = ACCOUNTS + threadIdx;\n\n                        while (!stop.get()) {\n                            int sum;\n\n                            while (true) {\n                                sum = 0;\n\n                                try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                    Map<Integer, Account> data = cache.getAll(keys);\n\n                                    for (int i = 0; i < ACCOUNTS; i++) {\n                                        Account account = data.get(i);\n\n                                        assertNotNull(account);\n\n                                        sum += account.value();\n                                    }\n\n                                    if (ThreadLocalRandom.current().nextBoolean())\n                                        cache.put(putKey, new Account(sum));\n\n                                    tx.commit();\n                                }\n                                catch (TransactionOptimisticException ignored) {\n                                    continue;\n                                }\n\n                                break;\n                            }\n\n                            assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n                        }\n\n                        return null;\n                    }\n                    catch (Throwable e) {\n                        stop.set(true);\n\n                        log.error(\"Unexpected error: \" + e);\n\n                        throw e;\n                    }\n                }\n            }, (SRVS + CLIENTS) * 2, \"update-thread\");\n\n            IgniteInternalFuture<?> updateFut = GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    try {\n                        int nodeIdx = idx.getAndIncrement() % clients.size();\n\n                        Ignite node = clients.get(nodeIdx);\n\n                        IgniteCache<Integer, Account> cache = node.cache(ccfg.getName());\n\n                        IgniteTransactions txs = node.transactions();\n\n                        ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                        while (!stop.get()) {\n                            int id1 = rnd.nextInt(ACCOUNTS);\n\n                            int id2 = rnd.nextInt(ACCOUNTS);\n\n                            while (id2 == id1)\n                                id2 = rnd.nextInt(ACCOUNTS);\n\n                            while (true) {\n                                try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                    Account a1 = cache.get(id1);\n                                    Account a2 = cache.get(id2);\n\n                                    assertNotNull(a1);\n                                    assertNotNull(a2);\n\n                                    if (a1.value() > 0) {\n                                        a1 = new Account(a1.value() - 1);\n                                        a2 = new Account(a2.value() + 1);\n                                    }\n\n                                    cache.put(id1, a1);\n                                    cache.put(id2, a2);\n\n                                    tx.commit();\n                                }\n                                catch (TransactionOptimisticException ignored) {\n                                    continue;\n                                }\n\n                                break;\n                            }\n                        }\n\n                        return null;\n                    }\n                    catch (Throwable e) {\n                        stop.set(true);\n\n                        log.error(\"Unexpected error: \" + e);\n\n                        throw e;\n                    }\n                }\n            }, 2, \"update-thread\");\n\n            try {\n                U.sleep(15_000);\n            }\n            finally {\n                stop.set(true);\n            }\n\n            readFut.get();\n            updateFut.get();\n            int sum = 0;\n\n            for (int i = 0; i < ACCOUNTS; i++) {\n                Account a = cache0.get(i);\n\n                assertNotNull(a);\n                assertTrue(a.value() >= 0);\n\n                log.info(\"Account: \" + a.value());\n\n                sum += a.value();\n            }\n\n            assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n        }\n        finally {\n            ignite(0).destroyCache(ccfg.getName());\n        }\n    }",
            "2909  \n2910  \n2911  \n2912  \n2913  \n2914  \n2915  \n2916  \n2917  \n2918  \n2919  \n2920  \n2921  \n2922  \n2923 +\n2924 +\n2925  \n2926  \n2927  \n2928  \n2929  \n2930  \n2931  \n2932  \n2933  \n2934  \n2935  \n2936  \n2937  \n2938  \n2939  \n2940  \n2941  \n2942  \n2943  \n2944  \n2945  \n2946  \n2947  \n2948  \n2949  \n2950  \n2951  \n2952  \n2953  \n2954  \n2955  \n2956  \n2957  \n2958  \n2959  \n2960  \n2961  \n2962  \n2963  \n2964  \n2965  \n2966  \n2967  \n2968  \n2969  \n2970  \n2971  \n2972  \n2973  \n2974  \n2975  \n2976  \n2977  \n2978  \n2979  \n2980  \n2981  \n2982  \n2983  \n2984  \n2985  \n2986  \n2987  \n2988  \n2989  \n2990  \n2991  \n2992  \n2993  \n2994  \n2995  \n2996  \n2997  \n2998  \n2999  \n3000  \n3001  \n3002  \n3003  \n3004  \n3005  \n3006  \n3007  \n3008  \n3009  \n3010  \n3011  \n3012  \n3013  \n3014  \n3015  \n3016  \n3017  \n3018  \n3019  \n3020  \n3021  \n3022  \n3023  \n3024  \n3025  \n3026  \n3027  \n3028  \n3029  \n3030  \n3031  \n3032  \n3033  \n3034  \n3035  \n3036  \n3037  \n3038  \n3039  \n3040  \n3041  \n3042  \n3043  \n3044  \n3045  \n3046  \n3047  \n3048  \n3049  \n3050  \n3051  \n3052  \n3053  \n3054  \n3055  \n3056  \n3057  \n3058  \n3059  \n3060  \n3061 +\n3062  \n3063  \n3064  \n3065  \n3066  \n3067  \n3068  \n3069  \n3070  \n3071  \n3072  \n3073  \n3074  \n3075  \n3076  \n3077  \n3078  \n3079  \n3080  \n3081  \n3082  \n3083  \n3084  \n3085  \n3086  \n3087  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testReadWriteAccountTx() throws Exception {\n        final CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED,\n            FULL_SYNC,\n            1,\n            false,\n            false);\n\n        ignite(0).createCache(ccfg);\n\n        try {\n            final int ACCOUNTS = SF.applyLB(50, 5);\n            final int VAL_PER_ACCOUNT = SF.applyLB(1000, 10);\n\n            IgniteCache<Integer, Account> cache0 = ignite(0).cache(ccfg.getName());\n\n            final Set<Integer> keys = new HashSet<>();\n\n            for (int i = 0; i < ACCOUNTS; i++) {\n                cache0.put(i, new Account(VAL_PER_ACCOUNT));\n\n                keys.add(i);\n            }\n\n            final List<Ignite> clients = clients();\n\n            final AtomicBoolean stop = new AtomicBoolean();\n\n            final AtomicInteger idx = new AtomicInteger();\n\n            IgniteInternalFuture<?> readFut = GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    try {\n                        int threadIdx = idx.getAndIncrement();\n\n                        int nodeIdx = threadIdx % (SRVS + CLIENTS);\n\n                        Ignite node = ignite(nodeIdx);\n\n                        IgniteCache<Integer, Account> cache = node.cache(ccfg.getName());\n\n                        IgniteTransactions txs = node.transactions();\n\n                        Integer putKey = ACCOUNTS + threadIdx;\n\n                        while (!stop.get()) {\n                            int sum;\n\n                            while (true) {\n                                sum = 0;\n\n                                try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                    Map<Integer, Account> data = cache.getAll(keys);\n\n                                    for (int i = 0; i < ACCOUNTS; i++) {\n                                        Account account = data.get(i);\n\n                                        assertNotNull(account);\n\n                                        sum += account.value();\n                                    }\n\n                                    if (ThreadLocalRandom.current().nextBoolean())\n                                        cache.put(putKey, new Account(sum));\n\n                                    tx.commit();\n                                }\n                                catch (TransactionOptimisticException ignored) {\n                                    continue;\n                                }\n\n                                break;\n                            }\n\n                            assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n                        }\n\n                        return null;\n                    }\n                    catch (Throwable e) {\n                        stop.set(true);\n\n                        log.error(\"Unexpected error: \" + e);\n\n                        throw e;\n                    }\n                }\n            }, (SRVS + CLIENTS) * 2, \"update-thread\");\n\n            IgniteInternalFuture<?> updateFut = GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n                @Override public Void call() throws Exception {\n                    try {\n                        int nodeIdx = idx.getAndIncrement() % clients.size();\n\n                        Ignite node = clients.get(nodeIdx);\n\n                        IgniteCache<Integer, Account> cache = node.cache(ccfg.getName());\n\n                        IgniteTransactions txs = node.transactions();\n\n                        ThreadLocalRandom rnd = ThreadLocalRandom.current();\n\n                        while (!stop.get()) {\n                            int id1 = rnd.nextInt(ACCOUNTS);\n\n                            int id2 = rnd.nextInt(ACCOUNTS);\n\n                            while (id2 == id1)\n                                id2 = rnd.nextInt(ACCOUNTS);\n\n                            while (true) {\n                                try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                    Account a1 = cache.get(id1);\n                                    Account a2 = cache.get(id2);\n\n                                    assertNotNull(a1);\n                                    assertNotNull(a2);\n\n                                    if (a1.value() > 0) {\n                                        a1 = new Account(a1.value() - 1);\n                                        a2 = new Account(a2.value() + 1);\n                                    }\n\n                                    cache.put(id1, a1);\n                                    cache.put(id2, a2);\n\n                                    tx.commit();\n                                }\n                                catch (TransactionOptimisticException ignored) {\n                                    continue;\n                                }\n\n                                break;\n                            }\n                        }\n\n                        return null;\n                    }\n                    catch (Throwable e) {\n                        stop.set(true);\n\n                        log.error(\"Unexpected error: \" + e);\n\n                        throw e;\n                    }\n                }\n            }, 2, \"update-thread\");\n\n            try {\n                U.sleep(SF.applyLB(15_000, 2_000));\n            }\n            finally {\n                stop.set(true);\n            }\n\n            readFut.get();\n            updateFut.get();\n            int sum = 0;\n\n            for (int i = 0; i < ACCOUNTS; i++) {\n                Account a = cache0.get(i);\n\n                assertNotNull(a);\n                assertTrue(a.value() >= 0);\n\n                log.info(\"Account: \" + a.value());\n\n                sum += a.value();\n            }\n\n            assertEquals(ACCOUNTS * VAL_PER_ACCOUNT, sum);\n        }\n        finally {\n            ignite(0).destroyCache(ccfg.getName());\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutFourNodesOneBackups()",
            " 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401 -\n 402  \n 403  \n 404  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutFourNodesOneBackups() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 60000;\n\n        checkRestartWithPut(duration, 2, 2);\n    }",
            " 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404 +\n 405  \n 406  \n 407  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutFourNodesOneBackups() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(60_000, 5_000);\n\n        checkRestartWithPut(duration, 2, 2);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutTwoNodesOneBackup()",
            " 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333 -\n 334  \n 335  \n 336  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutTwoNodesOneBackup() throws Throwable {\n        backups = 1;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 30000;\n\n        checkRestartWithPut(duration, 1, 1);\n    }",
            " 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336 +\n 337  \n 338  \n 339  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutTwoNodesOneBackup() throws Throwable {\n        backups = 1;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(30_000, 3_000);\n\n        checkRestartWithPut(duration, 1, 1);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithPutFourNodesNoBackups()",
            " 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367 -\n 368  \n 369  \n 370  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutFourNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 60000;\n\n        checkRestartWithPut(duration, 2, 2);\n    }",
            " 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370 +\n 371  \n 372  \n 373  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithPutFourNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(60_000, 5_000);\n\n        checkRestartWithPut(duration, 2, 2);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxPutAllFourNodesTwoBackups()",
            " 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588 -\n 589  \n 590  \n 591  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxPutAllFourNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithTxPutAll(duration, 2, 2);\n    }",
            " 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591 +\n 592  \n 593  \n 594  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxPutAllFourNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithTxPutAll(duration, 2, 2);\n    }"
        ],
        [
            "ZookeeperDiscoverySpiTest::testCommunicationFailureResolve_KillRandom()",
            "3086  \n3087  \n3088  \n3089  \n3090  \n3091  \n3092  \n3093  \n3094  \n3095  \n3096  \n3097  \n3098  \n3099  \n3100  \n3101  \n3102  \n3103  \n3104  \n3105  \n3106  \n3107  \n3108 -\n3109  \n3110  \n3111  \n3112  \n3113  \n3114  \n3115  \n3116  \n3117  \n3118  \n3119  \n3120  \n3121  \n3122  \n3123  \n3124  \n3125  \n3126  \n3127  \n3128  \n3129  \n3130  \n3131  \n3132  \n3133  \n3134  \n3135  \n3136  \n3137  \n3138  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testCommunicationFailureResolve_KillRandom() throws Exception {\n        sesTimeout = 2000;\n\n        testCommSpi = true;\n        commFailureRslvr = KillRandomCommunicationFailureResolver.FACTORY;\n\n        startGridsMultiThreaded(10);\n\n        clientMode(true);\n\n        startGridsMultiThreaded(10, 5);\n\n        int nodesCnt = 15;\n\n        waitForTopology(nodesCnt);\n\n        int nodeIdx = 15;\n\n        for (int i = 0; i < 10; i++) {\n            info(\"Iteration: \" + i);\n\n            ZookeeperDiscoverySpi spi = null;\n\n            for (Ignite node : G.allGrids()) {\n                ZkTestCommunicationSpi.testSpi(node).initCheckResult(100);\n\n                spi = spi(node);\n            }\n\n            assert spi != null;\n\n            try {\n                spi.resolveCommunicationFailure(spi.getRemoteNodes().iterator().next(), new Exception(\"test\"));\n            }\n            catch (IgniteSpiException ignore) {\n                // No-op.\n            }\n\n            boolean clientMode = ThreadLocalRandom.current().nextBoolean();\n\n            clientMode(clientMode);\n\n            startGrid(nodeIdx++);\n\n            nodesCnt = nodesCnt - KillRandomCommunicationFailureResolver.LAST_KILLED_NODES.size() + 1;\n\n            waitForTopology(nodesCnt);\n        }\n    }",
            "3087  \n3088  \n3089  \n3090  \n3091  \n3092  \n3093  \n3094  \n3095  \n3096  \n3097  \n3098  \n3099  \n3100  \n3101  \n3102  \n3103  \n3104  \n3105  \n3106  \n3107  \n3108  \n3109 +\n3110  \n3111  \n3112  \n3113  \n3114  \n3115  \n3116  \n3117  \n3118  \n3119  \n3120  \n3121  \n3122  \n3123  \n3124  \n3125  \n3126  \n3127  \n3128  \n3129  \n3130  \n3131  \n3132  \n3133  \n3134  \n3135  \n3136  \n3137  \n3138  \n3139  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testCommunicationFailureResolve_KillRandom() throws Exception {\n        sesTimeout = 2000;\n\n        testCommSpi = true;\n        commFailureRslvr = KillRandomCommunicationFailureResolver.FACTORY;\n\n        startGridsMultiThreaded(10);\n\n        clientMode(true);\n\n        startGridsMultiThreaded(10, 5);\n\n        int nodesCnt = 15;\n\n        waitForTopology(nodesCnt);\n\n        int nodeIdx = 15;\n\n        for (int i = 0; i < SF.applyLB(10, 2); i++) {\n            info(\"Iteration: \" + i);\n\n            ZookeeperDiscoverySpi spi = null;\n\n            for (Ignite node : G.allGrids()) {\n                ZkTestCommunicationSpi.testSpi(node).initCheckResult(100);\n\n                spi = spi(node);\n            }\n\n            assert spi != null;\n\n            try {\n                spi.resolveCommunicationFailure(spi.getRemoteNodes().iterator().next(), new Exception(\"test\"));\n            }\n            catch (IgniteSpiException ignore) {\n                // No-op.\n            }\n\n            boolean clientMode = ThreadLocalRandom.current().nextBoolean();\n\n            clientMode(clientMode);\n\n            startGrid(nodeIdx++);\n\n            nodesCnt = nodesCnt - KillRandomCommunicationFailureResolver.LAST_KILLED_NODES.size() + 1;\n\n            waitForTopology(nodesCnt);\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxTwoNodesOneBackup()",
            " 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350 -\n 351  \n 352  \n 353  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxTwoNodesOneBackup() throws Throwable {\n        backups = 1;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 30000;\n\n        checkRestartWithTx(duration, 1, 1, 3);\n    }",
            " 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353 +\n 354  \n 355  \n 356  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxTwoNodesOneBackup() throws Throwable {\n        backups = 1;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(30_000, 3_000);\n\n        checkRestartWithTx(duration, 1, 1, 3);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxTwoNodesNoBackups()",
            " 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316 -\n 317  \n 318  \n 319  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxTwoNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 30000;\n\n        checkRestartWithTx(duration, 1, 1, 3);\n    }",
            " 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319 +\n 320  \n 321  \n 322  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxTwoNodesNoBackups() throws Throwable {\n        backups = 0;\n        nodeCnt = 2;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(30_000, 3_000);\n\n        checkRestartWithTx(duration, 1, 1, 3);\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxPutAllTenNodesTwoBackups()",
            " 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571 -\n 572  \n 573  \n 574  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxPutAllTenNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 10;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 90000;\n\n        checkRestartWithTxPutAll(duration, 5, 5);\n    }",
            " 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574 +\n 575  \n 576  \n 577  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxPutAllTenNodesTwoBackups() throws Throwable {\n        backups = 2;\n        nodeCnt = 10;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(90_000, 6_000);\n\n        checkRestartWithTxPutAll(duration, 5, 5);\n    }"
        ],
        [
            "CacheSerializableTransactionsTest::incrementTxMultiple(boolean,boolean,boolean)",
            "3825  \n3826  \n3827  \n3828  \n3829  \n3830  \n3831  \n3832  \n3833  \n3834  \n3835  \n3836  \n3837  \n3838  \n3839  \n3840  \n3841  \n3842  \n3843  \n3844  \n3845  \n3846  \n3847  \n3848  \n3849  \n3850  \n3851  \n3852  \n3853  \n3854  \n3855  \n3856  \n3857  \n3858  \n3859  \n3860  \n3861  \n3862  \n3863  \n3864  \n3865  \n3866  \n3867  \n3868  \n3869  \n3870  \n3871  \n3872  \n3873  \n3874  \n3875  \n3876  \n3877  \n3878  \n3879  \n3880  \n3881  \n3882  \n3883 -\n3884  \n3885  \n3886  \n3887  \n3888  \n3889  \n3890  \n3891  \n3892  \n3893  \n3894  \n3895  \n3896  \n3897  \n3898  \n3899  \n3900  \n3901  \n3902  \n3903  \n3904  \n3905  \n3906  \n3907  \n3908  \n3909  \n3910  \n3911  \n3912  \n3913  \n3914  \n3915  \n3916  \n3917  \n3918  \n3919  \n3920  \n3921  \n3922  \n3923  \n3924  \n3925  \n3926  \n3927  \n3928  \n3929  \n3930  \n3931  \n3932  \n3933  \n3934  ",
            "    /**\n     * @param nearCache If {@code true} near cache is enabled.\n     * @param store If {@code true} cache store is enabled.\n     * @param restart If {@code true} restarts one node.\n     * @throws Exception If failed.\n     */\n    private void incrementTxMultiple(boolean nearCache, boolean store, final boolean restart) throws Exception {\n        final Ignite srv = ignite(1);\n\n        CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, store, false);\n\n        final List<Ignite> clients = clients();\n\n        final String cacheName = srv.createCache(ccfg).getName();\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        try {\n            final List<IgniteCache<Integer, Integer>> caches = new ArrayList<>();\n\n            for (Ignite client : clients) {\n                if (nearCache)\n                    caches.add(client.createNearCache(cacheName, new NearCacheConfiguration<Integer, Integer>()));\n                else\n                    caches.add(client.<Integer, Integer>cache(cacheName));\n            }\n\n            IgniteInternalFuture<?> restartFut = restart ? restartFuture(stop, null) : null;\n\n            for (int i = 0; i < 20; i += 2) {\n                final AtomicInteger cntr = new AtomicInteger();\n\n                final Integer key1 = i;\n                final Integer key2 = i + 1;\n\n                final AtomicInteger threadIdx = new AtomicInteger();\n\n                final int THREADS = 10;\n\n                final CyclicBarrier barrier = new CyclicBarrier(THREADS);\n\n                final ConcurrentSkipListSet<Integer> vals1 = new ConcurrentSkipListSet<>();\n                final ConcurrentSkipListSet<Integer> vals2 = new ConcurrentSkipListSet<>();\n\n                GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n                    @Override public Void call() throws Exception {\n                        int idx = threadIdx.getAndIncrement() % caches.size();\n\n                        IgniteCache<Integer, Integer> cache = caches.get(idx);\n\n                        Ignite ignite = cache.unwrap(Ignite.class);\n\n                        IgniteTransactions txs = ignite.transactions();\n\n                        log.info(\"Started update thread: \" + ignite.name());\n\n                        barrier.await();\n\n                        for (int i = 0; i < 1000; i++) {\n                            try {\n                                try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                    Integer val1 = cache.get(key1);\n                                    Integer val2 = cache.get(key2);\n\n                                    Integer newVal1 = val1 == null ? 1 : val1 + 1;\n                                    Integer newVal2 = val2 == null ? 1 : val2 + 1;\n\n                                    cache.put(key1, newVal1);\n                                    cache.put(key2, newVal2);\n\n                                    tx.commit();\n\n                                    assertTrue(vals1.add(newVal1));\n                                    assertTrue(vals2.add(newVal2));\n                                }\n\n                                cntr.incrementAndGet();\n                            }\n                            catch (TransactionOptimisticException ignore) {\n                                // Retry.\n                            }\n                            catch (IgniteException | CacheException e) {\n                                assertTrue(\"Unexpected exception [err=\" + e + \", cause=\" + e.getCause() + ']',\n                                    restart && X.hasCause(e, ClusterTopologyCheckedException.class));\n                            }\n                        }\n\n                        return null;\n                    }\n                }, THREADS, \"update-thread\").get();\n\n                log.info(\"Iteration [iter=\" + i + \", val=\" + cntr.get() + ']');\n\n                assertTrue(cntr.get() > 0);\n\n                checkValue(key1, cntr.get(), cacheName, restart);\n                checkValue(key2, cntr.get(), cacheName, restart);\n            }\n\n            stop.set(true);\n\n            if (restartFut != null)\n                restartFut.get();\n        }\n        finally {\n            stop.set(true);\n\n            destroyCache(cacheName);\n        }\n    }",
            "3826  \n3827  \n3828  \n3829  \n3830  \n3831  \n3832  \n3833  \n3834  \n3835  \n3836  \n3837  \n3838  \n3839  \n3840  \n3841  \n3842  \n3843  \n3844  \n3845  \n3846  \n3847  \n3848  \n3849  \n3850  \n3851  \n3852  \n3853  \n3854  \n3855  \n3856  \n3857  \n3858  \n3859  \n3860  \n3861  \n3862  \n3863  \n3864  \n3865  \n3866  \n3867  \n3868  \n3869  \n3870  \n3871  \n3872  \n3873  \n3874  \n3875  \n3876  \n3877  \n3878  \n3879  \n3880  \n3881  \n3882  \n3883  \n3884 +\n3885 +\n3886  \n3887  \n3888  \n3889  \n3890  \n3891  \n3892  \n3893  \n3894  \n3895  \n3896  \n3897  \n3898  \n3899  \n3900  \n3901  \n3902  \n3903  \n3904  \n3905  \n3906  \n3907  \n3908  \n3909  \n3910  \n3911  \n3912  \n3913  \n3914  \n3915  \n3916  \n3917  \n3918  \n3919  \n3920  \n3921  \n3922  \n3923  \n3924  \n3925  \n3926  \n3927  \n3928  \n3929  \n3930  \n3931  \n3932  \n3933  \n3934  \n3935  \n3936  ",
            "    /**\n     * @param nearCache If {@code true} near cache is enabled.\n     * @param store If {@code true} cache store is enabled.\n     * @param restart If {@code true} restarts one node.\n     * @throws Exception If failed.\n     */\n    private void incrementTxMultiple(boolean nearCache, boolean store, final boolean restart) throws Exception {\n        final Ignite srv = ignite(1);\n\n        CacheConfiguration<Integer, Integer> ccfg = cacheConfiguration(PARTITIONED, FULL_SYNC, 1, store, false);\n\n        final List<Ignite> clients = clients();\n\n        final String cacheName = srv.createCache(ccfg).getName();\n\n        final AtomicBoolean stop = new AtomicBoolean();\n\n        try {\n            final List<IgniteCache<Integer, Integer>> caches = new ArrayList<>();\n\n            for (Ignite client : clients) {\n                if (nearCache)\n                    caches.add(client.createNearCache(cacheName, new NearCacheConfiguration<Integer, Integer>()));\n                else\n                    caches.add(client.<Integer, Integer>cache(cacheName));\n            }\n\n            IgniteInternalFuture<?> restartFut = restart ? restartFuture(stop, null) : null;\n\n            for (int i = 0; i < 20; i += 2) {\n                final AtomicInteger cntr = new AtomicInteger();\n\n                final Integer key1 = i;\n                final Integer key2 = i + 1;\n\n                final AtomicInteger threadIdx = new AtomicInteger();\n\n                final int THREADS = 10;\n\n                final CyclicBarrier barrier = new CyclicBarrier(THREADS);\n\n                final ConcurrentSkipListSet<Integer> vals1 = new ConcurrentSkipListSet<>();\n                final ConcurrentSkipListSet<Integer> vals2 = new ConcurrentSkipListSet<>();\n\n                GridTestUtils.runMultiThreadedAsync(new Callable<Void>() {\n                    @Override public Void call() throws Exception {\n                        int idx = threadIdx.getAndIncrement() % caches.size();\n\n                        IgniteCache<Integer, Integer> cache = caches.get(idx);\n\n                        Ignite ignite = cache.unwrap(Ignite.class);\n\n                        IgniteTransactions txs = ignite.transactions();\n\n                        log.info(\"Started update thread: \" + ignite.name());\n\n                        barrier.await();\n\n                        final int ITERATIONS_COUNT = SF.applyLB(1000, 50);\n                        for (int i = 0; i < ITERATIONS_COUNT; i++) {\n                            try {\n                                try (Transaction tx = txs.txStart(OPTIMISTIC, SERIALIZABLE)) {\n                                    Integer val1 = cache.get(key1);\n                                    Integer val2 = cache.get(key2);\n\n                                    Integer newVal1 = val1 == null ? 1 : val1 + 1;\n                                    Integer newVal2 = val2 == null ? 1 : val2 + 1;\n\n                                    cache.put(key1, newVal1);\n                                    cache.put(key2, newVal2);\n\n                                    tx.commit();\n\n                                    assertTrue(vals1.add(newVal1));\n                                    assertTrue(vals2.add(newVal2));\n                                }\n\n                                cntr.incrementAndGet();\n                            }\n                            catch (TransactionOptimisticException ignore) {\n                                // Retry.\n                            }\n                            catch (IgniteException | CacheException e) {\n                                assertTrue(\"Unexpected exception [err=\" + e + \", cause=\" + e.getCause() + ']',\n                                    restart && X.hasCause(e, ClusterTopologyCheckedException.class));\n                            }\n                        }\n\n                        return null;\n                    }\n                }, THREADS, \"update-thread\").get();\n\n                log.info(\"Iteration [iter=\" + i + \", val=\" + cntr.get() + ']');\n\n                assertTrue(cntr.get() > 0);\n\n                checkValue(key1, cntr.get(), cacheName, restart);\n                checkValue(key2, cntr.get(), cacheName, restart);\n            }\n\n            stop.set(true);\n\n            if (restartFut != null)\n                restartFut.get();\n        }\n        finally {\n            stop.set(true);\n\n            destroyCache(cacheName);\n        }\n    }"
        ],
        [
            "GridCacheAbstractNodeRestartSelfTest::testRestartWithTxFourNodesOneBackups()",
            " 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435 -\n 436  \n 437  \n 438  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxFourNodesOneBackups() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = 60000;\n\n        checkRestartWithTx(duration, 2, 2, 3);\n    }",
            " 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438 +\n 439  \n 440  \n 441  ",
            "    /**\n     * @throws Exception If failed.\n     */\n    @Test\n    public void testRestartWithTxFourNodesOneBackups() throws Throwable {\n        backups = 1;\n        nodeCnt = 4;\n        keyCnt = 10;\n        partitions = 29;\n        rebalancMode = ASYNC;\n        evict = false;\n\n        long duration = SF.applyLB(60_000, 5_000);\n\n        checkRestartWithTx(duration, 2, 2, 3);\n    }"
        ]
    ],
    "7076f42763dcfdb28f626d2f8072e7f34b1ff8d7": [
        [
            "PageMemoryImpl::PageMemoryImpl(DirectMemoryProvider,long,GridCacheSharedContext,int,ReplacedPageWriter,GridInClosure3X,CheckpointLockStateChecker,DataRegionMetricsImpl,ThrottlingPolicy,CheckpointWriteProgressSupplier)",
            " 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  ",
            "    /**\n     * @param directMemoryProvider Memory allocator to use.\n     * @param sizes segments sizes, last is checkpoint pool size.\n     * @param ctx Cache shared context.\n     * @param pageSize Page size.\n     * @param flushDirtyPage write callback invoked when a dirty page is removed for replacement.\n     * @param changeTracker Callback invoked to track changes in pages.\n     * @param stateChecker Checkpoint lock state provider. Used to ensure lock is held by thread, which modify pages.\n     * @param memMetrics Memory metrics to track dirty pages count and page replace rate.\n     * @param throttlingPlc Write throttle enabled and its type. Null equal to none.\n     * @param cpProgressProvider checkpoint progress, base for throttling. Null disables throttling.\n     */\n    public PageMemoryImpl(\n        DirectMemoryProvider directMemoryProvider,\n        long[] sizes,\n        GridCacheSharedContext<?, ?> ctx,\n        int pageSize,\n        ReplacedPageWriter flushDirtyPage,\n        @Nullable GridInClosure3X<Long, FullPageId, PageMemoryEx> changeTracker,\n        CheckpointLockStateChecker stateChecker,\n        DataRegionMetricsImpl memMetrics,\n        @Nullable ThrottlingPolicy throttlingPlc,\n        @NotNull CheckpointWriteProgressSupplier cpProgressProvider\n    ) {\n        assert ctx != null;\n        assert pageSize > 0;\n\n        log = ctx.logger(PageMemoryImpl.class);\n\n        this.ctx = ctx;\n        this.directMemoryProvider = directMemoryProvider;\n        this.sizes = sizes;\n        this.flushDirtyPage = flushDirtyPage;\n        delayedPageReplacementTracker =\n            getBoolean(IGNITE_DELAYED_REPLACED_PAGE_WRITE, true)\n                ? new DelayedPageReplacementTracker(pageSize, flushDirtyPage, log, sizes.length - 1) :\n                null;\n        this.changeTracker = changeTracker;\n        this.stateChecker = stateChecker;\n        this.throttlingPlc = throttlingPlc != null ? throttlingPlc : ThrottlingPolicy.CHECKPOINT_BUFFER_ONLY;\n        this.cpProgressProvider = cpProgressProvider;\n\n        storeMgr = ctx.pageStore();\n        walMgr = ctx.wal();\n        encMgr = ctx.kernalContext().encryption();\n\n        assert storeMgr != null;\n        assert walMgr != null;\n        assert encMgr != null;\n\n        sysPageSize = pageSize + PAGE_OVERHEAD;\n\n        encPageSize = CU.encryptedPageSize(pageSize, ctx.kernalContext().config().getEncryptionSpi());\n\n        rwLock = new OffheapReadWriteLock(128);\n\n        this.memMetrics = memMetrics;\n    }",
            " 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327 +\n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  ",
            "    /**\n     * @param directMemoryProvider Memory allocator to use.\n     * @param sizes segments sizes, last is checkpoint pool size.\n     * @param ctx Cache shared context.\n     * @param pageSize Page size.\n     * @param flushDirtyPage write callback invoked when a dirty page is removed for replacement.\n     * @param changeTracker Callback invoked to track changes in pages.\n     * @param stateChecker Checkpoint lock state provider. Used to ensure lock is held by thread, which modify pages.\n     * @param memMetrics Memory metrics to track dirty pages count and page replace rate.\n     * @param throttlingPlc Write throttle enabled and its type. Null equal to none.\n     * @param cpProgressProvider checkpoint progress, base for throttling. Null disables throttling.\n     */\n    public PageMemoryImpl(\n        DirectMemoryProvider directMemoryProvider,\n        long[] sizes,\n        GridCacheSharedContext<?, ?> ctx,\n        int pageSize,\n        ReplacedPageWriter flushDirtyPage,\n        @Nullable GridInClosure3X<Long, FullPageId, PageMemoryEx> changeTracker,\n        CheckpointLockStateChecker stateChecker,\n        DataRegionMetricsImpl memMetrics,\n        @Nullable ThrottlingPolicy throttlingPlc,\n        @NotNull CheckpointWriteProgressSupplier cpProgressProvider\n    ) {\n        assert ctx != null;\n        assert pageSize > 0;\n\n        log = ctx.logger(PageMemoryImpl.class);\n\n        this.ctx = ctx;\n        this.directMemoryProvider = directMemoryProvider;\n        this.sizes = sizes;\n        this.flushDirtyPage = flushDirtyPage;\n        delayedPageReplacementTracker =\n            getBoolean(IGNITE_DELAYED_REPLACED_PAGE_WRITE, true)\n                ? new DelayedPageReplacementTracker(pageSize, flushDirtyPage, log, sizes.length - 1) :\n                null;\n        this.changeTracker = changeTracker;\n        this.stateChecker = stateChecker;\n        this.throttlingPlc = throttlingPlc != null ? throttlingPlc : ThrottlingPolicy.CHECKPOINT_BUFFER_ONLY;\n        this.cpProgressProvider = cpProgressProvider;\n\n        storeMgr = ctx.pageStore();\n        walMgr = ctx.wal();\n        encMgr = ctx.kernalContext().encryption();\n        encSpi = ctx.gridConfig().getEncryptionSpi();\n\n        assert storeMgr != null;\n        assert walMgr != null;\n        assert encMgr != null;\n\n        sysPageSize = pageSize + PAGE_OVERHEAD;\n\n        encPageSize = CU.encryptedPageSize(pageSize, ctx.kernalContext().config().getEncryptionSpi());\n\n        rwLock = new OffheapReadWriteLock(128);\n\n        this.memMetrics = memMetrics;\n    }"
        ],
        [
            "PageMemoryImpl::realPageSize(int)",
            " 968  \n 969  \n 970 -\n 971  \n 972  \n 973  \n 974  ",
            "    /** {@inheritDoc} */\n    @Override public int realPageSize(int grpId) {\n        if (encMgr.groupKey(grpId) == null)\n            return pageSize();\n\n        return encPageSize;\n    }",
            " 974  \n 975  \n 976 +\n 977  \n 978  \n 979  \n 980  ",
            "    /** {@inheritDoc} */\n    @Override public int realPageSize(int grpId) {\n        if ((encSpi instanceof NoopEncryptionSpi) || encMgr.groupKey(grpId) == null)\n            return pageSize();\n\n        return encPageSize;\n    }"
        ],
        [
            "RecordDataV1Serializer::writeEncryptedData(int,RecordType,ByteBuffer,ByteBuffer)",
            " 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312 -\n 313  \n 314  \n 315  \n 316  \n 317  ",
            "    /**\n     * Writes encrypted {@code clData} to {@code dst} stream.\n     *\n     * @param grpId Group id;\n     * @param plainRecType Plain record type\n     * @param clData Plain data.\n     * @param dst Destination buffer.\n     */\n    private void writeEncryptedData(int grpId, @Nullable RecordType plainRecType, ByteBuffer clData, ByteBuffer dst) {\n        int dtSz = encSpi.encryptedSize(clData.capacity());\n\n        dst.putInt(grpId);\n        dst.putInt(dtSz);\n\n        if (plainRecType != null)\n            putRecordType(dst, plainRecType);\n\n        Serializable key = cctx.kernalContext().encryption().groupKey(grpId);\n\n        assert key != null;\n\n        encSpi.encrypt(clData, key, dst);\n    }",
            " 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324 +\n 325  \n 326  \n 327  \n 328  \n 329  ",
            "    /**\n     * Writes encrypted {@code clData} to {@code dst} stream.\n     *\n     * @param grpId Group id;\n     * @param plainRecType Plain record type\n     * @param clData Plain data.\n     * @param dst Destination buffer.\n     */\n    private void writeEncryptedData(int grpId, @Nullable RecordType plainRecType, ByteBuffer clData, ByteBuffer dst) {\n        int dtSz = encSpi.encryptedSize(clData.capacity());\n\n        dst.putInt(grpId);\n        dst.putInt(dtSz);\n\n        if (plainRecType != null)\n            putRecordType(dst, plainRecType);\n\n        Serializable key = encMgr.groupKey(grpId);\n\n        assert key != null;\n\n        encSpi.encrypt(clData, key, dst);\n    }"
        ],
        [
            "RecordDataV1Serializer::needEncryption(WALRecord)",
            " 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  ",
            "    /**\n     * @param rec Record to check.\n     * @return {@code True} if this record should be encrypted.\n     */\n    private boolean needEncryption(WALRecord rec) {\n        if (!(rec instanceof WalRecordCacheGroupAware) || rec instanceof MetastoreDataRecord)\n            return false;\n\n        return needEncryption(((WalRecordCacheGroupAware)rec).groupId());\n    }",
            " 225  \n 226  \n 227  \n 228  \n 229  \n 230 +\n 231 +\n 232 +\n 233  \n 234  \n 235  \n 236  \n 237  ",
            "    /**\n     * @param rec Record to check.\n     * @return {@code True} if this record should be encrypted.\n     */\n    private boolean needEncryption(WALRecord rec) {\n        if (encSpi instanceof NoopEncryptionSpi)\n            return false;\n\n        if (!(rec instanceof WalRecordCacheGroupAware) || rec instanceof MetastoreDataRecord)\n            return false;\n\n        return needEncryption(((WalRecordCacheGroupAware)rec).groupId());\n    }"
        ],
        [
            "IgnitePageMemReplaceDelayedWriteUnitTest::createPageMemory(IgniteConfiguration,ReplacedPageWriter,int)",
            " 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  ",
            "    /**\n     * @param cfg configuration\n     * @param pageWriter writer for page replacement.\n     * @param pageSize page size\n     * @return implementation for test\n     */\n    @NotNull\n    private PageMemoryImpl createPageMemory(IgniteConfiguration cfg, ReplacedPageWriter pageWriter, int pageSize) {\n        IgniteCacheDatabaseSharedManager db = mock(GridCacheDatabaseSharedManager.class);\n\n        when(db.checkpointLockIsHeldByThread()).thenReturn(true);\n\n        GridCacheSharedContext sctx = Mockito.mock(GridCacheSharedContext.class);\n\n        when(sctx.pageStore()).thenReturn(new NoOpPageStoreManager());\n        when(sctx.wal()).thenReturn(new NoOpWALManager());\n        when(sctx.database()).thenReturn(db);\n        when(sctx.logger(any(Class.class))).thenReturn(log);\n\n        GridKernalContext kernalCtx = mock(GridKernalContext.class);\n\n        when(kernalCtx.config()).thenReturn(cfg);\n        when(kernalCtx.log(any(Class.class))).thenReturn(log);\n        when(kernalCtx.internalSubscriptionProcessor()).thenAnswer(new Answer<Object>() {\n            @Override public Object answer(InvocationOnMock mock) throws Throwable {\n                return new GridInternalSubscriptionProcessor(kernalCtx);\n            }\n        });\n        when(kernalCtx.encryption()).thenAnswer(new Answer<Object>() {\n            @Override public Object answer(InvocationOnMock mock) throws Throwable {\n                return new GridEncryptionManager(kernalCtx);\n            }\n        });\n        when(sctx.kernalContext()).thenReturn(kernalCtx);\n\n        DataRegionConfiguration regCfg = cfg.getDataStorageConfiguration().getDefaultDataRegionConfiguration();\n\n        DataRegionMetricsImpl memMetrics = new DataRegionMetricsImpl(regCfg);\n\n        long[] sizes = prepareSegmentSizes(regCfg.getMaxSize());\n\n        DirectMemoryProvider provider = new UnsafeMemoryProvider(log);\n\n        PageMemoryImpl memory = new PageMemoryImpl(provider, sizes, sctx, pageSize,\n            pageWriter, null, () -> true, memMetrics, PageMemoryImpl.ThrottlingPolicy.DISABLED,\n            mock(CheckpointWriteProgressSupplier.class));\n\n        memory.start();\n        return memory;\n    }",
            " 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221 +\n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  ",
            "    /**\n     * @param cfg configuration\n     * @param pageWriter writer for page replacement.\n     * @param pageSize page size\n     * @return implementation for test\n     */\n    @NotNull\n    private PageMemoryImpl createPageMemory(IgniteConfiguration cfg, ReplacedPageWriter pageWriter, int pageSize) {\n        IgniteCacheDatabaseSharedManager db = mock(GridCacheDatabaseSharedManager.class);\n\n        when(db.checkpointLockIsHeldByThread()).thenReturn(true);\n\n        GridCacheSharedContext sctx = Mockito.mock(GridCacheSharedContext.class);\n\n        when(sctx.gridConfig()).thenReturn(cfg);\n        when(sctx.pageStore()).thenReturn(new NoOpPageStoreManager());\n        when(sctx.wal()).thenReturn(new NoOpWALManager());\n        when(sctx.database()).thenReturn(db);\n        when(sctx.logger(any(Class.class))).thenReturn(log);\n\n        GridKernalContext kernalCtx = mock(GridKernalContext.class);\n\n        when(kernalCtx.config()).thenReturn(cfg);\n        when(kernalCtx.log(any(Class.class))).thenReturn(log);\n        when(kernalCtx.internalSubscriptionProcessor()).thenAnswer(new Answer<Object>() {\n            @Override public Object answer(InvocationOnMock mock) throws Throwable {\n                return new GridInternalSubscriptionProcessor(kernalCtx);\n            }\n        });\n        when(kernalCtx.encryption()).thenAnswer(new Answer<Object>() {\n            @Override public Object answer(InvocationOnMock mock) throws Throwable {\n                return new GridEncryptionManager(kernalCtx);\n            }\n        });\n        when(sctx.kernalContext()).thenReturn(kernalCtx);\n\n        DataRegionConfiguration regCfg = cfg.getDataStorageConfiguration().getDefaultDataRegionConfiguration();\n\n        DataRegionMetricsImpl memMetrics = new DataRegionMetricsImpl(regCfg);\n\n        long[] sizes = prepareSegmentSizes(regCfg.getMaxSize());\n\n        DirectMemoryProvider provider = new UnsafeMemoryProvider(log);\n\n        PageMemoryImpl memory = new PageMemoryImpl(provider, sizes, sctx, pageSize,\n            pageWriter, null, () -> true, memMetrics, PageMemoryImpl.ThrottlingPolicy.DISABLED,\n            mock(CheckpointWriteProgressSupplier.class));\n\n        memory.start();\n        return memory;\n    }"
        ],
        [
            "RecordDataV1Serializer::needEncryption(int)",
            " 230  \n 231  \n 232  \n 233  \n 234  \n 235 -\n 236  ",
            "    /**\n     * @param grpId Group id.\n     * @return {@code True} if this record should be encrypted.\n     */\n    private boolean needEncryption(int grpId) {\n        return cctx.kernalContext().encryption().groupKey(grpId) != null;\n    }",
            " 239  \n 240  \n 241  \n 242  \n 243  \n 244 +\n 245 +\n 246 +\n 247 +\n 248  ",
            "    /**\n     * @param grpId Group id.\n     * @return {@code True} if this record should be encrypted.\n     */\n    private boolean needEncryption(int grpId) {\n        if (encSpi instanceof NoopEncryptionSpi)\n            return false;\n\n        return encMgr.groupKey(grpId) != null;\n    }"
        ],
        [
            "RecordDataV1Serializer::readEncryptedData(ByteBufferBackedDataInput,boolean)",
            " 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261 -\n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  ",
            "    /**\n     * Reads and decrypt data from {@code in} stream.\n     *\n     * @param in Input stream.\n     * @param readType If {@code true} plain record type will be read from {@code in}.\n     * @return Plain data stream, group id, plain record type,\n     * @throws IOException If failed.\n     * @throws IgniteCheckedException If failed.\n     */\n    private T3<ByteBufferBackedDataInput, Integer, RecordType> readEncryptedData(ByteBufferBackedDataInput in,\n        boolean readType)\n        throws IOException, IgniteCheckedException {\n        int grpId = in.readInt();\n        int encRecSz = in.readInt();\n        RecordType plainRecType = null;\n\n        if (readType)\n            plainRecType = RecordV1Serializer.readRecordType(in);\n\n        byte[] encData = new byte[encRecSz];\n\n        in.readFully(encData);\n\n        Serializable key = cctx.kernalContext().encryption().groupKey(grpId);\n\n        if (key == null)\n            return new T3<>(null, grpId, plainRecType);\n\n        byte[] clData = encSpi.decrypt(encData, key);\n\n        return new T3<>(new ByteBufferBackedDataInputImpl().buffer(ByteBuffer.wrap(clData)), grpId, plainRecType);\n    }",
            " 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273 +\n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  ",
            "    /**\n     * Reads and decrypt data from {@code in} stream.\n     *\n     * @param in Input stream.\n     * @param readType If {@code true} plain record type will be read from {@code in}.\n     * @return Plain data stream, group id, plain record type,\n     * @throws IOException If failed.\n     * @throws IgniteCheckedException If failed.\n     */\n    private T3<ByteBufferBackedDataInput, Integer, RecordType> readEncryptedData(ByteBufferBackedDataInput in,\n        boolean readType)\n        throws IOException, IgniteCheckedException {\n        int grpId = in.readInt();\n        int encRecSz = in.readInt();\n        RecordType plainRecType = null;\n\n        if (readType)\n            plainRecType = RecordV1Serializer.readRecordType(in);\n\n        byte[] encData = new byte[encRecSz];\n\n        in.readFully(encData);\n\n        Serializable key = encMgr.groupKey(grpId);\n\n        if (key == null)\n            return new T3<>(null, grpId, plainRecType);\n\n        byte[] clData = encSpi.decrypt(encData, key);\n\n        return new T3<>(new ByteBufferBackedDataInputImpl().buffer(ByteBuffer.wrap(clData)), grpId, plainRecType);\n    }"
        ],
        [
            "RecordDataV1Serializer::RecordDataV1Serializer(GridCacheSharedContext)",
            " 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  ",
            "    /**\n     * @param cctx Cache shared context.\n     */\n    public RecordDataV1Serializer(GridCacheSharedContext cctx) {\n        this.cctx = cctx;\n        this.txRecordSerializer = new TxRecordSerializer();\n        this.co = cctx.kernalContext().cacheObjects();\n        this.pageSize = cctx.database().pageSize();\n        this.encSpi = cctx.gridConfig().getEncryptionSpi();\n\n        //This happen on offline WAL iteration(we don't have encryption keys available).\n        if (encSpi != null)\n            this.realPageSize = CU.encryptedPageSize(pageSize, encSpi);\n        else\n            this.realPageSize = pageSize;\n    }",
            " 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163 +\n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  ",
            "    /**\n     * @param cctx Cache shared context.\n     */\n    public RecordDataV1Serializer(GridCacheSharedContext cctx) {\n        this.cctx = cctx;\n        this.txRecordSerializer = new TxRecordSerializer();\n        this.co = cctx.kernalContext().cacheObjects();\n        this.pageSize = cctx.database().pageSize();\n        this.encSpi = cctx.gridConfig().getEncryptionSpi();\n        this.encMgr = cctx.kernalContext().encryption();\n\n        //This happen on offline WAL iteration(we don't have encryption keys available).\n        if (encSpi != null)\n            this.realPageSize = CU.encryptedPageSize(pageSize, encSpi);\n        else\n            this.realPageSize = pageSize;\n    }"
        ]
    ],
    "0af4fdf839fb1fb58e34a81bba473ec86792062b": [
        [
            "WebConsoleConfigurationSelfTest::prepareMetadata()",
            " 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170 -\n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215  \n 216  \n 217  \n 218  \n 219  \n 220  \n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632  \n 633  \n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649 -\n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661 -\n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673  \n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711  \n 712  \n 713  \n 714  \n 715  \n 716  \n 717  \n 718  \n 719  \n 720  \n 721  \n 722  \n 723  \n 724  \n 725  \n 726  \n 727  \n 728  \n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735  \n 736  \n 737  \n 738  \n 739  \n 740  \n 741  \n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786  \n 787  \n 788  \n 789  \n 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854  \n 855  \n 856  \n 857  \n 858  \n 859  \n 860  \n 861  \n 862  \n 863  \n 864  \n 865  \n 866  \n 867  \n 868  \n 869  \n 870  \n 871  \n 872  \n 873  \n 874  \n 875  \n 876  \n 877  \n 878  \n 879  \n 880  ",
            "    /**\n     * Prepare metadata for properties, which are possible to configure.\n     */\n    @SuppressWarnings(\"deprecation\")\n    protected void prepareMetadata() {\n        // Cluster configuration.\n        Set<String> igniteCfgProps = new HashSet<>();\n        igniteCfgProps.add(\"cacheConfiguration\");\n        igniteCfgProps.add(\"discoverySpi\");\n        igniteCfgProps.add(\"localHost\");\n        igniteCfgProps.add(\"atomicConfiguration\");\n        igniteCfgProps.add(\"userAttributes\");\n        igniteCfgProps.add(\"binaryConfiguration\");\n        igniteCfgProps.add(\"cacheKeyConfiguration\");\n        igniteCfgProps.add(\"checkpointSpi\");\n        igniteCfgProps.add(\"collisionSpi\");\n        igniteCfgProps.add(\"communicationSpi\");\n        igniteCfgProps.add(\"networkTimeout\");\n        igniteCfgProps.add(\"networkSendRetryDelay\");\n        igniteCfgProps.add(\"networkSendRetryCount\");\n        igniteCfgProps.add(\"connectorConfiguration\");\n        igniteCfgProps.add(\"dataStorageConfiguration\");\n        igniteCfgProps.add(\"deploymentMode\");\n        igniteCfgProps.add(\"peerClassLoadingEnabled\");\n        igniteCfgProps.add(\"peerClassLoadingMissedResourcesCacheSize\");\n        igniteCfgProps.add(\"peerClassLoadingThreadPoolSize\");\n        igniteCfgProps.add(\"peerClassLoadingLocalClassPathExclude\");\n        igniteCfgProps.add(\"classLoader\");\n        igniteCfgProps.add(\"deploymentSpi\");\n        igniteCfgProps.add(\"eventStorageSpi\");\n        igniteCfgProps.add(\"includeEventTypes\");\n        igniteCfgProps.add(\"failureDetectionTimeout\");\n        igniteCfgProps.add(\"clientFailureDetectionTimeout\");\n        igniteCfgProps.add(\"failoverSpi\");\n        igniteCfgProps.add(\"hadoopConfiguration\");\n        igniteCfgProps.add(\"loadBalancingSpi\");\n        igniteCfgProps.add(\"marshalLocalJobs\");\n\n        // Removed since 2.0.\n        // igniteCfgProps.add(\"marshallerCacheKeepAliveTime\");\n        // igniteCfgProps.add(\"marshallerCacheThreadPoolSize\");\n\n        igniteCfgProps.add(\"metricsExpireTime\");\n        igniteCfgProps.add(\"metricsHistorySize\");\n        igniteCfgProps.add(\"metricsLogFrequency\");\n        igniteCfgProps.add(\"metricsUpdateFrequency\");\n        igniteCfgProps.add(\"workDirectory\");\n        igniteCfgProps.add(\"consistentId\");\n        igniteCfgProps.add(\"warmupClosure\");\n        igniteCfgProps.add(\"activeOnStart\");\n        igniteCfgProps.add(\"cacheSanityCheckEnabled\");\n        igniteCfgProps.add(\"longQueryWarningTimeout\");\n        igniteCfgProps.add(\"odbcConfiguration\");\n        igniteCfgProps.add(\"serviceConfiguration\");\n        igniteCfgProps.add(\"sqlConnectorConfiguration\");\n        igniteCfgProps.add(\"sslContextFactory\");\n\n        // Removed since 2.0.\n        // igniteCfgProps.add(\"swapSpaceSpi\");\n\n        igniteCfgProps.add(\"publicThreadPoolSize\");\n        igniteCfgProps.add(\"systemThreadPoolSize\");\n        igniteCfgProps.add(\"serviceThreadPoolSize\");\n        igniteCfgProps.add(\"managementThreadPoolSize\");\n        igniteCfgProps.add(\"igfsThreadPoolSize\");\n        igniteCfgProps.add(\"rebalanceThreadPoolSize\");\n        igniteCfgProps.add(\"utilityCacheThreadPoolSize\");\n        igniteCfgProps.add(\"utilityCacheKeepAliveTime\");\n        igniteCfgProps.add(\"asyncCallbackPoolSize\");\n        igniteCfgProps.add(\"stripedPoolSize\");\n        igniteCfgProps.add(\"dataStreamerThreadPoolSize\");\n        igniteCfgProps.add(\"queryThreadPoolSize\");\n        igniteCfgProps.add(\"executorConfiguration\");\n\n        // Removed since 2.0.\n        // igniteCfgProps.add(\"clockSyncSamples\");\n        // igniteCfgProps.add(\"clockSyncFrequency\");\n\n        igniteCfgProps.add(\"timeServerPortBase\");\n        igniteCfgProps.add(\"timeServerPortRange\");\n        igniteCfgProps.add(\"transactionConfiguration\");\n        igniteCfgProps.add(\"clientConnectorConfiguration\");\n        igniteCfgProps.add(\"fileSystemConfiguration\");\n        igniteCfgProps.add(\"gridLogger\");\n        igniteCfgProps.add(\"pluginConfigurations\");\n        igniteCfgProps.add(\"mvccVacuumFrequency\");\n        igniteCfgProps.add(\"mvccVacuumThreadCount\");\n\n        Set<String> igniteCfgPropsDep = new HashSet<>();\n        igniteCfgPropsDep.add(\"gridName\");\n        igniteCfgPropsDep.add(\"lateAffinityAssignment\");\n        igniteCfgPropsDep.add(\"persistentStoreConfiguration\");\n        igniteCfgPropsDep.add(\"memoryConfiguration\");\n        igniteCfgPropsDep.add(\"marshaller\");\n        igniteCfgPropsDep.add(\"discoveryStartupDelay\");\n\n        Set<String> igniteCfgPropsExcl = new HashSet<>();\n        // igniteCfgPropsExcl.add(\"lifecycleBeans\");\n        igniteCfgPropsExcl.add(\"daemon\");\n        igniteCfgPropsExcl.add(\"clientMode\");\n        igniteCfgPropsExcl.add(\"indexingSpi\");\n        igniteCfgPropsExcl.add(\"nodeId\");\n\n        metadata.put(IgniteConfiguration.class,\n            new MetadataInfo(igniteCfgProps, igniteCfgPropsDep, igniteCfgPropsExcl));\n\n        Set<String> atomicCfgProps = new HashSet<>();\n        atomicCfgProps.add(\"cacheMode\");\n        atomicCfgProps.add(\"atomicSequenceReserveSize\");\n        atomicCfgProps.add(\"backups\");\n        atomicCfgProps.add(\"affinity\");\n\n        metadata.put(AtomicConfiguration.class, new MetadataInfo(atomicCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> binaryCfgProps = new HashSet<>();\n        binaryCfgProps.add(\"idMapper\");\n        binaryCfgProps.add(\"nameMapper\");\n        binaryCfgProps.add(\"serializer\");\n        binaryCfgProps.add(\"typeConfigurations\");\n        binaryCfgProps.add(\"compactFooter\");\n        metadata.put(BinaryConfiguration.class, new MetadataInfo(binaryCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> binaryTypeCfgProps = new HashSet<>();\n        binaryTypeCfgProps.add(\"typeName\");\n        binaryTypeCfgProps.add(\"idMapper\");\n        binaryTypeCfgProps.add(\"nameMapper\");\n        binaryTypeCfgProps.add(\"serializer\");\n        binaryTypeCfgProps.add(\"enum\");\n        binaryTypeCfgProps.add(\"enumValues\");\n        metadata.put(BinaryTypeConfiguration.class, new MetadataInfo(binaryTypeCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> sharedFsCheckpointProps = new HashSet<>();\n        sharedFsCheckpointProps.add(\"directoryPaths\");\n        metadata.put(SharedFsCheckpointSpi.class, new MetadataInfo(sharedFsCheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> s3CheckpointProps = new HashSet<>();\n        s3CheckpointProps.add(\"bucketNameSuffix\");\n        s3CheckpointProps.add(\"bucketEndpoint\");\n        s3CheckpointProps.add(\"sSEAlgorithm\");\n        s3CheckpointProps.add(\"checkpointListener\");\n        metadata.put(S3CheckpointSpi.class, new MetadataInfo(s3CheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> cacheCheckpointProps = new HashSet<>();\n        cacheCheckpointProps.add(\"cacheName\");\n        metadata.put(CacheCheckpointSpi.class, new MetadataInfo(cacheCheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> jdbcCheckpointProps = new HashSet<>();\n        // Only setter for dataSource.\n        // jdbcCheckpointProps.add(\"dataSourceBean\");\n        // jdbcCheckpointProps.add(\"dialect\");\n        jdbcCheckpointProps.add(\"checkpointListener\");\n        jdbcCheckpointProps.add(\"user\");\n        // Only on code generation.\n        jdbcCheckpointProps.add(\"pwd\");\n        jdbcCheckpointProps.add(\"checkpointTableName\");\n        jdbcCheckpointProps.add(\"numberOfRetries\");\n        jdbcCheckpointProps.add(\"keyFieldName\");\n        jdbcCheckpointProps.add(\"keyFieldType\");\n        jdbcCheckpointProps.add(\"valueFieldName\");\n        jdbcCheckpointProps.add(\"valueFieldType\");\n        jdbcCheckpointProps.add(\"expireDateFieldName\");\n        jdbcCheckpointProps.add(\"expireDateFieldType\");\n        metadata.put(JdbcCheckpointSpi.class, new MetadataInfo(jdbcCheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> cliConProps = new HashSet<>();\n        cliConProps.add(\"host\");\n        cliConProps.add(\"port\");\n        cliConProps.add(\"portRange\");\n        cliConProps.add(\"socketSendBufferSize\");\n        cliConProps.add(\"socketReceiveBufferSize\");\n        cliConProps.add(\"maxOpenCursorsPerConnection\");\n        cliConProps.add(\"threadPoolSize\");\n        cliConProps.add(\"tcpNoDelay\");\n        cliConProps.add(\"idleTimeout\");\n        cliConProps.add(\"sslEnabled\");\n        cliConProps.add(\"sslClientAuth\");\n        cliConProps.add(\"useIgniteSslContextFactory\");\n        cliConProps.add(\"sslContextFactory\");\n        cliConProps.add(\"jdbcEnabled\");\n        cliConProps.add(\"odbcEnabled\");\n        cliConProps.add(\"thinClientEnabled\");\n        metadata.put(ClientConnectorConfiguration.class, new MetadataInfo(cliConProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> jobStealingCollisionProps = new HashSet<>();\n        jobStealingCollisionProps.add(\"activeJobsThreshold\");\n        jobStealingCollisionProps.add(\"waitJobsThreshold\");\n        jobStealingCollisionProps.add(\"messageExpireTime\");\n        jobStealingCollisionProps.add(\"maximumStealingAttempts\");\n        jobStealingCollisionProps.add(\"stealingEnabled\");\n        jobStealingCollisionProps.add(\"externalCollisionListener\");\n        jobStealingCollisionProps.add(\"stealingAttributes\");\n        metadata.put(JobStealingCollisionSpi.class,\n            new MetadataInfo(jobStealingCollisionProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> priQueueCollisionProps = new HashSet<>();\n        priQueueCollisionProps.add(\"parallelJobsNumber\");\n        priQueueCollisionProps.add(\"waitingJobsNumber\");\n        priQueueCollisionProps.add(\"priorityAttributeKey\");\n        priQueueCollisionProps.add(\"jobPriorityAttributeKey\");\n        priQueueCollisionProps.add(\"defaultPriority\");\n        priQueueCollisionProps.add(\"starvationIncrement\");\n        priQueueCollisionProps.add(\"starvationPreventionEnabled\");\n        metadata.put(PriorityQueueCollisionSpi.class, new MetadataInfo(priQueueCollisionProps, EMPTY_FIELDS,\n            SPI_EXCLUDED_FIELDS));\n\n        Set<String> fifoQueueCollisionProps = new HashSet<>();\n        fifoQueueCollisionProps.add(\"parallelJobsNumber\");\n        fifoQueueCollisionProps.add(\"waitingJobsNumber\");\n        metadata.put(FifoQueueCollisionSpi.class,\n            new MetadataInfo(fifoQueueCollisionProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> commProps = new HashSet<>();\n        commProps.add(\"listener\");\n        commProps.add(\"localAddress\");\n        commProps.add(\"localPort\");\n        commProps.add(\"localPortRange\");\n        commProps.add(\"sharedMemoryPort\");\n        commProps.add(\"idleConnectionTimeout\");\n        commProps.add(\"connectTimeout\");\n        commProps.add(\"maxConnectTimeout\");\n        commProps.add(\"reconnectCount\");\n        commProps.add(\"socketSendBuffer\");\n        commProps.add(\"socketReceiveBuffer\");\n        commProps.add(\"slowClientQueueLimit\");\n        commProps.add(\"ackSendThreshold\");\n        commProps.add(\"messageQueueLimit\");\n        commProps.add(\"unacknowledgedMessagesBufferSize\");\n        commProps.add(\"socketWriteTimeout\");\n        commProps.add(\"selectorsCount\");\n        commProps.add(\"addressResolver\");\n        commProps.add(\"directBuffer\");\n        commProps.add(\"directSendBuffer\");\n        commProps.add(\"tcpNoDelay\");\n\n        Set<String> commPropsDep = new HashSet<>();\n        commPropsDep.add(\"discoveryStartupDelay\");\n\n        // Removed from configuration since ignite 2.3\n        Set<String> commPropsExcl = new HashSet<>();\n        commPropsExcl.add(\"discoveryStartupDelay\");\n        commPropsExcl.addAll(SPI_EXCLUDED_FIELDS);\n\n        metadata.put(TcpCommunicationSpi.class,\n            new MetadataInfo(commProps, commPropsDep, commPropsExcl));\n\n        Set<String> discoverySpiProps = new HashSet<>();\n        discoverySpiProps.add(\"ipFinder\");\n        discoverySpiProps.add(\"localAddress\");\n        discoverySpiProps.add(\"localPort\");\n        discoverySpiProps.add(\"localPortRange\");\n        discoverySpiProps.add(\"addressResolver\");\n        discoverySpiProps.add(\"socketTimeout\");\n        discoverySpiProps.add(\"ackTimeout\");\n        discoverySpiProps.add(\"maxAckTimeout\");\n        discoverySpiProps.add(\"networkTimeout\");\n        discoverySpiProps.add(\"joinTimeout\");\n        discoverySpiProps.add(\"threadPriority\");\n        // Removed since 2.0.\n        // discoverySpiProps.add(\"heartbeatFrequency\");\n        // discoverySpiProps.add(\"maxMissedHeartbeats\");\n        // discoverySpiProps.add(\"maxMissedClientHeartbeats\");\n        discoverySpiProps.add(\"topHistorySize\");\n        discoverySpiProps.add(\"listener\");\n        discoverySpiProps.add(\"dataExchange\");\n        discoverySpiProps.add(\"metricsProvider\");\n        discoverySpiProps.add(\"reconnectCount\");\n        discoverySpiProps.add(\"statisticsPrintFrequency\");\n        discoverySpiProps.add(\"ipFinderCleanFrequency\");\n        discoverySpiProps.add(\"authenticator\");\n        discoverySpiProps.add(\"forceServerMode\");\n        discoverySpiProps.add(\"clientReconnectDisabled\");\n        metadata.put(TcpDiscoverySpi.class, new MetadataInfo(discoverySpiProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> connectorProps = new HashSet<>();\n        connectorProps.add(\"jettyPath\");\n        connectorProps.add(\"host\");\n        connectorProps.add(\"port\");\n        connectorProps.add(\"portRange\");\n        connectorProps.add(\"idleQueryCursorTimeout\");\n        connectorProps.add(\"idleQueryCursorCheckFrequency\");\n        connectorProps.add(\"idleTimeout\");\n        connectorProps.add(\"receiveBufferSize\");\n        connectorProps.add(\"sendBufferSize\");\n        connectorProps.add(\"sendQueueLimit\");\n        connectorProps.add(\"directBuffer\");\n        connectorProps.add(\"noDelay\");\n        connectorProps.add(\"selectorCount\");\n        connectorProps.add(\"threadPoolSize\");\n        connectorProps.add(\"messageInterceptor\");\n        connectorProps.add(\"secretKey\");\n        connectorProps.add(\"sslEnabled\");\n        connectorProps.add(\"sslClientAuth\");\n        connectorProps.add(\"sslFactory\");\n        metadata.put(ConnectorConfiguration.class, new MetadataInfo(connectorProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> dataStorageProps = new HashSet<>();\n        dataStorageProps.add(\"pageSize\");\n        dataStorageProps.add(\"concurrencyLevel\");\n        dataStorageProps.add(\"systemRegionInitialSize\");\n        dataStorageProps.add(\"systemRegionMaxSize\");\n        dataStorageProps.add(\"defaultDataRegionConfiguration\");\n        dataStorageProps.add(\"dataRegionConfigurations\");\n        dataStorageProps.add(\"storagePath\");\n        dataStorageProps.add(\"checkpointFrequency\");\n        dataStorageProps.add(\"checkpointThreads\");\n        dataStorageProps.add(\"checkpointWriteOrder\");\n        dataStorageProps.add(\"walMode\");\n        dataStorageProps.add(\"walPath\");\n        dataStorageProps.add(\"walArchivePath\");\n        dataStorageProps.add(\"walSegments\");\n        dataStorageProps.add(\"walSegmentSize\");\n        dataStorageProps.add(\"walHistorySize\");\n        dataStorageProps.add(\"walBufferSize\");\n        dataStorageProps.add(\"walFlushFrequency\");\n        dataStorageProps.add(\"walFsyncDelayNanos\");\n        dataStorageProps.add(\"walRecordIteratorBufferSize\");\n        dataStorageProps.add(\"lockWaitTime\");\n        dataStorageProps.add(\"walThreadLocalBufferSize\");\n        dataStorageProps.add(\"metricsSubIntervalCount\");\n        dataStorageProps.add(\"metricsRateTimeInterval\");\n        dataStorageProps.add(\"fileIOFactory\");\n        dataStorageProps.add(\"walAutoArchiveAfterInactivity\");\n        dataStorageProps.add(\"metricsEnabled\");\n        dataStorageProps.add(\"alwaysWriteFullPages\");\n        dataStorageProps.add(\"writeThrottlingEnabled\");\n        dataStorageProps.add(\"walCompactionEnabled\");\n        metadata.put(DataStorageConfiguration.class, new MetadataInfo(dataStorageProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> dataRegionProps = new HashSet<>();\n        dataRegionProps.add(\"name\");\n        dataRegionProps.add(\"initialSize\");\n        dataRegionProps.add(\"maxSize\");\n        dataRegionProps.add(\"swapPath\");\n        dataRegionProps.add(\"checkpointPageBufferSize\");\n        dataRegionProps.add(\"pageEvictionMode\");\n        dataRegionProps.add(\"evictionThreshold\");\n        dataRegionProps.add(\"emptyPagesPoolSize\");\n        dataRegionProps.add(\"metricsSubIntervalCount\");\n        dataRegionProps.add(\"metricsRateTimeInterval\");\n        dataRegionProps.add(\"metricsEnabled\");\n        dataRegionProps.add(\"persistenceEnabled\");\n        metadata.put(DataRegionConfiguration.class, new MetadataInfo(dataRegionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> uriDeploymentProps = new HashSet<>();\n        uriDeploymentProps.add(\"uriList\");\n        uriDeploymentProps.add(\"temporaryDirectoryPath\");\n        uriDeploymentProps.add(\"scanners\");\n        uriDeploymentProps.add(\"listener\");\n        uriDeploymentProps.add(\"checkMd5\");\n        uriDeploymentProps.add(\"encodeUri\");\n        metadata.put(UriDeploymentSpi.class, new MetadataInfo(uriDeploymentProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> locDeploymentProps = new HashSet<>();\n        locDeploymentProps.add(\"listener\");\n        metadata.put(LocalDeploymentSpi.class, new MetadataInfo(locDeploymentProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> memoryEvtStorageProps = new HashSet<>();\n        memoryEvtStorageProps.add(\"expireAgeMs\");\n        memoryEvtStorageProps.add(\"expireCount\");\n        memoryEvtStorageProps.add(\"filter\");\n        metadata.put(MemoryEventStorageSpi.class, new MetadataInfo(memoryEvtStorageProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> alwaysFailoverProps = new HashSet<>();\n        alwaysFailoverProps.add(\"maximumFailoverAttempts\");\n        metadata.put(AlwaysFailoverSpi.class, new MetadataInfo(alwaysFailoverProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> jobStealingFailoverProps = new HashSet<>();\n        jobStealingFailoverProps.add(\"maximumFailoverAttempts\");\n        metadata.put(JobStealingFailoverSpi.class, new MetadataInfo(jobStealingFailoverProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> hadoopCfgProps = new HashSet<>();\n        hadoopCfgProps.add(\"mapReducePlanner\");\n        hadoopCfgProps.add(\"finishedJobInfoTtl\");\n        hadoopCfgProps.add(\"maxParallelTasks\");\n        hadoopCfgProps.add(\"maxTaskQueueSize\");\n        hadoopCfgProps.add(\"nativeLibraryNames\");\n        metadata.put(HadoopConfiguration.class, new MetadataInfo(hadoopCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> hadoopWeightMapReduceCfgProps = new HashSet<>();\n        hadoopWeightMapReduceCfgProps.add(\"localMapperWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"remoteMapperWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"localReducerWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"remoteReducerWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"preferLocalReducerThresholdWeight\");\n        metadata.put(IgniteHadoopWeightedMapReducePlanner.class,\n            new MetadataInfo(hadoopWeightMapReduceCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> weightedRndLoadBalancingProps = new HashSet<>();\n        weightedRndLoadBalancingProps.add(\"nodeWeight\");\n        weightedRndLoadBalancingProps.add(\"useWeights\");\n        metadata.put(WeightedRandomLoadBalancingSpi.class,\n            new MetadataInfo(weightedRndLoadBalancingProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> adaptiveLoadBalancingProps = new HashSet<>();\n        adaptiveLoadBalancingProps.add(\"loadProbe\");\n        metadata.put(AdaptiveLoadBalancingSpi.class,\n            new MetadataInfo(adaptiveLoadBalancingProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> roundRobinLoadBalancingProps = new HashSet<>();\n        roundRobinLoadBalancingProps.add(\"perTask\");\n        metadata.put(RoundRobinLoadBalancingSpi.class,\n            new MetadataInfo(roundRobinLoadBalancingProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> jobCntProbeProps = new HashSet<>();\n        jobCntProbeProps.add(\"useAverage\");\n        metadata.put(AdaptiveJobCountLoadProbe.class, new MetadataInfo(jobCntProbeProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> cpuLoadProbeProps = new HashSet<>();\n        cpuLoadProbeProps.add(\"useAverage\");\n        cpuLoadProbeProps.add(\"useProcessors\");\n        cpuLoadProbeProps.add(\"processorCoefficient\");\n        metadata.put(AdaptiveCpuLoadProbe.class, new MetadataInfo(cpuLoadProbeProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> adaptiveTimeProbeProps = new HashSet<>();\n        adaptiveTimeProbeProps.add(\"useAverage\");\n        metadata.put(AdaptiveProcessingTimeLoadProbe.class,\n            new MetadataInfo(adaptiveTimeProbeProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> optimizedMarshallerProps = new HashSet<>();\n        optimizedMarshallerProps.add(\"poolSize\");\n        optimizedMarshallerProps.add(\"requireSerializable\");\n\n        Set<String> optimizedMarshallerPropsExcl = new HashSet<>();\n        optimizedMarshallerPropsExcl.add(\"context\");\n\n        metadata.put(OptimizedMarshaller.class,\n            new MetadataInfo(optimizedMarshallerProps, EMPTY_FIELDS, optimizedMarshallerPropsExcl));\n\n        Set<String> memoryCfgProps = new HashSet<>();\n        memoryCfgProps.add(\"pageSize\");\n        memoryCfgProps.add(\"concurrencyLevel\");\n        memoryCfgProps.add(\"systemCacheInitialSize\");\n        memoryCfgProps.add(\"systemCacheMaxSize\");\n        memoryCfgProps.add(\"defaultMemoryPolicyName\");\n        memoryCfgProps.add(\"defaultMemoryPolicySize\");\n        memoryCfgProps.add(\"memoryPolicies\");\n        metadata.put(MemoryConfiguration.class, new MetadataInfo(EMPTY_FIELDS, memoryCfgProps, EMPTY_FIELDS));\n\n        Set<String> memoryPlcCfgProps = new HashSet<>();\n        memoryPlcCfgProps.add(\"name\");\n        memoryPlcCfgProps.add(\"initialSize\");\n        memoryPlcCfgProps.add(\"maxSize\");\n        memoryPlcCfgProps.add(\"swapFilePath\");\n        memoryPlcCfgProps.add(\"pageEvictionMode\");\n        memoryPlcCfgProps.add(\"evictionThreshold\");\n        memoryPlcCfgProps.add(\"emptyPagesPoolSize\");\n        memoryPlcCfgProps.add(\"subIntervals\");\n        memoryPlcCfgProps.add(\"rateTimeInterval\");\n        memoryPlcCfgProps.add(\"metricsEnabled\");\n        metadata.put(MemoryPolicyConfiguration.class, new MetadataInfo(EMPTY_FIELDS, memoryPlcCfgProps, EMPTY_FIELDS));\n\n        Set<String> odbcCfgProps = new HashSet<>();\n        odbcCfgProps.add(\"endpointAddress\");\n        odbcCfgProps.add(\"socketSendBufferSize\");\n        odbcCfgProps.add(\"socketReceiveBufferSize\");\n        odbcCfgProps.add(\"maxOpenCursors\");\n        odbcCfgProps.add(\"threadPoolSize\");\n        metadata.put(OdbcConfiguration.class, new MetadataInfo(EMPTY_FIELDS, odbcCfgProps, EMPTY_FIELDS));\n\n        Set<String> persistenceCfgProps = new HashSet<>();\n        persistenceCfgProps.add(\"persistentStorePath\");\n        persistenceCfgProps.add(\"metricsEnabled\");\n        persistenceCfgProps.add(\"alwaysWriteFullPages\");\n        persistenceCfgProps.add(\"checkpointingFrequency\");\n        persistenceCfgProps.add(\"checkpointingPageBufferSize\");\n        persistenceCfgProps.add(\"checkpointingThreads\");\n        persistenceCfgProps.add(\"walStorePath\");\n        persistenceCfgProps.add(\"walArchivePath\");\n        persistenceCfgProps.add(\"walSegments\");\n        persistenceCfgProps.add(\"walSegmentSize\");\n        persistenceCfgProps.add(\"walHistorySize\");\n        persistenceCfgProps.add(\"walFlushFrequency\");\n        persistenceCfgProps.add(\"walFsyncDelayNanos\");\n        persistenceCfgProps.add(\"walRecordIteratorBufferSize\");\n        persistenceCfgProps.add(\"lockWaitTime\");\n        persistenceCfgProps.add(\"rateTimeInterval\");\n        persistenceCfgProps.add(\"tlbSize\");\n        persistenceCfgProps.add(\"subIntervals\");\n        metadata.put(PersistentStoreConfiguration.class, new MetadataInfo(EMPTY_FIELDS, persistenceCfgProps, EMPTY_FIELDS));\n\n        Set<String> srvcCfgProps = new HashSet<>();\n        srvcCfgProps.add(\"name\");\n        srvcCfgProps.add(\"service\");\n        srvcCfgProps.add(\"maxPerNodeCount\");\n        srvcCfgProps.add(\"totalCount\");\n        // Field cache in model.\n        srvcCfgProps.add(\"cacheName\");\n        srvcCfgProps.add(\"affinityKey\");\n\n        Set<String> srvcCfgPropsExclude = new HashSet<>();\n        srvcCfgPropsExclude.add(\"nodeFilter\");\n\n        metadata.put(ServiceConfiguration.class, new MetadataInfo(srvcCfgProps, EMPTY_FIELDS, srvcCfgPropsExclude));\n\n        Set<String> sqlConnectorCfgProps = new HashSet<>();\n        sqlConnectorCfgProps.add(\"host\");\n        sqlConnectorCfgProps.add(\"port\");\n        sqlConnectorCfgProps.add(\"portRange\");\n        sqlConnectorCfgProps.add(\"socketSendBufferSize\");\n        sqlConnectorCfgProps.add(\"socketReceiveBufferSize\");\n        sqlConnectorCfgProps.add(\"maxOpenCursorsPerConnection\");\n        sqlConnectorCfgProps.add(\"threadPoolSize\");\n        sqlConnectorCfgProps.add(\"tcpNoDelay\");\n        metadata.put(SqlConnectorConfiguration.class, new MetadataInfo(EMPTY_FIELDS, sqlConnectorCfgProps, EMPTY_FIELDS));\n\n        Set<String> sslCfgProps = new HashSet<>();\n        sslCfgProps.add(\"keyAlgorithm\");\n        sslCfgProps.add(\"keyStoreFilePath\");\n        // Only on code generation.\n        sslCfgProps.add(\"keyStorePassword\");\n        sslCfgProps.add(\"keyStoreType\");\n        sslCfgProps.add(\"protocol\");\n        sslCfgProps.add(\"trustManagers\");\n        sslCfgProps.add(\"trustStoreFilePath\");\n        // Only on code generation.\n        sslCfgProps.add(\"trustStorePassword\");\n        sslCfgProps.add(\"trustStoreType\");\n        metadata.put(SslContextFactory.class, new MetadataInfo(sslCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> executorProps = new HashSet<>();\n        executorProps.add(\"name\");\n        executorProps.add(\"size\");\n        metadata.put(ExecutorConfiguration.class, new MetadataInfo(executorProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> transactionCfgProps = new HashSet<>();\n        transactionCfgProps.add(\"defaultTxConcurrency\");\n        transactionCfgProps.add(\"defaultTxIsolation\");\n        transactionCfgProps.add(\"defaultTxTimeout\");\n        transactionCfgProps.add(\"pessimisticTxLogLinger\");\n        transactionCfgProps.add(\"pessimisticTxLogSize\");\n        transactionCfgProps.add(\"txManagerFactory\");\n        metadata.put(TransactionConfiguration.class, new MetadataInfo(transactionCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        // Cache configuration.\n\n        Set<String> cacheCfgProps = new HashSet<>();\n        cacheCfgProps.add(\"name\");\n        cacheCfgProps.add(\"groupName\");\n        cacheCfgProps.add(\"cacheMode\");\n        cacheCfgProps.add(\"atomicityMode\");\n        cacheCfgProps.add(\"backups\");\n        cacheCfgProps.add(\"partitionLossPolicy\");\n        cacheCfgProps.add(\"readFromBackup\");\n        cacheCfgProps.add(\"copyOnRead\");\n        cacheCfgProps.add(\"isInvalidate\");\n        cacheCfgProps.add(\"affinityMapper\");\n        cacheCfgProps.add(\"topologyValidator\");\n        cacheCfgProps.add(\"maxConcurrentAsyncOperations\");\n        cacheCfgProps.add(\"defaultLockTimeout\");\n        cacheCfgProps.add(\"writeSynchronizationMode\");\n        cacheCfgProps.add(\"onheapCacheEnabled\");\n        cacheCfgProps.add(\"dataRegionName\");\n        // Removed since 2.0.\n        // cacheCfgProps.add(\"memoryMode\");\n        // cacheCfgProps.add(\"offHeapMode\");\n        // cacheCfgProps.add(\"offHeapMaxMemory\");\n        cacheCfgProps.add(\"evictionPolicy\");\n        cacheCfgProps.add(\"evictionFilter\");\n        // Removed since 2.0.\n        // cacheCfgProps.add(\"startSize\");\n        // cacheCfgProps.add(\"swapEnabled\");\n        cacheCfgProps.add(\"nearConfiguration\");\n        cacheCfgProps.add(\"sqlSchema\");\n        // Removed since 2.0.\n        // cacheCfgProps.add(\"sqlOnheapRowCacheSize\");\n        cacheCfgProps.add(\"queryDetailMetricsSize\");\n        cacheCfgProps.add(\"sqlFunctionClasses\");\n        // Removed since 2.0\n        // cacheCfgProps.add(\"snapshotableIndex\");\n        cacheCfgProps.add(\"sqlEscapeAll\");\n        cacheCfgProps.add(\"queryParallelism\");\n        cacheCfgProps.add(\"rebalanceMode\");\n        cacheCfgProps.add(\"rebalanceBatchSize\");\n        cacheCfgProps.add(\"rebalanceBatchesPrefetchCount\");\n        cacheCfgProps.add(\"rebalanceOrder\");\n        cacheCfgProps.add(\"rebalanceDelay\");\n        cacheCfgProps.add(\"rebalanceTimeout\");\n        cacheCfgProps.add(\"rebalanceThrottle\");\n        cacheCfgProps.add(\"statisticsEnabled\");\n        cacheCfgProps.add(\"managementEnabled\");\n        cacheCfgProps.add(\"cacheStoreFactory\");\n        cacheCfgProps.add(\"storeKeepBinary\");\n        cacheCfgProps.add(\"loadPreviousValue\");\n        cacheCfgProps.add(\"readThrough\");\n        cacheCfgProps.add(\"writeThrough\");\n        cacheCfgProps.add(\"writeBehindEnabled\");\n        cacheCfgProps.add(\"writeBehindBatchSize\");\n        cacheCfgProps.add(\"writeBehindFlushSize\");\n        cacheCfgProps.add(\"writeBehindFlushFrequency\");\n        cacheCfgProps.add(\"writeBehindFlushThreadCount\");\n        cacheCfgProps.add(\"writeBehindCoalescing\");\n        cacheCfgProps.add(\"indexedTypes\");\n        cacheCfgProps.add(\"queryEntities\");\n        cacheCfgProps.add(\"pluginConfigurations\");\n\n        Set<String> cacheCfgPropsDep = new HashSet<>();\n        // Removed since 2.0.\n        // cacheCfgPropsDep.add(\"atomicWriteOrderMode\");\n        cacheCfgPropsDep.add(\"memoryPolicyName\");\n        cacheCfgPropsDep.add(\"longQueryWarningTimeout\");\n\n        Set<String> cacheCfgPropsExcl = new HashSet<>();\n        cacheCfgPropsExcl.add(\"nodeFilter\");\n\n        metadata.put(CacheConfiguration.class, new MetadataInfo(cacheCfgProps, cacheCfgPropsDep, cacheCfgPropsExcl));\n\n        Set<String> rendezvousAffinityProps = new HashSet<>();\n        rendezvousAffinityProps.add(\"partitions\");\n        rendezvousAffinityProps.add(\"affinityBackupFilter\");\n        rendezvousAffinityProps.add(\"excludeNeighbors\");\n        metadata.put(RendezvousAffinityFunction.class, new MetadataInfo(rendezvousAffinityProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> nearCfgProps = new HashSet<>();\n        nearCfgProps.add(\"nearStartSize\");\n        nearCfgProps.add(\"nearEvictionPolicyFactory\");\n\n        Set<String> nearCfgPropsDep = new HashSet<>();\n        nearCfgPropsDep.add(\"nearEvictionPolicy\");\n\n        metadata.put(NearCacheConfiguration.class, new MetadataInfo(nearCfgProps, nearCfgPropsDep, EMPTY_FIELDS));\n\n        Set<String> jdbcPojoStoreProps = new HashSet<>();\n        // Only setter for dataSource field.\n        // jdbcPojoStoreProps.add(\"dataSourceBean\");\n        jdbcPojoStoreProps.add(\"dialect\");\n        jdbcPojoStoreProps.add(\"batchSize\");\n        jdbcPojoStoreProps.add(\"maximumPoolSize\");\n        jdbcPojoStoreProps.add(\"maximumWriteAttempts\");\n        jdbcPojoStoreProps.add(\"parallelLoadCacheMinimumThreshold\");\n        jdbcPojoStoreProps.add(\"hasher\");\n        jdbcPojoStoreProps.add(\"transformer\");\n        jdbcPojoStoreProps.add(\"sqlEscapeAll\");\n\n        // Configured via dataSource property.\n        Set<String> jdbcPojoStorePropsExcl = new HashSet<>();\n        jdbcPojoStorePropsExcl.add(\"dataSourceBean\");\n        jdbcPojoStorePropsExcl.add(\"dataSourceFactory\");\n\n        metadata.put(CacheJdbcPojoStoreFactory.class, new MetadataInfo(jdbcPojoStoreProps, EMPTY_FIELDS,\n            jdbcPojoStorePropsExcl));\n\n        Set<String> jdbcBlobStoreProps = new HashSet<>();\n        jdbcBlobStoreProps.add(\"connectionUrl\");\n        jdbcBlobStoreProps.add(\"user\");\n        // Only setter for dataSource.\n        // jdbcBlobStoreProps.add(\"dataSourceBean\");\n        // jdbcBlobStoreProps.add(\"dialect\");\n        jdbcBlobStoreProps.add(\"initSchema\");\n        jdbcBlobStoreProps.add(\"createTableQuery\");\n        jdbcBlobStoreProps.add(\"loadQuery\");\n        jdbcBlobStoreProps.add(\"insertQuery\");\n        jdbcBlobStoreProps.add(\"updateQuery\");\n        jdbcBlobStoreProps.add(\"deleteQuery\");\n        metadata.put(CacheJdbcBlobStore.class, new MetadataInfo(jdbcBlobStoreProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> hibernateBlobStoreProps = new HashSet<>();\n        hibernateBlobStoreProps.add(\"hibernateProperties\");\n        metadata.put(CacheHibernateBlobStore.class, new MetadataInfo(hibernateBlobStoreProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> igfsCfgProps = new HashSet<>();\n        igfsCfgProps.add(\"name\");\n        igfsCfgProps.add(\"defaultMode\");\n        // Removed since 2.0.\n        // igfsCfgProps.add(\"dualModeMaxPendingPutsSize\");\n        // igfsCfgProps.add(\"dualModePutExecutorService\");\n        // igfsCfgProps.add(\"dualModePutExecutorServiceShutdown\");\n        igfsCfgProps.add(\"fragmentizerEnabled\");\n        igfsCfgProps.add(\"fragmentizerConcurrentFiles\");\n        igfsCfgProps.add(\"fragmentizerThrottlingBlockLength\");\n        igfsCfgProps.add(\"fragmentizerThrottlingDelay\");\n        igfsCfgProps.add(\"ipcEndpointEnabled\");\n        igfsCfgProps.add(\"ipcEndpointConfiguration\");\n        igfsCfgProps.add(\"blockSize\");\n        // streamBufferSize field in model.\n        igfsCfgProps.add(\"bufferSize\");\n        // Removed since 2.0.\n        // igfsCfgProps.add(\"streamBufferSize\");\n        // igfsCfgProps.add(\"maxSpaceSize\");\n        igfsCfgProps.add(\"maximumTaskRangeLength\");\n        igfsCfgProps.add(\"managementPort\");\n        igfsCfgProps.add(\"perNodeBatchSize\");\n        igfsCfgProps.add(\"perNodeParallelBatchCount\");\n        igfsCfgProps.add(\"prefetchBlocks\");\n        igfsCfgProps.add(\"sequentialReadsBeforePrefetch\");\n        // Removed since 2.0.\n        // igfsCfgProps.add(\"trashPurgeTimeout\");\n        igfsCfgProps.add(\"colocateMetadata\");\n        igfsCfgProps.add(\"relaxedConsistency\");\n        igfsCfgProps.add(\"updateFileLengthOnFlush\");\n        igfsCfgProps.add(\"pathModes\");\n        igfsCfgProps.add(\"secondaryFileSystem\");\n\n        Set<String> igfsCfgPropsExclude = new HashSet<>();\n        igfsCfgPropsExclude.add(\"dataCacheConfiguration\");\n        igfsCfgPropsExclude.add(\"metaCacheConfiguration\");\n\n        metadata.put(FileSystemConfiguration.class, new MetadataInfo(igfsCfgProps, EMPTY_FIELDS, igfsCfgPropsExclude));\n\n        Set<String> igfsBlocMapperProps = new HashSet<>();\n        igfsBlocMapperProps.add(\"groupSize\");\n\n        metadata.put(IgfsGroupDataBlocksKeyMapper.class, new MetadataInfo(igfsBlocMapperProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> secHadoopIgfsCfgProps = new HashSet<>();\n        secHadoopIgfsCfgProps.add(\"defaultUserName\");\n        secHadoopIgfsCfgProps.add(\"fileSystemFactory\");\n\n        metadata.put(IgniteHadoopIgfsSecondaryFileSystem.class, new MetadataInfo(secHadoopIgfsCfgProps, EMPTY_FIELDS,\n            EMPTY_FIELDS));\n\n        Set<String> cachingIgfsCfgProps = new HashSet<>();\n        cachingIgfsCfgProps.add(\"uri\");\n        cachingIgfsCfgProps.add(\"configPaths\");\n\n        metadata.put(CachingHadoopFileSystemFactory.class, new MetadataInfo(cachingIgfsCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> ipcEndpointProps = new HashSet<>();\n        ipcEndpointProps.add(\"type\");\n        ipcEndpointProps.add(\"host\");\n        ipcEndpointProps.add(\"port\");\n        ipcEndpointProps.add(\"memorySize\");\n        ipcEndpointProps.add(\"threadCount\");\n        ipcEndpointProps.add(\"tokenDirectoryPath\");\n        metadata.put(IgfsIpcEndpointConfiguration.class, new MetadataInfo(ipcEndpointProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> qryEntityProps = new HashSet<>();\n        qryEntityProps.add(\"keyType\");\n        qryEntityProps.add(\"valueType\");\n        qryEntityProps.add(\"aliases\");\n        qryEntityProps.add(\"fields\");\n        qryEntityProps.add(\"indexes\");\n        qryEntityProps.add(\"tableName\");\n        qryEntityProps.add(\"keyFieldName\");\n        qryEntityProps.add(\"valueFieldName\");\n        qryEntityProps.add(\"keyFields\");\n        metadata.put(QueryEntity.class, new MetadataInfo(qryEntityProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> qryIdxProps = new HashSet<>();\n        qryIdxProps.add(\"name\");\n        qryIdxProps.add(\"indexType\");\n        qryIdxProps.add(\"fields\");\n\n        Set<String> qryIdxPropsExcl = new HashSet<>();\n        qryIdxPropsExcl.add(\"fieldNames\");\n\n        metadata.put(QueryIndex.class, new MetadataInfo(qryIdxProps, EMPTY_FIELDS, qryIdxPropsExcl));\n\n        Set<String> jdbcTypeProps = new HashSet<>();\n        jdbcTypeProps.add(\"cacheName\");\n        jdbcTypeProps.add(\"keyType\");\n        jdbcTypeProps.add(\"valueType\");\n        jdbcTypeProps.add(\"databaseSchema\");\n        jdbcTypeProps.add(\"databaseTable\");\n        jdbcTypeProps.add(\"keyFields\");\n        jdbcTypeProps.add(\"valueFields\");\n\n        metadata.put(JdbcType.class, new MetadataInfo(jdbcTypeProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> sorterEvictionProps = new HashSet<>();\n        sorterEvictionProps.add(\"batchSize\");\n        sorterEvictionProps.add(\"maxMemorySize\");\n        sorterEvictionProps.add(\"maxSize\");\n        metadata.put(SortedEvictionPolicy.class, new MetadataInfo(sorterEvictionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> lruEvictionProps = new HashSet<>();\n        lruEvictionProps.add(\"batchSize\");\n        lruEvictionProps.add(\"maxMemorySize\");\n        lruEvictionProps.add(\"maxSize\");\n        metadata.put(LruEvictionPolicy.class, new MetadataInfo(lruEvictionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> fifoEvictionProps = new HashSet<>();\n        fifoEvictionProps.add(\"batchSize\");\n        fifoEvictionProps.add(\"maxMemorySize\");\n        fifoEvictionProps.add(\"maxSize\");\n        metadata.put(FifoEvictionPolicy.class, new MetadataInfo(fifoEvictionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n    }",
            " 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140  \n 141  \n 142  \n 143  \n 144  \n 145  \n 146  \n 147  \n 148  \n 149  \n 150  \n 151  \n 152  \n 153  \n 154  \n 155  \n 156  \n 157  \n 158  \n 159  \n 160  \n 161  \n 162  \n 163  \n 164  \n 165  \n 166  \n 167  \n 168  \n 169  \n 170  \n 171  \n 172  \n 173  \n 174  \n 175  \n 176  \n 177  \n 178  \n 179  \n 180  \n 181  \n 182  \n 183  \n 184  \n 185  \n 186  \n 187  \n 188  \n 189  \n 190  \n 191  \n 192  \n 193  \n 194  \n 195  \n 196  \n 197  \n 198  \n 199  \n 200  \n 201  \n 202  \n 203  \n 204  \n 205  \n 206  \n 207  \n 208  \n 209  \n 210  \n 211  \n 212  \n 213  \n 214  \n 215 +\n 216 +\n 217 +\n 218 +\n 219 +\n 220 +\n 221  \n 222  \n 223  \n 224  \n 225  \n 226  \n 227  \n 228  \n 229  \n 230  \n 231  \n 232  \n 233  \n 234  \n 235  \n 236  \n 237  \n 238  \n 239  \n 240  \n 241  \n 242  \n 243  \n 244  \n 245  \n 246  \n 247  \n 248  \n 249  \n 250  \n 251  \n 252  \n 253  \n 254  \n 255  \n 256  \n 257  \n 258  \n 259  \n 260  \n 261  \n 262  \n 263  \n 264  \n 265  \n 266  \n 267  \n 268  \n 269  \n 270  \n 271  \n 272  \n 273  \n 274  \n 275  \n 276  \n 277  \n 278  \n 279  \n 280  \n 281  \n 282  \n 283  \n 284  \n 285  \n 286  \n 287  \n 288  \n 289  \n 290  \n 291  \n 292  \n 293  \n 294  \n 295  \n 296  \n 297  \n 298  \n 299  \n 300  \n 301  \n 302  \n 303  \n 304  \n 305  \n 306  \n 307  \n 308  \n 309  \n 310  \n 311  \n 312  \n 313  \n 314  \n 315  \n 316  \n 317  \n 318  \n 319  \n 320  \n 321  \n 322  \n 323  \n 324  \n 325  \n 326  \n 327  \n 328  \n 329  \n 330  \n 331  \n 332  \n 333  \n 334  \n 335  \n 336  \n 337  \n 338  \n 339  \n 340  \n 341  \n 342  \n 343  \n 344  \n 345  \n 346  \n 347  \n 348  \n 349  \n 350  \n 351  \n 352  \n 353  \n 354  \n 355  \n 356  \n 357  \n 358  \n 359  \n 360  \n 361  \n 362  \n 363  \n 364  \n 365  \n 366  \n 367  \n 368  \n 369  \n 370  \n 371  \n 372  \n 373  \n 374  \n 375  \n 376  \n 377  \n 378  \n 379  \n 380  \n 381  \n 382  \n 383  \n 384  \n 385  \n 386  \n 387  \n 388  \n 389  \n 390  \n 391  \n 392  \n 393  \n 394  \n 395  \n 396  \n 397  \n 398  \n 399  \n 400  \n 401  \n 402  \n 403  \n 404  \n 405  \n 406  \n 407  \n 408  \n 409  \n 410  \n 411  \n 412  \n 413  \n 414  \n 415  \n 416  \n 417  \n 418  \n 419  \n 420  \n 421  \n 422  \n 423  \n 424  \n 425  \n 426  \n 427  \n 428  \n 429  \n 430  \n 431  \n 432  \n 433  \n 434  \n 435  \n 436  \n 437  \n 438  \n 439  \n 440  \n 441  \n 442  \n 443  \n 444  \n 445  \n 446  \n 447  \n 448  \n 449  \n 450  \n 451  \n 452  \n 453  \n 454  \n 455  \n 456  \n 457  \n 458  \n 459  \n 460  \n 461  \n 462  \n 463  \n 464  \n 465  \n 466  \n 467  \n 468  \n 469  \n 470  \n 471  \n 472  \n 473  \n 474  \n 475  \n 476  \n 477  \n 478  \n 479  \n 480  \n 481  \n 482  \n 483  \n 484  \n 485  \n 486  \n 487  \n 488  \n 489  \n 490  \n 491  \n 492  \n 493  \n 494  \n 495  \n 496  \n 497  \n 498  \n 499  \n 500  \n 501  \n 502  \n 503  \n 504  \n 505  \n 506  \n 507  \n 508  \n 509  \n 510  \n 511  \n 512  \n 513  \n 514  \n 515  \n 516  \n 517  \n 518  \n 519  \n 520  \n 521  \n 522  \n 523  \n 524  \n 525  \n 526  \n 527  \n 528  \n 529  \n 530  \n 531  \n 532  \n 533  \n 534  \n 535  \n 536  \n 537  \n 538  \n 539  \n 540  \n 541  \n 542  \n 543  \n 544  \n 545  \n 546  \n 547  \n 548  \n 549  \n 550  \n 551  \n 552  \n 553  \n 554  \n 555  \n 556  \n 557  \n 558  \n 559  \n 560  \n 561  \n 562  \n 563  \n 564  \n 565  \n 566  \n 567  \n 568  \n 569  \n 570  \n 571  \n 572  \n 573  \n 574  \n 575  \n 576  \n 577  \n 578  \n 579  \n 580  \n 581  \n 582  \n 583  \n 584  \n 585  \n 586  \n 587  \n 588  \n 589  \n 590  \n 591  \n 592  \n 593  \n 594  \n 595  \n 596  \n 597  \n 598  \n 599  \n 600  \n 601  \n 602  \n 603  \n 604  \n 605  \n 606  \n 607  \n 608  \n 609  \n 610  \n 611  \n 612  \n 613  \n 614  \n 615  \n 616  \n 617  \n 618  \n 619  \n 620  \n 621  \n 622  \n 623  \n 624  \n 625  \n 626  \n 627  \n 628  \n 629  \n 630  \n 631  \n 632 +\n 633 +\n 634  \n 635  \n 636  \n 637  \n 638  \n 639  \n 640  \n 641  \n 642  \n 643  \n 644  \n 645  \n 646  \n 647  \n 648  \n 649  \n 650  \n 651  \n 652  \n 653  \n 654  \n 655  \n 656  \n 657  \n 658  \n 659  \n 660  \n 661 +\n 662  \n 663  \n 664  \n 665  \n 666  \n 667  \n 668  \n 669  \n 670  \n 671  \n 672  \n 673 +\n 674  \n 675  \n 676  \n 677  \n 678  \n 679  \n 680  \n 681  \n 682  \n 683  \n 684  \n 685  \n 686  \n 687  \n 688  \n 689  \n 690  \n 691  \n 692  \n 693  \n 694  \n 695  \n 696  \n 697  \n 698  \n 699  \n 700  \n 701  \n 702  \n 703  \n 704  \n 705  \n 706  \n 707  \n 708  \n 709  \n 710  \n 711 +\n 712 +\n 713 +\n 714 +\n 715 +\n 716 +\n 717 +\n 718 +\n 719 +\n 720 +\n 721 +\n 722 +\n 723 +\n 724 +\n 725 +\n 726 +\n 727 +\n 728 +\n 729  \n 730  \n 731  \n 732  \n 733  \n 734  \n 735 +\n 736 +\n 737 +\n 738  \n 739  \n 740  \n 741 +\n 742  \n 743  \n 744  \n 745  \n 746  \n 747  \n 748  \n 749  \n 750  \n 751  \n 752  \n 753  \n 754  \n 755  \n 756  \n 757  \n 758  \n 759  \n 760  \n 761  \n 762  \n 763  \n 764  \n 765  \n 766  \n 767  \n 768  \n 769  \n 770  \n 771  \n 772  \n 773  \n 774  \n 775  \n 776  \n 777  \n 778  \n 779  \n 780  \n 781  \n 782  \n 783  \n 784  \n 785  \n 786  \n 787  \n 788  \n 789  \n 790  \n 791  \n 792  \n 793  \n 794  \n 795  \n 796  \n 797  \n 798  \n 799  \n 800  \n 801  \n 802  \n 803  \n 804  \n 805  \n 806  \n 807  \n 808  \n 809  \n 810  \n 811  \n 812  \n 813  \n 814  \n 815  \n 816  \n 817  \n 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852 +\n 853  \n 854  \n 855  \n 856 +\n 857 +\n 858 +\n 859 +\n 860 +\n 861 +\n 862 +\n 863 +\n 864 +\n 865 +\n 866 +\n 867 +\n 868 +\n 869 +\n 870 +\n 871 +\n 872 +\n 873 +\n 874 +\n 875 +\n 876 +\n 877 +\n 878 +\n 879 +\n 880 +\n 881 +\n 882 +\n 883 +\n 884  \n 885  \n 886  \n 887  \n 888  \n 889  \n 890  \n 891  \n 892  \n 893  \n 894  \n 895  \n 896  \n 897  \n 898  \n 899  \n 900  \n 901  \n 902  \n 903  \n 904  \n 905  \n 906  \n 907  \n 908  \n 909  \n 910  \n 911  \n 912  \n 913  \n 914  \n 915  \n 916  \n 917  \n 918  \n 919  \n 920  \n 921  \n 922  \n 923  \n 924  \n 925  \n 926  \n 927  \n 928  \n 929  \n 930  \n 931  \n 932  \n 933  \n 934  \n 935  \n 936  \n 937  \n 938  \n 939  \n 940  \n 941  \n 942  \n 943  ",
            "    /**\n     * Prepare metadata for properties, which are possible to configure.\n     */\n    @SuppressWarnings(\"deprecation\")\n    protected void prepareMetadata() {\n        // Cluster configuration.\n        Set<String> igniteCfgProps = new HashSet<>();\n        igniteCfgProps.add(\"cacheConfiguration\");\n        igniteCfgProps.add(\"discoverySpi\");\n        igniteCfgProps.add(\"localHost\");\n        igniteCfgProps.add(\"atomicConfiguration\");\n        igniteCfgProps.add(\"userAttributes\");\n        igniteCfgProps.add(\"binaryConfiguration\");\n        igniteCfgProps.add(\"cacheKeyConfiguration\");\n        igniteCfgProps.add(\"checkpointSpi\");\n        igniteCfgProps.add(\"collisionSpi\");\n        igniteCfgProps.add(\"communicationSpi\");\n        igniteCfgProps.add(\"networkTimeout\");\n        igniteCfgProps.add(\"networkSendRetryDelay\");\n        igniteCfgProps.add(\"networkSendRetryCount\");\n        igniteCfgProps.add(\"connectorConfiguration\");\n        igniteCfgProps.add(\"dataStorageConfiguration\");\n        igniteCfgProps.add(\"deploymentMode\");\n        igniteCfgProps.add(\"peerClassLoadingEnabled\");\n        igniteCfgProps.add(\"peerClassLoadingMissedResourcesCacheSize\");\n        igniteCfgProps.add(\"peerClassLoadingThreadPoolSize\");\n        igniteCfgProps.add(\"peerClassLoadingLocalClassPathExclude\");\n        igniteCfgProps.add(\"classLoader\");\n        igniteCfgProps.add(\"deploymentSpi\");\n        igniteCfgProps.add(\"eventStorageSpi\");\n        igniteCfgProps.add(\"includeEventTypes\");\n        igniteCfgProps.add(\"failureDetectionTimeout\");\n        igniteCfgProps.add(\"clientFailureDetectionTimeout\");\n        igniteCfgProps.add(\"failoverSpi\");\n        igniteCfgProps.add(\"hadoopConfiguration\");\n        igniteCfgProps.add(\"loadBalancingSpi\");\n        igniteCfgProps.add(\"marshalLocalJobs\");\n\n        // Removed since 2.0.\n        // igniteCfgProps.add(\"marshallerCacheKeepAliveTime\");\n        // igniteCfgProps.add(\"marshallerCacheThreadPoolSize\");\n\n        igniteCfgProps.add(\"metricsExpireTime\");\n        igniteCfgProps.add(\"metricsHistorySize\");\n        igniteCfgProps.add(\"metricsLogFrequency\");\n        igniteCfgProps.add(\"metricsUpdateFrequency\");\n        igniteCfgProps.add(\"workDirectory\");\n        igniteCfgProps.add(\"consistentId\");\n        igniteCfgProps.add(\"warmupClosure\");\n        igniteCfgProps.add(\"activeOnStart\");\n        igniteCfgProps.add(\"cacheSanityCheckEnabled\");\n        igniteCfgProps.add(\"longQueryWarningTimeout\");\n        igniteCfgProps.add(\"odbcConfiguration\");\n        igniteCfgProps.add(\"serviceConfiguration\");\n        igniteCfgProps.add(\"sqlConnectorConfiguration\");\n        igniteCfgProps.add(\"sslContextFactory\");\n\n        // Removed since 2.0.\n        // igniteCfgProps.add(\"swapSpaceSpi\");\n\n        igniteCfgProps.add(\"publicThreadPoolSize\");\n        igniteCfgProps.add(\"systemThreadPoolSize\");\n        igniteCfgProps.add(\"serviceThreadPoolSize\");\n        igniteCfgProps.add(\"managementThreadPoolSize\");\n        igniteCfgProps.add(\"igfsThreadPoolSize\");\n        igniteCfgProps.add(\"utilityCacheThreadPoolSize\");\n        igniteCfgProps.add(\"utilityCacheKeepAliveTime\");\n        igniteCfgProps.add(\"asyncCallbackPoolSize\");\n        igniteCfgProps.add(\"stripedPoolSize\");\n        igniteCfgProps.add(\"dataStreamerThreadPoolSize\");\n        igniteCfgProps.add(\"queryThreadPoolSize\");\n        igniteCfgProps.add(\"executorConfiguration\");\n\n        // Removed since 2.0.\n        // igniteCfgProps.add(\"clockSyncSamples\");\n        // igniteCfgProps.add(\"clockSyncFrequency\");\n\n        igniteCfgProps.add(\"timeServerPortBase\");\n        igniteCfgProps.add(\"timeServerPortRange\");\n        igniteCfgProps.add(\"transactionConfiguration\");\n        igniteCfgProps.add(\"clientConnectorConfiguration\");\n        igniteCfgProps.add(\"fileSystemConfiguration\");\n        igniteCfgProps.add(\"gridLogger\");\n        igniteCfgProps.add(\"pluginConfigurations\");\n        igniteCfgProps.add(\"mvccVacuumFrequency\");\n        igniteCfgProps.add(\"mvccVacuumThreadCount\");\n\n        Set<String> igniteCfgPropsDep = new HashSet<>();\n        igniteCfgPropsDep.add(\"gridName\");\n        igniteCfgPropsDep.add(\"lateAffinityAssignment\");\n        igniteCfgPropsDep.add(\"persistentStoreConfiguration\");\n        igniteCfgPropsDep.add(\"memoryConfiguration\");\n        igniteCfgPropsDep.add(\"marshaller\");\n        igniteCfgPropsDep.add(\"discoveryStartupDelay\");\n\n        Set<String> igniteCfgPropsExcl = new HashSet<>();\n        // igniteCfgPropsExcl.add(\"lifecycleBeans\");\n        igniteCfgPropsExcl.add(\"daemon\");\n        igniteCfgPropsExcl.add(\"clientMode\");\n        igniteCfgPropsExcl.add(\"indexingSpi\");\n        igniteCfgPropsExcl.add(\"nodeId\");\n\n        metadata.put(IgniteConfiguration.class,\n            new MetadataInfo(igniteCfgProps, igniteCfgPropsDep, igniteCfgPropsExcl));\n\n        Set<String> cacheKeyCfgProps = new HashSet<>();\n        cacheKeyCfgProps.add(\"typeName\");\n        cacheKeyCfgProps.add(\"affinityKeyFieldName\");\n\n        metadata.put(CacheKeyConfiguration.class, new MetadataInfo(cacheKeyCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> atomicCfgProps = new HashSet<>();\n        atomicCfgProps.add(\"cacheMode\");\n        atomicCfgProps.add(\"atomicSequenceReserveSize\");\n        atomicCfgProps.add(\"backups\");\n        atomicCfgProps.add(\"affinity\");\n\n        metadata.put(AtomicConfiguration.class, new MetadataInfo(atomicCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> binaryCfgProps = new HashSet<>();\n        binaryCfgProps.add(\"idMapper\");\n        binaryCfgProps.add(\"nameMapper\");\n        binaryCfgProps.add(\"serializer\");\n        binaryCfgProps.add(\"typeConfigurations\");\n        binaryCfgProps.add(\"compactFooter\");\n        metadata.put(BinaryConfiguration.class, new MetadataInfo(binaryCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> binaryTypeCfgProps = new HashSet<>();\n        binaryTypeCfgProps.add(\"typeName\");\n        binaryTypeCfgProps.add(\"idMapper\");\n        binaryTypeCfgProps.add(\"nameMapper\");\n        binaryTypeCfgProps.add(\"serializer\");\n        binaryTypeCfgProps.add(\"enum\");\n        binaryTypeCfgProps.add(\"enumValues\");\n        metadata.put(BinaryTypeConfiguration.class, new MetadataInfo(binaryTypeCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> sharedFsCheckpointProps = new HashSet<>();\n        sharedFsCheckpointProps.add(\"directoryPaths\");\n        metadata.put(SharedFsCheckpointSpi.class, new MetadataInfo(sharedFsCheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> s3CheckpointProps = new HashSet<>();\n        s3CheckpointProps.add(\"bucketNameSuffix\");\n        s3CheckpointProps.add(\"bucketEndpoint\");\n        s3CheckpointProps.add(\"sSEAlgorithm\");\n        s3CheckpointProps.add(\"checkpointListener\");\n        metadata.put(S3CheckpointSpi.class, new MetadataInfo(s3CheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> cacheCheckpointProps = new HashSet<>();\n        cacheCheckpointProps.add(\"cacheName\");\n        metadata.put(CacheCheckpointSpi.class, new MetadataInfo(cacheCheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> jdbcCheckpointProps = new HashSet<>();\n        // Only setter for dataSource.\n        // jdbcCheckpointProps.add(\"dataSourceBean\");\n        // jdbcCheckpointProps.add(\"dialect\");\n        jdbcCheckpointProps.add(\"checkpointListener\");\n        jdbcCheckpointProps.add(\"user\");\n        // Only on code generation.\n        jdbcCheckpointProps.add(\"pwd\");\n        jdbcCheckpointProps.add(\"checkpointTableName\");\n        jdbcCheckpointProps.add(\"numberOfRetries\");\n        jdbcCheckpointProps.add(\"keyFieldName\");\n        jdbcCheckpointProps.add(\"keyFieldType\");\n        jdbcCheckpointProps.add(\"valueFieldName\");\n        jdbcCheckpointProps.add(\"valueFieldType\");\n        jdbcCheckpointProps.add(\"expireDateFieldName\");\n        jdbcCheckpointProps.add(\"expireDateFieldType\");\n        metadata.put(JdbcCheckpointSpi.class, new MetadataInfo(jdbcCheckpointProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> cliConProps = new HashSet<>();\n        cliConProps.add(\"host\");\n        cliConProps.add(\"port\");\n        cliConProps.add(\"portRange\");\n        cliConProps.add(\"socketSendBufferSize\");\n        cliConProps.add(\"socketReceiveBufferSize\");\n        cliConProps.add(\"maxOpenCursorsPerConnection\");\n        cliConProps.add(\"threadPoolSize\");\n        cliConProps.add(\"tcpNoDelay\");\n        cliConProps.add(\"idleTimeout\");\n        cliConProps.add(\"sslEnabled\");\n        cliConProps.add(\"sslClientAuth\");\n        cliConProps.add(\"useIgniteSslContextFactory\");\n        cliConProps.add(\"sslContextFactory\");\n        cliConProps.add(\"jdbcEnabled\");\n        cliConProps.add(\"odbcEnabled\");\n        cliConProps.add(\"thinClientEnabled\");\n        metadata.put(ClientConnectorConfiguration.class, new MetadataInfo(cliConProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> jobStealingCollisionProps = new HashSet<>();\n        jobStealingCollisionProps.add(\"activeJobsThreshold\");\n        jobStealingCollisionProps.add(\"waitJobsThreshold\");\n        jobStealingCollisionProps.add(\"messageExpireTime\");\n        jobStealingCollisionProps.add(\"maximumStealingAttempts\");\n        jobStealingCollisionProps.add(\"stealingEnabled\");\n        jobStealingCollisionProps.add(\"externalCollisionListener\");\n        jobStealingCollisionProps.add(\"stealingAttributes\");\n        metadata.put(JobStealingCollisionSpi.class,\n            new MetadataInfo(jobStealingCollisionProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> priQueueCollisionProps = new HashSet<>();\n        priQueueCollisionProps.add(\"parallelJobsNumber\");\n        priQueueCollisionProps.add(\"waitingJobsNumber\");\n        priQueueCollisionProps.add(\"priorityAttributeKey\");\n        priQueueCollisionProps.add(\"jobPriorityAttributeKey\");\n        priQueueCollisionProps.add(\"defaultPriority\");\n        priQueueCollisionProps.add(\"starvationIncrement\");\n        priQueueCollisionProps.add(\"starvationPreventionEnabled\");\n        metadata.put(PriorityQueueCollisionSpi.class, new MetadataInfo(priQueueCollisionProps, EMPTY_FIELDS,\n            SPI_EXCLUDED_FIELDS));\n\n        Set<String> fifoQueueCollisionProps = new HashSet<>();\n        fifoQueueCollisionProps.add(\"parallelJobsNumber\");\n        fifoQueueCollisionProps.add(\"waitingJobsNumber\");\n        metadata.put(FifoQueueCollisionSpi.class,\n            new MetadataInfo(fifoQueueCollisionProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> commProps = new HashSet<>();\n        commProps.add(\"listener\");\n        commProps.add(\"localAddress\");\n        commProps.add(\"localPort\");\n        commProps.add(\"localPortRange\");\n        commProps.add(\"sharedMemoryPort\");\n        commProps.add(\"idleConnectionTimeout\");\n        commProps.add(\"connectTimeout\");\n        commProps.add(\"maxConnectTimeout\");\n        commProps.add(\"reconnectCount\");\n        commProps.add(\"socketSendBuffer\");\n        commProps.add(\"socketReceiveBuffer\");\n        commProps.add(\"slowClientQueueLimit\");\n        commProps.add(\"ackSendThreshold\");\n        commProps.add(\"messageQueueLimit\");\n        commProps.add(\"unacknowledgedMessagesBufferSize\");\n        commProps.add(\"socketWriteTimeout\");\n        commProps.add(\"selectorsCount\");\n        commProps.add(\"addressResolver\");\n        commProps.add(\"directBuffer\");\n        commProps.add(\"directSendBuffer\");\n        commProps.add(\"tcpNoDelay\");\n\n        Set<String> commPropsDep = new HashSet<>();\n        commPropsDep.add(\"discoveryStartupDelay\");\n\n        // Removed from configuration since ignite 2.3\n        Set<String> commPropsExcl = new HashSet<>();\n        commPropsExcl.add(\"discoveryStartupDelay\");\n        commPropsExcl.addAll(SPI_EXCLUDED_FIELDS);\n\n        metadata.put(TcpCommunicationSpi.class,\n            new MetadataInfo(commProps, commPropsDep, commPropsExcl));\n\n        Set<String> discoverySpiProps = new HashSet<>();\n        discoverySpiProps.add(\"ipFinder\");\n        discoverySpiProps.add(\"localAddress\");\n        discoverySpiProps.add(\"localPort\");\n        discoverySpiProps.add(\"localPortRange\");\n        discoverySpiProps.add(\"addressResolver\");\n        discoverySpiProps.add(\"socketTimeout\");\n        discoverySpiProps.add(\"ackTimeout\");\n        discoverySpiProps.add(\"maxAckTimeout\");\n        discoverySpiProps.add(\"networkTimeout\");\n        discoverySpiProps.add(\"joinTimeout\");\n        discoverySpiProps.add(\"threadPriority\");\n        // Removed since 2.0.\n        // discoverySpiProps.add(\"heartbeatFrequency\");\n        // discoverySpiProps.add(\"maxMissedHeartbeats\");\n        // discoverySpiProps.add(\"maxMissedClientHeartbeats\");\n        discoverySpiProps.add(\"topHistorySize\");\n        discoverySpiProps.add(\"listener\");\n        discoverySpiProps.add(\"dataExchange\");\n        discoverySpiProps.add(\"metricsProvider\");\n        discoverySpiProps.add(\"reconnectCount\");\n        discoverySpiProps.add(\"statisticsPrintFrequency\");\n        discoverySpiProps.add(\"ipFinderCleanFrequency\");\n        discoverySpiProps.add(\"authenticator\");\n        discoverySpiProps.add(\"forceServerMode\");\n        discoverySpiProps.add(\"clientReconnectDisabled\");\n        metadata.put(TcpDiscoverySpi.class, new MetadataInfo(discoverySpiProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> connectorProps = new HashSet<>();\n        connectorProps.add(\"jettyPath\");\n        connectorProps.add(\"host\");\n        connectorProps.add(\"port\");\n        connectorProps.add(\"portRange\");\n        connectorProps.add(\"idleQueryCursorTimeout\");\n        connectorProps.add(\"idleQueryCursorCheckFrequency\");\n        connectorProps.add(\"idleTimeout\");\n        connectorProps.add(\"receiveBufferSize\");\n        connectorProps.add(\"sendBufferSize\");\n        connectorProps.add(\"sendQueueLimit\");\n        connectorProps.add(\"directBuffer\");\n        connectorProps.add(\"noDelay\");\n        connectorProps.add(\"selectorCount\");\n        connectorProps.add(\"threadPoolSize\");\n        connectorProps.add(\"messageInterceptor\");\n        connectorProps.add(\"secretKey\");\n        connectorProps.add(\"sslEnabled\");\n        connectorProps.add(\"sslClientAuth\");\n        connectorProps.add(\"sslFactory\");\n        metadata.put(ConnectorConfiguration.class, new MetadataInfo(connectorProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> dataStorageProps = new HashSet<>();\n        dataStorageProps.add(\"pageSize\");\n        dataStorageProps.add(\"concurrencyLevel\");\n        dataStorageProps.add(\"systemRegionInitialSize\");\n        dataStorageProps.add(\"systemRegionMaxSize\");\n        dataStorageProps.add(\"defaultDataRegionConfiguration\");\n        dataStorageProps.add(\"dataRegionConfigurations\");\n        dataStorageProps.add(\"storagePath\");\n        dataStorageProps.add(\"checkpointFrequency\");\n        dataStorageProps.add(\"checkpointThreads\");\n        dataStorageProps.add(\"checkpointWriteOrder\");\n        dataStorageProps.add(\"walMode\");\n        dataStorageProps.add(\"walPath\");\n        dataStorageProps.add(\"walArchivePath\");\n        dataStorageProps.add(\"walSegments\");\n        dataStorageProps.add(\"walSegmentSize\");\n        dataStorageProps.add(\"walHistorySize\");\n        dataStorageProps.add(\"walBufferSize\");\n        dataStorageProps.add(\"walFlushFrequency\");\n        dataStorageProps.add(\"walFsyncDelayNanos\");\n        dataStorageProps.add(\"walRecordIteratorBufferSize\");\n        dataStorageProps.add(\"lockWaitTime\");\n        dataStorageProps.add(\"walThreadLocalBufferSize\");\n        dataStorageProps.add(\"metricsSubIntervalCount\");\n        dataStorageProps.add(\"metricsRateTimeInterval\");\n        dataStorageProps.add(\"fileIOFactory\");\n        dataStorageProps.add(\"walAutoArchiveAfterInactivity\");\n        dataStorageProps.add(\"metricsEnabled\");\n        dataStorageProps.add(\"alwaysWriteFullPages\");\n        dataStorageProps.add(\"writeThrottlingEnabled\");\n        dataStorageProps.add(\"walCompactionEnabled\");\n        metadata.put(DataStorageConfiguration.class, new MetadataInfo(dataStorageProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> dataRegionProps = new HashSet<>();\n        dataRegionProps.add(\"name\");\n        dataRegionProps.add(\"initialSize\");\n        dataRegionProps.add(\"maxSize\");\n        dataRegionProps.add(\"swapPath\");\n        dataRegionProps.add(\"checkpointPageBufferSize\");\n        dataRegionProps.add(\"pageEvictionMode\");\n        dataRegionProps.add(\"evictionThreshold\");\n        dataRegionProps.add(\"emptyPagesPoolSize\");\n        dataRegionProps.add(\"metricsSubIntervalCount\");\n        dataRegionProps.add(\"metricsRateTimeInterval\");\n        dataRegionProps.add(\"metricsEnabled\");\n        dataRegionProps.add(\"persistenceEnabled\");\n        metadata.put(DataRegionConfiguration.class, new MetadataInfo(dataRegionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> uriDeploymentProps = new HashSet<>();\n        uriDeploymentProps.add(\"uriList\");\n        uriDeploymentProps.add(\"temporaryDirectoryPath\");\n        uriDeploymentProps.add(\"scanners\");\n        uriDeploymentProps.add(\"listener\");\n        uriDeploymentProps.add(\"checkMd5\");\n        uriDeploymentProps.add(\"encodeUri\");\n        metadata.put(UriDeploymentSpi.class, new MetadataInfo(uriDeploymentProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> locDeploymentProps = new HashSet<>();\n        locDeploymentProps.add(\"listener\");\n        metadata.put(LocalDeploymentSpi.class, new MetadataInfo(locDeploymentProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> memoryEvtStorageProps = new HashSet<>();\n        memoryEvtStorageProps.add(\"expireAgeMs\");\n        memoryEvtStorageProps.add(\"expireCount\");\n        memoryEvtStorageProps.add(\"filter\");\n        metadata.put(MemoryEventStorageSpi.class, new MetadataInfo(memoryEvtStorageProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> alwaysFailoverProps = new HashSet<>();\n        alwaysFailoverProps.add(\"maximumFailoverAttempts\");\n        metadata.put(AlwaysFailoverSpi.class, new MetadataInfo(alwaysFailoverProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> jobStealingFailoverProps = new HashSet<>();\n        jobStealingFailoverProps.add(\"maximumFailoverAttempts\");\n        metadata.put(JobStealingFailoverSpi.class, new MetadataInfo(jobStealingFailoverProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> hadoopCfgProps = new HashSet<>();\n        hadoopCfgProps.add(\"mapReducePlanner\");\n        hadoopCfgProps.add(\"finishedJobInfoTtl\");\n        hadoopCfgProps.add(\"maxParallelTasks\");\n        hadoopCfgProps.add(\"maxTaskQueueSize\");\n        hadoopCfgProps.add(\"nativeLibraryNames\");\n        metadata.put(HadoopConfiguration.class, new MetadataInfo(hadoopCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> hadoopWeightMapReduceCfgProps = new HashSet<>();\n        hadoopWeightMapReduceCfgProps.add(\"localMapperWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"remoteMapperWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"localReducerWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"remoteReducerWeight\");\n        hadoopWeightMapReduceCfgProps.add(\"preferLocalReducerThresholdWeight\");\n        metadata.put(IgniteHadoopWeightedMapReducePlanner.class,\n            new MetadataInfo(hadoopWeightMapReduceCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> weightedRndLoadBalancingProps = new HashSet<>();\n        weightedRndLoadBalancingProps.add(\"nodeWeight\");\n        weightedRndLoadBalancingProps.add(\"useWeights\");\n        metadata.put(WeightedRandomLoadBalancingSpi.class,\n            new MetadataInfo(weightedRndLoadBalancingProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> adaptiveLoadBalancingProps = new HashSet<>();\n        adaptiveLoadBalancingProps.add(\"loadProbe\");\n        metadata.put(AdaptiveLoadBalancingSpi.class,\n            new MetadataInfo(adaptiveLoadBalancingProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> roundRobinLoadBalancingProps = new HashSet<>();\n        roundRobinLoadBalancingProps.add(\"perTask\");\n        metadata.put(RoundRobinLoadBalancingSpi.class,\n            new MetadataInfo(roundRobinLoadBalancingProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> jobCntProbeProps = new HashSet<>();\n        jobCntProbeProps.add(\"useAverage\");\n        metadata.put(AdaptiveJobCountLoadProbe.class, new MetadataInfo(jobCntProbeProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> cpuLoadProbeProps = new HashSet<>();\n        cpuLoadProbeProps.add(\"useAverage\");\n        cpuLoadProbeProps.add(\"useProcessors\");\n        cpuLoadProbeProps.add(\"processorCoefficient\");\n        metadata.put(AdaptiveCpuLoadProbe.class, new MetadataInfo(cpuLoadProbeProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> adaptiveTimeProbeProps = new HashSet<>();\n        adaptiveTimeProbeProps.add(\"useAverage\");\n        metadata.put(AdaptiveProcessingTimeLoadProbe.class,\n            new MetadataInfo(adaptiveTimeProbeProps, EMPTY_FIELDS, SPI_EXCLUDED_FIELDS));\n\n        Set<String> optimizedMarshallerProps = new HashSet<>();\n        optimizedMarshallerProps.add(\"poolSize\");\n        optimizedMarshallerProps.add(\"requireSerializable\");\n\n        Set<String> optimizedMarshallerPropsExcl = new HashSet<>();\n        optimizedMarshallerPropsExcl.add(\"context\");\n\n        metadata.put(OptimizedMarshaller.class,\n            new MetadataInfo(optimizedMarshallerProps, EMPTY_FIELDS, optimizedMarshallerPropsExcl));\n\n        Set<String> memoryCfgProps = new HashSet<>();\n        memoryCfgProps.add(\"pageSize\");\n        memoryCfgProps.add(\"concurrencyLevel\");\n        memoryCfgProps.add(\"systemCacheInitialSize\");\n        memoryCfgProps.add(\"systemCacheMaxSize\");\n        memoryCfgProps.add(\"defaultMemoryPolicyName\");\n        memoryCfgProps.add(\"defaultMemoryPolicySize\");\n        memoryCfgProps.add(\"memoryPolicies\");\n        metadata.put(MemoryConfiguration.class, new MetadataInfo(EMPTY_FIELDS, memoryCfgProps, EMPTY_FIELDS));\n\n        Set<String> memoryPlcCfgProps = new HashSet<>();\n        memoryPlcCfgProps.add(\"name\");\n        memoryPlcCfgProps.add(\"initialSize\");\n        memoryPlcCfgProps.add(\"maxSize\");\n        memoryPlcCfgProps.add(\"swapFilePath\");\n        memoryPlcCfgProps.add(\"pageEvictionMode\");\n        memoryPlcCfgProps.add(\"evictionThreshold\");\n        memoryPlcCfgProps.add(\"emptyPagesPoolSize\");\n        memoryPlcCfgProps.add(\"subIntervals\");\n        memoryPlcCfgProps.add(\"rateTimeInterval\");\n        memoryPlcCfgProps.add(\"metricsEnabled\");\n        metadata.put(MemoryPolicyConfiguration.class, new MetadataInfo(EMPTY_FIELDS, memoryPlcCfgProps, EMPTY_FIELDS));\n\n        Set<String> odbcCfgProps = new HashSet<>();\n        odbcCfgProps.add(\"endpointAddress\");\n        odbcCfgProps.add(\"socketSendBufferSize\");\n        odbcCfgProps.add(\"socketReceiveBufferSize\");\n        odbcCfgProps.add(\"maxOpenCursors\");\n        odbcCfgProps.add(\"threadPoolSize\");\n        metadata.put(OdbcConfiguration.class, new MetadataInfo(EMPTY_FIELDS, odbcCfgProps, EMPTY_FIELDS));\n\n        Set<String> persistenceCfgProps = new HashSet<>();\n        persistenceCfgProps.add(\"persistentStorePath\");\n        persistenceCfgProps.add(\"metricsEnabled\");\n        persistenceCfgProps.add(\"alwaysWriteFullPages\");\n        persistenceCfgProps.add(\"checkpointingFrequency\");\n        persistenceCfgProps.add(\"checkpointingPageBufferSize\");\n        persistenceCfgProps.add(\"checkpointingThreads\");\n        persistenceCfgProps.add(\"walStorePath\");\n        persistenceCfgProps.add(\"walArchivePath\");\n        persistenceCfgProps.add(\"walSegments\");\n        persistenceCfgProps.add(\"walSegmentSize\");\n        persistenceCfgProps.add(\"walHistorySize\");\n        persistenceCfgProps.add(\"walFlushFrequency\");\n        persistenceCfgProps.add(\"walFsyncDelayNanos\");\n        persistenceCfgProps.add(\"walRecordIteratorBufferSize\");\n        persistenceCfgProps.add(\"lockWaitTime\");\n        persistenceCfgProps.add(\"rateTimeInterval\");\n        persistenceCfgProps.add(\"tlbSize\");\n        persistenceCfgProps.add(\"subIntervals\");\n        metadata.put(PersistentStoreConfiguration.class, new MetadataInfo(EMPTY_FIELDS, persistenceCfgProps, EMPTY_FIELDS));\n\n        Set<String> srvcCfgProps = new HashSet<>();\n        srvcCfgProps.add(\"name\");\n        srvcCfgProps.add(\"service\");\n        srvcCfgProps.add(\"maxPerNodeCount\");\n        srvcCfgProps.add(\"totalCount\");\n        // Field cache in model.\n        srvcCfgProps.add(\"cacheName\");\n        srvcCfgProps.add(\"affinityKey\");\n\n        Set<String> srvcCfgPropsExclude = new HashSet<>();\n        srvcCfgPropsExclude.add(\"nodeFilter\");\n\n        metadata.put(ServiceConfiguration.class, new MetadataInfo(srvcCfgProps, EMPTY_FIELDS, srvcCfgPropsExclude));\n\n        Set<String> sqlConnectorCfgProps = new HashSet<>();\n        sqlConnectorCfgProps.add(\"host\");\n        sqlConnectorCfgProps.add(\"port\");\n        sqlConnectorCfgProps.add(\"portRange\");\n        sqlConnectorCfgProps.add(\"socketSendBufferSize\");\n        sqlConnectorCfgProps.add(\"socketReceiveBufferSize\");\n        sqlConnectorCfgProps.add(\"maxOpenCursorsPerConnection\");\n        sqlConnectorCfgProps.add(\"threadPoolSize\");\n        sqlConnectorCfgProps.add(\"tcpNoDelay\");\n        metadata.put(SqlConnectorConfiguration.class, new MetadataInfo(EMPTY_FIELDS, sqlConnectorCfgProps, EMPTY_FIELDS));\n\n        Set<String> sslCfgProps = new HashSet<>();\n        sslCfgProps.add(\"keyAlgorithm\");\n        sslCfgProps.add(\"keyStoreFilePath\");\n        // Only on code generation.\n        sslCfgProps.add(\"keyStorePassword\");\n        sslCfgProps.add(\"keyStoreType\");\n        sslCfgProps.add(\"protocol\");\n        sslCfgProps.add(\"trustManagers\");\n        sslCfgProps.add(\"trustStoreFilePath\");\n        // Only on code generation.\n        sslCfgProps.add(\"trustStorePassword\");\n        sslCfgProps.add(\"trustStoreType\");\n        sslCfgProps.add(\"cipherSuites\");\n        sslCfgProps.add(\"protocols\");\n        metadata.put(SslContextFactory.class, new MetadataInfo(sslCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> executorProps = new HashSet<>();\n        executorProps.add(\"name\");\n        executorProps.add(\"size\");\n        metadata.put(ExecutorConfiguration.class, new MetadataInfo(executorProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> transactionCfgProps = new HashSet<>();\n        transactionCfgProps.add(\"defaultTxConcurrency\");\n        transactionCfgProps.add(\"defaultTxIsolation\");\n        transactionCfgProps.add(\"defaultTxTimeout\");\n        transactionCfgProps.add(\"pessimisticTxLogLinger\");\n        transactionCfgProps.add(\"pessimisticTxLogSize\");\n        transactionCfgProps.add(\"txManagerFactory\");\n        metadata.put(TransactionConfiguration.class, new MetadataInfo(transactionCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        // Cache configuration.\n\n        Set<String> cacheCfgProps = new HashSet<>();\n        cacheCfgProps.add(\"name\");\n        cacheCfgProps.add(\"groupName\");\n        cacheCfgProps.add(\"cacheMode\");\n        cacheCfgProps.add(\"atomicityMode\");\n        cacheCfgProps.add(\"backups\");\n        cacheCfgProps.add(\"partitionLossPolicy\");\n        cacheCfgProps.add(\"readFromBackup\");\n        cacheCfgProps.add(\"copyOnRead\");\n        cacheCfgProps.add(\"invalidate\");\n        cacheCfgProps.add(\"affinityMapper\");\n        cacheCfgProps.add(\"topologyValidator\");\n        cacheCfgProps.add(\"maxConcurrentAsyncOperations\");\n        cacheCfgProps.add(\"defaultLockTimeout\");\n        cacheCfgProps.add(\"writeSynchronizationMode\");\n        cacheCfgProps.add(\"onheapCacheEnabled\");\n        cacheCfgProps.add(\"dataRegionName\");\n        // Removed since 2.0.\n        // cacheCfgProps.add(\"memoryMode\");\n        // cacheCfgProps.add(\"offHeapMode\");\n        // cacheCfgProps.add(\"offHeapMaxMemory\");\n        cacheCfgProps.add(\"evictionPolicyFactory\");\n        cacheCfgProps.add(\"evictionFilter\");\n        // Removed since 2.0.\n        // cacheCfgProps.add(\"startSize\");\n        // cacheCfgProps.add(\"swapEnabled\");\n        cacheCfgProps.add(\"nearConfiguration\");\n        cacheCfgProps.add(\"sqlSchema\");\n        // Removed since 2.0.\n        // cacheCfgProps.add(\"sqlOnheapRowCacheSize\");\n        cacheCfgProps.add(\"queryDetailMetricsSize\");\n        cacheCfgProps.add(\"sqlFunctionClasses\");\n        // Removed since 2.0\n        // cacheCfgProps.add(\"snapshotableIndex\");\n        cacheCfgProps.add(\"sqlEscapeAll\");\n        cacheCfgProps.add(\"queryParallelism\");\n        cacheCfgProps.add(\"rebalanceMode\");\n        cacheCfgProps.add(\"rebalanceBatchSize\");\n        cacheCfgProps.add(\"rebalanceBatchesPrefetchCount\");\n        cacheCfgProps.add(\"rebalanceOrder\");\n        cacheCfgProps.add(\"rebalanceDelay\");\n        cacheCfgProps.add(\"rebalanceTimeout\");\n        cacheCfgProps.add(\"rebalanceThrottle\");\n        cacheCfgProps.add(\"statisticsEnabled\");\n        cacheCfgProps.add(\"managementEnabled\");\n        cacheCfgProps.add(\"cacheStoreFactory\");\n        cacheCfgProps.add(\"storeKeepBinary\");\n        cacheCfgProps.add(\"loadPreviousValue\");\n        cacheCfgProps.add(\"readThrough\");\n        cacheCfgProps.add(\"writeThrough\");\n        cacheCfgProps.add(\"writeBehindEnabled\");\n        cacheCfgProps.add(\"writeBehindBatchSize\");\n        cacheCfgProps.add(\"writeBehindFlushSize\");\n        cacheCfgProps.add(\"writeBehindFlushFrequency\");\n        cacheCfgProps.add(\"writeBehindFlushThreadCount\");\n        cacheCfgProps.add(\"writeBehindCoalescing\");\n        cacheCfgProps.add(\"indexedTypes\");\n        cacheCfgProps.add(\"queryEntities\");\n        cacheCfgProps.add(\"pluginConfigurations\");\n        cacheCfgProps.add(\"cacheWriterFactory\");\n        cacheCfgProps.add(\"cacheLoaderFactory\");\n        cacheCfgProps.add(\"expiryPolicyFactory\");\n        cacheCfgProps.add(\"storeConcurrentLoadAllThreshold\");\n        cacheCfgProps.add(\"sqlIndexMaxInlineSize\");\n        cacheCfgProps.add(\"sqlOnheapCacheEnabled\");\n        cacheCfgProps.add(\"sqlOnheapCacheMaxSize\");\n        cacheCfgProps.add(\"diskPageCompression\");\n        cacheCfgProps.add(\"diskPageCompressionLevel\");\n        cacheCfgProps.add(\"interceptor\");\n        cacheCfgProps.add(\"storeByValue\");\n        cacheCfgProps.add(\"eagerTtl\");\n        cacheCfgProps.add(\"encryptionEnabled\");\n        cacheCfgProps.add(\"eventsDisabled\");\n        cacheCfgProps.add(\"maxQueryIteratorsCount\");\n        cacheCfgProps.add(\"keyConfiguration\");\n        cacheCfgProps.add(\"cacheStoreSessionListenerFactories\");\n        cacheCfgProps.add(\"affinity\");\n\n        Set<String> cacheCfgPropsDep = new HashSet<>();\n        // Removed since 2.0.\n        // cacheCfgPropsDep.add(\"atomicWriteOrderMode\");\n        cacheCfgPropsDep.add(\"memoryPolicyName\");\n        cacheCfgPropsDep.add(\"longQueryWarningTimeout\");\n        cacheCfgPropsDep.add(\"rebalanceThreadPoolSize\");\n        cacheCfgPropsDep.add(\"transactionManagerLookupClassName\");\n        cacheCfgPropsDep.add(\"evictionPolicy\");\n\n        Set<String> cacheCfgPropsExcl = new HashSet<>();\n        cacheCfgPropsExcl.add(\"nodeFilter\");\n        cacheCfgPropsExcl.add(\"types\");\n\n        metadata.put(CacheConfiguration.class, new MetadataInfo(cacheCfgProps, cacheCfgPropsDep, cacheCfgPropsExcl));\n\n        Set<String> rendezvousAffinityProps = new HashSet<>();\n        rendezvousAffinityProps.add(\"partitions\");\n        rendezvousAffinityProps.add(\"affinityBackupFilter\");\n        rendezvousAffinityProps.add(\"excludeNeighbors\");\n        metadata.put(RendezvousAffinityFunction.class, new MetadataInfo(rendezvousAffinityProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> nearCfgProps = new HashSet<>();\n        nearCfgProps.add(\"nearStartSize\");\n        nearCfgProps.add(\"nearEvictionPolicyFactory\");\n\n        Set<String> nearCfgPropsDep = new HashSet<>();\n        nearCfgPropsDep.add(\"nearEvictionPolicy\");\n\n        metadata.put(NearCacheConfiguration.class, new MetadataInfo(nearCfgProps, nearCfgPropsDep, EMPTY_FIELDS));\n\n        Set<String> jdbcPojoStoreProps = new HashSet<>();\n        // Only setter for dataSource field.\n        // jdbcPojoStoreProps.add(\"dataSourceBean\");\n        jdbcPojoStoreProps.add(\"dialect\");\n        jdbcPojoStoreProps.add(\"batchSize\");\n        jdbcPojoStoreProps.add(\"maximumPoolSize\");\n        jdbcPojoStoreProps.add(\"maximumWriteAttempts\");\n        jdbcPojoStoreProps.add(\"parallelLoadCacheMinimumThreshold\");\n        jdbcPojoStoreProps.add(\"hasher\");\n        jdbcPojoStoreProps.add(\"transformer\");\n        jdbcPojoStoreProps.add(\"sqlEscapeAll\");\n\n        // Configured via dataSource property.\n        Set<String> jdbcPojoStorePropsExcl = new HashSet<>();\n        jdbcPojoStorePropsExcl.add(\"dataSourceBean\");\n        jdbcPojoStorePropsExcl.add(\"dataSourceFactory\");\n\n        metadata.put(CacheJdbcPojoStoreFactory.class, new MetadataInfo(jdbcPojoStoreProps, EMPTY_FIELDS,\n            jdbcPojoStorePropsExcl));\n\n        Set<String> jdbcBlobStoreProps = new HashSet<>();\n        jdbcBlobStoreProps.add(\"connectionUrl\");\n        jdbcBlobStoreProps.add(\"user\");\n        // Only setter for dataSource.\n        // jdbcBlobStoreProps.add(\"dataSourceBean\");\n        // jdbcBlobStoreProps.add(\"dialect\");\n        jdbcBlobStoreProps.add(\"initSchema\");\n        jdbcBlobStoreProps.add(\"createTableQuery\");\n        jdbcBlobStoreProps.add(\"loadQuery\");\n        jdbcBlobStoreProps.add(\"insertQuery\");\n        jdbcBlobStoreProps.add(\"updateQuery\");\n        jdbcBlobStoreProps.add(\"deleteQuery\");\n        metadata.put(CacheJdbcBlobStore.class, new MetadataInfo(jdbcBlobStoreProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> hibernateBlobStoreProps = new HashSet<>();\n        hibernateBlobStoreProps.add(\"hibernateProperties\");\n        metadata.put(CacheHibernateBlobStore.class, new MetadataInfo(hibernateBlobStoreProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> igfsCfgProps = new HashSet<>();\n        igfsCfgProps.add(\"name\");\n        igfsCfgProps.add(\"defaultMode\");\n        // Removed since 2.0.\n        // igfsCfgProps.add(\"dualModeMaxPendingPutsSize\");\n        // igfsCfgProps.add(\"dualModePutExecutorService\");\n        // igfsCfgProps.add(\"dualModePutExecutorServiceShutdown\");\n        igfsCfgProps.add(\"fragmentizerEnabled\");\n        igfsCfgProps.add(\"fragmentizerConcurrentFiles\");\n        igfsCfgProps.add(\"fragmentizerThrottlingBlockLength\");\n        igfsCfgProps.add(\"fragmentizerThrottlingDelay\");\n        igfsCfgProps.add(\"ipcEndpointEnabled\");\n        igfsCfgProps.add(\"ipcEndpointConfiguration\");\n        igfsCfgProps.add(\"blockSize\");\n        // streamBufferSize field in model.\n        igfsCfgProps.add(\"bufferSize\");\n        // Removed since 2.0.\n        // igfsCfgProps.add(\"streamBufferSize\");\n        // igfsCfgProps.add(\"maxSpaceSize\");\n        igfsCfgProps.add(\"maximumTaskRangeLength\");\n        igfsCfgProps.add(\"managementPort\");\n        igfsCfgProps.add(\"perNodeBatchSize\");\n        igfsCfgProps.add(\"perNodeParallelBatchCount\");\n        igfsCfgProps.add(\"prefetchBlocks\");\n        igfsCfgProps.add(\"sequentialReadsBeforePrefetch\");\n        // Removed since 2.0.\n        // igfsCfgProps.add(\"trashPurgeTimeout\");\n        igfsCfgProps.add(\"colocateMetadata\");\n        igfsCfgProps.add(\"relaxedConsistency\");\n        igfsCfgProps.add(\"updateFileLengthOnFlush\");\n        igfsCfgProps.add(\"pathModes\");\n        igfsCfgProps.add(\"secondaryFileSystem\");\n\n        Set<String> igfsCfgPropsExclude = new HashSet<>();\n        igfsCfgPropsExclude.add(\"dataCacheConfiguration\");\n        igfsCfgPropsExclude.add(\"metaCacheConfiguration\");\n\n        metadata.put(FileSystemConfiguration.class, new MetadataInfo(igfsCfgProps, EMPTY_FIELDS, igfsCfgPropsExclude));\n\n        Set<String> igfsBlocMapperProps = new HashSet<>();\n        igfsBlocMapperProps.add(\"groupSize\");\n\n        metadata.put(IgfsGroupDataBlocksKeyMapper.class, new MetadataInfo(igfsBlocMapperProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> secHadoopIgfsCfgProps = new HashSet<>();\n        secHadoopIgfsCfgProps.add(\"defaultUserName\");\n        secHadoopIgfsCfgProps.add(\"fileSystemFactory\");\n\n        metadata.put(IgniteHadoopIgfsSecondaryFileSystem.class, new MetadataInfo(secHadoopIgfsCfgProps, EMPTY_FIELDS,\n            EMPTY_FIELDS));\n\n        Set<String> cachingIgfsCfgProps = new HashSet<>();\n        cachingIgfsCfgProps.add(\"uri\");\n        cachingIgfsCfgProps.add(\"configPaths\");\n        cachingIgfsCfgProps.add(\"userNameMapper\");\n\n        metadata.put(CachingHadoopFileSystemFactory.class, new MetadataInfo(cachingIgfsCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> kerberosIgfsCfgProps = new HashSet<>();\n        kerberosIgfsCfgProps.add(\"uri\");\n        kerberosIgfsCfgProps.add(\"configPaths\");\n        kerberosIgfsCfgProps.add(\"userNameMapper\");\n        kerberosIgfsCfgProps.add(\"keyTab\");\n        kerberosIgfsCfgProps.add(\"keyTabPrincipal\");\n        kerberosIgfsCfgProps.add(\"reloginInterval\");\n\n        metadata.put(KerberosHadoopFileSystemFactory.class, new MetadataInfo(kerberosIgfsCfgProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> chainedIgfsUsrNameMapperProps = new HashSet<>();\n        chainedIgfsUsrNameMapperProps.add(\"mappers\");\n\n        metadata.put(ChainedUserNameMapper.class, new MetadataInfo(chainedIgfsUsrNameMapperProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> basicIgfsUsrNameMapperProps = new HashSet<>();\n        basicIgfsUsrNameMapperProps.add(\"defaultUserName\");\n        basicIgfsUsrNameMapperProps.add(\"useDefaultUserName\");\n        basicIgfsUsrNameMapperProps.add(\"mappings\");\n\n        metadata.put(BasicUserNameMapper.class, new MetadataInfo(basicIgfsUsrNameMapperProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> kerberosIgfsUsrNameMapperProps = new HashSet<>();\n        kerberosIgfsUsrNameMapperProps.add(\"instance\");\n        kerberosIgfsUsrNameMapperProps.add(\"realm\");\n\n        metadata.put(KerberosUserNameMapper.class, new MetadataInfo(kerberosIgfsUsrNameMapperProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> ipcEndpointProps = new HashSet<>();\n        ipcEndpointProps.add(\"type\");\n        ipcEndpointProps.add(\"host\");\n        ipcEndpointProps.add(\"port\");\n        ipcEndpointProps.add(\"memorySize\");\n        ipcEndpointProps.add(\"threadCount\");\n        ipcEndpointProps.add(\"tokenDirectoryPath\");\n        metadata.put(IgfsIpcEndpointConfiguration.class, new MetadataInfo(ipcEndpointProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> qryEntityProps = new HashSet<>();\n        qryEntityProps.add(\"keyType\");\n        qryEntityProps.add(\"valueType\");\n        qryEntityProps.add(\"aliases\");\n        qryEntityProps.add(\"fields\");\n        qryEntityProps.add(\"indexes\");\n        qryEntityProps.add(\"tableName\");\n        qryEntityProps.add(\"keyFieldName\");\n        qryEntityProps.add(\"valueFieldName\");\n        qryEntityProps.add(\"keyFields\");\n        metadata.put(QueryEntity.class, new MetadataInfo(qryEntityProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> qryIdxProps = new HashSet<>();\n        qryIdxProps.add(\"name\");\n        qryIdxProps.add(\"indexType\");\n        qryIdxProps.add(\"fields\");\n\n        Set<String> qryIdxPropsExcl = new HashSet<>();\n        qryIdxPropsExcl.add(\"fieldNames\");\n\n        metadata.put(QueryIndex.class, new MetadataInfo(qryIdxProps, EMPTY_FIELDS, qryIdxPropsExcl));\n\n        Set<String> jdbcTypeProps = new HashSet<>();\n        jdbcTypeProps.add(\"cacheName\");\n        jdbcTypeProps.add(\"keyType\");\n        jdbcTypeProps.add(\"valueType\");\n        jdbcTypeProps.add(\"databaseSchema\");\n        jdbcTypeProps.add(\"databaseTable\");\n        jdbcTypeProps.add(\"keyFields\");\n        jdbcTypeProps.add(\"valueFields\");\n\n        metadata.put(JdbcType.class, new MetadataInfo(jdbcTypeProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> sorterEvictionProps = new HashSet<>();\n        sorterEvictionProps.add(\"batchSize\");\n        sorterEvictionProps.add(\"maxMemorySize\");\n        sorterEvictionProps.add(\"maxSize\");\n        metadata.put(SortedEvictionPolicy.class, new MetadataInfo(sorterEvictionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> lruEvictionProps = new HashSet<>();\n        lruEvictionProps.add(\"batchSize\");\n        lruEvictionProps.add(\"maxMemorySize\");\n        lruEvictionProps.add(\"maxSize\");\n        metadata.put(LruEvictionPolicy.class, new MetadataInfo(lruEvictionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n\n        Set<String> fifoEvictionProps = new HashSet<>();\n        fifoEvictionProps.add(\"batchSize\");\n        fifoEvictionProps.add(\"maxMemorySize\");\n        fifoEvictionProps.add(\"maxSize\");\n        metadata.put(FifoEvictionPolicy.class, new MetadataInfo(fifoEvictionProps, EMPTY_FIELDS, EMPTY_FIELDS));\n    }"
        ]
    ],
    "567a8750ee0d4003fa0a387021b34b95b93184c5": [
        [
            "PagesWriteThrottle::onMarkDirty(boolean)",
            "  81  \n  82  \n  83  \n  84  \n  85  \n  86  \n  87  \n  88 -\n  89  \n  90  \n  91  \n  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99  \n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131 -\n 132 -\n 133  ",
            "    /** {@inheritDoc} */\n    @Override public void onMarkDirty(boolean isPageInCheckpoint) {\n        assert stateChecker.checkpointLockIsHeldByThread();\n\n        boolean shouldThrottle = false;\n\n        if (isPageInCheckpoint) {\n            int checkpointBufLimit = pageMemory.checkpointBufferPagesSize() * 2 / 3;\n\n            shouldThrottle = pageMemory.checkpointBufferPagesCount() > checkpointBufLimit;\n        }\n\n        if (!shouldThrottle && !throttleOnlyPagesInCheckpoint) {\n            AtomicInteger writtenPagesCntr = cpProgress.writtenPagesCounter();\n\n            if (writtenPagesCntr == null)\n                return; // Don't throttle if checkpoint is not running.\n\n            int cpWrittenPages = writtenPagesCntr.get();\n\n            int cpTotalPages = cpProgress.currentCheckpointPagesCount();\n\n            if (cpWrittenPages == cpTotalPages) {\n                // Checkpoint is already in fsync stage, increasing maximum ratio of dirty pages to 3/4\n                shouldThrottle = pageMemory.shouldThrottle(3.0 / 4);\n            } else {\n                double dirtyRatioThreshold = ((double)cpWrittenPages) / cpTotalPages;\n\n                // Starting with 0.05 to avoid throttle right after checkpoint start\n                // 7/12 is maximum ratio of dirty pages\n                dirtyRatioThreshold = (dirtyRatioThreshold * 0.95 + 0.05) * 7 / 12;\n\n                shouldThrottle = pageMemory.shouldThrottle(dirtyRatioThreshold);\n            }\n        }\n\n        AtomicInteger cntr = isPageInCheckpoint ? inCheckpointBackoffCntr : notInCheckpointBackoffCntr;\n\n        if (shouldThrottle) {\n            int throttleLevel = cntr.getAndIncrement();\n\n            long throttleParkTimeNs = (long) (STARTING_THROTTLE_NANOS * Math.pow(BACKOFF_RATIO, throttleLevel));\n\n            if (throttleParkTimeNs > LOGGING_THRESHOLD) {\n                U.warn(log, \"Parking thread=\" + Thread.currentThread().getName()\n                    + \" for timeout(ms)=\" + (throttleParkTimeNs / 1_000_000));\n            }\n\n            LockSupport.parkNanos(throttleParkTimeNs);\n        }\n        else\n            cntr.set(0);\n    }",
            "  92  \n  93  \n  94  \n  95  \n  96  \n  97  \n  98  \n  99 +\n 100  \n 101  \n 102  \n 103  \n 104  \n 105  \n 106  \n 107  \n 108  \n 109  \n 110  \n 111  \n 112  \n 113  \n 114  \n 115  \n 116  \n 117  \n 118  \n 119  \n 120  \n 121  \n 122  \n 123  \n 124  \n 125  \n 126  \n 127  \n 128  \n 129  \n 130  \n 131  \n 132  \n 133  \n 134  \n 135  \n 136  \n 137  \n 138  \n 139  \n 140 +\n 141 +\n 142 +\n 143  \n 144  \n 145 +\n 146 +\n 147 +\n 148 +\n 149 +\n 150 +\n 151 +\n 152 +\n 153  ",
            "    /** {@inheritDoc} */\n    @Override public void onMarkDirty(boolean isPageInCheckpoint) {\n        assert stateChecker.checkpointLockIsHeldByThread();\n\n        boolean shouldThrottle = false;\n\n        if (isPageInCheckpoint) {\n            int checkpointBufLimit = (int)(pageMemory.checkpointBufferPagesSize() * CP_BUF_FILL_THRESHOLD);\n\n            shouldThrottle = pageMemory.checkpointBufferPagesCount() > checkpointBufLimit;\n        }\n\n        if (!shouldThrottle && !throttleOnlyPagesInCheckpoint) {\n            AtomicInteger writtenPagesCntr = cpProgress.writtenPagesCounter();\n\n            if (writtenPagesCntr == null)\n                return; // Don't throttle if checkpoint is not running.\n\n            int cpWrittenPages = writtenPagesCntr.get();\n\n            int cpTotalPages = cpProgress.currentCheckpointPagesCount();\n\n            if (cpWrittenPages == cpTotalPages) {\n                // Checkpoint is already in fsync stage, increasing maximum ratio of dirty pages to 3/4\n                shouldThrottle = pageMemory.shouldThrottle(3.0 / 4);\n            } else {\n                double dirtyRatioThreshold = ((double)cpWrittenPages) / cpTotalPages;\n\n                // Starting with 0.05 to avoid throttle right after checkpoint start\n                // 7/12 is maximum ratio of dirty pages\n                dirtyRatioThreshold = (dirtyRatioThreshold * 0.95 + 0.05) * 7 / 12;\n\n                shouldThrottle = pageMemory.shouldThrottle(dirtyRatioThreshold);\n            }\n        }\n\n        AtomicInteger cntr = isPageInCheckpoint ? inCheckpointBackoffCntr : notInCheckpointBackoffCntr;\n\n        if (shouldThrottle) {\n            int throttleLevel = cntr.getAndIncrement();\n\n            long throttleParkTimeNs = (long) (STARTING_THROTTLE_NANOS * Math.pow(BACKOFF_RATIO, throttleLevel));\n\n            if (throttleParkTimeNs > LOGGING_THRESHOLD) {\n                U.warn(log, \"Parking thread=\" + Thread.currentThread().getName()\n                    + \" for timeout(ms)=\" + (throttleParkTimeNs / 1_000_000));\n            }\n\n            if (isPageInCheckpoint)\n                parkThrds.add(Thread.currentThread());\n\n            LockSupport.parkNanos(throttleParkTimeNs);\n        }\n        else {\n            int oldCntr = cntr.getAndSet(0);\n\n            if (isPageInCheckpoint && oldCntr != 0) {\n                parkThrds.forEach(LockSupport::unpark);\n                parkThrds.clear();\n            }\n        }\n    }"
        ]
    ],
    "829dc1f240c07731a1ee98ae18c80ea6074dc6c4": [
        [
            "PageMemoryImpl::refreshOutdatedPage(Segment,int,long,boolean)",
            " 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854 -\n 855 -\n 856  \n 857 -\n 858 -\n 859  \n 860  \n 861  ",
            "    /**\n     * @param seg Segment.\n     * @param grpId Cache group ID.\n     * @param pageId Page ID.\n     * @param rmv {@code True} if page should be removed.\n     * @return Relative pointer to refreshed page.\n     */\n    private long refreshOutdatedPage(Segment seg, int grpId, long pageId, boolean rmv) {\n        assert seg.writeLock().isHeldByCurrentThread();\n\n        int tag = seg.partGeneration(grpId, PageIdUtils.partId(pageId));\n\n        long relPtr = seg.loadedPages.refresh(grpId, PageIdUtils.effectivePageId(pageId), tag);\n\n        long absPtr = seg.absolute(relPtr);\n\n        GridUnsafe.setMemory(absPtr + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n        PageHeader.dirty(absPtr, false);\n\n        long tmpBufPtr = PageHeader.tempBufferPointer(absPtr);\n\n        if (tmpBufPtr != INVALID_REL_PTR) {\n            GridUnsafe.setMemory(checkpointPool.absolute(tmpBufPtr) + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n            PageHeader.tempBufferPointer(absPtr, INVALID_REL_PTR);\n\n            // We pinned the page when allocated the temp buffer, release it now.\n            PageHeader.releasePage(absPtr);\n\n            checkpointPool.releaseFreePage(tmpBufPtr);\n        }\n\n        if (rmv)\n            seg.loadedPages.remove(grpId, PageIdUtils.effectivePageId(pageId));\n\n        if (seg.segCheckpointPages != null)\n            seg.segCheckpointPages.remove(new FullPageId(pageId, grpId));\n\n        if (seg.dirtyPages != null)\n            seg.dirtyPages.remove(new FullPageId(pageId, grpId));\n\n        return relPtr;\n    }",
            " 818  \n 819  \n 820  \n 821  \n 822  \n 823  \n 824  \n 825  \n 826  \n 827  \n 828  \n 829  \n 830  \n 831  \n 832  \n 833  \n 834  \n 835  \n 836  \n 837  \n 838  \n 839  \n 840  \n 841  \n 842  \n 843  \n 844  \n 845  \n 846  \n 847  \n 848  \n 849  \n 850  \n 851  \n 852  \n 853  \n 854 +\n 855  \n 856 +\n 857 +\n 858 +\n 859 +\n 860 +\n 861 +\n 862 +\n 863  \n 864  \n 865  ",
            "    /**\n     * @param seg Segment.\n     * @param grpId Cache group ID.\n     * @param pageId Page ID.\n     * @param rmv {@code True} if page should be removed.\n     * @return Relative pointer to refreshed page.\n     */\n    private long refreshOutdatedPage(Segment seg, int grpId, long pageId, boolean rmv) {\n        assert seg.writeLock().isHeldByCurrentThread();\n\n        int tag = seg.partGeneration(grpId, PageIdUtils.partId(pageId));\n\n        long relPtr = seg.loadedPages.refresh(grpId, PageIdUtils.effectivePageId(pageId), tag);\n\n        long absPtr = seg.absolute(relPtr);\n\n        GridUnsafe.setMemory(absPtr + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n        PageHeader.dirty(absPtr, false);\n\n        long tmpBufPtr = PageHeader.tempBufferPointer(absPtr);\n\n        if (tmpBufPtr != INVALID_REL_PTR) {\n            GridUnsafe.setMemory(checkpointPool.absolute(tmpBufPtr) + PAGE_OVERHEAD, pageSize(), (byte)0);\n\n            PageHeader.tempBufferPointer(absPtr, INVALID_REL_PTR);\n\n            // We pinned the page when allocated the temp buffer, release it now.\n            PageHeader.releasePage(absPtr);\n\n            checkpointPool.releaseFreePage(tmpBufPtr);\n        }\n\n        if (rmv)\n            seg.loadedPages.remove(grpId, PageIdUtils.effectivePageId(pageId));\n\n        Collection<FullPageId> cpPages = seg.segCheckpointPages;\n\n        if (cpPages != null)\n            cpPages.remove(new FullPageId(pageId, grpId));\n\n        Collection<FullPageId> dirtyPages = seg.dirtyPages;\n\n        if (dirtyPages != null)\n            dirtyPages.remove(new FullPageId(pageId, grpId));\n\n        return relPtr;\n    }"
        ]
    ]
}